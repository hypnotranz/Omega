/**
 * OmegaLLM - Complete Code Dump
 * Generated: 2026-01-27
 * 
 * This file contains ALL TypeScript source files concatenated together.
 * Each section is prefixed with the file path.
 */


// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/adapters/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./logging";
export * from "./replay";
export * from "./llm-adapter";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/adapters/llm-adapter.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * LLM Adapters for OmegaLLM Oracle
 *
 * Provides concrete implementations of OracleAdapter that connect to real LLMs.
 * Reads API keys from environment variables - NEVER hardcode keys.
 *
 * Usage:
 *   import { createAnthropicOracle, createOpenAIOracle } from "./adapters/llm-adapter";
 *
 *   // Set ANTHROPIC_API_KEY or OPENAI_API_KEY in environment
 *   const oracle = createAnthropicOracle();
 *   const runtime = new RuntimeImpl(oracle, snapshots, receipts, commitAdapter);
 */

import type { CommitAdapter } from "../core/effects/runtimeImpl";
import type { LegacyOracleAdapter } from "../core/oracle/legacyAdapter";
import type { Val } from "../core/eval/values";
import type { OracleAdapter } from "../core/oracle/adapter";
import { LegacyOracleWrapper } from "../core/oracle/legacyAdapter";

// ============================================================
// Value Conversion Helpers
// ============================================================

/** Convert Omega Val to a prompt string for the LLM */
function valToPrompt(v: Val): string {
  switch (v.tag) {
    case "Str": return v.s;
    case "Num": return String(v.n);
    case "Bool": return v.b ? "true" : "false";
    case "Unit": return "";
    case "Sym": return v.name;
    case "Vector": return JSON.stringify(v.items.map(valToPrompt));
    case "Map": {
      const obj: Record<string, any> = {};
      for (const [k, val] of v.entries) {
        const key = k.tag === "Str" ? k.s : k.tag === "Sym" ? k.name : JSON.stringify(k);
        obj[key] = valToPrompt(val);
      }
      return JSON.stringify(obj);
    }
    default:
      return JSON.stringify(v);
  }
}

/** Parse LLM response text back to Val */
function responseToVal(text: string): Val {
  // Try to parse as JSON first
  try {
    const parsed = JSON.parse(text);
    return jsToVal(parsed);
  } catch {
    // Return as string
    return { tag: "Str", s: text };
  }
}

/** Convert JavaScript value to Val */
function jsToVal(x: unknown): Val {
  if (x === null || x === undefined) return { tag: "Unit" };
  if (typeof x === "number") return { tag: "Num", n: x };
  if (typeof x === "boolean") return { tag: "Bool", b: x };
  if (typeof x === "string") return { tag: "Str", s: x };
  if (Array.isArray(x)) return { tag: "Vector", items: x.map(jsToVal) };
  if (typeof x === "object") {
    const entries: Array<[Val, Val]> = Object.entries(x).map(([k, v]) => [
      { tag: "Str", s: k } as Val,
      jsToVal(v)
    ]);
    return { tag: "Map", entries };
  }
  return { tag: "Str", s: String(x) };
}

// ============================================================
// Anthropic (Claude) Adapter
// ============================================================

export interface AnthropicConfig {
  apiKey?: string;     // defaults to ANTHROPIC_API_KEY env var
  model?: string;      // defaults to claude-sonnet-4-20250514
  maxTokens?: number;  // defaults to 1024
}

function createAnthropicLegacy(config: AnthropicConfig = {}): LegacyOracleAdapter {
  const apiKey = config.apiKey || process.env.ANTHROPIC_API_KEY;
  if (!apiKey) {
    throw new Error("ANTHROPIC_API_KEY environment variable not set");
  }

  const model = config.model || "claude-sonnet-4-20250514";
  const maxTokens = config.maxTokens || 1024;

  return {
    async infer(payload: Val, _ctxDigest: string): Promise<Val> {
      const prompt = valToPrompt(payload);

      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "x-api-key": apiKey,
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify({
          model,
          max_tokens: maxTokens,
          messages: [{ role: "user", content: prompt }]
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`Anthropic API error: ${response.status} ${error}`);
      }

      const data = await response.json() as any;

      // Extract text from response
      const text = data.content?.[0]?.text || "";
      return responseToVal(text);
    }
  };
}

export function createAnthropicOracle(config: AnthropicConfig = {}): OracleAdapter {
  return new LegacyOracleWrapper(createAnthropicLegacy(config));
}

// ============================================================
// OpenAI Adapter
// ============================================================

export interface OpenAIConfig {
  apiKey?: string;     // defaults to OPENAI_API_KEY env var
  model?: string;      // defaults to gpt-4-turbo-preview
  maxTokens?: number;  // defaults to 1024
  baseUrl?: string;    // for OpenAI-compatible APIs
}

function createOpenAILegacy(config: OpenAIConfig = {}): LegacyOracleAdapter {
  const apiKey = config.apiKey || process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error("OPENAI_API_KEY environment variable not set");
  }

  const model = config.model || "gpt-4-turbo-preview";
  const maxTokens = config.maxTokens || 1024;
  const baseUrl = config.baseUrl || "https://api.openai.com/v1";

  return {
    async infer(payload: Val, _ctxDigest: string): Promise<Val> {
      const prompt = valToPrompt(payload);

      const response = await fetch(`${baseUrl}/chat/completions`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model,
          max_tokens: maxTokens,
          messages: [{ role: "user", content: prompt }]
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI API error: ${response.status} ${error}`);
      }

      const data = await response.json() as any;

      // Extract text from response
      const text = data.choices?.[0]?.message?.content || "";
      return responseToVal(text);
    }
  };
}

export function createOpenAIOracle(config: OpenAIConfig = {}): OracleAdapter {
  return new LegacyOracleWrapper(createOpenAILegacy(config));
}

// ============================================================
// Commit Adapter (for side effects)
// ============================================================

export interface ConsoleCommitConfig {
  log?: boolean;  // whether to log commits
}

/** Simple commit adapter that logs to console */
export function createConsoleCommit(config: ConsoleCommitConfig = {}): CommitAdapter {
  const shouldLog = config.log ?? true;

  return {
    async commit(payload: Val, _ctxDigest: string): Promise<Val> {
      if (shouldLog) {
        console.log("[COMMIT]", valToPrompt(payload));
      }
      return { tag: "Unit" };
    }
  };
}

// ============================================================
// Auto-detect Oracle (tries env vars)
// ============================================================

/**
 * Create an Oracle adapter by auto-detecting available API keys.
 * Checks ANTHROPIC_API_KEY first, then OPENAI_API_KEY.
 */
export function createAutoOracle(): OracleAdapter {
  if (process.env.ANTHROPIC_API_KEY) {
    console.log("[Oracle] Using Anthropic Claude");
    return createAnthropicOracle();
  }
  if (process.env.OPENAI_API_KEY) {
    console.log("[Oracle] Using OpenAI");
    return createOpenAIOracle();
  }
  throw new Error(
    "No LLM API key found. Set ANTHROPIC_API_KEY or OPENAI_API_KEY environment variable."
  );
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/adapters/logging.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ClockPort } from "../ports/clock";
import type { OraclePort, OracleRequest, OracleResponse } from "../ports/oracle";
import type { RngPort } from "../ports/rng";
import type { ToolPort, ToolCall, ToolResult } from "../ports/tool";
import type { ExecContext } from "../ports/types";

function makeId(kind: string): string {
  const random = Math.random().toString(36).slice(2);
  return `${kind}:${Date.now()}:${random}`;
}

/**
 * Wrap oracle port with logging.
 */
export function loggingOracle(inner: OraclePort): OraclePort {
  return {
    async infer(req: OracleRequest, ctx: ExecContext): Promise<OracleResponse> {
      const id = makeId("oracle");
      const start = Date.now();
      try {
        const res = await inner.infer(req, ctx);
        ctx.trace.emit({
          tag: "E_OracleCall",
          id,
          durationMs: Date.now() - start,
        });
        return res;
      } catch (error) {
        ctx.trace.emit({
          tag: "E_OracleCall",
          id,
          durationMs: Date.now() - start,
        });
        throw error;
      }
    },
  };
}

/**
 * Wrap tool port with logging.
 */
export function loggingTool(inner: ToolPort): ToolPort {
  return {
    async call(call: ToolCall, ctx: ExecContext): Promise<ToolResult> {
      const id = makeId("tool");
      const start = Date.now();
      const res = await inner.call(call, ctx);
      ctx.trace.emit({
        tag: "E_ToolCall",
        id,
        tool: call.name,
        durationMs: Date.now() - start,
      });
      return res;
    },
  };
}

/**
 * Wrap clock port with logging.
 */
export function loggingClock(inner: ClockPort): ClockPort {
  return {
    nowMs(ctx: ExecContext): number {
      const value = inner.nowMs(ctx);
      const id = makeId("clock");
      ctx.trace.emit({ tag: "E_ClockRead", id, valueMs: value });
      return value;
    },
    async sleepMs(ms: number, ctx: ExecContext): Promise<void> {
      return inner.sleepMs(ms, ctx);
    },
  };
}

/**
 * Wrap RNG port with logging.
 */
export function loggingRng(inner: RngPort): RngPort {
  return {
    nextU32(ctx: ExecContext): number {
      const value = inner.nextU32(ctx);
      const id = makeId("rng");
      ctx.trace.emit({ tag: "E_RngRead", id, value });
      return value;
    },
    nextFloat(ctx: ExecContext): number {
      return inner.nextFloat(ctx);
    },
    nextInt(min: number, max: number, ctx: ExecContext): number {
      return inner.nextInt(min, max, ctx);
    },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/adapters/replay.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ClockPort } from "../ports/clock";
import type { OraclePort, OracleRequest, OracleResponse } from "../ports/oracle";
import type { RngPort } from "../ports/rng";
import type { ExecContext } from "../ports/types";

/**
 * Replay event log entry.
 */
export interface ReplayLogEntry {
  id: string;
  tag: string;
  request?: unknown;
  response?: unknown;
  value?: unknown;
}

/**
 * Replay log source.
 */
export interface ReplayLog {
  get(id: string): ReplayLogEntry | undefined;
  getByTag(tag: string): ReplayLogEntry[];
}

function takeEntry(entries: ReplayLogEntry[], index: { value: number }, kind: string): ReplayLogEntry {
  const entry = entries[index.value++];
  if (!entry) {
    throw new Error(`Replay log exhausted for ${kind}`);
  }
  return entry;
}

/**
 * Create replay oracle that returns logged responses.
 */
export function replayOracle(log: ReplayLog): OraclePort {
  const entries = log.getByTag("E_OracleCall");
  const index = { value: 0 };

  return {
    async infer(_req: OracleRequest, _ctx: ExecContext): Promise<OracleResponse> {
      const entry = takeEntry(entries, index, "oracle calls");
      if (entry.response === undefined) {
        throw new Error("Replay log entry missing oracle response");
      }
      return entry.response as OracleResponse;
    },
  };
}

/**
 * Create replay clock that returns logged times.
 */
export function replayClock(log: ReplayLog): ClockPort {
  const entries = log.getByTag("E_ClockRead");
  const index = { value: 0 };

  return {
    nowMs(_ctx: ExecContext): number {
      const entry = takeEntry(entries, index, "clock reads");
      if (entry.value === undefined) {
        throw new Error("Replay log entry missing clock value");
      }
      return entry.value as number;
    },
    async sleepMs(_ms: number, _ctx: ExecContext): Promise<void> {
      // No-op in replay mode
    },
  };
}

/**
 * Create replay RNG that returns logged values.
 */
export function replayRng(log: ReplayLog): RngPort {
  const entries = log.getByTag("E_RngRead");
  const index = { value: 0 };

  const take = (): number => {
    const entry = takeEntry(entries, index, "RNG reads");
    if (entry.value === undefined) {
      throw new Error("Replay log entry missing RNG value");
    }
    return entry.value as number;
  };

  return {
    nextU32(_ctx: ExecContext): number {
      return take();
    },
    nextFloat(ctx: ExecContext): number {
      const value = take();
      return value / 0xFFFFFFFF;
    },
    nextInt(min: number, max: number, _ctx: ExecContext): number {
      if (max <= min) {
        throw new Error("max must be greater than min");
      }
      return min + (take() % (max - min));
    },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/artifacts/cas.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-7.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

export type Hash = string;

export interface CAS {
  putJSON(x: unknown): Hash;
  getJSON(h: Hash): unknown;
  putText(s: string): Hash;
  getText(h: Hash): string;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/artifacts/hash.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import { createHash } from "node:crypto";

export type Hash = string;

/** Deterministic SHA-256 digest for text. */
export function sha256Text(s: string): Hash {
  return createHash("sha256").update(s, "utf8").digest("hex");
}

/** JSON replacer that handles BigInt. */
function jsonReplacer(_key: string, value: unknown): unknown {
  if (typeof value === "bigint") {
    return { __bigint__: value.toString() };
  }
  return value;
}

/** Deterministic SHA-256 digest for JSON (stable if JSON.stringify stable). */
export function sha256JSON(x: unknown): Hash {
  return sha256Text(JSON.stringify(x, jsonReplacer));
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/artifacts/registry.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Hash } from "./hash";

export type RegistryEntry = {
  name: string;
  time: number; // unix ms
};

export type Registry = {
  candidates: Record<Hash, RegistryEntry>;
  trusted: Record<Hash, RegistryEntry>;
  pointers: {
    defaultExpander?: Hash;
    defaultPolicy?: Hash;
  };
};

export function emptyRegistry(): Registry {
  return { candidates: {}, trusted: {}, pointers: {} };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/ast.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

export type Expr =
  | { tag: "Lit"; value: number | string | boolean | null }
  | { tag: "Var"; name: string }
  | { tag: "Lambda"; params: string[]; body: Expr }
  | { tag: "OracleLambda"; params: string[]; spec: Expr }  // oracle-lambda: first-class inference procedure
  | { tag: "If"; test: Expr; conseq: Expr; alt: Expr }
  | { tag: "Begin"; exprs: Expr[] }
  | { tag: "Define"; name: string; rhs: Expr }
  | { tag: "Set"; name: string; rhs: Expr }
  | { tag: "App"; fn: Expr; args: Expr[] }
  | { tag: "Quote"; datum: unknown }
  | { tag: "QuoteSyntax"; datum: unknown }
  | { tag: "Let"; bindings: Array<{ name: string; init: Expr }>; body: Expr }
  | { tag: "Letrec"; bindings: Array<{ name: string; init: Expr }>; body: Expr }
  | { tag: "Effect"; op: string; args: Expr[] }
  | { tag: "Handle"; body: Expr; handler: HandlerExpr }
  | { tag: "Match"; scrutinee: Expr; clauses: Array<{ pat: Pattern; body: Expr }> };

export type Pattern =
  | { tag: "PWild" }
  | { tag: "PVar"; name: string } // binder name (already internalized by lowering)
  | { tag: "PLit"; value: number | string | boolean | null }
  | { tag: "PVector"; items: Pattern[] };

export type HandlerExpr = {
  on: Array<{ op: string; params: string[]; k: string; body: Expr }>;
  ret?: { v: string; body: Expr };
  fin?: { body: Expr };
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/commit/commit.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/commit/commit.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Commit barrier with truth regime gating

import type { Profile, TruthRegime } from "../governance/profile";
import type { CapSet } from "../governance/caps";
import { capRequire } from "../governance/caps";
import type { Hash } from "../artifacts/hash";
import type { MeaningVal } from "../oracle/meaning";
import type { TestReport } from "../test/testRunner";

// =========================================================================
// Obligation Types
// =========================================================================

export type ObligationNone = { tag: "OblNone" };

export type ObligationTests = {
  tag: "OblTests";
  spec: unknown; // TestSpec
  passed?: boolean;
  report?: TestReport;
};

export type Obligation = ObligationNone | ObligationTests;

// =========================================================================
// Commit Gate
// =========================================================================

export type CommitGateResult = {
  ok: boolean;
  why?: string;
};

/**
 * Check if a Meaning can be committed under the given truth regime.
 *
 * - speculative: always allowed (no verification required)
 * - test-certified: requires obligation tests to be passed
 * - proof-certified: requires formal proof (stubbed for now)
 */
export function canCommitMeaning(profile: Profile, m: MeaningVal): CommitGateResult {
  // Speculative truth regime allows all commits
  if (profile.truth === "speculative") {
    return { ok: true };
  }

  // Test-certified and stricter require obligation discharge
  const obl = parseObligation(m.obligation);

  if (!obl) {
    return { ok: false, why: "missing obligation" };
  }

  if (obl.tag === "OblNone") {
    // No obligation specified - only allowed in speculative
    return { ok: false, why: "no obligation specified for non-speculative regime" };
  }

  if (obl.tag === "OblTests") {
    if (!obl.passed) {
      return { ok: false, why: "tests not marked passed" };
    }
    if (obl.report && !obl.report.passed) {
      return { ok: false, why: "test report indicates failure" };
    }
    return { ok: true };
  }

  return { ok: false, why: `unsupported obligation kind: ${(obl as Obligation).tag}` };
}

/**
 * Parse an obligation from the Meaning's obligation field.
 * Handles both Val representations and raw Obligation objects.
 */
function parseObligation(val: unknown): Obligation | null {
  if (!val) return null;

  if (typeof val === "object" && "tag" in val) {
    const v = val as { tag: string };
    if (v.tag === "OblNone" || v.tag === "OblTests") {
      return val as Obligation;
    }

    // Handle Val representation
    if (v.tag === "Map" && "entries" in val) {
      const entries = (val as { entries: Array<[unknown, unknown]> }).entries;
      const tagEntry = entries.find(([k]) => {
        const key = k as any;
        return key && typeof key === "object" && key.tag === "Str" && typeof key.s === "string" && key.s === "tag";
      });
      if (tagEntry) {
        const tagVal = tagEntry[1] as any;
        if (tagVal?.tag === "Str" && typeof tagVal.s === "string") {
          if (tagVal.s === "OblNone") return { tag: "OblNone" };
          if (tagVal.s === "OblTests") {
            // Extract passed and report from entries
            const passedEntry = entries.find(([k]) => {
              const key = k as any;
              return key && typeof key === "object" && key.tag === "Str" && typeof key.s === "string" && key.s === "passed";
            });
            const passedVal = passedEntry?.[1] as { b?: boolean } | undefined;
            const passed = passedVal?.b ?? false;
            return { tag: "OblTests", spec: {}, passed };
          }
        }
      }
    }
  }

  return null;
}

// =========================================================================
// Commit Rewrite
// =========================================================================

export type ApplyRewrite = (rewriteExpr: unknown, envRef: Hash) => Promise<Hash>;

/**
 * Commit a rewrite Meaning to the runtime environment.
 *
 * 1. Checks capability (cap.commit.rewrite)
 * 2. Checks truth regime gate
 * 3. Applies the rewrite to the environment
 */
export async function commitRewriteMeaning(
  profile: Profile,
  envRef: Hash,
  m: MeaningVal,
  applyRewrite: ApplyRewrite,
): Promise<Hash> {
  // Check capability
  capRequire(profile.caps, "commit.rewrite", "commit/rewrite");

  // Check truth regime gate
  const gate = canCommitMeaning(profile, m);
  if (!gate.ok) {
    throw new Error(`commit blocked by truth regime (${profile.truth}): ${gate.why}`);
  }

  // Ensure rewrite field exists
  if (!m.rewrite) {
    throw new Error("commit/rewrite: Meaning has no rewrite field");
  }

  // Apply rewrite by evaluating rewrite expr in envRef and returning new envRef
  return await applyRewrite(m.rewrite, envRef);
}

// =========================================================================
// Helper: Attach Test Report to Meaning
// =========================================================================

/**
 * Attach a test report to a Meaning's obligation field.
 * Creates an OblTests obligation if none exists.
 */
export function attachTestReport(m: MeaningVal, report: TestReport): MeaningVal {
  const obl = parseObligation(m.obligation);

  if (!obl || obl.tag !== "OblTests") {
    // Create new OblTests obligation
    return {
      ...m,
      obligation: {
        tag: "OblTests",
        spec: { tag: "OmegaTests", cases: [] },
        passed: report.passed,
        report,
      } as unknown as typeof m.obligation,
    };
  }

  // Update existing OblTests
  return {
    ...m,
    obligation: {
      ...obl,
      passed: report.passed,
      report,
    } as unknown as typeof m.obligation,
  };
}

// =========================================================================
// Truth Regime Helpers
// =========================================================================

/**
 * Check if a truth regime is at least as strict as another.
 */
export function isRegimeAtLeast(have: TruthRegime, need: TruthRegime): boolean {
  const order: Record<TruthRegime, number> = {
    "speculative": 0,
    "test-certified": 1,
    "proof-certified": 2,
    "consensus-certified": 3,
  };
  return (order[have] ?? 0) >= (order[need] ?? 0);
}

/**
 * Get the strictest regime between two.
 */
export function strictestRegime(a: TruthRegime, b: TruthRegime): TruthRegime {
  const order: Record<TruthRegime, number> = {
    "speculative": 0,
    "test-certified": 1,
    "proof-certified": 2,
    "consensus-certified": 3,
  };
  return order[a] >= order[b] ? a : b;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/commit/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/commit/index.ts
// Commit barrier exports

export {
  type ObligationNone,
  type ObligationTests,
  type Obligation,
  type CommitGateResult,
  type ApplyRewrite,
  canCommitMeaning,
  commitRewriteMeaning,
  attachTestReport,
  isRegimeAtLeast,
  strictestRegime,
} from "./commit";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/anf.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/anf.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: ANF (A-Normal Form) conversion from Core AST

import type { Expr, Pattern, HandlerExpr } from "../ast";
import type { Val } from "../eval/values";
import { VUnit, VTrue, VFalse } from "../eval/values";
import type {
  ANFAtom,
  ANFPrim,
  ANFExpr,
  ANFProgram,
  ANFPattern,
  ANFHandler,
  ANFMatchClause,
  SourceLocation,
  SourceMap,
  SourceMapEntry,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// ANF Conversion Context
// ─────────────────────────────────────────────────────────────────

/**
 * Context for ANF conversion, tracking fresh names and source locations.
 */
type ANFContext = {
  /** Counter for fresh variable names */
  counter: number;
  /** Source map entries being built */
  sourceMapEntries: SourceMapEntry[];
  /** Current source location */
  currentLoc?: SourceLocation;
  /** Free variables encountered */
  freeVars: Set<string>;
  /** Bound variables in current scope */
  boundVars: Set<string>;
};

/**
 * Create a fresh ANF context.
 */
function createANFContext(): ANFContext {
  return {
    counter: 0,
    sourceMapEntries: [],
    freeVars: new Set(),
    boundVars: new Set(),
  };
}

/**
 * Generate a fresh variable name.
 */
function freshName(ctx: ANFContext, prefix: string = "t"): string {
  return `${prefix}$${ctx.counter++}`;
}

// ─────────────────────────────────────────────────────────────────
// Value to ANF Literal
// ─────────────────────────────────────────────────────────────────

/**
 * Convert a literal value to a Val for ANF.
 */
function litToVal(value: number | string | boolean | null): Val {
  if (value === null) return VUnit;
  if (typeof value === "boolean") return value ? VTrue : VFalse;
  if (typeof value === "number") return { tag: "Num", n: value };
  if (typeof value === "string") return { tag: "Str", s: value };
  return VUnit;
}

/**
 * Convert a datum (quote) to a Val.
 */
function datumToVal(datum: unknown): Val {
  if (datum === null || datum === undefined) return VUnit;
  if (typeof datum === "boolean") return datum ? VTrue : VFalse;
  if (typeof datum === "number") return { tag: "Num", n: datum };
  if (typeof datum === "string") return { tag: "Str", s: datum };
  if (typeof datum === "symbol") {
    return { tag: "Sym", name: datum.description ?? "symbol" };
  }
  if (Array.isArray(datum)) {
    return { tag: "Vector", items: datum.map(datumToVal) };
  }
  // Fallback for objects - treat as symbol
  return { tag: "Sym", name: String(datum) };
}

// ─────────────────────────────────────────────────────────────────
// Pattern Conversion
// ─────────────────────────────────────────────────────────────────

/**
 * Convert an AST pattern to an ANF pattern.
 */
function convertPattern(pat: Pattern): ANFPattern {
  switch (pat.tag) {
    case "PWild":
      return { tag: "PWild" };
    case "PVar":
      return { tag: "PVar", name: pat.name };
    case "PLit":
      return { tag: "PLit", v: litToVal(pat.value) };
    case "PVector":
      return { tag: "PVector", items: pat.items.map(convertPattern) };
  }
}

// ─────────────────────────────────────────────────────────────────
// ANF Conversion (CPS-style transformation)
// ─────────────────────────────────────────────────────────────────

/**
 * Main ANF conversion: transform an expression, calling continuation with atom result.
 *
 * The continuation receives an ANFAtom and returns the ANFExpr to use it in.
 * This CPS-style ensures all intermediate values get let-bound.
 */
function anfConvert(
  ctx: ANFContext,
  expr: Expr,
  k: (atom: ANFAtom) => ANFExpr
): ANFExpr {
  switch (expr.tag) {
    case "Lit": {
      const atom: ANFAtom = { tag: "Lit", v: litToVal(expr.value) };
      return k(atom);
    }

    case "Var": {
      // Track free vs bound variables
      if (!ctx.boundVars.has(expr.name)) {
        ctx.freeVars.add(expr.name);
      }
      const atom: ANFAtom = { tag: "Var", name: expr.name };
      return k(atom);
    }

    case "Quote": {
      // Quote creates a literal value
      const name = freshName(ctx, "q");
      const rhs: ANFPrim = { tag: "Quote", datum: expr.datum };
      return {
        tag: "Let",
        name,
        rhs,
        body: k({ tag: "Var", name }),
        loc: ctx.currentLoc,
      };
    }

    case "Lambda": {
      const name = freshName(ctx, "fn");

      // Save bound vars and add params
      const savedBound = new Set(ctx.boundVars);
      for (const p of expr.params) {
        ctx.boundVars.add(p);
      }

      // Convert body
      const body = anfConvert(ctx, expr.body, (a) => ({ tag: "Return", v: a }));

      // Restore bound vars
      ctx.boundVars = savedBound;

      const rhs: ANFPrim = { tag: "Lambda", params: expr.params, body };
      return {
        tag: "Let",
        name,
        rhs,
        body: k({ tag: "Var", name }),
        loc: ctx.currentLoc,
      };
    }

    case "OracleLambda": {
      // Oracle lambdas become Effect calls when invoked
      // For now, convert spec and create a marker closure
      const name = freshName(ctx, "oracle");
      return anfConvert(ctx, expr.spec, (specAtom) => {
        const rhs: ANFPrim = {
          tag: "Effect",
          op: "oracle.define",
          args: [specAtom, { tag: "Lit", v: { tag: "Vector", items: expr.params.map(p => ({ tag: "Str", s: p })) } }],
        };
        return {
          tag: "Let",
          name,
          rhs,
          body: k({ tag: "Var", name }),
          loc: ctx.currentLoc,
        };
      });
    }

    case "If": {
      return anfConvert(ctx, expr.test, (testAtom) => {
        // Simplified If: both branches return directly, continuation applied to result
        const thn = anfConvert(ctx, expr.conseq, k);
        const els = anfConvert(ctx, expr.alt, k);

        return {
          tag: "If",
          test: testAtom,
          thn,
          els,
          loc: ctx.currentLoc,
        };
      });
    }

    case "Begin": {
      if (expr.exprs.length === 0) {
        return k({ tag: "Lit", v: VUnit });
      }
      if (expr.exprs.length === 1) {
        return anfConvert(ctx, expr.exprs[0], k);
      }

      // Convert first expression, ignoring result, then continue with rest
      const [first, ...rest] = expr.exprs;
      return anfConvert(ctx, first, (_atom) => {
        return anfConvert(ctx, { tag: "Begin", exprs: rest }, k);
      });
    }

    case "Define": {
      // Define is like a let that adds to environment
      ctx.boundVars.add(expr.name);
      return anfConvert(ctx, expr.rhs, (rhsAtom) => {
        // Create a binding and continue
        return {
          tag: "Let",
          name: expr.name,
          rhs: { tag: "Prim", name: "identity", args: [rhsAtom] },
          body: k({ tag: "Var", name: expr.name }),
          loc: ctx.currentLoc,
        };
      });
    }

    case "Set": {
      return anfConvert(ctx, expr.rhs, (rhsAtom) => {
        return {
          tag: "Set",
          name: expr.name,
          rhs: rhsAtom,
          body: k({ tag: "Lit", v: VUnit }),
          loc: ctx.currentLoc,
        };
      });
    }

    case "App": {
      // Convert function, then convert all args, then call
      return anfConvert(ctx, expr.fn, (fnAtom) => {
        return anfConvertArgs(ctx, expr.args, [], (argAtoms) => {
          const callName = freshName(ctx, "call");
          const rhs: ANFPrim = { tag: "Call", fn: fnAtom, args: argAtoms };
          return {
            tag: "Let",
            name: callName,
            rhs,
            body: k({ tag: "Var", name: callName }),
            loc: ctx.currentLoc,
          };
        });
      });
    }

    case "Effect": {
      // Effect operations are preserved!
      return anfConvertArgs(ctx, expr.args, [], (argAtoms) => {
        const effectName = freshName(ctx, "eff");
        const rhs: ANFPrim = { tag: "Effect", op: expr.op, args: argAtoms };
        return {
          tag: "Let",
          name: effectName,
          rhs,
          body: k({ tag: "Var", name: effectName }),
          loc: ctx.currentLoc,
        };
      });
    }

    case "Handle": {
      const bodyExpr = anfConvert(ctx, expr.body, (a) => ({ tag: "Return", v: a }));
      const handler = convertHandler(ctx, expr.handler);

      const handleName = freshName(ctx, "handle");
      const rhs: ANFPrim = { tag: "Handle", body: bodyExpr, handler };
      return {
        tag: "Let",
        name: handleName,
        rhs,
        body: k({ tag: "Var", name: handleName }),
        loc: ctx.currentLoc,
      };
    }

    case "Match": {
      return anfConvert(ctx, expr.scrutinee, (scrutAtom) => {
        const clauses: ANFMatchClause[] = expr.clauses.map((c) => {
          // Add pattern variables to scope
          const savedBound = new Set(ctx.boundVars);
          addPatternVars(ctx, c.pat);

          const body = anfConvert(ctx, c.body, (a) => ({ tag: "Return", v: a }));

          ctx.boundVars = savedBound;

          return {
            pat: convertPattern(c.pat),
            body,
          };
        });

        const matchName = freshName(ctx, "match");
        const rhs: ANFPrim = { tag: "Match", scrut: scrutAtom, clauses };
        return {
          tag: "Let",
          name: matchName,
          rhs,
          body: k({ tag: "Var", name: matchName }),
          loc: ctx.currentLoc,
        };
      });
    }
  }
}

/**
 * Convert a list of argument expressions to ANF atoms.
 */
function anfConvertArgs(
  ctx: ANFContext,
  args: Expr[],
  acc: ANFAtom[],
  k: (atoms: ANFAtom[]) => ANFExpr
): ANFExpr {
  if (args.length === 0) {
    return k(acc);
  }

  const [first, ...rest] = args;
  return anfConvert(ctx, first, (atom) => {
    return anfConvertArgs(ctx, rest, [...acc, atom], k);
  });
}

/**
 * Convert handler expression to ANF handler.
 */
function convertHandler(ctx: ANFContext, handler: HandlerExpr): ANFHandler {
  const anfHandler: ANFHandler = {
    on: handler.on.map((clause) => {
      // Add params and k to scope
      const savedBound = new Set(ctx.boundVars);
      for (const p of clause.params) {
        ctx.boundVars.add(p);
      }
      ctx.boundVars.add(clause.k);

      const body = anfConvert(ctx, clause.body, (a) => ({ tag: "Return", v: a }));

      ctx.boundVars = savedBound;

      return {
        op: clause.op,
        params: clause.params,
        k: clause.k,
        body,
      };
    }),
  };

  if (handler.ret) {
    const savedBound = new Set(ctx.boundVars);
    ctx.boundVars.add(handler.ret.v);
    anfHandler.ret = {
      v: handler.ret.v,
      body: anfConvert(ctx, handler.ret.body, (a) => ({ tag: "Return", v: a })),
    };
    ctx.boundVars = savedBound;
  }

  if (handler.fin) {
    anfHandler.fin = {
      body: anfConvert(ctx, handler.fin.body, (a) => ({ tag: "Return", v: a })),
    };
  }

  return anfHandler;
}

/**
 * Add pattern variables to bound vars.
 */
function addPatternVars(ctx: ANFContext, pat: Pattern): void {
  switch (pat.tag) {
    case "PWild":
    case "PLit":
      break;
    case "PVar":
      ctx.boundVars.add(pat.name);
      break;
    case "PVector":
      for (const item of pat.items) {
        addPatternVars(ctx, item);
      }
      break;
  }
}

// ─────────────────────────────────────────────────────────────────
// Public API
// ─────────────────────────────────────────────────────────────────

/**
 * Convert a Core AST expression to ANF.
 */
export function toANF(expr: Expr, sourceLabel?: string): ANFProgram {
  const ctx = createANFContext();

  if (sourceLabel) {
    ctx.currentLoc = { source: sourceLabel, line: 1, column: 1 };
  }

  const body = anfConvert(ctx, expr, (a) => ({ tag: "Return", v: a }));

  return {
    body,
    freeVars: Array.from(ctx.freeVars),
  };
}

/**
 * Create source map from ANF context.
 */
export function createSourceMap(entries: SourceMapEntry[]): SourceMap {
  return { entries };
}

// ─────────────────────────────────────────────────────────────────
// ANF Utilities
// ─────────────────────────────────────────────────────────────────

/**
 * Count the number of let bindings in an ANF expression.
 */
export function countBindings(expr: ANFExpr): number {
  switch (expr.tag) {
    case "Return":
      return 0;
    case "Let":
      return 1 + countBindings(expr.body);
    case "LetRec":
      return expr.bindings.length + countBindings(expr.body);
    case "If":
      return countBindings(expr.thn) + countBindings(expr.els);
    case "Seq":
      return countBindings(expr.first) + countBindings(expr.second);
    case "Set":
      return countBindings(expr.body);
  }
}

/**
 * Count effect operations in an ANF expression.
 */
export function countEffects(expr: ANFExpr): number {
  let count = 0;

  function visitPrim(prim: ANFPrim): void {
    if (prim.tag === "Effect") {
      count++;
    } else if (prim.tag === "Lambda") {
      visitExpr(prim.body);
    } else if (prim.tag === "Handle") {
      visitExpr(prim.body);
      for (const clause of prim.handler.on) {
        visitExpr(clause.body);
      }
      if (prim.handler.ret) visitExpr(prim.handler.ret.body);
      if (prim.handler.fin) visitExpr(prim.handler.fin.body);
    } else if (prim.tag === "Match") {
      for (const clause of prim.clauses) {
        visitExpr(clause.body);
      }
    }
  }

  function visitExpr(e: ANFExpr): void {
    switch (e.tag) {
      case "Return":
        break;
      case "Let":
        visitPrim(e.rhs);
        visitExpr(e.body);
        break;
      case "LetRec":
        for (const b of e.bindings) {
          visitPrim(b.rhs);
        }
        visitExpr(e.body);
        break;
      case "If":
        visitExpr(e.thn);
        visitExpr(e.els);
        break;
      case "Seq":
        visitExpr(e.first);
        visitExpr(e.second);
        break;
      case "Set":
        visitExpr(e.body);
        break;
    }
  }

  visitExpr(expr);
  return count;
}

/**
 * Find all effect operation names in an ANF expression.
 */
export function findEffectOps(expr: ANFExpr): Set<string> {
  const ops = new Set<string>();

  function visitPrim(prim: ANFPrim): void {
    if (prim.tag === "Effect") {
      ops.add(prim.op);
    } else if (prim.tag === "Lambda") {
      visitExpr(prim.body);
    } else if (prim.tag === "Handle") {
      visitExpr(prim.body);
      for (const clause of prim.handler.on) {
        visitExpr(clause.body);
      }
      if (prim.handler.ret) visitExpr(prim.handler.ret.body);
      if (prim.handler.fin) visitExpr(prim.handler.fin.body);
    } else if (prim.tag === "Match") {
      for (const clause of prim.clauses) {
        visitExpr(clause.body);
      }
    }
  }

  function visitExpr(e: ANFExpr): void {
    switch (e.tag) {
      case "Return":
        break;
      case "Let":
        visitPrim(e.rhs);
        visitExpr(e.body);
        break;
      case "LetRec":
        for (const b of e.bindings) {
          visitPrim(b.rhs);
        }
        visitExpr(e.body);
        break;
      case "If":
        visitExpr(e.thn);
        visitExpr(e.els);
        break;
      case "Seq":
        visitExpr(e.first);
        visitExpr(e.second);
        break;
      case "Set":
        visitExpr(e.body);
        break;
    }
  }

  visitExpr(expr);
  return ops;
}

/**
 * Pretty-print an ANF expression (for debugging).
 */
export function anfToString(expr: ANFExpr, indent: number = 0): string {
  const pad = "  ".repeat(indent);

  function atomStr(a: ANFAtom): string {
    return a.tag === "Lit" ? JSON.stringify(a.v) : a.name;
  }

  function primStr(p: ANFPrim): string {
    switch (p.tag) {
      case "Lambda":
        return `(lambda (${p.params.join(" ")}) ...)`;
      case "Call":
        return `(${atomStr(p.fn)} ${p.args.map(atomStr).join(" ")})`;
      case "Effect":
        return `(effect ${p.op} ${p.args.map(atomStr).join(" ")})`;
      case "Quote":
        return `(quote ${JSON.stringify(p.datum)})`;
      case "Prim":
        return `(prim ${p.name} ${p.args.map(atomStr).join(" ")})`;
      case "Match":
        return `(match ${atomStr(p.scrut)} ...)`;
      case "Handle":
        return `(handle ...)`;
      case "MakeClosure":
        return `(make-closure ...)`;
    }
  }

  switch (expr.tag) {
    case "Return":
      return `${pad}(return ${atomStr(expr.v)})`;
    case "Let":
      return `${pad}(let ${expr.name} = ${primStr(expr.rhs)}\n${anfToString(expr.body, indent + 1)})`;
    case "LetRec":
      const binds = expr.bindings.map(b => `${b.name} = ${primStr(b.rhs)}`).join(", ");
      return `${pad}(letrec [${binds}]\n${anfToString(expr.body, indent + 1)})`;
    case "If":
      return `${pad}(if ${atomStr(expr.test)}\n${anfToString(expr.thn, indent + 1)}\n${anfToString(expr.els, indent + 1)})`;
    case "Seq":
      return `${pad}(seq\n${anfToString(expr.first, indent + 1)}\n${anfToString(expr.second, indent + 1)})`;
    case "Set":
      return `${pad}(set! ${expr.name} ${atomStr(expr.rhs)}\n${anfToString(expr.body, indent + 1)})`;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/bytecode.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/bytecode.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Bytecode generation from ANF

import type { Val } from "../eval/values";
import { VUnit } from "../eval/values";
import type {
  ANFAtom,
  ANFPrim,
  ANFExpr,
  ANFProgram,
  ANFPattern,
  ANFHandler,
  Instr,
  BytecodeFunction,
  BytecodeHandler,
  BytecodeProgram,
  SourceMap,
  SourceMapEntry,
  SourceLocation,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Bytecode Generation Context
// ─────────────────────────────────────────────────────────────────

/**
 * Context for bytecode generation.
 */
type BytecodeContext = {
  /** Constant pool */
  constants: Val[];
  /** Constant index lookup */
  constantMap: Map<string, number>;
  /** Function pool */
  functions: BytecodeFunction[];
  /** Handler definitions */
  handlers: BytecodeHandler[];
  /** Current function being compiled */
  currentFn: BytecodeFunction | null;
  /** Local variable name to slot mapping */
  locals: Map<string, number>;
  /** Next local slot */
  nextLocal: number;
  /** Label counter */
  labelCounter: number;
  /** Source map entries */
  sourceMapEntries: SourceMapEntry[];
  /** Free variables */
  freeVars: string[];
};

/**
 * Create a fresh bytecode context.
 */
function createBytecodeContext(): BytecodeContext {
  return {
    constants: [],
    constantMap: new Map(),
    functions: [],
    handlers: [],
    currentFn: null,
    locals: new Map(),
    nextLocal: 0,
    labelCounter: 0,
    sourceMapEntries: [],
    freeVars: [],
  };
}

/**
 * Add a constant to the pool, returning its index.
 */
function addConstant(ctx: BytecodeContext, val: Val): number {
  const key = JSON.stringify(val);
  const existing = ctx.constantMap.get(key);
  if (existing !== undefined) {
    return existing;
  }
  const idx = ctx.constants.length;
  ctx.constants.push(val);
  ctx.constantMap.set(key, idx);
  return idx;
}

/**
 * Get or allocate a local slot for a variable.
 */
function getLocalSlot(ctx: BytecodeContext, name: string): number {
  const existing = ctx.locals.get(name);
  if (existing !== undefined) {
    return existing;
  }
  const slot = ctx.nextLocal++;
  ctx.locals.set(name, slot);
  return slot;
}

/**
 * Fresh label number.
 */
function freshLabel(ctx: BytecodeContext): number {
  return ctx.labelCounter++;
}

/**
 * Emit an instruction to the current function.
 */
function emit(ctx: BytecodeContext, instr: Instr): void {
  if (ctx.currentFn) {
    ctx.currentFn.code.push(instr);
  }
}

/**
 * Get current instruction index.
 */
function currentIP(ctx: BytecodeContext): number {
  return ctx.currentFn ? ctx.currentFn.code.length : 0;
}

// ─────────────────────────────────────────────────────────────────
// Atom Compilation
// ─────────────────────────────────────────────────────────────────

/**
 * Compile an ANF atom (pushes value onto stack).
 */
function compileAtom(ctx: BytecodeContext, atom: ANFAtom): void {
  switch (atom.tag) {
    case "Lit": {
      const k = addConstant(ctx, atom.v);
      emit(ctx, { op: "CONST", k });
      break;
    }
    case "Var": {
      const slot = ctx.locals.get(atom.name);
      if (slot !== undefined) {
        emit(ctx, { op: "LOAD", slot });
      } else {
        // Global or free variable
        emit(ctx, { op: "GLOAD", name: atom.name });
      }
      break;
    }
  }
}

// ─────────────────────────────────────────────────────────────────
// Primitive Compilation
// ─────────────────────────────────────────────────────────────────

/**
 * Find free variables in an ANF expression.
 */
function findFreeVarsInExpr(expr: ANFExpr, bound: Set<string>): Set<string> {
  const free = new Set<string>();

  function checkAtom(atom: ANFAtom): void {
    if (atom.tag === "Var" && !bound.has(atom.name)) {
      free.add(atom.name);
    }
  }

  function checkPrim(prim: ANFPrim, innerBound: Set<string>): void {
    switch (prim.tag) {
      case "Call":
        checkAtom(prim.fn);
        prim.args.forEach(checkAtom);
        break;
      case "Effect":
      case "Prim":
        prim.args.forEach(checkAtom);
        break;
      case "Lambda": {
        const lambdaBound = new Set(innerBound);
        prim.params.forEach(p => lambdaBound.add(p));
        for (const fv of findFreeVarsInExpr(prim.body, lambdaBound)) {
          if (!bound.has(fv)) free.add(fv);
        }
        break;
      }
      case "Match":
        checkAtom(prim.scrut);
        // Patterns bind variables - simplified handling
        break;
      case "Handle":
        for (const fv of findFreeVarsInExpr(prim.body, innerBound)) {
          free.add(fv);
        }
        break;
      default:
        break;
    }
  }

  function visit(e: ANFExpr, innerBound: Set<string>): void {
    switch (e.tag) {
      case "Return":
        checkAtom(e.v);
        break;
      case "Let": {
        checkPrim(e.rhs, innerBound);
        const newBound = new Set(innerBound);
        newBound.add(e.name);
        visit(e.body, newBound);
        break;
      }
      case "LetRec": {
        const newBound = new Set(innerBound);
        e.bindings.forEach(b => newBound.add(b.name));
        e.bindings.forEach(b => checkPrim(b.rhs, newBound));
        visit(e.body, newBound);
        break;
      }
      case "If":
        checkAtom(e.test);
        visit(e.thn, innerBound);
        visit(e.els, innerBound);
        break;
      case "Seq":
        visit(e.first, innerBound);
        visit(e.second, innerBound);
        break;
      case "Set":
        checkAtom(e.rhs);
        visit(e.body, innerBound);
        break;
    }
  }

  visit(expr, bound);
  return free;
}

/**
 * Compile an ANF primitive (leaves result on stack).
 */
function compilePrim(ctx: BytecodeContext, prim: ANFPrim): void {
  switch (prim.tag) {
    case "Lambda": {
      // Find free variables in the lambda body
      const paramSet = new Set(prim.params);
      const freeVars = findFreeVarsInExpr(prim.body, paramSet);

      // Determine which free vars are available in current scope
      const captured: number[] = [];
      const capturedNames: string[] = [];
      for (const fv of freeVars) {
        const slot = ctx.locals.get(fv);
        if (slot !== undefined) {
          captured.push(slot);
          capturedNames.push(fv);
        }
      }

      // Create a new function
      const fnId = ctx.functions.length;
      const savedLocals = new Map(ctx.locals);
      const savedNextLocal = ctx.nextLocal;
      const savedFn = ctx.currentFn;

      // Create new function
      const fn: BytecodeFunction = {
        id: fnId,
        arity: prim.params.length,
        localCount: 0,
        code: [],
        label: prim.label,
      };
      ctx.functions.push(fn);
      ctx.currentFn = fn;

      // Reset locals for function
      ctx.locals = new Map();
      ctx.nextLocal = 0;

      // Allocate slots for parameters
      for (const param of prim.params) {
        getLocalSlot(ctx, param);
      }

      // Allocate slots for captured variables (after params)
      for (const name of capturedNames) {
        getLocalSlot(ctx, name);
      }

      // Compile function body
      compileExpr(ctx, prim.body);

      // Ensure return
      emit(ctx, { op: "RET" });

      fn.localCount = ctx.nextLocal;

      // Restore context
      ctx.locals = savedLocals;
      ctx.nextLocal = savedNextLocal;
      ctx.currentFn = savedFn;

      // Push closure with captured variable slots
      emit(ctx, { op: "CLOSURE", fnId, captured });
      break;
    }

    case "Call": {
      // Push function
      compileAtom(ctx, prim.fn);
      // Push args
      for (const arg of prim.args) {
        compileAtom(ctx, arg);
      }
      // Call
      emit(ctx, { op: "CALL", argc: prim.args.length });
      break;
    }

    case "Effect": {
      // Effects are preserved! Push args and emit effect instruction
      for (const arg of prim.args) {
        compileAtom(ctx, arg);
      }
      emit(ctx, { op: "EFFECT", opName: prim.op, argc: prim.args.length });
      break;
    }

    case "Quote": {
      const val = datumToVal(prim.datum);
      const k = addConstant(ctx, val);
      emit(ctx, { op: "CONST", k });
      break;
    }

    case "Prim": {
      // Built-in primitive operations
      for (const arg of prim.args) {
        compileAtom(ctx, arg);
      }
      emit(ctx, { op: "PRIM", name: prim.name, argc: prim.args.length });
      break;
    }

    case "Match": {
      compileAtom(ctx, prim.scrut);

      // For simplicity, generate if-else chain for patterns
      // A more sophisticated version would use dispatch tables
      const endLabel = freshLabel(ctx);

      for (let i = 0; i < prim.clauses.length; i++) {
        const clause = prim.clauses[i];
        const nextLabel = i < prim.clauses.length - 1 ? freshLabel(ctx) : endLabel;

        // Compile pattern test
        compilePatternTest(ctx, clause.pat, nextLabel);

        // Bind pattern variables
        compilePatternBind(ctx, clause.pat);

        // Compile body
        compileExpr(ctx, clause.body);

        // Jump to end
        emit(ctx, { op: "JMP", label: endLabel });

        // Next clause label
        if (i < prim.clauses.length - 1) {
          // Mark label position (simplified - in real impl would patch jumps)
        }
      }

      // End label
      break;
    }

    case "Handle": {
      const handlerId = ctx.handlers.length;

      // Create handler definition
      const handler: BytecodeHandler = {
        id: handlerId,
        ops: new Map(),
      };

      // Compile handler clauses into functions
      for (const clause of prim.handler.on) {
        const fnId = ctx.functions.length;
        const fn: BytecodeFunction = {
          id: fnId,
          arity: clause.params.length + 1, // +1 for continuation
          localCount: 0,
          code: [],
        };
        ctx.functions.push(fn);

        const savedLocals = new Map(ctx.locals);
        const savedNextLocal = ctx.nextLocal;
        const savedFn = ctx.currentFn;

        ctx.currentFn = fn;
        ctx.locals = new Map();
        ctx.nextLocal = 0;

        // Allocate slots for params and k
        const paramSlots: number[] = [];
        for (const p of clause.params) {
          paramSlots.push(getLocalSlot(ctx, p));
        }
        const kSlot = getLocalSlot(ctx, clause.k);

        compileExpr(ctx, clause.body);
        emit(ctx, { op: "RET" });

        fn.localCount = ctx.nextLocal;

        handler.ops.set(clause.op, { paramSlots, kSlot, codeStart: fnId });

        ctx.locals = savedLocals;
        ctx.nextLocal = savedNextLocal;
        ctx.currentFn = savedFn;
      }

      // Compile ret clause if present
      if (prim.handler.ret) {
        const fnId = ctx.functions.length;
        const fn: BytecodeFunction = {
          id: fnId,
          arity: 1,
          localCount: 0,
          code: [],
        };
        ctx.functions.push(fn);

        const savedLocals = new Map(ctx.locals);
        const savedNextLocal = ctx.nextLocal;
        const savedFn = ctx.currentFn;

        ctx.currentFn = fn;
        ctx.locals = new Map();
        ctx.nextLocal = 0;

        handler.retSlot = getLocalSlot(ctx, prim.handler.ret.v);
        compileExpr(ctx, prim.handler.ret.body);
        emit(ctx, { op: "RET" });

        fn.localCount = ctx.nextLocal;
        handler.retCodeStart = fnId;

        ctx.locals = savedLocals;
        ctx.nextLocal = savedNextLocal;
        ctx.currentFn = savedFn;
      }

      ctx.handlers.push(handler);

      // Emit handle instruction
      emit(ctx, { op: "HANDLE", handlerId });

      // Compile body
      compileExpr(ctx, prim.body);

      // End handler
      emit(ctx, { op: "UNHANDLE" });
      break;
    }

    case "MakeClosure": {
      // After closure conversion - not implemented yet
      compilePrim(ctx, prim.lambda);
      break;
    }
  }
}

/**
 * Convert datum to Val for quotes.
 */
function datumToVal(datum: unknown): Val {
  if (datum === null || datum === undefined) return VUnit;
  if (typeof datum === "boolean") return datum ? { tag: "Bool", b: true } : { tag: "Bool", b: false };
  if (typeof datum === "number") return { tag: "Num", n: datum };
  if (typeof datum === "string") return { tag: "Str", s: datum };
  if (typeof datum === "symbol") {
    return { tag: "Sym", name: datum.description ?? "symbol" };
  }
  if (Array.isArray(datum)) {
    return { tag: "Vector", items: datum.map(datumToVal) };
  }
  return { tag: "Sym", name: String(datum) };
}

/**
 * Compile pattern test (for match expressions).
 */
function compilePatternTest(ctx: BytecodeContext, pat: ANFPattern, failLabel: number): void {
  switch (pat.tag) {
    case "PWild":
      // Always matches
      break;
    case "PVar":
      // Always matches, binding happens later
      break;
    case "PLit": {
      emit(ctx, { op: "DUP" });
      const k = addConstant(ctx, pat.v);
      emit(ctx, { op: "CONST", k });
      emit(ctx, { op: "PRIM", name: "eq?", argc: 2 });
      emit(ctx, { op: "JMPIF", labelTrue: currentIP(ctx) + 1, labelFalse: failLabel });
      break;
    }
    case "PVector":
      // TODO: Implement vector pattern matching
      break;
  }
}

/**
 * Compile pattern binding (bind pattern variables).
 */
function compilePatternBind(ctx: BytecodeContext, pat: ANFPattern): void {
  switch (pat.tag) {
    case "PWild":
      emit(ctx, { op: "POP" });
      break;
    case "PVar": {
      const slot = getLocalSlot(ctx, pat.name);
      emit(ctx, { op: "STORE", slot });
      break;
    }
    case "PLit":
      emit(ctx, { op: "POP" });
      break;
    case "PVector":
      // TODO: Implement vector pattern binding
      emit(ctx, { op: "POP" });
      break;
  }
}

// ─────────────────────────────────────────────────────────────────
// Expression Compilation
// ─────────────────────────────────────────────────────────────────

/**
 * Compile an ANF expression.
 */
function compileExpr(ctx: BytecodeContext, expr: ANFExpr): void {
  switch (expr.tag) {
    case "Return": {
      compileAtom(ctx, expr.v);
      break;
    }

    case "Let": {
      // Compile RHS
      compilePrim(ctx, expr.rhs);

      // Store in local
      const slot = getLocalSlot(ctx, expr.name);
      emit(ctx, { op: "STORE", slot });

      // Compile body
      compileExpr(ctx, expr.body);
      break;
    }

    case "LetRec": {
      // Allocate slots for all bindings first
      for (const binding of expr.bindings) {
        getLocalSlot(ctx, binding.name);
      }

      // Initialize with undefined
      for (const binding of expr.bindings) {
        const k = addConstant(ctx, VUnit);
        emit(ctx, { op: "CONST", k });
        const slot = ctx.locals.get(binding.name)!;
        emit(ctx, { op: "STORE", slot });
      }

      // Compile each binding's RHS
      for (const binding of expr.bindings) {
        compilePrim(ctx, binding.rhs);
        const slot = ctx.locals.get(binding.name)!;
        emit(ctx, { op: "STORE", slot });
      }

      // Compile body
      compileExpr(ctx, expr.body);
      break;
    }

    case "If": {
      compileAtom(ctx, expr.test);

      // Emit placeholder JMPIF - we'll patch the false label
      const jmpifIdx = currentIP(ctx);
      emit(ctx, { op: "JMPIF", labelTrue: jmpifIdx + 1, labelFalse: 0 }); // placeholder

      // Then branch
      compileExpr(ctx, expr.thn);

      // Emit placeholder JMP to end - we'll patch this too
      const jmpEndIdx = currentIP(ctx);
      emit(ctx, { op: "JMP", label: 0 }); // placeholder

      // Now we know where the else branch starts
      const elseStart = currentIP(ctx);

      // Patch the JMPIF false label
      if (ctx.currentFn) {
        const jmpif = ctx.currentFn.code[jmpifIdx];
        if (jmpif.op === "JMPIF") {
          ctx.currentFn.code[jmpifIdx] = { ...jmpif, labelFalse: elseStart };
        }
      }

      // Else branch
      compileExpr(ctx, expr.els);

      // Now we know where the end is
      const endPos = currentIP(ctx);

      // Patch the JMP to end
      if (ctx.currentFn) {
        const jmp = ctx.currentFn.code[jmpEndIdx];
        if (jmp.op === "JMP") {
          ctx.currentFn.code[jmpEndIdx] = { ...jmp, label: endPos };
        }
      }

      break;
    }

    case "Seq": {
      compileExpr(ctx, expr.first);
      emit(ctx, { op: "POP" }); // Discard first result
      compileExpr(ctx, expr.second);
      break;
    }

    case "Set": {
      compileAtom(ctx, expr.rhs);

      const slot = ctx.locals.get(expr.name);
      if (slot !== undefined) {
        emit(ctx, { op: "STORE", slot });
      } else {
        emit(ctx, { op: "GSTORE", name: expr.name });
      }

      compileExpr(ctx, expr.body);
      break;
    }
  }
}

// ─────────────────────────────────────────────────────────────────
// Public API
// ─────────────────────────────────────────────────────────────────

/**
 * Compile an ANF program to bytecode.
 */
export function toBytecode(anf: ANFProgram): BytecodeProgram {
  const ctx = createBytecodeContext();
  ctx.freeVars = [...anf.freeVars];

  // Create entry function
  const entryFn: BytecodeFunction = {
    id: 0,
    arity: 0,
    localCount: 0,
    code: [],
    label: "entry",
  };
  ctx.functions.push(entryFn);
  ctx.currentFn = entryFn;

  // Compile program body
  compileExpr(ctx, anf.body);
  emit(ctx, { op: "RET" });

  entryFn.localCount = ctx.nextLocal;

  return {
    constants: ctx.constants,
    functions: ctx.functions,
    handlers: ctx.handlers,
    entryFn: 0,
    freeVars: ctx.freeVars,
    sourceMap: { entries: ctx.sourceMapEntries },
  };
}

/**
 * Count instructions in bytecode program.
 */
export function countInstructions(program: BytecodeProgram): number {
  return program.functions.reduce((sum, fn) => sum + fn.code.length, 0);
}

/**
 * Count effect instructions in bytecode program.
 */
export function countEffectInstructions(program: BytecodeProgram): number {
  let count = 0;
  for (const fn of program.functions) {
    for (const instr of fn.code) {
      if (instr.op === "EFFECT") {
        count++;
      }
    }
  }
  return count;
}

/**
 * Find all effect operations in bytecode program.
 */
export function findEffectOpsInBytecode(program: BytecodeProgram): Set<string> {
  const ops = new Set<string>();
  for (const fn of program.functions) {
    for (const instr of fn.code) {
      if (instr.op === "EFFECT") {
        ops.add(instr.opName);
      }
    }
  }
  return ops;
}

/**
 * Disassemble bytecode function (for debugging).
 */
export function disassemble(fn: BytecodeFunction): string {
  const lines: string[] = [];
  lines.push(`; Function ${fn.id}${fn.label ? ` (${fn.label})` : ""}`);
  lines.push(`; Arity: ${fn.arity}, Locals: ${fn.localCount}`);

  for (let i = 0; i < fn.code.length; i++) {
    const instr = fn.code[i];
    lines.push(`  ${i.toString().padStart(4)}: ${formatInstr(instr)}`);
  }

  return lines.join("\n");
}

/**
 * Format a single instruction.
 */
function formatInstr(instr: Instr): string {
  switch (instr.op) {
    case "CONST":
      return `CONST ${instr.k}`;
    case "LOAD":
      return `LOAD ${instr.slot}`;
    case "STORE":
      return `STORE ${instr.slot}`;
    case "GLOAD":
      return `GLOAD ${instr.name}`;
    case "GSTORE":
      return `GSTORE ${instr.name}`;
    case "CLOSURE":
      return `CLOSURE ${instr.fnId} [${instr.captured.join(", ")}]`;
    case "CALL":
      return `CALL ${instr.argc}`;
    case "TAILCALL":
      return `TAILCALL ${instr.argc}`;
    case "RET":
      return "RET";
    case "POP":
      return "POP";
    case "DUP":
      return "DUP";
    case "JMP":
      return `JMP ${instr.label}`;
    case "JMPIF":
      return `JMPIF ${instr.labelTrue} ${instr.labelFalse}`;
    case "EFFECT":
      return `EFFECT ${instr.opName} ${instr.argc}`;
    case "HANDLE":
      return `HANDLE ${instr.handlerId}`;
    case "UNHANDLE":
      return "UNHANDLE";
    case "PRIM":
      return `PRIM ${instr.name} ${instr.argc}`;
    case "MATCH":
      return `MATCH [${instr.clauseLabels.join(", ")}]`;
    case "FAIL":
      return `FAIL ${instr.reasonK}`;
    case "NOP":
      return "NOP";
    case "DEBUG":
      return `DEBUG "${instr.info}"`;
  }
}

/**
 * Disassemble entire bytecode program.
 */
export function disassembleProgram(program: BytecodeProgram): string {
  const lines: string[] = [];

  lines.push("; Constants:");
  for (let i = 0; i < program.constants.length; i++) {
    lines.push(`  ${i}: ${JSON.stringify(program.constants[i])}`);
  }
  lines.push("");

  lines.push("; Free variables:");
  lines.push(`  [${program.freeVars.join(", ")}]`);
  lines.push("");

  lines.push("; Functions:");
  for (const fn of program.functions) {
    lines.push(disassemble(fn));
    lines.push("");
  }

  return lines.join("\n");
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/desugar.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "../../outcome/diagnostic";
import { errorDiag } from "../../outcome/diagnostic";
import type { CoreForm, CoreFormTag, DesugarResult, Form, ValueLiteral } from "./types";

const ERR_UNKNOWN = "E0001";

export function desugarForm(form: Form): DesugarResult {
  const diagnostics: Diagnostic[] = [];
  const coreForm = desugar(form, diagnostics);

  return {
    ok: diagnostics.length === 0,
    coreForm,
    diagnostics,
  };
}

function desugar(form: Form, diagnostics: Diagnostic[]): CoreForm {
  switch (form.tag) {
    case "Number":
    case "String":
    case "Keyword":
    case "Symbol":
    case "Atom":
      return quoteLiteral(literal(form), metaFor(form));
    default:
      break;
  }

  if (form.tag !== "List" || !form.children || form.children.length === 0) {
    return quoteLiteral(literal(form), metaFor(form));
  }

  const head = form.children[0];
  const headSym = head.tag === "Symbol" ? String(head.value) : null;
  const args = form.children.slice(1);

  switch (headSym) {
    case "quote":
      return { tag: "quote", meta: metaFor(form), args: [literal(args[0])] };
    case "pure":
    case "fail":
    case "emit":
    case "observe":
    case "commit":
    case "validate":
    case "with-budget":
    case "with-timeout":
    case "infer":
    case "tool-call":
      return simpleCore(headSym, metaFor(form), args, diagnostics);
    case "bind":
    case "catch":
      return simpleCore(headSym, metaFor(form), args, diagnostics);
    case "all":
    case "any":
    case "race":
    case "sequence":
      return { tag: headSym as CoreFormTag, meta: metaFor(form), args: args.map(arg => desugar(arg, diagnostics)) };
    case "if":
      return {
        tag: "branch",
        meta: metaFor(form),
        args: args.map(arg => desugar(arg, diagnostics)),
      };
    case "lambda": {
      const paramsForm = args[0];
      const params =
        paramsForm?.children?.map(p => String(p.value)) ?? [];
      const body = args[1] ? desugar(args[1], diagnostics) : quoteLiteral(literalAtom(null, form.meta), form.meta);
      return { tag: "lambda", meta: metaFor(form), args: [literalAtom(params, form.meta), body] };
    }
    case "let":
    case "letrec": {
      const bindingsForm = args[0];
      const bodyForm = args[1];
      const bindings: [string, CoreForm][] = [];
      const pairs = bindingsForm?.children ?? [];
      for (const pair of pairs) {
        const [nameForm, exprForm] = pair.children ?? [];
        bindings.push([String(nameForm?.value ?? ""), desugar(exprForm, diagnostics)]);
      }
      return {
        tag: headSym as CoreFormTag,
        meta: metaFor(form),
        args: [literalAtom(bindings, form.meta), desugar(bodyForm, diagnostics)],
      };
    }
    case "let*": {
      const bindingsForm = args[0];
      const bodyForm = args[1];
      const pairs = bindingsForm?.children ?? [];
      let body = desugar(bodyForm, diagnostics);
      for (let i = pairs.length - 1; i >= 0; i--) {
        const pair = pairs[i];
        const [nameForm, exprForm] = pair.children ?? [];
        body = {
          tag: "let",
          meta: metaFor(pair),
          args: [literalAtom([[String(nameForm?.value ?? ""), desugar(exprForm, diagnostics)]], pair.meta), body],
        };
      }
      return body;
    }
    case "begin": {
      const forms = args.map(arg => desugar(arg, diagnostics));
      return { tag: "begin", meta: metaFor(form), args: forms };
    }
    case "and": {
      if (args.length === 0) return quoteLiteral(literalAtom(true, form.meta), form.meta);
      const base = desugar(args[args.length - 1], diagnostics);
      const remaining = args.slice(0, -1);
      return remaining.reduceRight<CoreForm>((acc, arg) => {
        return {
          tag: "branch",
          meta: metaFor(form),
          args: [desugar(arg, diagnostics), acc, quoteLiteral(literalAtom(false, form.meta), form.meta)],
        };
      }, base);
    }
    case "or": {
      if (args.length === 0) return quoteLiteral(literalAtom(false, form.meta), form.meta);
      const [first, ...rest] = args;
      if (rest.length === 0) return desugar(first, diagnostics);
      const tempName = "__or_tmp";
      const restBranch = rest
        .slice(0, -1)
        .reduceRight<CoreForm>(
        (acc, arg) => ({
          tag: "branch",
          meta: form.meta,
          args: [desugar(arg, diagnostics), desugar(arg, diagnostics), acc],
        }),
        desugar(rest[rest.length - 1], diagnostics)
      );
      return {
        tag: "let",
        meta: metaFor(form),
        args: [
          literalAtom([[tempName, desugar(first, diagnostics)]], form.meta),
          {
            tag: "branch",
            meta: metaFor(form),
            args: [quoteLiteral(literalAtom(tempName, form.meta), form.meta), quoteLiteral(literalAtom(tempName, form.meta), form.meta), restBranch],
          },
        ],
      };
    }
    default:
      diagnostics.push(errorDiag(ERR_UNKNOWN, `Unknown form: ${headSym ?? head.tag}`, { span: form.meta.span }));
      return quoteLiteral(literal(form), metaFor(form));
  }
}

function simpleCore(tag: string, meta: Form["meta"], args: Form[], diagnostics: Diagnostic[]): CoreForm {
  return {
    tag: tag as CoreFormTag,
    meta,
    args: args.map(arg => desugar(arg, diagnostics)),
  };
}

function literalAtom(value: unknown, meta: Form["meta"]): ValueLiteral {
  return { tag: "literal", meta, value };
}

function literal(form: Form | undefined): ValueLiteral {
  if (!form) return { tag: "literal", meta: { span: { startLine: 0, startCol: 0, endLine: 0, endCol: 0 } as any }, value: null };
  return { tag: "literal", meta: form.meta, value: form.tag === "Number" ? Number(form.value) : form.value };
}

function quoteLiteral(value: ValueLiteral, meta: Form["meta"]): CoreForm {
  return { tag: "quote", meta, args: [value] };
}

function metaFor(form: Form): Form["meta"] {
  return { ...form.meta, originalForm: form };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/differential.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/differential.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Differential testing harness - comparing interpreter vs compiled

import type { Expr } from "../ast";
import type { Val } from "../eval/values";
import { VUnit } from "../eval/values";
import { sha256JSON } from "../artifacts/hash";
import type {
  ANFProgram,
  BytecodeProgram,
  IRProgram,
  DifferentialReport,
  EffectTraceEntry,
  CompilerObligation,
  EvidenceRef,
  VMConfig,
} from "./types";
import { compile, getIR, CompilationResult } from "./pipeline";
import { run, getResult, createDefaultHandlers, EffectHandler, defaultVMConfig } from "./vm";
import { toBytecode } from "./bytecode";

// ─────────────────────────────────────────────────────────────────
// Interpreter Simulation
// ─────────────────────────────────────────────────────────────────

/**
 * Simulated interpreter state for differential testing.
 */
export type InterpreterState = {
  result: Val;
  effectTrace: EffectTraceEntry[];
  oracleCallCount: number;
};

/**
 * Simple interpreter for ANF (for differential testing).
 *
 * This interprets ANF directly without going through bytecode,
 * allowing us to compare against the full compiler pipeline.
 */
export function interpretANF(
  program: ANFProgram,
  env: Map<string, Val> = new Map(),
  handlers: Map<string, EffectHandler> = createDefaultHandlers(),
  maxOps: number = 50
): InterpreterState {
  const effectTrace: EffectTraceEntry[] = [];
  let oracleCallCount = 0;
  let ops = 0;

  // Environment for variable bindings
  const bindings = new Map<string, Val>(env);

  function evalAtom(atom: { tag: "Lit"; v: Val } | { tag: "Var"; name: string }): Val {
    if (atom.tag === "Lit") {
      return atom.v;
    }
    return bindings.get(atom.name) ?? VUnit;
  }

  function evalPrim(prim: any): Val {
    ops++;
    if (ops > maxOps) {
      throw new Error("Operation limit exceeded");
    }

    switch (prim.tag) {
      case "Lambda": {
        // Create a closure-like value
        return {
          tag: "Closure",
          params: prim.params,
          body: prim.body,
          env: Array.from(bindings.entries()),
        } as any;
      }

      case "Call": {
        const fnVal = evalAtom(prim.fn);
        const args = prim.args.map(evalAtom);

        if ((fnVal as any).tag === "Closure") {
          const closure = fnVal as any;
          const savedBindings = new Map(bindings);

          // Start with closure's captured environment
          const closureEnv = new Map<string, Val>();
          for (const [k, v] of closure.env) {
            closureEnv.set(k, v);
          }

          // Add current bindings that aren't shadowed by closure env
          for (const [k, v] of bindings) {
            if (!closureEnv.has(k)) {
              closureEnv.set(k, v);
            }
          }

          // Set up new environment for call
          bindings.clear();
          for (const [k, v] of closureEnv) {
            bindings.set(k, v);
          }

          // Bind parameters
          for (let i = 0; i < closure.params.length; i++) {
            bindings.set(closure.params[i], args[i] ?? VUnit);
          }

          const result = evalExpr(closure.body);

          // Restore bindings
          bindings.clear();
          for (const [k, v] of savedBindings) {
            bindings.set(k, v);
          }

          return result;
        }

        return VUnit;
      }

      case "Effect": {
        const args = prim.args.map(evalAtom);

        // Record effect
        const entry: EffectTraceEntry = {
          op: prim.op,
          argsDigest: sha256JSON(args),
          seq: effectTrace.length,
        };

        if (prim.op === "infer.op") {
          oracleCallCount++;
        }

        // Invoke handler
        const handler = handlers.get(prim.op);
        if (handler) {
          const result = handler(prim.op, args, (r) => r);
          entry.result = result;
          effectTrace.push(entry);
          return result;
        }

        effectTrace.push(entry);
        return VUnit;
      }

      case "Quote": {
        return datumToVal(prim.datum);
      }

      case "Prim": {
        const args = prim.args.map(evalAtom);
        return evalPrimOp(prim.name, args);
      }

      case "Match": {
        const scrut = evalAtom(prim.scrut);

        for (const clause of prim.clauses) {
          const match = matchPattern(clause.pat, scrut);
          if (match) {
            // Bind pattern variables
            for (const [name, val] of match) {
              bindings.set(name, val);
            }
            return evalExpr(clause.body);
          }
        }

        return VUnit;
      }

      case "Handle": {
        // Simplified - just evaluate body
        return evalExpr(prim.body);
      }

      default:
        return VUnit;
    }
  }

  function evalExpr(expr: any): Val {
    ops++;
    if (ops > maxOps) {
      throw new Error("Operation limit exceeded");
    }

    switch (expr.tag) {
      case "Return":
        return evalAtom(expr.v);

      case "Let": {
        const val = evalPrim(expr.rhs);
        bindings.set(expr.name, val);
        return evalExpr(expr.body);
      }

      case "LetRec": {
        // Initialize bindings
        for (const b of expr.bindings) {
          bindings.set(b.name, VUnit);
        }
        // Evaluate RHS
        for (const b of expr.bindings) {
          bindings.set(b.name, evalPrim(b.rhs));
        }
        return evalExpr(expr.body);
      }

      case "If": {
        const test = evalAtom(expr.test);
        if (isTruthy(test)) {
          return evalExpr(expr.thn);
        } else {
          return evalExpr(expr.els);
        }
      }

      case "Seq":
        evalExpr(expr.first);
        return evalExpr(expr.second);

      case "Set": {
        const val = evalAtom(expr.rhs);
        bindings.set(expr.name, val);
        return evalExpr(expr.body);
      }

      default:
        return VUnit;
    }
  }

  try {
    const result = evalExpr(program.body);
    return { result, effectTrace, oracleCallCount };
  } catch (e) {
    return {
      result: { tag: "Sym", name: `error:${e instanceof Error ? e.message : String(e)}` },
      effectTrace,
      oracleCallCount,
    };
  }
}

/**
 * Evaluate a primitive operation.
 */
function evalPrimOp(name: string, args: Val[]): Val {
  switch (name) {
    case "+":
      if (args[0]?.tag === "Num" && args[1]?.tag === "Num") {
        return { tag: "Num", n: args[0].n + args[1].n };
      }
      return VUnit;
    case "-":
      if (args[0]?.tag === "Num" && args[1]?.tag === "Num") {
        return { tag: "Num", n: args[0].n - args[1].n };
      }
      return VUnit;
    case "*":
      if (args[0]?.tag === "Num" && args[1]?.tag === "Num") {
        return { tag: "Num", n: args[0].n * args[1].n };
      }
      return VUnit;
    case "=":
    case "eq?":
      return valEqual(args[0], args[1]) ? { tag: "Bool", b: true } : { tag: "Bool", b: false };
    case "<":
      if (args[0]?.tag === "Num" && args[1]?.tag === "Num") {
        return { tag: "Bool", b: args[0].n < args[1].n };
      }
      return { tag: "Bool", b: false };
    case "identity":
      return args[0] ?? VUnit;
    case "undefined":
      return VUnit;
    case "cons":
      return { tag: "Pair", car: args[0] ?? VUnit, cdr: args[1] ?? VUnit };
    case "car":
      return args[0]?.tag === "Pair" ? args[0].car : VUnit;
    case "cdr":
      return args[0]?.tag === "Pair" ? args[0].cdr : VUnit;
    default:
      return VUnit;
  }
}

/**
 * Match a pattern against a value.
 */
function matchPattern(pat: any, val: Val): Map<string, Val> | null {
  switch (pat.tag) {
    case "PWild":
      return new Map();
    case "PVar":
      return new Map([[pat.name, val]]);
    case "PLit":
      return valEqual(pat.v, val) ? new Map() : null;
    case "PVector":
      if (val.tag !== "Vector") return null;
      if (pat.items.length !== val.items.length) return null;
      const bindings = new Map<string, Val>();
      for (let i = 0; i < pat.items.length; i++) {
        const sub = matchPattern(pat.items[i], val.items[i]);
        if (!sub) return null;
        for (const [k, v] of sub) {
          bindings.set(k, v);
        }
      }
      return bindings;
    default:
      return null;
  }
}

/**
 * Convert datum to Val.
 */
function datumToVal(datum: unknown): Val {
  if (datum === null || datum === undefined) return VUnit;
  if (typeof datum === "boolean") return { tag: "Bool", b: datum };
  if (typeof datum === "number") return { tag: "Num", n: datum };
  if (typeof datum === "string") return { tag: "Str", s: datum };
  if (Array.isArray(datum)) {
    return { tag: "Vector", items: datum.map(datumToVal) };
  }
  return { tag: "Sym", name: String(datum) };
}

/**
 * Check if a value is truthy.
 */
function isTruthy(val: Val): boolean {
  if (val.tag === "Bool") return val.b;
  if (val.tag === "Unit") return false;
  return true;
}

/**
 * Check value equality.
 */
function valEqual(a: Val | undefined, b: Val | undefined): boolean {
  if (!a || !b) return a === b;
  if (a.tag !== b.tag) return false;

  switch (a.tag) {
    case "Unit":
      return true;
    case "Num":
      return a.n === (b as { tag: "Num"; n: number }).n;
    case "Bool":
      return a.b === (b as { tag: "Bool"; b: boolean }).b;
    case "Str":
      return a.s === (b as { tag: "Str"; s: string }).s;
    case "Sym":
      return a.name === (b as { tag: "Sym"; name: string }).name;
    default:
      return JSON.stringify(a) === JSON.stringify(b);
  }
}

// ─────────────────────────────────────────────────────────────────
// Differential Testing
// ─────────────────────────────────────────────────────────────────

/**
 * Run differential test comparing interpreter vs compiled execution.
 */
export function differentialRun(
  expr: Expr,
  env: Map<string, Val> = new Map(),
  config: {
    maxOps?: number;
    handlers?: Map<string, EffectHandler>;
    strict?: boolean;
  } = {}
): DifferentialReport {
  const maxOps = config.maxOps ?? 50;
  const handlers = config.handlers ?? createDefaultHandlers();
  const strict = config.strict ?? true;

  // Compile to ANF
  const compiled = compile(expr, { target: "anf" });
  const anfProgram = compiled.program.program as ANFProgram;

  // Run interpreter
  const interpResult = interpretANF(anfProgram, env, handlers, maxOps);

  // Compile to bytecode and run VM
  const bytecodeProgram = toBytecode(anfProgram);
  const vmConfig: VMConfig = {
    ...defaultVMConfig,
    maxOperations: maxOps,
  };
  const vmState = run(bytecodeProgram, [], env, vmConfig, handlers);
  const compiledResult = getResult(vmState);

  // Compare outputs
  const outputsMatch = valEqual(interpResult.result, compiledResult);

  // Compare effect traces
  const effectsMatch = compareEffectTraces(
    interpResult.effectTrace,
    vmState.effectTrace,
    strict
  );

  // Compare oracle consumption
  const oracleMatch = strict
    ? interpResult.oracleCallCount === vmState.oracleCallCount
    : vmState.oracleCallCount <= interpResult.oracleCallCount;

  // Collect mismatches
  const mismatches: string[] = [];

  if (!outputsMatch) {
    mismatches.push(
      `Output mismatch: interp=${JSON.stringify(interpResult.result)}, compiled=${JSON.stringify(compiledResult)}`
    );
  }

  if (!effectsMatch) {
    mismatches.push(
      `Effect trace mismatch: interp=${interpResult.effectTrace.length} effects, compiled=${vmState.effectTrace.length} effects`
    );
  }

  if (!oracleMatch) {
    mismatches.push(
      `Oracle call mismatch: interp=${interpResult.oracleCallCount}, compiled=${vmState.oracleCallCount}`
    );
  }

  return {
    outputsMatch,
    effectsMatch,
    oracleMatch,
    interpOutput: interpResult.result,
    compiledOutput: compiledResult,
    interpEffects: interpResult.effectTrace,
    compiledEffects: vmState.effectTrace,
    interpOracleCalls: interpResult.oracleCallCount,
    compiledOracleCalls: vmState.oracleCallCount,
    mismatches,
    passed: outputsMatch && effectsMatch && oracleMatch,
  };
}

/**
 * Compare two effect traces.
 */
export function compareEffectTraces(
  interp: EffectTraceEntry[],
  compiled: EffectTraceEntry[],
  strict: boolean
): boolean {
  if (strict) {
    // Strict: exact match
    if (interp.length !== compiled.length) return false;

    for (let i = 0; i < interp.length; i++) {
      if (interp[i].op !== compiled[i].op) return false;
      if (interp[i].argsDigest !== compiled[i].argsDigest) return false;
    }

    return true;
  } else {
    // Pragmatic: compiled may have fewer effects if outputs match
    // Just check that all interp effects appear in compiled
    for (const interpEffect of interp) {
      const found = compiled.some(
        c => c.op === interpEffect.op && c.argsDigest === interpEffect.argsDigest
      );
      if (!found) return false;
    }
    return true;
  }
}

/**
 * Create evidence from differential test result.
 */
export function createTestEvidence(
  report: DifferentialReport,
  testId: string
): EvidenceRef {
  return {
    kind: "test-run",
    ref: sha256JSON({ testId, report }),
    timestamp: Date.now(),
  };
}

/**
 * Satisfy differential test obligation.
 */
export function satisfyDifferentialObligation(
  obligations: CompilerObligation[],
  report: DifferentialReport,
  testId: string
): { obligations: CompilerObligation[]; evidence: EvidenceRef | null } {
  const evidence = report.passed ? createTestEvidence(report, testId) : null;

  const updated = obligations.map(o => {
    if (o.kind === "differential-test" && o.status === "pending") {
      return {
        ...o,
        status: report.passed ? ("satisfied" as const) : ("failed" as const),
        evidence: evidence?.ref,
        error: report.passed ? undefined : report.mismatches.join("; "),
      };
    }
    return o;
  });

  return { obligations: updated, evidence };
}

// ─────────────────────────────────────────────────────────────────
// Metamorphic Testing
// ─────────────────────────────────────────────────────────────────

/**
 * Run metamorphic test: f(g(x)) == g(f(x)) for commutative operations.
 */
export function metamorphicTest(
  expr1: Expr,
  expr2: Expr,
  env: Map<string, Val> = new Map(),
  maxOps: number = 50
): { passed: boolean; result1: Val; result2: Val } {
  const handlers = createDefaultHandlers();

  const compiled1 = compile(expr1, { target: "anf" });
  const compiled2 = compile(expr2, { target: "anf" });

  const anf1 = compiled1.program.program as ANFProgram;
  const anf2 = compiled2.program.program as ANFProgram;

  const result1 = interpretANF(anf1, env, handlers, maxOps).result;
  const result2 = interpretANF(anf2, env, handlers, maxOps).result;

  return {
    passed: valEqual(result1, result2),
    result1,
    result2,
  };
}

// ─────────────────────────────────────────────────────────────────
// Test Harness
// ─────────────────────────────────────────────────────────────────

/**
 * Full differential test harness.
 */
export function runDifferentialTestSuite(
  testCases: Array<{ name: string; expr: Expr; env?: Map<string, Val> }>,
  config: { maxOps?: number; strict?: boolean } = {}
): { passed: number; failed: number; reports: Map<string, DifferentialReport> } {
  let passed = 0;
  let failed = 0;
  const reports = new Map<string, DifferentialReport>();

  for (const testCase of testCases) {
    const report = differentialRun(testCase.expr, testCase.env, config);
    reports.set(testCase.name, report);

    if (report.passed) {
      passed++;
    } else {
      failed++;
    }
  }

  return { passed, failed, reports };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/expander.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "../../outcome/diagnostic";
import { errorDiag } from "../../outcome/diagnostic";
import type { ExpandResult, Form, MacroDefinition, MacroEnv, PatternRule } from "./types";

const ERR_NO_PATTERN = "E1000";

export function createMacroEnv(): MacroEnv {
  return {
    macros: new Map(),
    gensymCounter: 0,
    hygieneContext: { scope: 0, marks: new Set(), renames: new Map() },
  };
}

export function defineMacro(env: MacroEnv, name: string, def: Omit<MacroDefinition, "name">): void {
  env.macros.set(name, { name, ...def });
}

export function gensym(env: MacroEnv, prefix = "g"): string {
  const id = `${prefix}$${env.gensymCounter++}`;
  return id;
}

export function expandModule(forms: Form[], env: MacroEnv): ExpandResult[] {
  return forms.map(f => expand(f, env));
}

export function expand(form: Form, env: MacroEnv): ExpandResult {
  const diagnostics: Diagnostic[] = [];

  if (form.tag !== "List" || !form.children || form.children.length === 0) {
    return { ok: true, form, diagnostics, macrosUsed: [] };
  }

  const head = form.children[0];
  const macroName = head.tag === "Symbol" ? String(head.value) : null;

  if (macroName && env.macros.has(macroName)) {
    const macro = env.macros.get(macroName)!;
    const args = form.children.slice(1);
    const expanded = applyMacro(macro, macroName, args, env, diagnostics);
    if (!expanded) {
      return { ok: false, form, diagnostics, macrosUsed: [macroName] };
    }
    const marked = markExpanded(expanded, form);
    return { ok: diagnostics.length === 0, form: marked, diagnostics, macrosUsed: [macroName] };
  }

  // No macro: expand children recursively
  const newChildren = form.children.map(child => expand(child, env).form);
  return {
    ok: true,
    macrosUsed: [],
    diagnostics,
    form: { ...form, children: newChildren },
  };
}

function applyMacro(
  macro: MacroDefinition,
  macroName: string,
  args: Form[],
  env: MacroEnv,
  diagnostics: Diagnostic[]
): Form | null {
  if (macro.transformer) {
    return macro.transformer(args, env);
  }

  if (!macro.patterns || macro.patterns.length === 0) {
    diagnostics.push(errorDiag(ERR_NO_PATTERN, `Macro ${macroName} has no patterns`));
    return null;
  }

  for (const rule of macro.patterns) {
    const bindings = matchPattern(rule.pattern, args, macroName);
    if (!bindings) continue;
    if (rule.guards && !rule.guards(bindings)) continue;
    return instantiateTemplate(rule.template, bindings);
  }

  diagnostics.push(errorDiag(ERR_NO_PATTERN, `No matching pattern for macro ${macroName}`));
  return null;
}

function matchPattern(pattern: Form, args: Form[], macroName: string): Map<string, Form> | null {
  // Expect pattern to be a list with the macro name as head
  if (pattern.tag !== "List" || !pattern.children) return null;
  if (pattern.children.length === 0) return null;
  const [head, ...patArgs] = pattern.children;
  if (head.tag !== "Symbol" || head.value !== macroName) return null;
  if (patArgs.length !== args.length) return null;

  const bindings = new Map<string, Form>();
  for (let i = 0; i < patArgs.length; i++) {
    if (!matchForm(patArgs[i], args[i], bindings)) return null;
  }
  return bindings;
}

function matchForm(pattern: Form, value: Form, bindings: Map<string, Form>): boolean {
  if (pattern.tag === "Symbol") {
    const name = String(pattern.value);
    bindings.set(name, value);
    return true;
  }

  if (pattern.tag !== value.tag) return false;

  if ((pattern.tag === "List" || pattern.tag === "Vector" || pattern.tag === "Map") && pattern.children) {
    if (!value.children || pattern.children.length !== value.children.length) return false;
    for (let i = 0; i < pattern.children.length; i++) {
      if (!matchForm(pattern.children[i], value.children[i], bindings)) return false;
    }
    return true;
  }

  return pattern.value === value.value;
}

function instantiateTemplate(template: Form, bindings: Map<string, Form>): Form {
  if (template.tag === "Symbol") {
    const name = String(template.value);
    if (bindings.has(name)) {
      const bound = bindings.get(name)!;
      return { ...bound, meta: { ...bound.meta, macroExpanded: true } };
    }
  }

  if (template.children) {
    const children = template.children.map(child => instantiateTemplate(child, bindings));
    return { ...template, children, meta: { ...template.meta, macroExpanded: true } };
  }

  return { ...template, meta: { ...template.meta, macroExpanded: true } };
}

function markExpanded(expanded: Form, original: Form): Form {
  const mark = (f: Form): Form => {
    const meta = { ...f.meta, macroExpanded: true, originalForm: original };
    const children = f.children?.map(mark);
    return { ...f, meta, children };
  };
  return mark(expanded);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/flowPipeline.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowCompileConfig, FlowCompileResult } from "./types";
import { defaultFlowCompileConfig } from "./pipelineDefaults";
import { readForms } from "./reader";
import { createMacroEnv, expandModule } from "./expander";
import { desugarForm } from "./desugar";
import { createLowerEnv, lowerCoreForm } from "./lower";
import { normalizeFlowIR } from "./normalize";
import { buildSourceMap } from "./sourcemap";
import { CURRENT_IR_VERSION } from "../../frameir/version";
import type { FlowIR } from "../../frameir/flow";
import type { IRBundle } from "../../frameir/bundle";

export interface FlowCompilePipeline {
  compile(source: string, config?: Partial<FlowCompileConfig>): FlowCompileResult;
}

export function createFlowPipeline(): FlowCompilePipeline {
  return {
    compile(source: string, config?: Partial<FlowCompileConfig>) {
      return compileSource(source, { ...defaultFlowCompileConfig, ...config });
    },
  };
}

function compileSource(source: string, config: FlowCompileConfig): FlowCompileResult {
  const phases: FlowCompileResult["phases"] = {};
  const diagnostics: FlowCompileResult["diagnostics"] = [];

  // Read
  const readResult = readForms(source);
  phases.read = readResult;
  diagnostics.push(...readResult.diagnostics);
  if (!readResult.ok) return { ok: false, diagnostics, phases };

  // Expand
  const macroEnv = createMacroEnv();
  const expandResults = expandModule(readResult.forms, macroEnv);
  expandResults.forEach(r => diagnostics.push(...r.diagnostics));
  if (expandResults.some(r => !r.ok)) {
    phases.expand = expandResults[0];
    return { ok: false, diagnostics, phases };
  }
  const expandedForms = expandResults.map(r => r.form);
  phases.expand = expandResults[0];

  // Desugar (single form support for now)
  const desugarResults = expandedForms.map(f => desugarForm(f));
  desugarResults.forEach(r => diagnostics.push(...r.diagnostics));
  if (desugarResults.some(r => !r.ok)) {
    phases.desugar = desugarResults[0];
    return { ok: false, diagnostics, phases };
  }
  const coreForm = desugarResults[0].coreForm;
  phases.desugar = desugarResults[0];

  // Lower
  const lowerEnv = createLowerEnv();
  const lowerResult = lowerCoreForm(coreForm, lowerEnv);
  phases.lower = lowerResult;
  diagnostics.push(...lowerResult.diagnostics);
  if (!lowerResult.ok || (lowerResult.ir as FlowIR).tag?.startsWith?.("V")) {
    return { ok: false, diagnostics, phases };
  }

  let flow = lowerResult.ir as FlowIR;

  // Normalize
  const normalizeResult = normalizeFlowIR(flow, config.normalize);
  phases.normalize = normalizeResult;
  diagnostics.push(...normalizeResult.diagnostics);
  if (!normalizeResult.ok) return { ok: false, diagnostics, phases };
  flow = normalizeResult.ir;

  const bundle = buildBundle(flow, lowerResult.fnDefs);
  const sourceMap = config.sourceMap ? buildSourceMap(flow, lowerResult.fnDefs) : undefined;

  return {
    ok: diagnostics.length === 0,
    bundle,
    sourceMap,
    diagnostics,
    phases,
  };
}

function buildBundle(entry: FlowIR, fnDefs: IRBundle["fns"][string][]): IRBundle {
  const fns: IRBundle["fns"] = {};
  for (const fn of fnDefs) {
    fns[fn.fnId] = fn;
  }
  return {
    v: CURRENT_IR_VERSION,
    entry,
    fns,
    schemas: {},
    toolContracts: {},
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Compiler Pipeline - Module exports

// ─────────────────────────────────────────────────────────────────
// Types
// ─────────────────────────────────────────────────────────────────

export type {
  // Source mapping
  SourceLocation,
  SourceMapEntry,
  SourceMap,
  // ANF types
  ANFAtom,
  ANFPrim,
  ANFExpr,
  ANFProgram,
  ANFPattern,
  ANFHandler,
  ANFMatchClause,
  // Bytecode types
  Instr,
  BytecodeFunction,
  BytecodeHandler,
  BytecodeProgram,
  // IR union
  IRProgram,
  // Pipeline types
  ObligationKind,
  CompilerObligation,
  EvidenceRef,
  ProgramArtifact,
  PassRecord,
  CompilerPass,
  // Testing types
  EffectTraceEntry,
  DifferentialReport,
  // Optimization types
  CSECandidate,
  OptimizationResult,
  // Configuration
  CompilerConfig,
  VMConfig,
  VMState,
  VMFrame,
} from "./types";

export {
  DEFAULT_COMPILER_CONFIG,
  DEFAULT_VM_CONFIG,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// ANF Conversion
// ─────────────────────────────────────────────────────────────────

export {
  toANF,
  createSourceMap,
  countBindings,
  countEffects,
  findEffectOps,
  anfToString,
} from "./anf";

// ─────────────────────────────────────────────────────────────────
// Bytecode Generation
// ─────────────────────────────────────────────────────────────────

export {
  toBytecode,
  countInstructions,
  countEffectInstructions,
  findEffectOpsInBytecode,
  disassemble,
  disassembleProgram,
} from "./bytecode";

// ─────────────────────────────────────────────────────────────────
// VM Execution
// ─────────────────────────────────────────────────────────────────

export type { EffectHandler, EffectHandlerRegistry } from "./vm";

export {
  defaultVMConfig,
  createDefaultHandlers,
  createVMState,
  step,
  run,
  getResult,
  getSourceLocation,
  getCallStack,
  setBreakpoint,
  atBreakpoint,
} from "./vm";

// ─────────────────────────────────────────────────────────────────
// Optimization Passes
// ─────────────────────────────────────────────────────────────────

export {
  findCSECandidates,
  applyCSE,
  countOracleCalls,
  optimizeCSE,
  eliminateDeadCode,
  optimizeANF,
} from "./optimize";

// ─────────────────────────────────────────────────────────────────
// Compiler Pipeline
// ─────────────────────────────────────────────────────────────────

export type { CompilationResult, CompileProfile } from "./pipeline";

export {
  defaultCompilerConfig,
  storeIR,
  getIR,
  clearIRStore,
  compile,
  createArtifact,
  recordEvidence,
  allObligationsSatisfied,
  getPendingObligations,
  COMPILE_PROFILES,
  compileWithProfile,
  getIRSummary,
  getSourceLocationForIP,
  disassembleFromDigest,
} from "./pipeline";

// ─────────────────────────────────────────────────────────────────
// Differential Testing
// ─────────────────────────────────────────────────────────────────

export type { InterpreterState } from "./differential";

export {
  interpretANF,
  differentialRun,
  compareEffectTraces,
  createTestEvidence,
  satisfyDifferentialObligation,
  metamorphicTest,
  runDifferentialTestSuite,
} from "./differential";

// FlowIR pipeline (Job 014)
export { readForms } from "./reader";
export { createMacroEnv, defineMacro, expandModule, gensym } from "./expander";
export { desugarForm } from "./desugar";
export { createLowerEnv, lowerCoreForm } from "./lower";
export { normalizeFlowIR } from "./normalize";
export { createFlowPipeline, defaultFlowCompileConfig } from "./pipeline";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/lower.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "../../outcome/diagnostic";
import { errorDiag } from "../../outcome/diagnostic";
import type { FlowIR } from "../../frameir/flow";
import type { FnDefIR } from "../../frameir/bundle";
import type { PromptIR } from "../../frameir/prompt";
import type { ValueIR, VRef, VRecord, VList } from "../../frameir/value";
import { CURRENT_IR_VERSION } from "../../frameir/version";
import type { CoreForm, LowerEnv, LowerResult, ValueLiteral } from "./types";

const ERR_UNKNOWN = "E0001";
const ERR_TOOL_CONTRACT = "E0303";

export function createLowerEnv(): LowerEnv {
  return {
    fnDefs: new Map(),
    schemas: new Map(),
    toolContracts: new Map(),
    globals: new Map(),
    capturedVars: new Set(),
  };
}

export function lowerCoreForm(form: CoreForm, env: LowerEnv): LowerResult {
  const diagnostics: Diagnostic[] = [];

  if ((form as any).tag === "literal") {
    return { ok: true, ir: lowerLiteral(form as unknown as ValueLiteral), fnDefs: [], diagnostics };
  }

  switch (form.tag) {
    case "quote": {
      const value = lowerLiteral(form.args[0] as ValueLiteral);
      return { ok: true, ir: value, fnDefs: [], diagnostics };
    }
    case "pure": {
      const value = lowerCoreForm(form.args[0] as CoreForm, env);
      diagnostics.push(...value.diagnostics);
      return {
        ok: diagnostics.length === 0 && value.ok,
        ir: { v: CURRENT_IR_VERSION, tag: "FPure", value: value.ir as ValueIR, meta: { span: spanFor(form) } },
        fnDefs: value.fnDefs,
        diagnostics,
      };
    }
    case "bind": {
      const flowRes = lowerCoreForm(form.args[0] as CoreForm, env);
      const lambdaRes = lowerCoreForm(form.args[1] as CoreForm, env);
      diagnostics.push(...flowRes.diagnostics, ...lambdaRes.diagnostics);

      const fnDef = extractFnDef(lambdaRes);
      if (!fnDef) {
        diagnostics.push(errorDiag(ERR_UNKNOWN, "Bind expects lambda as continuation", { span: form.meta.span }));
        return { ok: false, ir: flowRes.ir as any, fnDefs: [...flowRes.fnDefs, ...lambdaRes.fnDefs], diagnostics };
      }

      const k: VRef = { v: CURRENT_IR_VERSION, tag: "VRef", ref: { kind: "Fn", id: fnDef.fnId } };
      const ir: FlowIR = {
        v: CURRENT_IR_VERSION,
        tag: "FBind",
        flow: flowRes.ir as FlowIR,
        k,
        meta: { span: spanFor(form) },
      };

      return {
        ok: diagnostics.length === 0 && flowRes.ok && lambdaRes.ok,
        ir,
        fnDefs: [...flowRes.fnDefs, ...lambdaRes.fnDefs],
        diagnostics,
      };
    }
    case "infer": {
      const promptRes = lowerCoreForm(form.args[0] as CoreForm, env);
      const opts = form.args[1] ? lowerCoreForm(form.args[1] as CoreForm, env) : null;
      diagnostics.push(...promptRes.diagnostics, ...(opts?.diagnostics ?? []));
      return {
        ok: diagnostics.length === 0 && promptRes.ok && (opts?.ok ?? true),
        ir: {
          v: CURRENT_IR_VERSION,
          tag: "FInfer",
          prompt: promptRes.ir as PromptIR,
          options: opts?.ir as ValueIR | undefined,
          meta: { span: spanFor(form) },
        },
        fnDefs: [...promptRes.fnDefs, ...(opts?.fnDefs ?? [])],
        diagnostics,
      };
    }
    case "tool-call": {
      const tool = lowerCoreForm(form.args[0] as CoreForm, env);
      const args = lowerCoreForm(form.args[1] as CoreForm, env);
      diagnostics.push(...tool.diagnostics, ...args.diagnostics);

      let contract: VRef | undefined;
      if (form.args[2]) {
        const name = (form.args[2] as any)?.args?.[0]?.value ?? (form.args[2] as any)?.value;
        if (!env.toolContracts.has(name)) {
          diagnostics.push(errorDiag(ERR_TOOL_CONTRACT, `Unknown tool contract: ${name}`, { span: form.meta.span }));
        } else {
          contract = { v: CURRENT_IR_VERSION, tag: "VRef", ref: { kind: "ToolContract", id: String(name) } };
        }
      }

      return {
        ok: diagnostics.length === 0 && tool.ok && args.ok,
        ir: {
          v: CURRENT_IR_VERSION,
          tag: "FToolCall",
          tool: tool.ir as ValueIR,
          args: args.ir as ValueIR,
          contract,
          meta: { span: spanFor(form) },
        },
        fnDefs: [...tool.fnDefs, ...args.fnDefs],
        diagnostics,
      };
    }
    case "with-budget":
    case "with-timeout": {
      const budgetRes = lowerCoreForm(form.args[0] as CoreForm, env);
      const flowRes = lowerCoreForm(form.args[1] as CoreForm, env);
      diagnostics.push(...budgetRes.diagnostics, ...flowRes.diagnostics);
      const base = {
        ok: diagnostics.length === 0 && budgetRes.ok && flowRes.ok,
        fnDefs: [...budgetRes.fnDefs, ...flowRes.fnDefs],
        diagnostics,
      };
      if (form.tag === "with-budget") {
        return {
          ...base,
          ir: {
            v: CURRENT_IR_VERSION,
            tag: "FWithBudget",
            budget: budgetRes.ir as ValueIR,
            flow: flowRes.ir as FlowIR,
            meta: { span: spanFor(form) },
          },
        };
      }
      return {
        ...base,
        ir: {
          v: CURRENT_IR_VERSION,
          tag: "FWithTimeout",
          ms: budgetRes.ir as ValueIR,
          flow: flowRes.ir as FlowIR,
          meta: { span: spanFor(form) },
        } as any,
      };
    }
    case "fail": {
      const reason = lowerCoreForm(form.args[0] as CoreForm, env);
      diagnostics.push(...reason.diagnostics);
      return {
        ok: diagnostics.length === 0 && reason.ok,
        ir: { v: CURRENT_IR_VERSION, tag: "FFail", reason: reason.ir as ValueIR, meta: { span: spanFor(form) } },
        fnDefs: reason.fnDefs,
        diagnostics,
      };
    }
    case "branch": {
      const [predForm, thenForm, elseForm] = form.args as CoreForm[];
      const pred = lowerCoreForm(predForm, env);
      const thn = lowerCoreForm(thenForm, env);
      const els = lowerCoreForm(elseForm, env);
      diagnostics.push(...pred.diagnostics, ...thn.diagnostics, ...els.diagnostics);
      return {
        ok: diagnostics.length === 0 && pred.ok && thn.ok && els.ok,
        ir: {
          v: CURRENT_IR_VERSION,
          tag: "FBranch",
          pred: pred.ir as ValueIR,
          then: thn.ir as FlowIR,
          else: els.ir as FlowIR,
          meta: { span: spanFor(form) },
        },
        fnDefs: [...pred.fnDefs, ...thn.fnDefs, ...els.fnDefs],
        diagnostics,
      };
    }
    case "sequence": {
      const children = form.args.map(arg => lowerCoreForm(arg as CoreForm, env));
      children.forEach(r => diagnostics.push(...r.diagnostics));
      return {
        ok: diagnostics.length === 0 && children.every(r => r.ok),
        ir: { v: CURRENT_IR_VERSION, tag: "FSequence", flows: children.map(r => r.ir as FlowIR), meta: { span: spanFor(form) } },
        fnDefs: children.flatMap(r => r.fnDefs),
        diagnostics,
      };
    }
    case "lambda": {
      const paramsLit = form.args[0] as ValueLiteral;
      const bodyForm = form.args[1] as CoreForm;
      const params = Array.isArray(paramsLit.value) ? (paramsLit.value as string[]) : [];
      const bodyRes = lowerCoreForm(bodyForm, env);
      diagnostics.push(...bodyRes.diagnostics);
      const fnId = `fn:${env.fnDefs.size}`;
      const captures = computeCaptures(bodyRes.ir as any, params, env);
      const fn: FnDefIR = {
        v: CURRENT_IR_VERSION,
        tag: "FnDef",
        fnId,
        params,
        body: bodyRes.ir as FlowIR | ValueIR,
        captures,
        meta: { span: spanFor(form) },
      };
      return {
        ok: diagnostics.length === 0 && bodyRes.ok,
        ir: { v: CURRENT_IR_VERSION, tag: "VRef", ref: { kind: "Fn", id: fnId } },
        fnDefs: [...bodyRes.fnDefs, fn],
        diagnostics,
      };
    }
    default:
      diagnostics.push(errorDiag(ERR_UNKNOWN, `Unknown core form: ${form.tag}`, { span: form.meta.span }));
      return { ok: false, ir: null as any, fnDefs: [], diagnostics };
  }
}

function lowerLiteral(lit: ValueLiteral): ValueIR {
  const value = lit.value;
  if (typeof value === "number") {
    return { v: CURRENT_IR_VERSION, tag: "VInt", value: String(value) };
  }
  if (typeof value === "boolean") {
    return { v: CURRENT_IR_VERSION, tag: "VBool", value };
  }
  if (value === null || typeof value === "undefined") {
    return { v: CURRENT_IR_VERSION, tag: "VNil" };
  }
  if (typeof value === "string") {
    if (value.startsWith(":")) return { v: CURRENT_IR_VERSION, tag: "VKeyword", name: value.slice(1) } as any;
    return { v: CURRENT_IR_VERSION, tag: "VStr", value };
  }
  if (Array.isArray(value)) {
    const items = value.map(v => lowerLiteral({ tag: "literal", meta: lit.meta, value: v }));
    return { v: CURRENT_IR_VERSION, tag: "VList", items } as VList;
  }
  if (typeof value === "object" && "tag" in (value as any)) {
    return value as ValueIR;
  }
  if (typeof value === "object") {
    const entries = Object.entries(value as Record<string, unknown>).map(([k, v]) => ({
      k: { v: CURRENT_IR_VERSION, tag: "VKeyword", name: k } as any,
      v: lowerLiteral({ tag: "literal", meta: lit.meta, value: v }),
    }));
    return { v: CURRENT_IR_VERSION, tag: "VRecord", entries } as VRecord;
  }
  return { v: CURRENT_IR_VERSION, tag: "VStr", value: String(value) };
}

function extractFnDef(res: LowerResult): FnDefIR | null {
  const fn = res.fnDefs.find(def => def.tag === "FnDef");
  return fn ?? null;
}

function computeCaptures(body: FlowIR | ValueIR, params: string[], env: LowerEnv): ValueIR | undefined {
  // Simple capture: use globals present in env.globals but not params
  const captures: Record<string, ValueIR> = {};
  for (const [name, value] of env.globals.entries()) {
    if (!params.includes(name)) {
      captures[name] = value;
    }
  }
  const entries = Object.entries(captures).map(([k, v]) => ({
    k: { v: CURRENT_IR_VERSION, tag: "VSymbol", name: k } as any,
    v,
  }));
  if (entries.length === 0) return undefined;
  return { v: CURRENT_IR_VERSION, tag: "VRecord", entries } as VRecord;
}

function spanFor(form: CoreForm | ValueLiteral): any {
  const meta: any = (form as any).meta;
  if (meta?.originalForm?.children?.[0]?.meta?.span) {
    return meta.originalForm.children[0].meta.span;
  }
  return meta?.span ?? undefined;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/normalize.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "../../outcome/diagnostic";
import type { FlowIR } from "../../frameir/flow";
import type { ValueIR } from "../../frameir/value";
import { normalizeFlow } from "../../frameir/normalize";
import { hashNode } from "../../frameir/hash";
import { CURRENT_IR_VERSION } from "../../frameir/version";
import type { NormalizeConfigFlow, NormalizeResultFlow, RewriteRecord } from "./types";

export function normalizeFlowIR(flow: FlowIR, config: NormalizeConfigFlow): NormalizeResultFlow {
  const diagnostics: Diagnostic[] = [];
  const rewrites: RewriteRecord[] = [];

  let current = config.flattenPrompts || config.flattenSequences ? normalizeFlow(flow) : flow;

  if (config.insertImplicitTimeouts) {
    const before = hashNode(current);
    current = {
      v: CURRENT_IR_VERSION,
      tag: "FWithTimeout",
      ms: timeoutValue(config),
      flow: current,
      meta: current.meta,
    } as any;
    rewrites.push({
      kind: "implicit-timeout",
      before,
      after: hashNode(current),
      location: current.meta?.span,
    });
  }

  if (config.insertImplicitBudgets) {
    const before = hashNode(current);
    current = {
      v: CURRENT_IR_VERSION,
      tag: "FWithBudget",
      budget: budgetValue(config),
      flow: current,
      meta: current.meta,
    } as any;
    rewrites.push({
      kind: "implicit-budget",
      before,
      after: hashNode(current),
      location: current.meta?.span,
    });
  }

  return {
    ok: diagnostics.length === 0,
    ir: current,
    rewrites,
    diagnostics,
  };
}

function budgetValue(config: NormalizeConfigFlow): ValueIR {
  const budget = config.defaultBudget ?? { llmCalls: 0, tokens: 0, timeMs: 0 };
  return {
    v: CURRENT_IR_VERSION,
    tag: "VRecord",
    entries: [
      { k: { v: CURRENT_IR_VERSION, tag: "VKeyword", name: "llmCalls" } as any, v: intVal(budget.llmCalls) },
      { k: { v: CURRENT_IR_VERSION, tag: "VKeyword", name: "tokens" } as any, v: intVal(budget.tokens) },
      { k: { v: CURRENT_IR_VERSION, tag: "VKeyword", name: "timeMs" } as any, v: intVal(budget.timeMs) },
    ],
  } as any;
}

function timeoutValue(config: NormalizeConfigFlow): ValueIR {
  const ms = config.defaultTimeoutMs ?? 0;
  return intVal(ms);
}

function intVal(n: number): ValueIR {
  return { v: CURRENT_IR_VERSION, tag: "VInt", value: String(n) } as any;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/optimize.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/optimize.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Optimization passes for ANF - CSE, fusion, and oracle cost reduction

import { sha256JSON } from "../artifacts/hash";
import type {
  ANFAtom,
  ANFPrim,
  ANFExpr,
  ANFProgram,
  CompilerObligation,
  CSECandidate,
  OptimizationResult,
  ProgramArtifact,
} from "./types";
import { countBindings, findEffectOps } from "./anf";

// ─────────────────────────────────────────────────────────────────
// CSE (Common Subexpression Elimination) for Oracle Calls
// ─────────────────────────────────────────────────────────────────

/**
 * Compute a digest for an ANF primitive (for CSE comparison).
 */
function primDigest(prim: ANFPrim): string {
  // For CSE, we need structural comparison
  // Effects are identified by (op, args) tuple
  if (prim.tag === "Effect") {
    return sha256JSON({ tag: "Effect", op: prim.op, args: prim.args });
  }
  if (prim.tag === "Call") {
    return sha256JSON({ tag: "Call", fn: prim.fn, args: prim.args });
  }
  if (prim.tag === "Prim") {
    return sha256JSON({ tag: "Prim", name: prim.name, args: prim.args });
  }
  // Other primitives (Lambda, Quote, etc.) are not candidates for CSE
  return sha256JSON(prim);
}

/**
 * Check if a primitive is a CSE candidate (pure or idempotent).
 */
function isCSECandidate(prim: ANFPrim): boolean {
  switch (prim.tag) {
    case "Prim":
      // Most built-in primitives are pure
      return true;
    case "Call":
      // Calls to unknown functions are not safe
      return false;
    case "Effect":
      // Effects with these ops are safe to dedupe (idempotent inference)
      return prim.op === "infer.op" || prim.op === "oracle.classify";
    default:
      return false;
  }
}

/**
 * Collect all let bindings with their primitives for CSE analysis.
 */
function collectBindings(
  expr: ANFExpr,
  acc: Array<{ name: string; prim: ANFPrim; digest: string }>
): void {
  switch (expr.tag) {
    case "Let":
      if (isCSECandidate(expr.rhs)) {
        acc.push({ name: expr.name, prim: expr.rhs, digest: primDigest(expr.rhs) });
      }
      collectBindings(expr.body, acc);
      break;
    case "LetRec":
      for (const b of expr.bindings) {
        if (isCSECandidate(b.rhs)) {
          acc.push({ name: b.name, prim: b.rhs, digest: primDigest(b.rhs) });
        }
      }
      collectBindings(expr.body, acc);
      break;
    case "If":
      collectBindings(expr.thn, acc);
      collectBindings(expr.els, acc);
      break;
    case "Seq":
      collectBindings(expr.first, acc);
      collectBindings(expr.second, acc);
      break;
    case "Set":
      collectBindings(expr.body, acc);
      break;
    case "Return":
      // No bindings
      break;
  }
}

/**
 * Find CSE candidates - expressions that appear multiple times.
 */
export function findCSECandidates(program: ANFProgram): CSECandidate[] {
  const bindings: Array<{ name: string; prim: ANFPrim; digest: string }> = [];
  collectBindings(program.body, bindings);

  // Group by digest
  const groups = new Map<string, typeof bindings>();
  for (const b of bindings) {
    const existing = groups.get(b.digest);
    if (existing) {
      existing.push(b);
    } else {
      groups.set(b.digest, [b]);
    }
  }

  // Find duplicates
  const candidates: CSECandidate[] = [];
  for (const [digest, group] of groups) {
    if (group.length > 1) {
      // Check if this is an oracle/effect call
      const isOracleCall = group[0].prim.tag === "Effect" &&
        (group[0].prim.op === "infer.op" || group[0].prim.op.startsWith("oracle"));

      candidates.push({
        exprDigest: digest,
        locations: group.map(b => b.name),
        estimatedSaving: isOracleCall ? group.length - 1 : 0,
        safe: true,
      });
    }
  }

  return candidates;
}

/**
 * Apply CSE transformation to eliminate duplicate expressions.
 */
export function applyCSE(program: ANFProgram): { program: ANFProgram; eliminated: number } {
  const candidates = findCSECandidates(program);

  if (candidates.length === 0) {
    return { program, eliminated: 0 };
  }

  // Build substitution map: later occurrences -> first occurrence
  const substitutions = new Map<string, string>();
  let eliminated = 0;

  for (const candidate of candidates) {
    if (candidate.locations.length > 1) {
      const first = candidate.locations[0];
      for (let i = 1; i < candidate.locations.length; i++) {
        substitutions.set(candidate.locations[i], first);
        eliminated++;
      }
    }
  }

  // Transform the program
  const transformedBody = transformExprCSE(program.body, substitutions);

  return {
    program: {
      body: transformedBody,
      freeVars: program.freeVars,
      defs: program.defs,
    },
    eliminated,
  };
}

/**
 * Transform an ANF expression applying CSE substitutions.
 */
function transformExprCSE(
  expr: ANFExpr,
  substitutions: Map<string, string>
): ANFExpr {
  switch (expr.tag) {
    case "Let": {
      // If this binding is a duplicate, replace with reference to first
      const replacement = substitutions.get(expr.name);
      if (replacement) {
        // Skip this let and substitute in body
        const transformedBody = transformExprCSE(expr.body, substitutions);
        return substituteVar(transformedBody, expr.name, { tag: "Var", name: replacement });
      }

      return {
        tag: "Let",
        name: expr.name,
        rhs: expr.rhs,
        body: transformExprCSE(expr.body, substitutions),
        loc: expr.loc,
      };
    }

    case "LetRec": {
      // Filter out eliminated bindings
      const filteredBindings = expr.bindings.filter(b => !substitutions.has(b.name));

      return {
        tag: "LetRec",
        bindings: filteredBindings,
        body: transformExprCSE(expr.body, substitutions),
        loc: expr.loc,
      };
    }

    case "If":
      return {
        tag: "If",
        test: expr.test,
        thn: transformExprCSE(expr.thn, substitutions),
        els: transformExprCSE(expr.els, substitutions),
        loc: expr.loc,
      };

    case "Seq":
      return {
        tag: "Seq",
        first: transformExprCSE(expr.first, substitutions),
        second: transformExprCSE(expr.second, substitutions),
        loc: expr.loc,
      };

    case "Set":
      return {
        tag: "Set",
        name: expr.name,
        rhs: expr.rhs,
        body: transformExprCSE(expr.body, substitutions),
        loc: expr.loc,
      };

    case "Return":
      return expr;
  }
}

/**
 * Substitute a variable in an ANF expression.
 */
function substituteVar(expr: ANFExpr, oldName: string, newAtom: ANFAtom): ANFExpr {
  function substAtom(atom: ANFAtom): ANFAtom {
    if (atom.tag === "Var" && atom.name === oldName) {
      return newAtom;
    }
    return atom;
  }

  function substPrim(prim: ANFPrim): ANFPrim {
    switch (prim.tag) {
      case "Call":
        return {
          ...prim,
          fn: substAtom(prim.fn),
          args: prim.args.map(substAtom),
        };
      case "Effect":
        return {
          ...prim,
          args: prim.args.map(substAtom),
        };
      case "Prim":
        return {
          ...prim,
          args: prim.args.map(substAtom),
        };
      case "Match":
        return {
          ...prim,
          scrut: substAtom(prim.scrut),
          clauses: prim.clauses.map(c => ({
            ...c,
            body: substituteVar(c.body, oldName, newAtom),
          })),
        };
      case "Handle":
        return {
          ...prim,
          body: substituteVar(prim.body, oldName, newAtom),
          handler: {
            ...prim.handler,
            on: prim.handler.on.map(clause => ({
              ...clause,
              body: substituteVar(clause.body, oldName, newAtom),
            })),
            ret: prim.handler.ret ? {
              ...prim.handler.ret,
              body: substituteVar(prim.handler.ret.body, oldName, newAtom),
            } : undefined,
            fin: prim.handler.fin ? {
              ...prim.handler.fin,
              body: substituteVar(prim.handler.fin.body, oldName, newAtom),
            } : undefined,
          },
        };
      case "Lambda":
        // Don't substitute if the lambda binds the variable
        if (prim.params.includes(oldName)) {
          return prim;
        }
        return {
          ...prim,
          body: substituteVar(prim.body, oldName, newAtom),
        };
      default:
        return prim;
    }
  }

  switch (expr.tag) {
    case "Let":
      // Don't substitute if this let shadows the variable
      if (expr.name === oldName) {
        return {
          ...expr,
          rhs: substPrim(expr.rhs),
        };
      }
      return {
        ...expr,
        rhs: substPrim(expr.rhs),
        body: substituteVar(expr.body, oldName, newAtom),
      };

    case "LetRec":
      // Check if any binding shadows the variable
      if (expr.bindings.some(b => b.name === oldName)) {
        return expr;
      }
      return {
        ...expr,
        bindings: expr.bindings.map(b => ({
          ...b,
          rhs: substPrim(b.rhs),
        })),
        body: substituteVar(expr.body, oldName, newAtom),
      };

    case "If":
      return {
        ...expr,
        test: substAtom(expr.test),
        thn: substituteVar(expr.thn, oldName, newAtom),
        els: substituteVar(expr.els, oldName, newAtom),
      };

    case "Seq":
      return {
        ...expr,
        first: substituteVar(expr.first, oldName, newAtom),
        second: substituteVar(expr.second, oldName, newAtom),
      };

    case "Set":
      return {
        ...expr,
        rhs: substAtom(expr.rhs),
        body: substituteVar(expr.body, oldName, newAtom),
      };

    case "Return":
      return {
        ...expr,
        v: substAtom(expr.v),
      };
  }
}

// ─────────────────────────────────────────────────────────────────
// Oracle Call Counting
// ─────────────────────────────────────────────────────────────────

/**
 * Count potential oracle calls in an ANF program.
 */
export function countOracleCalls(program: ANFProgram): number {
  let count = 0;

  function countPrim(prim: ANFPrim): void {
    if (prim.tag === "Effect" && (prim.op === "infer.op" || prim.op.startsWith("oracle"))) {
      count++;
    }
    if (prim.tag === "Lambda") {
      countExpr(prim.body);
    }
    if (prim.tag === "Handle") {
      countExpr(prim.body);
      for (const clause of prim.handler.on) {
        countExpr(clause.body);
      }
      if (prim.handler.ret) countExpr(prim.handler.ret.body);
      if (prim.handler.fin) countExpr(prim.handler.fin.body);
    }
    if (prim.tag === "Match") {
      for (const clause of prim.clauses) {
        countExpr(clause.body);
      }
    }
  }

  function countExpr(expr: ANFExpr): void {
    switch (expr.tag) {
      case "Let":
        countPrim(expr.rhs);
        countExpr(expr.body);
        break;
      case "LetRec":
        for (const b of expr.bindings) {
          countPrim(b.rhs);
        }
        countExpr(expr.body);
        break;
      case "If":
        countExpr(expr.thn);
        countExpr(expr.els);
        break;
      case "Seq":
        countExpr(expr.first);
        countExpr(expr.second);
        break;
      case "Set":
        countExpr(expr.body);
        break;
      case "Return":
        break;
    }
  }

  countExpr(program.body);
  return count;
}

// ─────────────────────────────────────────────────────────────────
// Optimization Result Computation
// ─────────────────────────────────────────────────────────────────

/**
 * Run CSE optimization and compute result with metrics.
 */
export function optimizeCSE(program: ANFProgram): OptimizationResult {
  const beforeOracleCalls = countOracleCalls(program);
  const beforeBindings = countBindings(program.body);
  const candidates = findCSECandidates(program);

  const { program: optimized, eliminated } = applyCSE(program);

  const afterOracleCalls = countOracleCalls(optimized);
  const afterBindings = countBindings(optimized.body);

  // Generate obligations
  const obligations: CompilerObligation[] = [
    {
      kind: "differential-test",
      description: "CSE optimization must preserve output",
      status: "pending",
    },
    {
      kind: "effect-preservation",
      description: "CSE must not eliminate observable effects",
      status: "pending",
    },
  ];

  return {
    passName: "CSE",
    before: { oracleCalls: beforeOracleCalls, bindings: beforeBindings },
    after: { oracleCalls: afterOracleCalls, bindings: afterBindings },
    candidates,
    obligations,
  };
}

// ─────────────────────────────────────────────────────────────────
// Dead Code Elimination
// ─────────────────────────────────────────────────────────────────

/**
 * Find all variables used in an ANF expression.
 */
function findUsedVars(expr: ANFExpr): Set<string> {
  const used = new Set<string>();

  function addAtom(atom: ANFAtom): void {
    if (atom.tag === "Var") {
      used.add(atom.name);
    }
  }

  function visitPrim(prim: ANFPrim): void {
    switch (prim.tag) {
      case "Call":
        addAtom(prim.fn);
        prim.args.forEach(addAtom);
        break;
      case "Effect":
        prim.args.forEach(addAtom);
        break;
      case "Prim":
        prim.args.forEach(addAtom);
        break;
      case "Lambda":
        visitExpr(prim.body);
        break;
      case "Match":
        addAtom(prim.scrut);
        for (const clause of prim.clauses) {
          visitExpr(clause.body);
        }
        break;
      case "Handle":
        visitExpr(prim.body);
        for (const clause of prim.handler.on) {
          visitExpr(clause.body);
        }
        if (prim.handler.ret) visitExpr(prim.handler.ret.body);
        if (prim.handler.fin) visitExpr(prim.handler.fin.body);
        break;
      case "Quote":
      case "MakeClosure":
        break;
    }
  }

  function visitExpr(e: ANFExpr): void {
    switch (e.tag) {
      case "Let":
        visitPrim(e.rhs);
        visitExpr(e.body);
        break;
      case "LetRec":
        for (const b of e.bindings) {
          visitPrim(b.rhs);
        }
        visitExpr(e.body);
        break;
      case "If":
        addAtom(e.test);
        visitExpr(e.thn);
        visitExpr(e.els);
        break;
      case "Seq":
        visitExpr(e.first);
        visitExpr(e.second);
        break;
      case "Set":
        addAtom(e.rhs);
        visitExpr(e.body);
        break;
      case "Return":
        addAtom(e.v);
        break;
    }
  }

  visitExpr(expr);
  return used;
}

/**
 * Remove dead (unused) bindings.
 */
export function eliminateDeadCode(program: ANFProgram): ANFProgram {
  const used = findUsedVars(program.body);

  function transformExpr(expr: ANFExpr): ANFExpr {
    switch (expr.tag) {
      case "Let":
        // Keep binding if used or if RHS has effects
        if (used.has(expr.name) || hasEffects(expr.rhs)) {
          return {
            ...expr,
            body: transformExpr(expr.body),
          };
        }
        // Skip this binding
        return transformExpr(expr.body);

      case "LetRec":
        const keptBindings = expr.bindings.filter(
          b => used.has(b.name) || hasEffects(b.rhs)
        );
        if (keptBindings.length === 0) {
          return transformExpr(expr.body);
        }
        return {
          ...expr,
          bindings: keptBindings,
          body: transformExpr(expr.body),
        };

      case "If":
        return {
          ...expr,
          thn: transformExpr(expr.thn),
          els: transformExpr(expr.els),
        };

      case "Seq":
        return {
          ...expr,
          first: transformExpr(expr.first),
          second: transformExpr(expr.second),
        };

      case "Set":
        return {
          ...expr,
          body: transformExpr(expr.body),
        };

      case "Return":
        return expr;
    }
  }

  return {
    body: transformExpr(program.body),
    freeVars: program.freeVars,
    defs: program.defs,
  };
}

/**
 * Check if a primitive has side effects.
 */
function hasEffects(prim: ANFPrim): boolean {
  return prim.tag === "Effect" || prim.tag === "Call";
}

// ─────────────────────────────────────────────────────────────────
// Combined Optimization Pipeline
// ─────────────────────────────────────────────────────────────────

/**
 * Run all optimization passes.
 */
export function optimizeANF(
  program: ANFProgram,
  options: { enableCSE?: boolean; enableDCE?: boolean } = {}
): { program: ANFProgram; results: OptimizationResult[] } {
  const results: OptimizationResult[] = [];
  let current = program;

  // CSE pass
  if (options.enableCSE !== false) {
    const cseResult = optimizeCSE(current);
    const { program: cseProgram } = applyCSE(current);
    results.push(cseResult);
    current = cseProgram;
  }

  // DCE pass
  if (options.enableDCE !== false) {
    const beforeBindings = countBindings(current.body);
    current = eliminateDeadCode(current);
    const afterBindings = countBindings(current.body);

    results.push({
      passName: "DCE",
      before: { oracleCalls: countOracleCalls(program), bindings: beforeBindings },
      after: { oracleCalls: countOracleCalls(current), bindings: afterBindings },
      candidates: [],
      obligations: [
        {
          kind: "differential-test",
          description: "DCE must preserve output",
          status: "pending",
        },
      ],
    });
  }

  return { program: current, results };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/pipeline.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/pipeline.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Compiler pipeline with obligation-carrying rewrites

import type { Expr } from "../ast";
import type { Val, IRVal } from "../eval/values";
import { sha256JSON } from "../artifacts/hash";
import type {
  ANFProgram,
  BytecodeProgram,
  IRProgram,
  ProgramArtifact,
  CompilerObligation,
  EvidenceRef,
  PassRecord,
  SourceMap,
  CompilerConfig,
  DEFAULT_COMPILER_CONFIG,
  OptimizationResult,
} from "./types";
import { toANF, createSourceMap, countBindings } from "./anf";
import { toBytecode, countInstructions } from "./bytecode";
import { optimizeANF, optimizeCSE, applyCSE, countOracleCalls } from "./optimize";

// ─────────────────────────────────────────────────────────────────
// Default Configuration
// ─────────────────────────────────────────────────────────────────

export const defaultCompilerConfig: CompilerConfig = {
  target: "anf",
  enableCSE: true,
  enableClosureConversion: false,
  enableDefunctionalization: false,
  enableTCO: true,
  maxInlineDepth: 3,
  profileName: "pragmatic",
  allowCompileTimeInference: false,
  debug: true,
};

// ─────────────────────────────────────────────────────────────────
// IR Store (content-addressed storage for IR programs)
// ─────────────────────────────────────────────────────────────────

/**
 * Global IR store - maps digest to IR program.
 */
const irStore = new Map<string, IRProgram>();

/**
 * Store an IR program and return its digest.
 */
export function storeIR(ir: IRProgram): string {
  const digest = sha256JSON(ir);
  irStore.set(digest, ir);
  return digest;
}

/**
 * Retrieve an IR program by digest.
 */
export function getIR(digest: string): IRProgram | undefined {
  return irStore.get(digest);
}

/**
 * Clear the IR store (for testing).
 */
export function clearIRStore(): void {
  irStore.clear();
}

// ─────────────────────────────────────────────────────────────────
// Compiler Pipeline
// ─────────────────────────────────────────────────────────────────

/**
 * Compilation result with IR and metadata.
 */
export type CompilationResult = {
  /** The compiled IR value */
  ir: IRVal;
  /** The stored IR program */
  program: IRProgram;
  /** Pass records */
  passes: PassRecord[];
  /** Obligations from optimization passes */
  obligations: CompilerObligation[];
  /** Optimization results */
  optimizations: OptimizationResult[];
  /** Source map */
  sourceMap: SourceMap;
};

/**
 * Compile an expression to IR.
 *
 * This is the main compiler entry point implementing the pipeline:
 * 1. Core AST → ANF (lowering)
 * 2. ANF optimization (CSE, DCE)
 * 3. ANF → Bytecode (optional, if target is bytecode)
 * 4. Verification obligations
 */
export function compile(
  expr: Expr,
  config: Partial<CompilerConfig> = {}
): CompilationResult {
  const cfg: CompilerConfig = { ...defaultCompilerConfig, ...config };
  const passes: PassRecord[] = [];
  const obligations: CompilerObligation[] = [];
  const optimizations: OptimizationResult[] = [];
  const sourceMapEntries: SourceMap["entries"] = [];

  const startTime = Date.now();

  // ─────────────────────────────────────────────────────────────
  // Phase 1: Lowering to ANF
  // ─────────────────────────────────────────────────────────────

  const anfProgram = toANF(expr, "source");

  passes.push({
    name: "toANF",
    inputForm: "core-ast",
    outputForm: "anf",
    timestamp: Date.now(),
    metrics: {
      bindings: countBindings(anfProgram.body),
      freeVars: anfProgram.freeVars.length,
    },
  });

  // ─────────────────────────────────────────────────────────────
  // Phase 2: Optimization (governed by profile)
  // ─────────────────────────────────────────────────────────────

  let optimizedANF = anfProgram;

  if (cfg.enableCSE) {
    // Check profile allows optimization
    const profileAllowsCSE = cfg.profileName !== "airgap";

    if (profileAllowsCSE) {
      const { program: cseProgram, results } = optimizeANF(anfProgram, {
        enableCSE: true,
        enableDCE: true,
      });

      optimizedANF = cseProgram;
      optimizations.push(...results);

      // Collect obligations from optimizations
      for (const result of results) {
        obligations.push(...result.obligations);
      }

      passes.push({
        name: "optimize",
        inputForm: "anf",
        outputForm: "anf",
        timestamp: Date.now(),
        metrics: {
          oracleCallsBefore: countOracleCalls(anfProgram),
          oracleCallsAfter: countOracleCalls(optimizedANF),
          bindingsBefore: countBindings(anfProgram.body),
          bindingsAfter: countBindings(optimizedANF.body),
        },
      });
    } else {
      // Profile forbids optimization - record why
      obligations.push({
        kind: "profile-compliance",
        description: `CSE optimization skipped: profile '${cfg.profileName}' forbids it`,
        status: "satisfied",
      });
    }
  }

  // ─────────────────────────────────────────────────────────────
  // Phase 3: Bytecode Generation (if requested)
  // ─────────────────────────────────────────────────────────────

  let irProgram: IRProgram;

  if (cfg.target === "bytecode") {
    const bytecodeProgram = toBytecode(optimizedANF);

    passes.push({
      name: "toBytecode",
      inputForm: "anf",
      outputForm: "bytecode",
      timestamp: Date.now(),
      metrics: {
        instructions: countInstructions(bytecodeProgram),
        functions: bytecodeProgram.functions.length,
      },
    });

    irProgram = { form: "bytecode", program: bytecodeProgram };
  } else {
    irProgram = { form: "anf", program: optimizedANF };
  }

  // ─────────────────────────────────────────────────────────────
  // Phase 4: Store and Create IR Value
  // ─────────────────────────────────────────────────────────────

  const digest = storeIR(irProgram);

  const sourceMap: SourceMap = {
    entries: sourceMapEntries,
  };

  const irVal: IRVal = {
    tag: "IR",
    form: cfg.target,
    digest,
    irRef: digest,
  };

  // Add verification obligations
  obligations.push({
    kind: "differential-test",
    description: "Compiled code must produce same output as interpreter",
    status: "pending",
  });

  obligations.push({
    kind: "effect-preservation",
    description: "Effect emissions must be preserved in compiled code",
    status: "pending",
  });

  return {
    ir: irVal,
    program: irProgram,
    passes,
    obligations,
    optimizations,
    sourceMap,
  };
}

// ─────────────────────────────────────────────────────────────────
// Artifact Creation
// ─────────────────────────────────────────────────────────────────

/**
 * Create a program artifact from an expression.
 */
export function createArtifact(
  expr: Expr,
  config: Partial<CompilerConfig> = {}
): ProgramArtifact {
  const result = compile(expr, config);

  const payload = result.program.form === "anf"
    ? result.program.program
    : result.program.program;

  return {
    form: result.program.form === "anf" ? "anf" : "bytecode",
    payload,
    sourceMap: result.sourceMap,
    obligations: result.obligations,
    evidence: [],
    digest: result.ir.digest,
    passHistory: result.passes,
  };
}

/**
 * Record evidence for a satisfied obligation.
 */
export function recordEvidence(
  artifact: ProgramArtifact,
  obligationIndex: number,
  evidence: EvidenceRef
): ProgramArtifact {
  const obligations = [...artifact.obligations];

  if (obligationIndex >= 0 && obligationIndex < obligations.length) {
    obligations[obligationIndex] = {
      ...obligations[obligationIndex],
      status: "satisfied",
      evidence: evidence.ref,
    };
  }

  return {
    ...artifact,
    obligations,
    evidence: [...artifact.evidence, evidence],
  };
}

/**
 * Check if all obligations are satisfied.
 */
export function allObligationsSatisfied(artifact: ProgramArtifact): boolean {
  return artifact.obligations.every(o => o.status === "satisfied");
}

/**
 * Get pending obligations.
 */
export function getPendingObligations(
  artifact: ProgramArtifact
): CompilerObligation[] {
  return artifact.obligations.filter(o => o.status === "pending");
}

// ─────────────────────────────────────────────────────────────────
// Profile-Governed Compilation
// ─────────────────────────────────────────────────────────────────

/**
 * Profile configuration for compilation.
 */
export type CompileProfile = {
  name: string;
  allowCSE: boolean;
  allowCompileTimeInference: boolean;
  requireDifferentialTest: boolean;
  maxOptimizationPasses: number;
};

/**
 * Built-in compile profiles.
 */
export const COMPILE_PROFILES: Record<string, CompileProfile> = {
  strict: {
    name: "strict",
    allowCSE: false,
    allowCompileTimeInference: false,
    requireDifferentialTest: true,
    maxOptimizationPasses: 0,
  },
  pragmatic: {
    name: "pragmatic",
    allowCSE: true,
    allowCompileTimeInference: false,
    requireDifferentialTest: true,
    maxOptimizationPasses: 10,
  },
  explore: {
    name: "explore",
    allowCSE: true,
    allowCompileTimeInference: true,
    requireDifferentialTest: false,
    maxOptimizationPasses: 20,
  },
  airgap: {
    name: "airgap",
    allowCSE: false,
    allowCompileTimeInference: false,
    requireDifferentialTest: true,
    maxOptimizationPasses: 0,
  },
};

/**
 * Compile with profile governance.
 */
export function compileWithProfile(
  expr: Expr,
  profileName: string,
  additionalConfig: Partial<CompilerConfig> = {}
): CompilationResult {
  const profile = COMPILE_PROFILES[profileName] ?? COMPILE_PROFILES.pragmatic;

  const config: Partial<CompilerConfig> = {
    ...additionalConfig,
    profileName: profile.name,
    enableCSE: profile.allowCSE,
    allowCompileTimeInference: profile.allowCompileTimeInference,
  };

  const result = compile(expr, config);

  // Add profile-specific obligations
  if (profile.requireDifferentialTest) {
    const hasTest = result.obligations.some(o => o.kind === "differential-test");
    if (!hasTest) {
      result.obligations.push({
        kind: "differential-test",
        description: `Profile '${profile.name}' requires differential testing`,
        status: "pending",
      });
    }
  }

  return result;
}

// ─────────────────────────────────────────────────────────────────
// IR Inspection (for ReqObserve)
// ─────────────────────────────────────────────────────────────────

/**
 * Get IR summary for observation.
 */
export function getIRSummary(digest: string): object | undefined {
  const ir = getIR(digest);
  if (!ir) return undefined;

  if (ir.form === "anf") {
    const anf = ir.program as ANFProgram;
    return {
      form: "anf",
      bindings: countBindings(anf.body),
      freeVars: anf.freeVars,
      oracleCalls: countOracleCalls(anf),
    };
  } else {
    const bc = ir.program as BytecodeProgram;
    return {
      form: "bytecode",
      instructions: countInstructions(bc),
      functions: bc.functions.length,
      constants: bc.constants.length,
      freeVars: bc.freeVars,
    };
  }
}

/**
 * Get source location for an IP in bytecode.
 */
export function getSourceLocationForIP(
  digest: string,
  fnId: number,
  ip: number
): object | undefined {
  const ir = getIR(digest);
  if (!ir || ir.form !== "bytecode") return undefined;

  const bc = ir.program as BytecodeProgram;
  const fn = bc.functions[fnId];
  if (!fn || !fn.sourceMap) return undefined;

  const entry = fn.sourceMap.entries.find(e => e.irPos === ip);
  return entry?.loc;
}

/**
 * Disassemble a function from IR.
 */
export function disassembleFromDigest(
  digest: string,
  fnId: number
): string | undefined {
  const ir = getIR(digest);
  if (!ir || ir.form !== "bytecode") return undefined;

  const bc = ir.program as BytecodeProgram;
  const fn = bc.functions[fnId];
  if (!fn) return undefined;

  // Use bytecode disassembler
  const { disassemble } = require("./bytecode");
  return disassemble(fn);
}

// FlowIR compilation pipeline (Job 014)
export { createFlowPipeline } from "./flowPipeline";
export { defaultFlowCompileConfig } from "./pipelineDefaults";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/pipelineDefaults.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowCompileConfig } from "./types";

export const defaultFlowCompileConfig: FlowCompileConfig = {
  normalize: {
    flattenSequences: true,
    flattenPrompts: true,
    insertImplicitBudgets: false,
    insertImplicitTimeouts: false,
  },
  lint: false,
  sourceMap: true,
  debug: false,
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/reader.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "../../outcome/diagnostic";
import { errorDiag } from "../../outcome/diagnostic";
import type { Form, FormMeta, ReadResult } from "./types";

type SpanState = { line: number; col: number };

const ERR_UNBALANCED = "E0002";
const ERR_STRING = "E0003";

export function readForms(source: string, filename = "<stdin>"): ReadResult {
  const diagnostics: Diagnostic[] = [];
  const forms: Form[] = [];

  let idx = 0;
  let pos: SpanState = { line: 1, col: 1 };

  const peek = () => source[idx];
  const eof = () => idx >= source.length;

  function advance(): string {
    const ch = source[idx++];
    if (ch === "\n") {
      pos = { line: pos.line + 1, col: 1 };
    } else {
      pos = { line: pos.line, col: pos.col + 1 };
    }
    return ch;
  }

  function skipWhitespace(): void {
    while (!eof()) {
      const ch = peek();
      if (/\s/.test(ch)) {
        advance();
        continue;
      }
      if (ch === ";") {
        // comment to end of line
        while (!eof() && advance() !== "\n") {
          /* skip */
        }
        continue;
      }
      break;
    }
  }

  function spanFrom(start: SpanState): FormMeta["span"] {
    return {
      file: filename,
      startLine: start.line,
      startCol: start.col,
      endLine: pos.line,
      endCol: pos.col - 1,
    };
  }

  function parseString(start: SpanState): Form | null {
    // consume opening quote
    advance();
    let value = "";
    while (!eof()) {
      const ch = advance();
      if (ch === `"`) {
        return {
          tag: "String",
          value,
          meta: { span: spanFrom(start) },
        };
      }
      if (ch === "\\") {
        const next = advance();
        switch (next) {
          case "n":
            value += "\n";
            break;
          case "t":
            value += "\t";
            break;
          case "\\":
          case `"`:
            value += next;
            break;
          default:
            value += next;
        }
      } else {
        value += ch;
      }
    }

    diagnostics.push(
      errorDiag(ERR_STRING, "Invalid string literal: unterminated", { span: spanFrom(start) })
    );
    return null;
  }

  function parseNumber(start: SpanState, firstChar: string): Form {
    let numStr = firstChar;
    while (!eof() && /[0-9._-]/.test(peek())) {
      numStr += advance();
    }
    const num = Number(numStr);
    return {
      tag: "Number",
      value: num,
      meta: { span: spanFrom(start) },
    };
  }

  function parseSymbol(start: SpanState, firstChar: string): Form {
    let sym = firstChar;
    while (
      !eof() &&
      !/\s/.test(peek()) &&
      !"()[]{}".includes(peek())
    ) {
      sym += advance();
    }
    return {
      tag: sym.startsWith(":") ? "Keyword" : "Symbol",
      value: sym,
      meta: { span: spanFrom(start) },
    };
  }

  function parseDelimited(kind: "List" | "Vector" | "Map", endCh: string): Form | null {
    const start = { ...pos };
    advance(); // consume opener
    const children: Form[] = [];

    while (true) {
      skipWhitespace();
      if (eof()) {
        diagnostics.push(
          errorDiag(ERR_UNBALANCED, "Unbalanced parentheses", { span: spanFrom(start) })
        );
        return null;
      }
      if (peek() === endCh) {
        advance();
        return { tag: kind, value: null, children, meta: { span: spanFrom(start) } };
      }
      const child = parseForm();
      if (!child) return null;
      children.push(child);
    }
  }

  function parseForm(): Form | null {
    skipWhitespace();
    if (eof()) return null;
    const start = { ...pos };
    const ch = peek();

    if (ch === "(") return parseDelimited("List", ")");
    if (ch === "[") return parseDelimited("Vector", "]");
    if (ch === "{") return parseDelimited("Map", "}");
    if (ch === `"`) return parseString(start);
    if (/[0-9]/.test(ch) || (ch === "-" && /[0-9]/.test(source[idx + 1]))) {
      return parseNumber(start, advance());
    }

    return parseSymbol(start, advance());
  }

  while (true) {
    skipWhitespace();
    if (eof()) break;
    const form = parseForm();
    if (!form) {
      break;
    }
    forms.push(form);
  }

  return { ok: diagnostics.length === 0, forms, diagnostics };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/sourcemap.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowIR } from "../../frameir/flow";
import type { FnDefIR } from "../../frameir/bundle";
import type { SourceMap } from "./types";
import { hashNode } from "../../frameir/hash";
import type { Span } from "../../frameir/meta";

export function buildSourceMap(entry: FlowIR, fns: FnDefIR[]): SourceMap {
  const irToSource = new Map<string, Span>();

  const record = (node: { meta?: { span?: Span } } | null | undefined): void => {
    if (!node || !node.meta?.span) return;
    irToSource.set(hashNode(node as any), node.meta.span);
  };

  const visitFlow = (flow: FlowIR): void => {
    record(flow);
    switch (flow.tag) {
      case "FPure":
        record(flow.value as any);
        break;
      case "FBind":
        visitFlow(flow.flow);
        break;
      case "FCatch":
        visitFlow(flow.flow);
        break;
      case "FWithBudget":
      case "FWithTimeout":
        visitFlow(flow.flow);
        break;
      case "FAll":
      case "FAny":
      case "FRace":
      case "FSequence":
        flow.flows.forEach(visitFlow);
        break;
      case "FBranch":
        visitFlow(flow.then);
        visitFlow(flow.else);
        break;
      case "FInfer":
      case "FToolCall":
      case "FValidate":
      case "FCommit":
      case "FEmit":
      case "FObserve":
      case "FSuspend":
        // No child flows to traverse
        break;
      case "FLoop":
        // Treat loop step/until as values
        break;
      default:
        break;
    }
  };

  visitFlow(entry);
  for (const fn of fns) {
    record(fn);
    if ((fn.body as any)?.tag?.startsWith("F")) {
      visitFlow(fn.body as FlowIR);
    }
  }

  return {
    version: 3,
    file: "",
    sourceRoot: "",
    sources: [],
    names: [],
    mappings: "",
    entries: [],
    irToSource,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Compiler Pipeline - Type definitions

import type { Val } from "../eval/values";
import type { Expr } from "../ast";
import type { Hash } from "../artifacts/hash";
import type { FlowIR } from "../../frameir/flow";
import type { ValueIR } from "../../frameir/value";
import type { PromptIR } from "../../frameir/prompt";
import type { IRBundle, FnDefIR } from "../../frameir/bundle";
import type { Span } from "../../frameir/meta";
import type { Diagnostic } from "../../outcome/diagnostic";

// ─────────────────────────────────────────────────────────────────
// Source Location and Source Maps
// ─────────────────────────────────────────────────────────────────

/**
 * Source location in the original program.
 */
export type SourceLocation = {
  /** Source file or expression identifier */
  source: string;
  /** Line number (1-based) */
  line: number;
  /** Column number (1-based) */
  column: number;
  /** Optional end position */
  endLine?: number;
  endColumn?: number;
};

/**
 * Source map entry mapping IR position to source location.
 */
export type SourceMapEntry = {
  /** IR instruction index or ANF binding name */
  irPos: number | string;
  /** Source location */
  loc: SourceLocation;
  /** Lexical scope/frame name for debugging */
  scope?: string;
  /** Local variable names in scope at this point */
  locals?: string[];
};

/**
 * Source map for an IR program.
 */
export type SourceMap = {
  /** Entries mapping IR positions to source */
  entries: SourceMapEntry[];
  /** Original source text (optional, for display) */
  originalSource?: string;
  /** Optional V2 fields for FlowIR pipeline */
  version?: 3;
  file?: string;
  sourceRoot?: string;
  sources?: string[];
  names?: string[];
  mappings?: string;
  /** Map of IR node hash to source span */
  irToSource?: Map<string, Span>;
};

// ─────────────────────────────────────────────────────────────────
// ANF (A-Normal Form) IR
// ─────────────────────────────────────────────────────────────────

/**
 * ANF atomic value - no computation, just a reference.
 */
export type ANFAtom =
  | { tag: "Lit"; v: Val }
  | { tag: "Var"; name: string };

/**
 * ANF primitive operation - the right-hand side of a let binding.
 */
export type ANFPrim =
  | { tag: "Lambda"; params: string[]; body: ANFExpr; label?: string }
  | { tag: "Call"; fn: ANFAtom; args: ANFAtom[] }
  | { tag: "Effect"; op: string; args: ANFAtom[] }    // Preserved effect emission!
  | { tag: "Quote"; datum: unknown }
  | { tag: "Prim"; name: string; args: ANFAtom[] }    // Built-in ops: +, -, etc.
  | { tag: "Match"; scrut: ANFAtom; clauses: ANFMatchClause[] }
  | { tag: "Handle"; body: ANFExpr; handler: ANFHandler }
  | { tag: "MakeClosure"; lambda: ANFPrim; captured: string[] };  // After closure conversion

/**
 * ANF match clause.
 */
export type ANFMatchClause = {
  pat: ANFPattern;
  body: ANFExpr;
};

/**
 * ANF pattern for match expressions.
 */
export type ANFPattern =
  | { tag: "PWild" }
  | { tag: "PVar"; name: string }
  | { tag: "PLit"; v: Val }
  | { tag: "PVector"; items: ANFPattern[] };

/**
 * ANF handler (for Handle expressions).
 */
export type ANFHandler = {
  on: Array<{ op: string; params: string[]; k: string; body: ANFExpr }>;
  ret?: { v: string; body: ANFExpr };
  fin?: { body: ANFExpr };
};

/**
 * ANF expression - either a let binding, conditional, or return.
 */
export type ANFExpr =
  | { tag: "Let"; name: string; rhs: ANFPrim; body: ANFExpr; loc?: SourceLocation }
  | { tag: "LetRec"; bindings: Array<{ name: string; rhs: ANFPrim }>; body: ANFExpr; loc?: SourceLocation }
  | { tag: "If"; test: ANFAtom; thn: ANFExpr; els: ANFExpr; loc?: SourceLocation }
  | { tag: "Seq"; first: ANFExpr; second: ANFExpr; loc?: SourceLocation }  // For begin sequences
  | { tag: "Set"; name: string; rhs: ANFAtom; body: ANFExpr; loc?: SourceLocation }
  | { tag: "Return"; v: ANFAtom; loc?: SourceLocation };

/**
 * ANF program - a complete compiled unit.
 */
export type ANFProgram = {
  /** Top-level expression */
  body: ANFExpr;
  /** Top-level definitions (for modules) */
  defs?: Map<string, ANFPrim>;
  /** Free variables required from environment */
  freeVars: string[];
};

// ─────────────────────────────────────────────────────────────────
// Bytecode IR (Stack-based VM)
// ─────────────────────────────────────────────────────────────────

/**
 * Bytecode instruction.
 */
export type Instr =
  | { op: "CONST"; k: number }                    // Push constant pool[k]
  | { op: "LOAD"; slot: number }                  // Push locals[slot]
  | { op: "STORE"; slot: number }                 // Pop to locals[slot]
  | { op: "GLOAD"; name: string }                 // Load global/free var
  | { op: "GSTORE"; name: string }                // Store global/free var
  | { op: "CLOSURE"; fnId: number; captured: number[] }  // Create closure from fn pool
  | { op: "CALL"; argc: number }                  // Call fn with argc args
  | { op: "TAILCALL"; argc: number }              // Tail call optimization
  | { op: "RET" }                                 // Return top of stack
  | { op: "POP" }                                 // Discard top of stack
  | { op: "DUP" }                                 // Duplicate top of stack
  | { op: "JMP"; label: number }                  // Unconditional jump
  | { op: "JMPIF"; labelTrue: number; labelFalse: number }  // Conditional jump
  | { op: "EFFECT"; opName: string; argc: number }  // Emit algebraic effect!
  | { op: "HANDLE"; handlerId: number }           // Begin handler region
  | { op: "UNHANDLE" }                            // End handler region
  | { op: "PRIM"; name: string; argc: number }    // Primitive operation
  | { op: "MATCH"; clauseLabels: number[] }       // Pattern match dispatch
  | { op: "FAIL"; reasonK: number }               // Fail with reason from constant pool
  | { op: "NOP" }                                 // No operation (for alignment)
  | { op: "DEBUG"; info: string };                // Debug breakpoint/info

/**
 * Bytecode function.
 */
export type BytecodeFunction = {
  /** Function identifier */
  id: number;
  /** Number of parameters */
  arity: number;
  /** Number of local variable slots */
  localCount: number;
  /** Instruction sequence */
  code: Instr[];
  /** Source map for this function */
  sourceMap?: SourceMap;
  /** Label for debugging */
  label?: string;
};

/**
 * Bytecode handler definition.
 */
export type BytecodeHandler = {
  id: number;
  ops: Map<string, { paramSlots: number[]; kSlot: number; codeStart: number }>;
  retSlot?: number;
  retCodeStart?: number;
  finCodeStart?: number;
};

/**
 * Bytecode program - a complete compiled unit.
 */
export type BytecodeProgram = {
  /** Constant pool */
  constants: Val[];
  /** Function pool */
  functions: BytecodeFunction[];
  /** Handler definitions */
  handlers: BytecodeHandler[];
  /** Entry point function ID */
  entryFn: number;
  /** Free variables required from environment */
  freeVars: string[];
  /** Global source map */
  sourceMap: SourceMap;
};

// ─────────────────────────────────────────────────────────────────
// IR Program (Union of ANF and Bytecode)
// ─────────────────────────────────────────────────────────────────

export type IRProgram =
  | { form: "anf"; program: ANFProgram }
  | { form: "bytecode"; program: BytecodeProgram };

// ─────────────────────────────────────────────────────────────────
// Compiler Pipeline Types
// ─────────────────────────────────────────────────────────────────

/**
 * Obligation kind for compiler passes.
 */
export type ObligationKind =
  | "differential-test"    // Must pass differential test against interpreter
  | "metamorphic-test"     // Must pass metamorphic invariant tests
  | "effect-preservation"  // Must preserve effect emissions
  | "ledger-equivalence"   // Must produce equivalent ledger events
  | "profile-compliance";  // Must respect profile constraints

/**
 * Compiler obligation - a proof requirement for a pass.
 */
export type CompilerObligation = {
  kind: ObligationKind;
  description: string;
  /** Status: pending, satisfied, failed */
  status: "pending" | "satisfied" | "failed";
  /** Evidence reference (e.g., test run receipt) */
  evidence?: string;
  /** Error message if failed */
  error?: string;
};

/**
 * Evidence reference for satisfied obligations.
 */
export type EvidenceRef = {
  /** Type of evidence */
  kind: "test-run" | "proof" | "manual-review";
  /** Reference to the evidence (receipt hash, proof hash, etc.) */
  ref: string;
  /** Timestamp */
  timestamp: number;
};

/**
 * Program artifact - output of a compiler pass.
 */
export type ProgramArtifact = {
  /** Form of the artifact */
  form: "core-ast" | "anf" | "bytecode";
  /** The payload (AST, ANF program, or bytecode program) */
  payload: Expr | ANFProgram | BytecodeProgram;
  /** Source map */
  sourceMap: SourceMap;
  /** Attached obligations */
  obligations: CompilerObligation[];
  /** Evidence for satisfied obligations */
  evidence: EvidenceRef[];
  /** Content-addressed digest */
  digest: Hash;
  /** Pass history */
  passHistory: PassRecord[];
};

/**
 * Record of a compiler pass application.
 */
export type PassRecord = {
  /** Pass name */
  name: string;
  /** Input form */
  inputForm: string;
  /** Output form */
  outputForm: string;
  /** Timestamp */
  timestamp: number;
  /** Metrics (e.g., oracle call reduction) */
  metrics?: Record<string, number>;
};

/**
 * Compiler pass function signature.
 */
export type CompilerPass = (artifact: ProgramArtifact) => ProgramArtifact;

// ─────────────────────────────────────────────────────────────────
// Differential Testing Types
// ─────────────────────────────────────────────────────────────────

/**
 * Effect trace entry - records an effect emission.
 */
export type EffectTraceEntry = {
  /** Effect operation name */
  op: string;
  /** Arguments (hashed for comparison) */
  argsDigest: Hash;
  /** Timestamp/ordering */
  seq: number;
  /** Result (if available) */
  result?: Val;
};

/**
 * Differential test report.
 */
export type DifferentialReport = {
  /** Did outputs match? */
  outputsMatch: boolean;
  /** Did effect traces match? */
  effectsMatch: boolean;
  /** Did oracle consumption match? */
  oracleMatch: boolean;
  /** Interpreter output */
  interpOutput: Val;
  /** Compiled output */
  compiledOutput: Val;
  /** Interpreter effect trace */
  interpEffects: EffectTraceEntry[];
  /** Compiled effect trace */
  compiledEffects: EffectTraceEntry[];
  /** Interpreter oracle calls */
  interpOracleCalls: number;
  /** Compiled oracle calls */
  compiledOracleCalls: number;
  /** Any mismatches found */
  mismatches: string[];
  /** Overall pass/fail */
  passed: boolean;
};

// ─────────────────────────────────────────────────────────────────
// Optimization Types
// ─────────────────────────────────────────────────────────────────

/**
 * CSE (Common Subexpression Elimination) candidate.
 */
export type CSECandidate = {
  /** Expression being duplicated */
  exprDigest: Hash;
  /** Locations of duplicates */
  locations: string[];
  /** Estimated oracle call savings */
  estimatedSaving: number;
  /** Whether it's safe to eliminate (pure or idempotent) */
  safe: boolean;
};

/**
 * Optimization result with before/after metrics.
 */
export type OptimizationResult = {
  /** Pass name */
  passName: string;
  /** Before metrics */
  before: { oracleCalls: number; bindings: number; instructions?: number };
  /** After metrics */
  after: { oracleCalls: number; bindings: number; instructions?: number };
  /** Candidates found and applied */
  candidates: CSECandidate[];
  /** Obligations generated */
  obligations: CompilerObligation[];
};

// ─────────────────────────────────────────────────────────────────
// Compiler Configuration
// ─────────────────────────────────────────────────────────────────

/**
 * Compiler configuration options.
 */
export type CompilerConfig = {
  /** Target IR form */
  target: "anf" | "bytecode";
  /** Enable CSE optimization */
  enableCSE: boolean;
  /** Enable closure conversion */
  enableClosureConversion: boolean;
  /** Enable defunctionalization */
  enableDefunctionalization: boolean;
  /** Enable tail call optimization */
  enableTCO: boolean;
  /** Maximum inlining depth */
  maxInlineDepth: number;
  /** Profile for governance constraints */
  profileName: string;
  /** Whether compile-time inference is allowed */
  allowCompileTimeInference: boolean;
  /** Debug mode (include extra source map info) */
  debug: boolean;
};

/**
 * Default compiler configuration.
 */
export const DEFAULT_COMPILER_CONFIG: CompilerConfig = {
  target: "anf",
  enableCSE: true,
  enableClosureConversion: false,
  enableDefunctionalization: false,
  enableTCO: true,
  maxInlineDepth: 3,
  profileName: "pragmatic",
  allowCompileTimeInference: false,
  debug: true,
};

// ─────────────────────────────────────────────────────────────────
// VM State Types
// ─────────────────────────────────────────────────────────────────

/**
 * VM stack frame.
 */
export type VMFrame = {
  /** Function ID being executed */
  fnId: number;
  /** Instruction pointer */
  ip: number;
  /** Local variable slots */
  locals: Val[];
  /** Return address (fnId, ip) */
  returnAddr?: { fnId: number; ip: number };
  /** Source location for debugging */
  sourceLoc?: SourceLocation;
};

/**
 * VM execution state.
 */
export type VMState = {
  /** Value stack */
  stack: Val[];
  /** Call stack (frames) */
  frames: VMFrame[];
  /** Current frame index */
  currentFrame: number;
  /** Handler stack */
  handlerStack: { handlerId: number; frameIndex: number }[];
  /** Global environment */
  globals: Map<string, Val>;
  /** Effect trace */
  effectTrace: EffectTraceEntry[];
  /** Oracle call count */
  oracleCallCount: number;
  /** Execution status */
  status: "running" | "paused" | "completed" | "error";
  /** Error message if status is error */
  error?: string;
  /** Fuel/operation limit remaining */
  fuel: number;
};

/**
 * VM configuration.
 */
export type VMConfig = {
  /** Maximum operation count (fuel) */
  maxOperations: number;
  /** Maximum stack depth */
  maxStackDepth: number;
  /** Maximum call depth */
  maxCallDepth: number;
  /** Enable stepping mode */
  stepping: boolean;
  /** Breakpoints (by instruction index) */
  breakpoints: Set<number>;
};

/**
 * Default VM configuration.
 */
export const DEFAULT_VM_CONFIG: VMConfig = {
  maxOperations: 50,  // Low default for safety
  maxStackDepth: 1000,
  maxCallDepth: 100,
  stepping: false,
  breakpoints: new Set(),
};

// ============================================================
// FlowIR compilation pipeline (Job 014)
// ============================================================

export type FormTag =
  | "Atom"
  | "Symbol"
  | "Keyword"
  | "Number"
  | "String"
  | "List"
  | "Vector"
  | "Map";

export interface FormMeta {
  span: Span;
  macroExpanded?: boolean;
  originalForm?: Form;
}

export interface Form {
  tag: FormTag;
  meta: FormMeta;
  value: unknown;
  children?: Form[];
}

export interface ReadResult {
  ok: boolean;
  forms: Form[];
  diagnostics: Diagnostic[];
}

export interface MacroEnv {
  macros: Map<string, MacroDefinition>;
  gensymCounter: number;
  hygieneContext: HygieneContext;
}

export interface MacroDefinition {
  name: string;
  transformer?: (args: Form[], env: MacroEnv) => Form;
  patterns?: PatternRule[];
}

export interface PatternRule {
  pattern: Form;
  template: Form;
  guards?: (bindings: Map<string, Form>) => boolean;
}

export interface HygieneContext {
  scope: number;
  marks: Set<number>;
  renames: Map<string, string>;
}

export interface ExpandResult {
  ok: boolean;
  form: Form;
  diagnostics: Diagnostic[];
  macrosUsed: string[];
}

export type CoreFormTag =
  | "quote"
  | "if"
  | "lambda"
  | "let"
  | "letrec"
  | "begin"
  | "set!"
  | "define"
  | "pure"
  | "bind"
  | "fail"
  | "catch"
  | "with-budget"
  | "with-timeout"
  | "infer"
  | "tool-call"
  | "validate"
  | "commit"
  | "emit"
  | "observe"
  | "all"
  | "race"
  | "any"
  | "sequence"
  | "branch"
  | "loop";

export interface ValueLiteral {
  tag: "literal";
  meta: FormMeta;
  value: unknown;
}

export interface CoreForm {
  tag: CoreFormTag;
  meta: FormMeta;
  args: (CoreForm | ValueLiteral)[];
}

export interface DesugarResult {
  ok: boolean;
  coreForm: CoreForm;
  diagnostics: Diagnostic[];
}

export interface LowerEnv {
  fnDefs: Map<string, FnDefIR>;
  schemas: Map<string, unknown>;
  toolContracts: Map<string, unknown>;
  globals: Map<string, ValueIR>;
  currentFn?: string;
  capturedVars: Set<string>;
}

export interface LowerResult {
  ok: boolean;
  ir: FlowIR | ValueIR | PromptIR;
  fnDefs: FnDefIR[];
  diagnostics: Diagnostic[];
}

export interface NormalizeConfigFlow {
  flattenSequences: boolean;
  flattenPrompts: boolean;
  insertImplicitBudgets: boolean;
  insertImplicitTimeouts: boolean;
  defaultBudget?: {
    llmCalls: number;
    tokens: number;
    timeMs: number;
  };
  defaultTimeoutMs?: number;
}

export interface RewriteRecord {
  kind: string;
  location?: Span;
  before: string;
  after: string;
}

export interface NormalizeResultFlow {
  ok: boolean;
  ir: FlowIR;
  rewrites: RewriteRecord[];
  diagnostics: Diagnostic[];
}

export interface FlowCompileConfig {
  normalize: NormalizeConfigFlow;
  lint: boolean;
  sourceMap: boolean;
  debug: boolean;
}

export interface FlowCompileResult {
  ok: boolean;
  bundle?: IRBundle;
  sourceMap?: SourceMap;
  diagnostics: Diagnostic[];
  phases: {
    read?: ReadResult;
    expand?: ExpandResult;
    desugar?: DesugarResult;
    lower?: LowerResult;
    normalize?: NormalizeResultFlow;
  };
}

// Aliases for convenience with Flow pipeline nomenclature
export type NormalizeConfig = NormalizeConfigFlow;
export type CompileConfig = FlowCompileConfig;
export type CompileResult = FlowCompileResult;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/compiler/vm.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/compiler/vm.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Prompt 17: Bytecode VM execution with effect preservation

import type { Val } from "../eval/values";
import { VUnit, VTrue, VFalse } from "../eval/values";
import { sha256JSON } from "../artifacts/hash";
import type {
  BytecodeProgram,
  BytecodeFunction,
  Instr,
  VMState,
  VMFrame,
  VMConfig,
  DEFAULT_VM_CONFIG,
  EffectTraceEntry,
  SourceLocation,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// VM Configuration
// ─────────────────────────────────────────────────────────────────

/**
 * Default VM configuration with conservative limits.
 */
export const defaultVMConfig: VMConfig = {
  maxOperations: 50,
  maxStackDepth: 1000,
  maxCallDepth: 100,
  stepping: false,
  breakpoints: new Set(),
};

// ─────────────────────────────────────────────────────────────────
// Effect Handler Interface
// ─────────────────────────────────────────────────────────────────

/**
 * Effect handler function signature.
 */
export type EffectHandler = (
  op: string,
  args: Val[],
  resume: (result: Val) => Val
) => Val;

/**
 * Effect handler registry.
 */
export type EffectHandlerRegistry = Map<string, EffectHandler>;

/**
 * Create default effect handlers.
 */
export function createDefaultHandlers(): EffectHandlerRegistry {
  const handlers = new Map<string, EffectHandler>();

  // Default infer.op handler (pass through)
  handlers.set("infer.op", (_op, _args, resume) => {
    return resume(VUnit);
  });

  // Default amb.choose handler (take first)
  handlers.set("amb.choose", (_op, args, resume) => {
    if (args.length > 0 && args[0].tag === "Vector" && args[0].items.length > 0) {
      return resume(args[0].items[0]);
    }
    return resume(VUnit);
  });

  return handlers;
}

// ─────────────────────────────────────────────────────────────────
// VM State Management
// ─────────────────────────────────────────────────────────────────

/**
 * Create initial VM state.
 */
export function createVMState(
  program: BytecodeProgram,
  args: Val[] = [],
  globals: Map<string, Val> = new Map(),
  config: VMConfig = defaultVMConfig
): VMState {
  // Initialize globals with free variables
  const globalEnv = new Map(globals);
  for (const freeVar of program.freeVars) {
    if (!globalEnv.has(freeVar)) {
      globalEnv.set(freeVar, VUnit);
    }
  }

  // Create initial frame for entry function
  const entryFn = program.functions[program.entryFn];
  const initialFrame: VMFrame = {
    fnId: program.entryFn,
    ip: 0,
    locals: new Array(entryFn.localCount).fill(VUnit),
  };

  // Set arguments in initial frame
  for (let i = 0; i < args.length && i < initialFrame.locals.length; i++) {
    initialFrame.locals[i] = args[i];
  }

  return {
    stack: [],
    frames: [initialFrame],
    currentFrame: 0,
    handlerStack: [],
    globals: globalEnv,
    effectTrace: [],
    oracleCallCount: 0,
    status: "running",
    fuel: config.maxOperations,
  };
}

/**
 * Get current frame.
 */
function currentFrame(state: VMState): VMFrame {
  return state.frames[state.currentFrame];
}

/**
 * Get current instruction.
 */
function currentInstr(state: VMState, program: BytecodeProgram): Instr | null {
  const frame = currentFrame(state);
  const fn = program.functions[frame.fnId];
  if (frame.ip >= fn.code.length) {
    return null;
  }
  return fn.code[frame.ip];
}

/**
 * Push a value onto the stack.
 */
function push(state: VMState, val: Val): void {
  state.stack.push(val);
}

/**
 * Pop a value from the stack.
 */
function pop(state: VMState): Val {
  if (state.stack.length === 0) {
    throw new Error("VM stack underflow");
  }
  return state.stack.pop()!;
}

/**
 * Peek at top of stack.
 */
function peek(state: VMState): Val {
  if (state.stack.length === 0) {
    throw new Error("VM stack underflow");
  }
  return state.stack[state.stack.length - 1];
}

// ─────────────────────────────────────────────────────────────────
// Primitive Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Execute a primitive operation.
 */
function executePrim(name: string, args: Val[]): Val {
  switch (name) {
    case "+": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return { tag: "Num", n: args[0].n + args[1].n };
      }
      return VUnit;
    }
    case "-": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return { tag: "Num", n: args[0].n - args[1].n };
      }
      return VUnit;
    }
    case "*": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return { tag: "Num", n: args[0].n * args[1].n };
      }
      return VUnit;
    }
    case "/": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num" && args[1].n !== 0) {
        return { tag: "Num", n: args[0].n / args[1].n };
      }
      return VUnit;
    }
    case "=":
    case "eq?": {
      if (args.length >= 2) {
        return valEqual(args[0], args[1]) ? VTrue : VFalse;
      }
      return VFalse;
    }
    case "<": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return args[0].n < args[1].n ? VTrue : VFalse;
      }
      return VFalse;
    }
    case ">": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return args[0].n > args[1].n ? VTrue : VFalse;
      }
      return VFalse;
    }
    case "<=": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return args[0].n <= args[1].n ? VTrue : VFalse;
      }
      return VFalse;
    }
    case ">=": {
      if (args.length >= 2 && args[0].tag === "Num" && args[1].tag === "Num") {
        return args[0].n >= args[1].n ? VTrue : VFalse;
      }
      return VFalse;
    }
    case "not": {
      if (args.length >= 1) {
        return isTruthy(args[0]) ? VFalse : VTrue;
      }
      return VTrue;
    }
    case "cons": {
      if (args.length >= 2) {
        return { tag: "Pair", car: args[0], cdr: args[1] };
      }
      return VUnit;
    }
    case "car": {
      if (args.length >= 1 && args[0].tag === "Pair") {
        return args[0].car;
      }
      return VUnit;
    }
    case "cdr": {
      if (args.length >= 1 && args[0].tag === "Pair") {
        return args[0].cdr;
      }
      return VUnit;
    }
    case "null?": {
      if (args.length >= 1) {
        return args[0].tag === "Unit" ? VTrue : VFalse;
      }
      return VTrue;
    }
    case "pair?": {
      if (args.length >= 1) {
        return args[0].tag === "Pair" ? VTrue : VFalse;
      }
      return VFalse;
    }
    case "identity": {
      return args.length >= 1 ? args[0] : VUnit;
    }
    case "undefined": {
      return VUnit;
    }
    case "string-append": {
      let result = "";
      for (const arg of args) {
        if (arg.tag === "Str") {
          result += arg.s;
        }
      }
      return { tag: "Str", s: result };
    }
    case "string-length": {
      if (args.length >= 1 && args[0].tag === "Str") {
        return { tag: "Num", n: args[0].s.length };
      }
      return { tag: "Num", n: 0 };
    }
    case "vector": {
      return { tag: "Vector", items: args };
    }
    case "vector-ref": {
      if (args.length >= 2 && args[0].tag === "Vector" && args[1].tag === "Num") {
        const idx = args[1].n;
        if (idx >= 0 && idx < args[0].items.length) {
          return args[0].items[idx];
        }
      }
      return VUnit;
    }
    case "vector-length": {
      if (args.length >= 1 && args[0].tag === "Vector") {
        return { tag: "Num", n: args[0].items.length };
      }
      return { tag: "Num", n: 0 };
    }
    default:
      return VUnit;
  }
}

/**
 * Check if two values are equal.
 */
function valEqual(a: Val, b: Val): boolean {
  if (a.tag !== b.tag) return false;

  switch (a.tag) {
    case "Unit":
    case "Uninit":
      return true;
    case "Num":
      return a.n === (b as { tag: "Num"; n: number }).n;
    case "Bool":
      return a.b === (b as { tag: "Bool"; b: boolean }).b;
    case "Str":
      return a.s === (b as { tag: "Str"; s: string }).s;
    case "Sym":
      return a.name === (b as { tag: "Sym"; name: string }).name;
    case "Pair": {
      const bPair = b as { tag: "Pair"; car: Val; cdr: Val };
      return valEqual(a.car, bPair.car) && valEqual(a.cdr, bPair.cdr);
    }
    case "Vector": {
      const bVec = b as { tag: "Vector"; items: Val[] };
      if (a.items.length !== bVec.items.length) return false;
      return a.items.every((item, i) => valEqual(item, bVec.items[i]));
    }
    default:
      // For complex types, use JSON comparison
      return JSON.stringify(a) === JSON.stringify(b);
  }
}

/**
 * Check if a value is truthy.
 */
function isTruthy(val: Val): boolean {
  if (val.tag === "Bool") return val.b;
  if (val.tag === "Unit") return false;
  return true;
}

// ─────────────────────────────────────────────────────────────────
// VM Execution
// ─────────────────────────────────────────────────────────────────

/**
 * Execute a single instruction.
 */
export function step(
  state: VMState,
  program: BytecodeProgram,
  handlers: EffectHandlerRegistry = createDefaultHandlers()
): VMState {
  if (state.status !== "running") {
    return state;
  }

  if (state.fuel <= 0) {
    state.status = "error";
    state.error = "Fuel exhausted (operation limit reached)";
    return state;
  }

  const instr = currentInstr(state, program);
  if (instr === null) {
    state.status = "completed";
    return state;
  }

  const frame = currentFrame(state);
  const fn = program.functions[frame.fnId];

  // Decrement fuel
  state.fuel--;

  try {
    switch (instr.op) {
      case "CONST": {
        const val = program.constants[instr.k];
        push(state, val);
        frame.ip++;
        break;
      }

      case "LOAD": {
        const val = frame.locals[instr.slot];
        push(state, val);
        frame.ip++;
        break;
      }

      case "STORE": {
        const val = pop(state);
        frame.locals[instr.slot] = val;
        frame.ip++;
        break;
      }

      case "GLOAD": {
        const val = state.globals.get(instr.name) ?? VUnit;
        push(state, val);
        frame.ip++;
        break;
      }

      case "GSTORE": {
        const val = pop(state);
        state.globals.set(instr.name, val);
        frame.ip++;
        break;
      }

      case "CLOSURE": {
        // Create a closure value referencing the function
        const closureVal: Val = {
          tag: "Closure",
          params: [],
          body: { tag: "Lit", value: null }, // Placeholder
          env: {} as any,
        };
        // Store fnId in a way we can recover it
        (closureVal as any).vmFnId = instr.fnId;
        (closureVal as any).captured = instr.captured.map(slot => frame.locals[slot]);
        push(state, closureVal);
        frame.ip++;
        break;
      }

      case "CALL": {
        // Pop arguments in reverse order
        const args: Val[] = [];
        for (let i = 0; i < instr.argc; i++) {
          args.unshift(pop(state));
        }

        // Pop function
        const fnVal = pop(state);

        // Check if it's a VM closure
        if ((fnVal as any).vmFnId !== undefined) {
          const targetFnId = (fnVal as any).vmFnId;
          const targetFn = program.functions[targetFnId];

          // Create new frame
          const newFrame: VMFrame = {
            fnId: targetFnId,
            ip: 0,
            locals: new Array(targetFn.localCount).fill(VUnit),
            returnAddr: { fnId: frame.fnId, ip: frame.ip + 1 },
          };

          // Copy arguments to locals
          for (let i = 0; i < args.length && i < newFrame.locals.length; i++) {
            newFrame.locals[i] = args[i];
          }

          // Copy captured values
          const captured = (fnVal as any).captured ?? [];
          for (let i = 0; i < captured.length; i++) {
            if (args.length + i < newFrame.locals.length) {
              newFrame.locals[args.length + i] = captured[i];
            }
          }

          state.frames.push(newFrame);
          state.currentFrame = state.frames.length - 1;
        } else {
          // Native or external function - just push unit
          push(state, VUnit);
          frame.ip++;
        }
        break;
      }

      case "TAILCALL": {
        // Similar to CALL but reuse current frame
        const args: Val[] = [];
        for (let i = 0; i < instr.argc; i++) {
          args.unshift(pop(state));
        }

        const fnVal = pop(state);

        if ((fnVal as any).vmFnId !== undefined) {
          const targetFnId = (fnVal as any).vmFnId;
          const targetFn = program.functions[targetFnId];

          // Reuse frame
          frame.fnId = targetFnId;
          frame.ip = 0;
          frame.locals = new Array(targetFn.localCount).fill(VUnit);

          for (let i = 0; i < args.length && i < frame.locals.length; i++) {
            frame.locals[i] = args[i];
          }
        } else {
          push(state, VUnit);
          frame.ip++;
        }
        break;
      }

      case "RET": {
        const retVal = state.stack.length > 0 ? pop(state) : VUnit;

        if (state.currentFrame > 0) {
          // Return to caller
          const returnAddr = frame.returnAddr;
          state.frames.pop();
          state.currentFrame--;

          push(state, retVal);

          if (returnAddr) {
            currentFrame(state).ip = returnAddr.ip;
          }
        } else {
          // Top-level return
          push(state, retVal);
          state.status = "completed";
        }
        break;
      }

      case "POP": {
        pop(state);
        frame.ip++;
        break;
      }

      case "DUP": {
        const val = peek(state);
        push(state, val);
        frame.ip++;
        break;
      }

      case "JMP": {
        frame.ip = instr.label;
        break;
      }

      case "JMPIF": {
        const test = pop(state);
        if (isTruthy(test)) {
          frame.ip = instr.labelTrue;
        } else {
          frame.ip = instr.labelFalse;
        }
        break;
      }

      case "EFFECT": {
        // Effects are preserved! Pop args and invoke handler
        const args: Val[] = [];
        for (let i = 0; i < instr.argc; i++) {
          args.unshift(pop(state));
        }

        // Record effect in trace
        const traceEntry: EffectTraceEntry = {
          op: instr.opName,
          argsDigest: sha256JSON(args),
          seq: state.effectTrace.length,
        };

        // Track oracle calls
        if (instr.opName === "infer.op") {
          state.oracleCallCount++;
        }

        // Find and invoke handler
        const handler = handlers.get(instr.opName);
        if (handler) {
          // Simple synchronous resume - real impl would be more complex
          const result = handler(instr.opName, args, (r) => r);
          traceEntry.result = result;
          push(state, result);
        } else {
          // No handler - push unit
          push(state, VUnit);
        }

        state.effectTrace.push(traceEntry);
        frame.ip++;
        break;
      }

      case "HANDLE": {
        // Push handler onto handler stack
        state.handlerStack.push({
          handlerId: instr.handlerId,
          frameIndex: state.currentFrame,
        });
        frame.ip++;
        break;
      }

      case "UNHANDLE": {
        // Pop handler from handler stack
        if (state.handlerStack.length > 0) {
          state.handlerStack.pop();
        }
        frame.ip++;
        break;
      }

      case "PRIM": {
        const args: Val[] = [];
        for (let i = 0; i < instr.argc; i++) {
          args.unshift(pop(state));
        }
        const result = executePrim(instr.name, args);
        push(state, result);
        frame.ip++;
        break;
      }

      case "MATCH": {
        // Simplified - just jump to first clause
        if (instr.clauseLabels.length > 0) {
          frame.ip = instr.clauseLabels[0];
        } else {
          frame.ip++;
        }
        break;
      }

      case "FAIL": {
        const reason = program.constants[instr.reasonK];
        state.status = "error";
        state.error = `Fail: ${JSON.stringify(reason)}`;
        break;
      }

      case "NOP": {
        frame.ip++;
        break;
      }

      case "DEBUG": {
        // Debugging instruction - pause if stepping
        frame.ip++;
        break;
      }
    }
  } catch (e) {
    state.status = "error";
    state.error = e instanceof Error ? e.message : String(e);
  }

  return state;
}

/**
 * Run VM until completion or fuel exhaustion.
 */
export function run(
  program: BytecodeProgram,
  args: Val[] = [],
  globals: Map<string, Val> = new Map(),
  config: VMConfig = defaultVMConfig,
  handlers: EffectHandlerRegistry = createDefaultHandlers()
): VMState {
  let state = createVMState(program, args, globals, config);

  while (state.status === "running") {
    state = step(state, program, handlers);
  }

  return state;
}

/**
 * Get the result value from completed VM state.
 */
export function getResult(state: VMState): Val {
  if (state.stack.length > 0) {
    return state.stack[state.stack.length - 1];
  }
  return VUnit;
}

/**
 * Get source location for current instruction.
 */
export function getSourceLocation(
  state: VMState,
  program: BytecodeProgram
): SourceLocation | undefined {
  const frame = currentFrame(state);
  const fn = program.functions[frame.fnId];

  if (fn.sourceMap) {
    const entry = fn.sourceMap.entries.find(e => e.irPos === frame.ip);
    if (entry) {
      return entry.loc;
    }
  }

  return undefined;
}

/**
 * Get call stack for debugging.
 */
export function getCallStack(state: VMState, program: BytecodeProgram): string[] {
  const stack: string[] = [];

  for (const frame of state.frames) {
    const fn = program.functions[frame.fnId];
    const label = fn.label ?? `fn${fn.id}`;
    stack.push(`${label}:${frame.ip}`);
  }

  return stack;
}

/**
 * Set a breakpoint.
 */
export function setBreakpoint(state: VMState, ip: number): void {
  // Would need to track breakpoints in config
}

/**
 * Check if VM is at a breakpoint.
 */
export function atBreakpoint(state: VMState, config: VMConfig): boolean {
  const frame = currentFrame(state);
  return config.breakpoints.has(frame.ip);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/actor.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/actor.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: Actor model with mailboxes

import type { Val, FiberId, ActorVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type { State } from "../eval/machine";
import type { ActorState, ConcurrencyEvent } from "./types";
import { makeActor } from "./types";
import type { SchedulerState } from "./scheduler";
import { spawnFiber, getFiber, blockFiber, unblockFiber } from "./scheduler";

// ─────────────────────────────────────────────────────────────────
// Actor registry
// ─────────────────────────────────────────────────────────────────

const actorRegistry = new Map<string, ActorState>();
let nextActorId = 0;

/**
 * Generate a unique actor ID.
 */
function genActorId(): string {
  return `actor-${nextActorId++}`;
}

/**
 * Reset the actor registry (for testing).
 */
export function resetActorRegistry(): void {
  actorRegistry.clear();
  nextActorId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Actor creation and management
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new actor with a backing fiber.
 */
export function createActor(
  scheduler: SchedulerState,
  initialState: State,
  options: { name?: string; parentId?: FiberId } = {}
): ActorVal {
  const id = genActorId();

  // Spawn the backing fiber
  const fiber = spawnFiber(scheduler, initialState, {
    name: options.name ? `${options.name}-fiber` : undefined,
    parentId: options.parentId,
  });

  const state: ActorState = {
    id,
    name: options.name,
    fiberId: fiber.id,
    mailbox: [],
    processing: false,
  };

  actorRegistry.set(id, state);
  return makeActor(id, fiber.id, options.name);
}

/**
 * Get actor state.
 */
export function getActorState(id: string): ActorState | undefined {
  return actorRegistry.get(id);
}

/**
 * Get the fiber ID for an actor.
 */
export function getActorFiberId(id: string): FiberId | undefined {
  return actorRegistry.get(id)?.fiberId;
}

// ─────────────────────────────────────────────────────────────────
// Message passing
// ─────────────────────────────────────────────────────────────────

/**
 * Send a message to an actor's mailbox.
 * This is asynchronous - the caller does not wait.
 */
export function sendMessage(
  scheduler: SchedulerState,
  actorId: string,
  message: Val,
  onEvent?: (event: ConcurrencyEvent) => void
): boolean {
  const actor = actorRegistry.get(actorId);
  if (!actor) return false;

  // Add message to mailbox
  actor.mailbox.push(message);

  // Wake up the actor's fiber if it's blocked waiting for messages
  const fiber = getFiber(scheduler, actor.fiberId);
  if (fiber && fiber.status === "blocked" && fiber.blockReason?.tag === "channel") {
    // The actor was waiting for messages
    unblockFiber(scheduler, actor.fiberId);
  }

  return true;
}

/**
 * Receive a message from the actor's mailbox.
 * Returns the message if available, undefined if blocked.
 */
export function receiveMessage(
  scheduler: SchedulerState,
  actorId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): Val | undefined {
  const actor = actorRegistry.get(actorId);
  if (!actor) return undefined;

  // Check that this is the actor's fiber
  if (actor.fiberId !== fiberId) return undefined;

  if (actor.mailbox.length > 0) {
    // Get next message
    const message = actor.mailbox.shift()!;
    actor.processing = true;
    return message;
  }

  // No messages, block until one arrives
  blockFiber(scheduler, fiberId, { tag: "channel", channelId: actorId, op: "recv" });
  return undefined;
}

/**
 * Indicate that message processing is complete.
 */
export function messageProcessed(actorId: string): void {
  const actor = actorRegistry.get(actorId);
  if (actor) {
    actor.processing = false;
  }
}

/**
 * Get the number of pending messages in the mailbox.
 */
export function mailboxSize(actorId: string): number {
  const actor = actorRegistry.get(actorId);
  return actor?.mailbox.length ?? 0;
}

/**
 * Check if the actor is currently processing a message.
 */
export function isProcessing(actorId: string): boolean {
  const actor = actorRegistry.get(actorId);
  return actor?.processing ?? false;
}

// ─────────────────────────────────────────────────────────────────
// Actor supervision
// ─────────────────────────────────────────────────────────────────

/**
 * SupervisorStrategy: How to handle actor failures.
 */
export type SupervisorStrategy =
  | { tag: "restart" }           // Restart the failed actor
  | { tag: "stop" }              // Stop the failed actor
  | { tag: "escalate" }          // Propagate failure to supervisor
  | { tag: "resume" };           // Ignore the failure

/**
 * SupervisorState: State of an actor supervisor.
 */
export type SupervisorState = {
  id: string;
  name?: string;
  children: string[];            // Actor IDs
  strategy: SupervisorStrategy;
  restartCount: Map<string, number>;
  maxRestarts: number;
};

const supervisorRegistry = new Map<string, SupervisorState>();
let nextSupervisorId = 0;

/**
 * Create a supervisor.
 */
export function createSupervisor(
  strategy: SupervisorStrategy = { tag: "restart" },
  options: { name?: string; maxRestarts?: number } = {}
): { id: string; supervisor: SupervisorState } {
  const id = `supervisor-${nextSupervisorId++}`;
  const supervisor: SupervisorState = {
    id,
    name: options.name,
    children: [],
    strategy,
    restartCount: new Map(),
    maxRestarts: options.maxRestarts ?? 3,
  };
  supervisorRegistry.set(id, supervisor);
  return { id, supervisor };
}

/**
 * Add an actor to a supervisor.
 */
export function supervisorAddChild(supervisorId: string, actorId: string): boolean {
  const supervisor = supervisorRegistry.get(supervisorId);
  if (!supervisor) return false;

  if (!supervisor.children.includes(actorId)) {
    supervisor.children.push(actorId);
  }
  return true;
}

/**
 * Handle a child actor failure.
 */
export function supervisorHandleFailure(
  scheduler: SchedulerState,
  supervisorId: string,
  actorId: string,
  error: string,
  restartFn: (actorId: string) => ActorVal | undefined
): { action: SupervisorStrategy["tag"]; newActor?: ActorVal } {
  const supervisor = supervisorRegistry.get(supervisorId);
  if (!supervisor) {
    return { action: "stop" };
  }

  switch (supervisor.strategy.tag) {
    case "restart": {
      // Check restart limit
      const restarts = (supervisor.restartCount.get(actorId) ?? 0) + 1;
      supervisor.restartCount.set(actorId, restarts);

      if (restarts > supervisor.maxRestarts) {
        // Too many restarts, stop instead
        return { action: "stop" };
      }

      // Restart the actor
      const newActor = restartFn(actorId);
      return { action: "restart", newActor };
    }

    case "stop":
      return { action: "stop" };

    case "escalate":
      return { action: "escalate" };

    case "resume":
      return { action: "resume" };

    default:
      return { action: "stop" };
  }
}

/**
 * Reset supervisor registry (for testing).
 */
export function resetSupervisorRegistry(): void {
  supervisorRegistry.clear();
  nextSupervisorId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Ask pattern (synchronous request-response)
// ─────────────────────────────────────────────────────────────────

/**
 * AskRequest: A request with a reply-to address.
 */
export type AskRequest = {
  tag: "ask";
  payload: Val;
  replyTo: string;  // IVar ID for the response
};

/**
 * Create an ask request.
 */
export function createAskRequest(payload: Val, replyIVarId: string): Val {
  return {
    tag: "Map",
    entries: [
      [{ tag: "Sym", name: "tag" }, { tag: "Str", s: "ask" }],
      [{ tag: "Sym", name: "payload" }, payload],
      [{ tag: "Sym", name: "replyTo" }, { tag: "Str", s: replyIVarId }],
    ],
  };
}

/**
 * Check if a value is an ask request.
 */
export function isAskRequest(v: Val): boolean {
  if (v.tag !== "Map") return false;
  for (const [k, val] of v.entries) {
    if (k.tag === "Sym" && k.name === "tag" && val.tag === "Str" && val.s === "ask") {
      return true;
    }
  }
  return false;
}

/**
 * Extract the reply-to IVar ID from an ask request.
 */
export function extractReplyTo(v: Val): string | undefined {
  if (v.tag !== "Map") return undefined;
  for (const [k, val] of v.entries) {
    if (k.tag === "Sym" && k.name === "replyTo" && val.tag === "Str") {
      return val.s;
    }
  }
  return undefined;
}

/**
 * Extract the payload from an ask request.
 */
export function extractPayload(v: Val): Val | undefined {
  if (v.tag !== "Map") return undefined;
  for (const [k, val] of v.entries) {
    if (k.tag === "Sym" && k.name === "payload") {
      return val;
    }
  }
  return undefined;
}

// ─────────────────────────────────────────────────────────────────
// Reset all actor registries
// ─────────────────────────────────────────────────────────────────

/**
 * Reset all actor-related registries (for testing).
 */
export function resetAllActorRegistries(): void {
  resetActorRegistry();
  resetSupervisorRegistry();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/critic.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/critic.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: Concurrency critic for deadlock detection and race analysis

import type { Val, FiberId } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type {
  FiberState,
  BlockReason,
  SchedulerState,
  ConcurrencyEvent,
  MutexState,
  IVarState,
  ChannelState,
} from "./types";
import { getMutexState, getIVarState, getChannelState } from "./sync";

// ─────────────────────────────────────────────────────────────────
// Deadlock detection
// ─────────────────────────────────────────────────────────────────

/**
 * DeadlockInfo: Information about a detected deadlock.
 */
export type DeadlockInfo = {
  /** Fibers involved in the deadlock */
  fibers: FiberId[];
  /** Wait-for edges (fiber -> what it's waiting for) */
  waitForGraph: Map<FiberId, { resource: string; holder?: FiberId }>;
  /** The cycle in the wait-for graph */
  cycle: FiberId[];
  /** Human-readable description */
  description: string;
  /** Timestamp of detection */
  detectedAt: number;
};

/**
 * Build a wait-for graph from the scheduler state.
 */
export function buildWaitForGraph(
  scheduler: SchedulerState
): Map<FiberId, { resource: string; holder?: FiberId }> {
  const graph = new Map<FiberId, { resource: string; holder?: FiberId }>();

  for (const [fiberId, fiber] of scheduler.fibers) {
    if (fiber.status !== "blocked" || !fiber.blockReason) continue;

    const reason = fiber.blockReason;
    switch (reason.tag) {
      case "join": {
        graph.set(fiberId, { resource: `fiber:${reason.fiberId}`, holder: reason.fiberId });
        break;
      }

      case "mutex": {
        const mutex = getMutexState(reason.mutexId);
        graph.set(fiberId, {
          resource: `mutex:${reason.mutexId}`,
          holder: mutex?.holder,
        });
        break;
      }

      case "ivar": {
        // IVars don't have holders in the same sense
        graph.set(fiberId, { resource: `ivar:${reason.ivarId}` });
        break;
      }

      case "channel": {
        graph.set(fiberId, {
          resource: `channel:${reason.op}:${reason.channelId}`,
        });
        break;
      }

      case "yield": {
        // Yielded fibers aren't really blocked
        break;
      }
    }
  }

  return graph;
}

/**
 * Detect cycles in the wait-for graph (classic deadlock detection).
 */
export function detectCycle(
  waitForGraph: Map<FiberId, { resource: string; holder?: FiberId }>
): FiberId[] | undefined {
  const visited = new Set<FiberId>();
  const stack = new Set<FiberId>();
  const path: FiberId[] = [];

  function dfs(fiberId: FiberId): FiberId[] | undefined {
    if (stack.has(fiberId)) {
      // Found a cycle
      const cycleStart = path.indexOf(fiberId);
      return path.slice(cycleStart);
    }

    if (visited.has(fiberId)) {
      return undefined;
    }

    visited.add(fiberId);
    stack.add(fiberId);
    path.push(fiberId);

    const edge = waitForGraph.get(fiberId);
    if (edge?.holder !== undefined) {
      const cycle = dfs(edge.holder);
      if (cycle) return cycle;
    }

    path.pop();
    stack.delete(fiberId);
    return undefined;
  }

  for (const fiberId of waitForGraph.keys()) {
    const cycle = dfs(fiberId);
    if (cycle) return cycle;
  }

  return undefined;
}

/**
 * Detect deadlocks in the scheduler.
 */
export function detectDeadlock(scheduler: SchedulerState): DeadlockInfo | undefined {
  // Build wait-for graph
  const waitForGraph = buildWaitForGraph(scheduler);

  // Detect cycle
  const cycle = detectCycle(waitForGraph);
  if (!cycle || cycle.length === 0) {
    return undefined;
  }

  // Build deadlock info
  const description = buildDeadlockDescription(cycle, waitForGraph, scheduler);

  return {
    fibers: cycle,
    waitForGraph,
    cycle,
    description,
    detectedAt: Date.now(),
  };
}

/**
 * Build a human-readable description of a deadlock.
 */
function buildDeadlockDescription(
  cycle: FiberId[],
  waitForGraph: Map<FiberId, { resource: string; holder?: FiberId }>,
  scheduler: SchedulerState
): string {
  const parts: string[] = ["Deadlock detected:"];

  for (let i = 0; i < cycle.length; i++) {
    const fiberId = cycle[i];
    const nextFiberId = cycle[(i + 1) % cycle.length];
    const fiber = scheduler.fibers.get(fiberId);
    const edge = waitForGraph.get(fiberId);

    const fiberName = fiber?.name ?? `fiber-${fiberId}`;
    parts.push(`  ${fiberName} waiting on ${edge?.resource ?? "unknown"}`);
  }

  return parts.join("\n");
}

// ─────────────────────────────────────────────────────────────────
// Race condition detection (static analysis)
// ─────────────────────────────────────────────────────────────────

/**
 * PotentialRace: A potential race condition.
 */
export type PotentialRace = {
  /** Type of race */
  kind: "read-write" | "write-write";
  /** Resource being accessed */
  resource: string;
  /** Fibers involved */
  fibers: FiberId[];
  /** Description */
  description: string;
};

/**
 * AccessRecord: Record of a resource access.
 */
export type AccessRecord = {
  fiberId: FiberId;
  resource: string;
  operation: "read" | "write";
  timestamp: number;
  protected: boolean;  // Was the access protected by a mutex?
};

/**
 * Analyze events for potential race conditions.
 */
export function analyzeRaces(
  events: ConcurrencyEvent[],
  accessRecords: AccessRecord[]
): PotentialRace[] {
  const races: PotentialRace[] = [];

  // Group accesses by resource
  const byResource = new Map<string, AccessRecord[]>();
  for (const record of accessRecords) {
    const existing = byResource.get(record.resource) ?? [];
    existing.push(record);
    byResource.set(record.resource, existing);
  }

  // Check each resource for unprotected concurrent accesses
  for (const [resource, accesses] of byResource) {
    // Filter to unprotected accesses
    const unprotected = accesses.filter(a => !a.protected);
    if (unprotected.length < 2) continue;

    // Check for conflicting accesses from different fibers
    const writes = unprotected.filter(a => a.operation === "write");
    const reads = unprotected.filter(a => a.operation === "read");

    // Write-write races
    const writeFibers = new Set(writes.map(w => w.fiberId));
    if (writeFibers.size > 1) {
      races.push({
        kind: "write-write",
        resource,
        fibers: Array.from(writeFibers),
        description: `Multiple fibers writing to ${resource} without synchronization`,
      });
    }

    // Read-write races
    if (writes.length > 0 && reads.length > 0) {
      const readFibers = new Set(reads.map(r => r.fiberId));
      for (const write of writes) {
        for (const readFiber of readFibers) {
          if (readFiber !== write.fiberId) {
            races.push({
              kind: "read-write",
              resource,
              fibers: [write.fiberId, readFiber],
              description: `Fiber ${write.fiberId} writes to ${resource} while fiber ${readFiber} reads without synchronization`,
            });
          }
        }
      }
    }
  }

  return races;
}

// ─────────────────────────────────────────────────────────────────
// Schedule exploration (for finding bugs)
// ─────────────────────────────────────────────────────────────────

/**
 * ScheduleExplorationConfig: Configuration for schedule exploration.
 */
export type ScheduleExplorationConfig = {
  /** Maximum number of schedules to explore */
  maxSchedules: number;
  /** Maximum steps per schedule */
  maxStepsPerSchedule: number;
  /** Random seed for deterministic exploration */
  seed: number;
  /** Stop on first failure? */
  stopOnFirstFailure: boolean;
};

export const DEFAULT_EXPLORATION_CONFIG: ScheduleExplorationConfig = {
  maxSchedules: 100,
  maxStepsPerSchedule: 10000,
  seed: 12345,
  stopOnFirstFailure: true,
};

/**
 * ScheduleExplorationResult: Result of schedule exploration.
 */
export type ScheduleExplorationResult = {
  /** Number of schedules explored */
  schedulesExplored: number;
  /** Schedules that led to deadlock */
  deadlockSchedules: Array<{ decisions: number[]; info: DeadlockInfo }>;
  /** Schedules that led to errors */
  errorSchedules: Array<{ decisions: number[]; fiberId: FiberId; error: string }>;
  /** All unique outcomes observed */
  outcomes: Map<Hash, { count: number; decisions: number[] }>;
  /** Exploration statistics */
  stats: {
    totalSteps: number;
    deadlocks: number;
    errors: number;
    successful: number;
  };
};

/**
 * Explore different schedules to find concurrency bugs.
 * This is a simplified DPOR/PCT-style exploration.
 */
export function exploreSchedules(
  createScheduler: () => { scheduler: SchedulerState; runFn: () => void },
  config: Partial<ScheduleExplorationConfig> = {}
): ScheduleExplorationResult {
  const fullConfig: ScheduleExplorationConfig = {
    ...DEFAULT_EXPLORATION_CONFIG,
    ...config,
  };

  const result: ScheduleExplorationResult = {
    schedulesExplored: 0,
    deadlockSchedules: [],
    errorSchedules: [],
    outcomes: new Map(),
    stats: {
      totalSteps: 0,
      deadlocks: 0,
      errors: 0,
      successful: 0,
    },
  };

  // Simple random exploration with different seeds
  for (let i = 0; i < fullConfig.maxSchedules; i++) {
    const seed = fullConfig.seed + i;
    result.schedulesExplored++;

    // Create scheduler with random policy
    const { scheduler, runFn } = createScheduler();
    scheduler.policy = { tag: "Random", seed };

    try {
      runFn();
    } catch {
      // Ignore exceptions from runFn
    }

    result.stats.totalSteps += scheduler.stepCount;

    // Check for deadlock
    const deadlock = detectDeadlock(scheduler);
    if (deadlock) {
      result.stats.deadlocks++;
      const decisions = scheduler.decisions.map(d => d.decisionIndex);
      result.deadlockSchedules.push({ decisions, info: deadlock });

      if (fullConfig.stopOnFirstFailure) {
        break;
      }
      continue;
    }

    // Check for errors
    let hasError = false;
    for (const [fiberId, fiber] of scheduler.fibers) {
      if (fiber.status === "error") {
        result.stats.errors++;
        const decisions = scheduler.decisions.map(d => d.decisionIndex);
        result.errorSchedules.push({
          decisions,
          fiberId,
          error: fiber.error ?? "Unknown error",
        });
        hasError = true;

        if (fullConfig.stopOnFirstFailure) {
          break;
        }
      }
    }

    if (hasError && fullConfig.stopOnFirstFailure) {
      break;
    }

    if (!hasError && !deadlock) {
      result.stats.successful++;

      // Record outcome
      const outcomeHash = hashSchedulerOutcome(scheduler);
      const existing = result.outcomes.get(outcomeHash);
      if (existing) {
        existing.count++;
      } else {
        const decisions = scheduler.decisions.map(d => d.decisionIndex);
        result.outcomes.set(outcomeHash, { count: 1, decisions });
      }
    }
  }

  return result;
}

/**
 * Hash the outcome of a scheduler run for comparison.
 */
function hashSchedulerOutcome(scheduler: SchedulerState): Hash {
  const results: Array<[FiberId, string]> = [];
  for (const [id, fiber] of scheduler.fibers) {
    if (fiber.status === "done" && fiber.result) {
      results.push([id, sha256JSON(fiber.result)]);
    }
  }
  results.sort((a, b) => a[0] - b[0]);
  return sha256JSON(results);
}

// ─────────────────────────────────────────────────────────────────
// Concurrency event analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Summarize concurrency events for debugging.
 */
export function summarizeEvents(events: ConcurrencyEvent[]): {
  spawns: number;
  yields: number;
  joins: number;
  mutexOps: number;
  ivarOps: number;
  channelOps: number;
  deadlocks: number;
  errors: number;
} {
  const summary = {
    spawns: 0,
    yields: 0,
    joins: 0,
    mutexOps: 0,
    ivarOps: 0,
    channelOps: 0,
    deadlocks: 0,
    errors: 0,
  };

  for (const event of events) {
    switch (event.tag) {
      case "spawn":
        summary.spawns++;
        break;
      case "yield":
        summary.yields++;
        break;
      case "join":
        summary.joins++;
        break;
      case "mutexLock":
      case "mutexUnlock":
      case "mutexBlock":
        summary.mutexOps++;
        break;
      case "ivarPut":
      case "ivarTake":
      case "ivarBlock":
        summary.ivarOps++;
        break;
      case "chanSend":
      case "chanRecv":
        summary.channelOps++;
        break;
      case "deadlock":
        summary.deadlocks++;
        break;
      case "error":
        summary.errors++;
        break;
    }
  }

  return summary;
}

/**
 * Find events related to a specific fiber.
 */
export function filterEventsByFiber(
  events: ConcurrencyEvent[],
  fiberId: FiberId
): ConcurrencyEvent[] {
  return events.filter(event => {
    switch (event.tag) {
      case "spawn":
        return event.fiberId === fiberId || event.parentId === fiberId;
      case "yield":
      case "join":
      case "done":
      case "error":
      case "mutexLock":
      case "mutexUnlock":
      case "mutexBlock":
      case "ivarPut":
      case "ivarTake":
      case "ivarBlock":
      case "chanSend":
      case "chanRecv":
        return event.fiberId === fiberId;
      case "schedule":
        return event.decision.chosenFiberId === fiberId;
      case "deadlock":
        return event.blocked.includes(fiberId);
      default:
        return false;
    }
  });
}

// ─────────────────────────────────────────────────────────────────
// Diagnostic reporting
// ─────────────────────────────────────────────────────────────────

/**
 * ConcurrencyDiagnostic: A diagnostic report about concurrency issues.
 */
export type ConcurrencyDiagnostic = {
  severity: "info" | "warning" | "error";
  code: string;
  message: string;
  fiberId?: FiberId;
  resource?: string;
  suggestion?: string;
};

/**
 * Generate diagnostics from scheduler state and events.
 */
export function generateDiagnostics(
  scheduler: SchedulerState,
  events: ConcurrencyEvent[]
): ConcurrencyDiagnostic[] {
  const diagnostics: ConcurrencyDiagnostic[] = [];

  // Check for deadlock
  const deadlock = detectDeadlock(scheduler);
  if (deadlock) {
    diagnostics.push({
      severity: "error",
      code: "DEADLOCK",
      message: deadlock.description,
      suggestion: "Consider reordering lock acquisitions or using try-lock with timeout",
    });
  }

  // Check for starvation (fibers that haven't run in a while)
  const now = Date.now();
  for (const [fiberId, fiber] of scheduler.fibers) {
    if (fiber.status === "ready" && fiber.stepCount === 0) {
      const age = now - fiber.createdAt;
      if (age > 1000) {  // More than 1 second
        diagnostics.push({
          severity: "warning",
          code: "STARVATION",
          message: `Fiber ${fiber.name ?? fiberId} has been ready but not scheduled for ${age}ms`,
          fiberId,
          suggestion: "Consider using a fair scheduling policy",
        });
      }
    }
  }

  // Check for long-running fibers
  for (const [fiberId, fiber] of scheduler.fibers) {
    if (fiber.stepCount > 10000) {
      diagnostics.push({
        severity: "warning",
        code: "LONG_RUNNING",
        message: `Fiber ${fiber.name ?? fiberId} has run ${fiber.stepCount} steps`,
        fiberId,
        suggestion: "Consider adding yield points for better interleaving",
      });
    }
  }

  return diagnostics;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: SICP-style concurrency with fibers, schedulers, and synchronization

export * from "./types";
export * from "./scheduler";
export * from "./sync";
export * from "./singleflight";
export * from "./actor";
export * from "./critic";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/scheduler.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/scheduler.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: Deterministic fiber scheduler with policy-based scheduling

import type { Val, FiberId, FiberVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type { State } from "../eval/machine";
import { sha256JSON } from "../artifacts/hash";
import {
  type FiberState,
  type FiberStatus,
  type BlockReason,
  type SchedulePolicy,
  type ScheduleDecision,
  type SchedulerState,
  type SchedulerStatus,
  type ConcurrencyEvent,
  type ConcurrencyBudget,
  DEFAULT_CONCURRENCY_BUDGET,
  makeFiber,
} from "./types";

// Re-export scheduler types for convenience
export type { SchedulerState, SchedulePolicy, SchedulerStatus } from "./types";

// ─────────────────────────────────────────────────────────────────
// Scheduler registry (global state for managing schedulers)
// ─────────────────────────────────────────────────────────────────

const schedulerRegistry = new Map<string, SchedulerState>();
let nextSchedulerId = 0;
let nextFiberId = 0;

/**
 * Generate a unique scheduler ID.
 */
function genSchedulerId(): string {
  return `sched-${nextSchedulerId++}`;
}

/**
 * Generate a unique fiber ID.
 */
export function genFiberId(): FiberId {
  return nextFiberId++;
}

/**
 * Reset the scheduler registry (for testing).
 */
export function resetSchedulerRegistry(): void {
  schedulerRegistry.clear();
  nextSchedulerId = 0;
  nextFiberId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Scheduler creation and management
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new scheduler with the given policy.
 */
export function createScheduler(
  policy: SchedulePolicy = { tag: "RoundRobin" },
  name?: string
): SchedulerState {
  const id = genSchedulerId();
  const state: SchedulerState = {
    fibers: new Map(),
    readyQueue: [],
    running: undefined,
    policy,
    stepCount: 0,
    decisions: [],
    replayIndex: 0,
    rngState: policy.tag === "Random" ? policy.seed : undefined,
  };

  schedulerRegistry.set(id, state);
  return state;
}

/**
 * Get a scheduler by ID.
 */
export function getScheduler(id: string): SchedulerState | undefined {
  return schedulerRegistry.get(id);
}

/**
 * Clone a scheduler state (for speculation/backtracking).
 */
export function cloneScheduler(state: SchedulerState): SchedulerState {
  const id = genSchedulerId();
  const cloned: SchedulerState = {
    fibers: new Map(
      Array.from(state.fibers.entries()).map(([k, v]) => [k, { ...v, children: [...v.children] }])
    ),
    readyQueue: [...state.readyQueue],
    running: state.running,
    policy: { ...state.policy } as SchedulePolicy,
    stepCount: state.stepCount,
    decisions: [...state.decisions],
    replayIndex: state.replayIndex,
    rngState: state.rngState,
  };

  schedulerRegistry.set(id, cloned);
  return cloned;
}

// ─────────────────────────────────────────────────────────────────
// Fiber management
// ─────────────────────────────────────────────────────────────────

/**
 * Spawn a new fiber in the scheduler.
 */
export function spawnFiber(
  scheduler: SchedulerState,
  machineState: State,
  options: { name?: string; parentId?: FiberId } = {}
): FiberState {
  const id = genFiberId();
  const fiber: FiberState = {
    id,
    name: options.name,
    machineState,
    status: "ready",
    stepCount: 0,
    parentId: options.parentId,
    children: [],
    createdAt: Date.now(),
  };

  // Register fiber
  scheduler.fibers.set(id, fiber);

  // Add to ready queue
  scheduler.readyQueue.push(id);

  // Update parent's children list
  if (options.parentId !== undefined) {
    const parent = scheduler.fibers.get(options.parentId);
    if (parent) {
      parent.children.push(id);
    }
  }

  return fiber;
}

/**
 * Get a fiber by ID.
 */
export function getFiber(scheduler: SchedulerState, id: FiberId): FiberState | undefined {
  return scheduler.fibers.get(id);
}

/**
 * Update a fiber's status.
 */
export function setFiberStatus(
  scheduler: SchedulerState,
  id: FiberId,
  status: FiberStatus,
  options: { blockReason?: BlockReason; result?: Val; error?: string } = {}
): void {
  const fiber = scheduler.fibers.get(id);
  if (!fiber) return;

  const oldStatus = fiber.status;
  fiber.status = status;
  fiber.blockReason = options.blockReason;

  if (status === "done") {
    fiber.result = options.result;
  } else if (status === "error") {
    fiber.error = options.error;
  }

  // Update ready queue based on status change
  if (oldStatus === "ready" && status !== "ready") {
    // Remove from ready queue
    const idx = scheduler.readyQueue.indexOf(id);
    if (idx >= 0) {
      scheduler.readyQueue.splice(idx, 1);
    }
  } else if (oldStatus !== "ready" && status === "ready") {
    // Add to ready queue
    if (!scheduler.readyQueue.includes(id)) {
      scheduler.readyQueue.push(id);
    }
  }

  // Clear running if this fiber was running
  if (scheduler.running === id && status !== "running") {
    scheduler.running = undefined;
  }
}

/**
 * Mark a fiber as blocked.
 */
export function blockFiber(
  scheduler: SchedulerState,
  id: FiberId,
  reason: BlockReason
): void {
  setFiberStatus(scheduler, id, "blocked", { blockReason: reason });
}

/**
 * Unblock a fiber (make it ready again).
 */
export function unblockFiber(scheduler: SchedulerState, id: FiberId): void {
  const fiber = scheduler.fibers.get(id);
  if (fiber && fiber.status === "blocked") {
    setFiberStatus(scheduler, id, "ready");
  }
}

/**
 * Complete a fiber with a result.
 */
export function completeFiber(
  scheduler: SchedulerState,
  id: FiberId,
  result: Val
): void {
  setFiberStatus(scheduler, id, "done", { result });

  // Unblock any fibers waiting to join this one
  for (const [, fiber] of scheduler.fibers) {
    if (
      fiber.status === "blocked" &&
      fiber.blockReason?.tag === "join" &&
      fiber.blockReason.fiberId === id
    ) {
      unblockFiber(scheduler, fiber.id);
    }
  }
}

/**
 * Fail a fiber with an error.
 */
export function failFiber(
  scheduler: SchedulerState,
  id: FiberId,
  error: string
): void {
  setFiberStatus(scheduler, id, "error", { error });
}

// ─────────────────────────────────────────────────────────────────
// Scheduling policies
// ─────────────────────────────────────────────────────────────────

/**
 * Simple LCG random number generator for deterministic scheduling.
 */
function lcgRandom(state: number): { value: number; nextState: number } {
  // Parameters from Numerical Recipes
  const a = 1664525;
  const c = 1013904223;
  const m = Math.pow(2, 32);
  const nextState = (a * state + c) % m;
  return { value: nextState / m, nextState };
}

/**
 * Select the next fiber to run based on the scheduling policy.
 */
export function selectNextFiber(scheduler: SchedulerState): FiberId | undefined {
  const readyFibers = scheduler.readyQueue;
  if (readyFibers.length === 0) return undefined;

  let chosenIndex: number;
  let chosenId: FiberId;

  switch (scheduler.policy.tag) {
    case "RoundRobin": {
      // Simple round-robin: take the first ready fiber
      chosenIndex = 0;
      chosenId = readyFibers[0];
      break;
    }

    case "FairRR": {
      // Fair round-robin with quantum
      // For now, same as round-robin but respects step limits
      chosenIndex = 0;
      chosenId = readyFibers[0];
      break;
    }

    case "Random": {
      // Deterministic random selection using LCG
      if (scheduler.rngState === undefined) {
        scheduler.rngState = 0;
      }
      const { value, nextState } = lcgRandom(scheduler.rngState);
      scheduler.rngState = nextState;
      chosenIndex = Math.floor(value * readyFibers.length);
      chosenId = readyFibers[chosenIndex];
      break;
    }

    case "Replay": {
      // Replay mode: use recorded decisions
      const decisions = scheduler.policy.decisions;
      if (scheduler.replayIndex < decisions.length) {
        chosenIndex = decisions[scheduler.replayIndex];
        scheduler.replayIndex++;
        // Validate the choice
        if (chosenIndex >= readyFibers.length) {
          // Invalid replay decision, fall back to round-robin
          chosenIndex = 0;
        }
        chosenId = readyFibers[chosenIndex];
      } else {
        // No more replay decisions, fall back to round-robin
        chosenIndex = 0;
        chosenId = readyFibers[0];
      }
      break;
    }

    default:
      chosenIndex = 0;
      chosenId = readyFibers[0];
  }

  // Record the decision
  const decision: ScheduleDecision = {
    readySetHash: hashReadySet(readyFibers),
    chosenFiberId: chosenId,
    decisionIndex: chosenIndex,
    stepCount: scheduler.stepCount,
    timestamp: Date.now(),
  };
  scheduler.decisions.push(decision);

  return chosenId;
}

/**
 * Hash the ready set for decision recording.
 */
function hashReadySet(readyFibers: FiberId[]): string {
  return sha256JSON(readyFibers);
}

// ─────────────────────────────────────────────────────────────────
// Scheduler execution
// ─────────────────────────────────────────────────────────────────

/**
 * Configuration for running the scheduler.
 */
export type SchedulerConfig = {
  /** Maximum total steps across all fibers */
  maxSteps: number;
  /** Maximum steps per fiber before forced yield */
  stepsPerQuantum: number;
  /** Event handler callback */
  onEvent?: (event: ConcurrencyEvent) => void;
  /** Step function for executing a single CEKS step */
  stepFn: (machineState: State) => { state: State; done: boolean; result?: Val; error?: string };
};

/**
 * Run the scheduler until completion or budget exhaustion.
 */
export function runScheduler(
  scheduler: SchedulerState,
  config: SchedulerConfig
): SchedulerStatus {
  let totalSteps = 0;

  while (totalSteps < config.maxSteps) {
    // Get current status
    const status = getSchedulerStatus(scheduler);

    // Check for terminal states
    if (status.tag === "done" || status.tag === "deadlock" || status.tag === "error") {
      return status;
    }

    // Select next fiber to run
    const nextFiberId = selectNextFiber(scheduler);
    if (nextFiberId === undefined) {
      // No ready fibers, check if done or deadlocked
      return getSchedulerStatus(scheduler);
    }

    // Run the selected fiber for its quantum
    const fiber = scheduler.fibers.get(nextFiberId)!;
    scheduler.running = nextFiberId;
    fiber.status = "running";

    // Remove from ready queue
    const idx = scheduler.readyQueue.indexOf(nextFiberId);
    if (idx >= 0) {
      scheduler.readyQueue.splice(idx, 1);
    }

    // Execute steps within quantum
    let quantumSteps = 0;
    while (quantumSteps < config.stepsPerQuantum) {
      const stepResult = config.stepFn(fiber.machineState);
      fiber.machineState = stepResult.state;
      fiber.stepCount++;
      scheduler.stepCount++;
      totalSteps++;
      quantumSteps++;

      if (stepResult.done) {
        if (stepResult.error) {
          failFiber(scheduler, nextFiberId, stepResult.error);
          config.onEvent?.({
            tag: "error",
            fiberId: nextFiberId,
            message: stepResult.error,
            timestamp: Date.now(),
          });
        } else {
          completeFiber(scheduler, nextFiberId, stepResult.result ?? VUnit);
          config.onEvent?.({
            tag: "done",
            fiberId: nextFiberId,
            valueHash: sha256JSON(stepResult.result ?? VUnit),
            timestamp: Date.now(),
          });
        }
        break;
      }

      // Check if fiber got blocked (would be set by effect handlers)
      if ((fiber as any).status === "blocked") {
        break;
      }

      // Check budget
      if (totalSteps >= config.maxSteps) {
        break;
      }
    }

    // If still running, yield back to ready queue
    if ((fiber as any).status === "running") {
      fiber.status = "ready";
      scheduler.readyQueue.push(nextFiberId);
      scheduler.running = undefined;

      config.onEvent?.({
        tag: "yield",
        fiberId: nextFiberId,
        timestamp: Date.now(),
      });
    }
  }

  // Budget exhausted
  return getSchedulerStatus(scheduler);
}

/**
 * Get the current status of the scheduler.
 */
export function getSchedulerStatus(scheduler: SchedulerState): SchedulerStatus {
  // Check if any fiber is running
  if (scheduler.running !== undefined) {
    return { tag: "running", fiberId: scheduler.running };
  }

  // Check if there are ready fibers
  if (scheduler.readyQueue.length > 0) {
    return { tag: "idle" };
  }

  // Check if all fibers are done
  const blockedFibers: FiberId[] = [];
  const results = new Map<FiberId, Val>();
  let hasError = false;
  let errorFiberId: FiberId | undefined;
  let errorMessage: string | undefined;

  for (const [id, fiber] of scheduler.fibers) {
    if (fiber.status === "blocked") {
      blockedFibers.push(id);
    } else if (fiber.status === "done" && fiber.result !== undefined) {
      results.set(id, fiber.result);
    } else if (fiber.status === "error") {
      hasError = true;
      errorFiberId = id;
      errorMessage = fiber.error;
    }
  }

  if (hasError && errorFiberId !== undefined) {
    return { tag: "error", fiberId: errorFiberId, message: errorMessage ?? "Unknown error" };
  }

  if (blockedFibers.length > 0) {
    // All remaining fibers are blocked - deadlock
    return { tag: "deadlock", blocked: blockedFibers };
  }

  // All fibers done
  return { tag: "done", results };
}

// ─────────────────────────────────────────────────────────────────
// Event ledger
// ─────────────────────────────────────────────────────────────────

/**
 * Create an event ledger for recording concurrency events.
 */
export function createEventLedger(): ConcurrencyEvent[] {
  return [];
}

/**
 * Record an event to the ledger.
 */
export function recordEvent(ledger: ConcurrencyEvent[], event: ConcurrencyEvent): void {
  ledger.push(event);
}

/**
 * Extract schedule decisions from an event ledger.
 */
export function extractDecisions(ledger: ConcurrencyEvent[]): number[] {
  return ledger
    .filter((e): e is Extract<ConcurrencyEvent, { tag: "schedule" }> => e.tag === "schedule")
    .map((e) => e.decision.decisionIndex);
}

/**
 * Create a replay policy from recorded decisions.
 */
export function createReplayPolicy(decisions: number[]): SchedulePolicy {
  return { tag: "Replay", decisions };
}

// ─────────────────────────────────────────────────────────────────
// Fiber operations (effects)
// ─────────────────────────────────────────────────────────────────

/**
 * Yield the current fiber, allowing other fibers to run.
 */
export function yieldFiber(scheduler: SchedulerState, fiberId: FiberId): void {
  const fiber = scheduler.fibers.get(fiberId);
  if (!fiber || fiber.status !== "running") return;

  fiber.status = "ready";
  scheduler.readyQueue.push(fiberId);
  scheduler.running = undefined;
}

/**
 * Join on another fiber (wait for it to complete).
 */
export function joinFiber(
  scheduler: SchedulerState,
  waiterId: FiberId,
  targetId: FiberId
): Val | undefined {
  const target = scheduler.fibers.get(targetId);
  if (!target) {
    // Target doesn't exist, return unit
    return VUnit;
  }

  if (target.status === "done") {
    // Already done, return result immediately
    return target.result ?? VUnit;
  }

  if (target.status === "error") {
    // Target errored
    return { tag: "Err", message: target.error ?? "Fiber error" };
  }

  // Block the waiter until target completes
  blockFiber(scheduler, waiterId, { tag: "join", fiberId: targetId });
  return undefined; // Indicates caller should suspend
}

/**
 * Get the result of a completed fiber.
 */
export function getFiberResult(scheduler: SchedulerState, fiberId: FiberId): Val | undefined {
  const fiber = scheduler.fibers.get(fiberId);
  if (!fiber) return undefined;
  if (fiber.status === "done") return fiber.result;
  if (fiber.status === "error") {
    return { tag: "Err", message: fiber.error ?? "Fiber error" };
  }
  return undefined;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/singleflight.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/singleflight.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: Singleflight memoization for deduplicating concurrent oracle calls

import type { Val, FiberId, IVarVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type { SchedulerState } from "./scheduler";
import { createIVar, putIVar, takeIVar, getIVarState, isIVarFull } from "./sync";

// ─────────────────────────────────────────────────────────────────
// Singleflight types
// ─────────────────────────────────────────────────────────────────

/**
 * SingleflightKey: Hash of the call signature for deduplication.
 */
export type SingleflightKey = Hash;

/**
 * SingleflightEntry: An in-flight or completed computation.
 */
export type SingleflightEntry = {
  /** The IVar holding the result */
  ivar: IVarVal;
  /** The fiber that initiated the call */
  initiator: FiberId;
  /** Fibers waiting for the result */
  waiters: FiberId[];
  /** Whether the computation is complete */
  complete: boolean;
  /** The result (if complete) */
  result?: Val;
  /** Creation timestamp */
  createdAt: number;
};

/**
 * SingleflightGroup: A group of deduplicated calls.
 */
export type SingleflightGroup = {
  /** Active entries by key */
  entries: Map<SingleflightKey, SingleflightEntry>;
  /** Name for debugging */
  name?: string;
  /** Statistics */
  stats: {
    hits: number;
    misses: number;
    completions: number;
  };
};

// ─────────────────────────────────────────────────────────────────
// Singleflight registry
// ─────────────────────────────────────────────────────────────────

const groupRegistry = new Map<string, SingleflightGroup>();
let nextGroupId = 0;

/**
 * Generate a unique group ID.
 */
function genGroupId(): string {
  return `sfgroup-${nextGroupId++}`;
}

/**
 * Reset the singleflight registry (for testing).
 */
export function resetSingleflightRegistry(): void {
  groupRegistry.clear();
  nextGroupId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Singleflight group operations
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new singleflight group.
 */
export function createSingleflightGroup(name?: string): { id: string; group: SingleflightGroup } {
  const id = genGroupId();
  const group: SingleflightGroup = {
    entries: new Map(),
    name,
    stats: {
      hits: 0,
      misses: 0,
      completions: 0,
    },
  };
  groupRegistry.set(id, group);
  return { id, group };
}

/**
 * Get a singleflight group by ID.
 */
export function getSingleflightGroup(id: string): SingleflightGroup | undefined {
  return groupRegistry.get(id);
}

// ─────────────────────────────────────────────────────────────────
// Singleflight call operations
// ─────────────────────────────────────────────────────────────────

/**
 * Result of a singleflight request.
 */
export type SingleflightResult =
  | { tag: "hit"; result: Val }           // Result already available
  | { tag: "initiated"; ivar: IVarVal }   // This fiber initiates the call
  | { tag: "waiting"; ivar: IVarVal };    // Another fiber is computing

/**
 * Request a singleflight call.
 *
 * If a call with the same key is in-flight, returns the IVar to wait on.
 * If the call is new, creates an entry and returns the IVar for the caller to fill.
 */
export function singleflightDo(
  groupId: string,
  key: SingleflightKey,
  fiberId: FiberId
): SingleflightResult {
  const group = groupRegistry.get(groupId);
  if (!group) {
    // Group doesn't exist, create one inline
    const { id } = createSingleflightGroup();
    return singleflightDo(id, key, fiberId);
  }

  // Check for existing entry
  const existing = group.entries.get(key);
  if (existing) {
    if (existing.complete && existing.result !== undefined) {
      // Already complete, return result directly
      group.stats.hits++;
      return { tag: "hit", result: existing.result };
    }

    // In-flight, add to waiters
    if (!existing.waiters.includes(fiberId)) {
      existing.waiters.push(fiberId);
    }
    group.stats.hits++;
    return { tag: "waiting", ivar: existing.ivar };
  }

  // New call - create entry
  group.stats.misses++;
  const ivar = createIVar(`sf-${key.slice(0, 8)}`);
  const entry: SingleflightEntry = {
    ivar,
    initiator: fiberId,
    waiters: [],
    complete: false,
    createdAt: Date.now(),
  };
  group.entries.set(key, entry);

  return { tag: "initiated", ivar };
}

/**
 * Complete a singleflight call with a result.
 */
export function singleflightComplete(
  scheduler: SchedulerState,
  groupId: string,
  key: SingleflightKey,
  result: Val,
  fiberId: FiberId
): boolean {
  const group = groupRegistry.get(groupId);
  if (!group) return false;

  const entry = group.entries.get(key);
  if (!entry) return false;

  // Only the initiator can complete
  if (entry.initiator !== fiberId) return false;

  // Already complete?
  if (entry.complete) return false;

  // Mark complete and store result
  entry.complete = true;
  entry.result = result;
  group.stats.completions++;

  // Put value in IVar (wakes all waiters)
  putIVar(scheduler, entry.ivar.id, result, fiberId);

  return true;
}

/**
 * Wait for a singleflight result (blocking).
 * Returns the result if available, undefined if blocked.
 */
export function singleflightWait(
  scheduler: SchedulerState,
  groupId: string,
  key: SingleflightKey,
  fiberId: FiberId
): Val | undefined {
  const group = groupRegistry.get(groupId);
  if (!group) return undefined;

  const entry = group.entries.get(key);
  if (!entry) return undefined;

  // Check if already complete
  if (entry.complete && entry.result !== undefined) {
    return entry.result;
  }

  // Wait on the IVar
  return takeIVar(scheduler, entry.ivar.id, fiberId);
}

/**
 * Get the result of a singleflight call (non-blocking).
 */
export function singleflightTryGet(
  groupId: string,
  key: SingleflightKey
): Val | undefined {
  const group = groupRegistry.get(groupId);
  if (!group) return undefined;

  const entry = group.entries.get(key);
  if (!entry || !entry.complete) return undefined;

  return entry.result;
}

/**
 * Check if a singleflight call is in-flight.
 */
export function singleflightInFlight(groupId: string, key: SingleflightKey): boolean {
  const group = groupRegistry.get(groupId);
  if (!group) return false;

  const entry = group.entries.get(key);
  return entry !== undefined && !entry.complete;
}

/**
 * Get singleflight group statistics.
 */
export function singleflightStats(groupId: string): { hits: number; misses: number; completions: number } | undefined {
  const group = groupRegistry.get(groupId);
  if (!group) return undefined;
  return { ...group.stats };
}

// ─────────────────────────────────────────────────────────────────
// Convenience: Hash a call signature
// ─────────────────────────────────────────────────────────────────

/**
 * Create a singleflight key from a function name and arguments.
 */
export function singleflightKey(fnName: string, args: Val[]): SingleflightKey {
  return sha256JSON({ fn: fnName, args });
}

// ─────────────────────────────────────────────────────────────────
// Memoization table (longer-lived caching)
// ─────────────────────────────────────────────────────────────────

/**
 * MemoEntry: A cached result with metadata.
 */
export type MemoEntry = {
  result: Val;
  createdAt: number;
  accessCount: number;
  lastAccessedAt: number;
};

/**
 * MemoTable: A memoization table for caching results.
 */
export type MemoTable = {
  entries: Map<SingleflightKey, MemoEntry>;
  name?: string;
  maxSize: number;
  stats: {
    hits: number;
    misses: number;
    evictions: number;
  };
};

const memoRegistry = new Map<string, MemoTable>();
let nextMemoId = 0;

/**
 * Create a new memo table.
 */
export function createMemoTable(maxSize: number = 1000, name?: string): { id: string; table: MemoTable } {
  const id = `memo-${nextMemoId++}`;
  const table: MemoTable = {
    entries: new Map(),
    name,
    maxSize,
    stats: {
      hits: 0,
      misses: 0,
      evictions: 0,
    },
  };
  memoRegistry.set(id, table);
  return { id, table };
}

/**
 * Get a value from the memo table.
 */
export function memoGet(tableId: string, key: SingleflightKey): Val | undefined {
  const table = memoRegistry.get(tableId);
  if (!table) return undefined;

  const entry = table.entries.get(key);
  if (!entry) {
    table.stats.misses++;
    return undefined;
  }

  // Update access statistics
  entry.accessCount++;
  entry.lastAccessedAt = Date.now();
  table.stats.hits++;

  return entry.result;
}

/**
 * Set a value in the memo table.
 */
export function memoSet(tableId: string, key: SingleflightKey, value: Val): void {
  const table = memoRegistry.get(tableId);
  if (!table) return;

  // Evict if at capacity (simple LRU approximation)
  if (table.entries.size >= table.maxSize && !table.entries.has(key)) {
    // Find least recently accessed entry
    let oldestKey: SingleflightKey | undefined;
    let oldestTime = Infinity;

    for (const [k, e] of table.entries) {
      if (e.lastAccessedAt < oldestTime) {
        oldestTime = e.lastAccessedAt;
        oldestKey = k;
      }
    }

    if (oldestKey) {
      table.entries.delete(oldestKey);
      table.stats.evictions++;
    }
  }

  const now = Date.now();
  table.entries.set(key, {
    result: value,
    createdAt: now,
    accessCount: 1,
    lastAccessedAt: now,
  });
}

/**
 * Clear a memo table.
 */
export function memoClear(tableId: string): void {
  const table = memoRegistry.get(tableId);
  if (table) {
    table.entries.clear();
  }
}

/**
 * Get memo table statistics.
 */
export function memoStats(tableId: string): { hits: number; misses: number; evictions: number; size: number } | undefined {
  const table = memoRegistry.get(tableId);
  if (!table) return undefined;
  return {
    ...table.stats,
    size: table.entries.size,
  };
}

/**
 * Reset memo registry (for testing).
 */
export function resetMemoRegistry(): void {
  memoRegistry.clear();
  nextMemoId = 0;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/sync.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/sync.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: Synchronization primitives - Mutex, IVar, Channel

import type { Val, FiberId, MutexVal, IVarVal, ChannelVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type {
  MutexState,
  IVarState,
  ChannelState,
  ConcurrencyEvent,
} from "./types";
import { makeMutex, makeIVar, makeChannel } from "./types";
import type { SchedulerState } from "./scheduler";
import { blockFiber, unblockFiber } from "./scheduler";

// ─────────────────────────────────────────────────────────────────
// Mutex registry
// ─────────────────────────────────────────────────────────────────

const mutexRegistry = new Map<string, MutexState>();
let nextMutexId = 0;

/**
 * Generate a unique mutex ID.
 */
function genMutexId(): string {
  return `mutex-${nextMutexId++}`;
}

/**
 * Reset the mutex registry (for testing).
 */
export function resetMutexRegistry(): void {
  mutexRegistry.clear();
  nextMutexId = 0;
}

// ─────────────────────────────────────────────────────────────────
// IVar registry
// ─────────────────────────────────────────────────────────────────

const ivarRegistry = new Map<string, IVarState>();
let nextIVarId = 0;

/**
 * Generate a unique IVar ID.
 */
function genIVarId(): string {
  return `ivar-${nextIVarId++}`;
}

/**
 * Reset the IVar registry (for testing).
 */
export function resetIVarRegistry(): void {
  ivarRegistry.clear();
  nextIVarId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Channel registry
// ─────────────────────────────────────────────────────────────────

const channelRegistry = new Map<string, ChannelState>();
let nextChannelId = 0;

/**
 * Generate a unique channel ID.
 */
function genChannelId(): string {
  return `chan-${nextChannelId++}`;
}

/**
 * Reset the channel registry (for testing).
 */
export function resetChannelRegistry(): void {
  channelRegistry.clear();
  nextChannelId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Mutex operations
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new mutex.
 */
export function createMutex(name?: string): MutexVal {
  const id = genMutexId();
  const state: MutexState = {
    id,
    name,
    holder: undefined,
    waitQueue: [],
    acquisitionCount: 0,
  };
  mutexRegistry.set(id, state);
  return makeMutex(id, name);
}

/**
 * Get mutex state.
 */
export function getMutexState(id: string): MutexState | undefined {
  return mutexRegistry.get(id);
}

/**
 * Acquire a mutex (blocking).
 * Returns true if acquired immediately, false if blocked.
 */
export function acquireMutex(
  scheduler: SchedulerState,
  mutexId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): boolean {
  const mutex = mutexRegistry.get(mutexId);
  if (!mutex) return false;

  if (mutex.holder === undefined) {
    // Mutex is free, acquire it
    mutex.holder = fiberId;
    mutex.acquisitionCount++;
    onEvent?.({
      tag: "mutexLock",
      fiberId,
      mutexId,
      timestamp: Date.now(),
    });
    return true;
  }

  if (mutex.holder === fiberId) {
    // Already held by this fiber - this is a deadlock attempt
    // In a real implementation, we might support reentrant mutexes
    return false;
  }

  // Mutex is held by another fiber, block and wait
  mutex.waitQueue.push(fiberId);
  blockFiber(scheduler, fiberId, { tag: "mutex", mutexId });
  onEvent?.({
    tag: "mutexBlock",
    fiberId,
    mutexId,
    timestamp: Date.now(),
  });
  return false;
}

/**
 * Release a mutex.
 * Returns the next fiber to wake up, if any.
 */
export function releaseMutex(
  scheduler: SchedulerState,
  mutexId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): FiberId | undefined {
  const mutex = mutexRegistry.get(mutexId);
  if (!mutex) return undefined;

  if (mutex.holder !== fiberId) {
    // Not held by this fiber
    return undefined;
  }

  onEvent?.({
    tag: "mutexUnlock",
    fiberId,
    mutexId,
    timestamp: Date.now(),
  });

  // Check wait queue
  if (mutex.waitQueue.length > 0) {
    // Wake up next waiter
    const nextFiberId = mutex.waitQueue.shift()!;
    mutex.holder = nextFiberId;
    mutex.acquisitionCount++;
    unblockFiber(scheduler, nextFiberId);
    onEvent?.({
      tag: "mutexLock",
      fiberId: nextFiberId,
      mutexId,
      timestamp: Date.now(),
    });
    return nextFiberId;
  }

  // No waiters, release the mutex
  mutex.holder = undefined;
  return undefined;
}

/**
 * Try to acquire a mutex without blocking.
 * Returns true if acquired, false otherwise.
 */
export function tryAcquireMutex(
  mutexId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): boolean {
  const mutex = mutexRegistry.get(mutexId);
  if (!mutex) return false;

  if (mutex.holder === undefined) {
    mutex.holder = fiberId;
    mutex.acquisitionCount++;
    onEvent?.({
      tag: "mutexLock",
      fiberId,
      mutexId,
      timestamp: Date.now(),
    });
    return true;
  }

  return false;
}

// ─────────────────────────────────────────────────────────────────
// IVar operations (single-assignment variables)
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new IVar.
 */
export function createIVar(name?: string): IVarVal {
  const id = genIVarId();
  const state: IVarState = {
    id,
    name,
    value: undefined,
    isFull: false,
    waitQueue: [],
  };
  ivarRegistry.set(id, state);
  return makeIVar(id, name);
}

/**
 * Get IVar state.
 */
export function getIVarState(id: string): IVarState | undefined {
  return ivarRegistry.get(id);
}

/**
 * Put a value into an IVar.
 * Returns true if successful, false if already full.
 */
export function putIVar(
  scheduler: SchedulerState,
  ivarId: string,
  value: Val,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): boolean {
  const ivar = ivarRegistry.get(ivarId);
  if (!ivar) return false;

  if (ivar.isFull) {
    // Already has a value - IVars are single-assignment
    return false;
  }

  // Set the value
  ivar.value = value;
  ivar.isFull = true;

  onEvent?.({
    tag: "ivarPut",
    fiberId,
    ivarId,
    valueHash: JSON.stringify(value).slice(0, 16),
    timestamp: Date.now(),
  });

  // Wake up all waiting fibers
  for (const waiterId of ivar.waitQueue) {
    unblockFiber(scheduler, waiterId);
  }
  ivar.waitQueue = [];

  return true;
}

/**
 * Take a value from an IVar (blocking if empty).
 * Returns the value if available, undefined if blocked.
 */
export function takeIVar(
  scheduler: SchedulerState,
  ivarId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): Val | undefined {
  const ivar = ivarRegistry.get(ivarId);
  if (!ivar) return undefined;

  if (ivar.isFull) {
    // Value is available
    onEvent?.({
      tag: "ivarTake",
      fiberId,
      ivarId,
      timestamp: Date.now(),
    });
    return ivar.value;
  }

  // Block until value is available
  ivar.waitQueue.push(fiberId);
  blockFiber(scheduler, fiberId, { tag: "ivar", ivarId });
  onEvent?.({
    tag: "ivarBlock",
    fiberId,
    ivarId,
    timestamp: Date.now(),
  });
  return undefined;
}

/**
 * Try to take a value from an IVar without blocking.
 */
export function tryTakeIVar(ivarId: string): Val | undefined {
  const ivar = ivarRegistry.get(ivarId);
  if (!ivar || !ivar.isFull) return undefined;
  return ivar.value;
}

/**
 * Check if an IVar is full.
 */
export function isIVarFull(ivarId: string): boolean {
  const ivar = ivarRegistry.get(ivarId);
  return ivar?.isFull ?? false;
}

// ─────────────────────────────────────────────────────────────────
// Channel operations
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new channel.
 */
export function createChannel(bufferSize: number = 0, name?: string): ChannelVal {
  const id = genChannelId();
  const state: ChannelState = {
    id,
    name,
    bufferSize,
    buffer: [],
    sendQueue: [],
    recvQueue: [],
    closed: false,
  };
  channelRegistry.set(id, state);
  return makeChannel(id, bufferSize, name);
}

/**
 * Get channel state.
 */
export function getChannelState(id: string): ChannelState | undefined {
  return channelRegistry.get(id);
}

/**
 * Send a value to a channel (blocking if buffer is full).
 * Returns true if sent immediately, false if blocked.
 */
export function sendChannel(
  scheduler: SchedulerState,
  channelId: string,
  value: Val,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): boolean {
  const channel = channelRegistry.get(channelId);
  if (!channel || channel.closed) return false;

  // Check if there are waiting receivers
  if (channel.recvQueue.length > 0) {
    // Direct handoff to waiting receiver
    const receiverId = channel.recvQueue.shift()!;
    unblockFiber(scheduler, receiverId);
    // Store value for receiver to pick up
    channel.buffer.push(value);
    onEvent?.({
      tag: "chanSend",
      fiberId,
      channelId,
      valueHash: JSON.stringify(value).slice(0, 16),
      timestamp: Date.now(),
    });
    return true;
  }

  // Check if buffer has space
  if (channel.buffer.length < channel.bufferSize) {
    channel.buffer.push(value);
    onEvent?.({
      tag: "chanSend",
      fiberId,
      channelId,
      valueHash: JSON.stringify(value).slice(0, 16),
      timestamp: Date.now(),
    });
    return true;
  }

  // For unbuffered channels, or if buffer is full, block
  channel.sendQueue.push({ fiberId, value });
  blockFiber(scheduler, fiberId, { tag: "channel", channelId, op: "send" });
  return false;
}

/**
 * Receive a value from a channel (blocking if empty).
 * Returns the value if available, undefined if blocked.
 */
export function recvChannel(
  scheduler: SchedulerState,
  channelId: string,
  fiberId: FiberId,
  onEvent?: (event: ConcurrencyEvent) => void
): Val | undefined {
  const channel = channelRegistry.get(channelId);
  if (!channel) return undefined;

  // Check if there are buffered values
  if (channel.buffer.length > 0) {
    const value = channel.buffer.shift()!;

    // If there are waiting senders, move one to buffer
    if (channel.sendQueue.length > 0) {
      const sender = channel.sendQueue.shift()!;
      channel.buffer.push(sender.value);
      unblockFiber(scheduler, sender.fiberId);
    }

    onEvent?.({
      tag: "chanRecv",
      fiberId,
      channelId,
      timestamp: Date.now(),
    });
    return value;
  }

  // Check for waiting senders (unbuffered channel rendezvous)
  if (channel.sendQueue.length > 0) {
    const sender = channel.sendQueue.shift()!;
    unblockFiber(scheduler, sender.fiberId);
    onEvent?.({
      tag: "chanRecv",
      fiberId,
      channelId,
      timestamp: Date.now(),
    });
    return sender.value;
  }

  // Check if channel is closed
  if (channel.closed) {
    return { tag: "Sym", name: "closed" };
  }

  // Block until a value is available
  channel.recvQueue.push(fiberId);
  blockFiber(scheduler, fiberId, { tag: "channel", channelId, op: "recv" });
  return undefined;
}

/**
 * Close a channel.
 */
export function closeChannel(
  scheduler: SchedulerState,
  channelId: string
): void {
  const channel = channelRegistry.get(channelId);
  if (!channel || channel.closed) return;

  channel.closed = true;

  // Wake up all waiting receivers with closed signal
  for (const receiverId of channel.recvQueue) {
    unblockFiber(scheduler, receiverId);
  }
  channel.recvQueue = [];

  // Wake up all waiting senders (they will see closed channel)
  for (const { fiberId } of channel.sendQueue) {
    unblockFiber(scheduler, fiberId);
  }
  channel.sendQueue = [];
}

/**
 * Check if a channel is closed.
 */
export function isChannelClosed(channelId: string): boolean {
  const channel = channelRegistry.get(channelId);
  return channel?.closed ?? true;
}

// ─────────────────────────────────────────────────────────────────
// Serializer (SICP-style mutex wrapper)
// ─────────────────────────────────────────────────────────────────

/**
 * SerializerState: Wraps a mutex to provide SICP-style serialization.
 */
export type SerializerState = {
  mutexId: string;
  name?: string;
};

const serializerRegistry = new Map<string, SerializerState>();
let nextSerializerId = 0;

/**
 * Create a serializer (SICP-style).
 */
export function createSerializer(name?: string): { id: string; mutex: MutexVal } {
  const id = `serializer-${nextSerializerId++}`;
  const mutex = createMutex(name ? `${name}-mutex` : undefined);
  serializerRegistry.set(id, { mutexId: mutex.id, name });
  return { id, mutex };
}

/**
 * Get the mutex for a serializer.
 */
export function getSerializerMutex(id: string): string | undefined {
  return serializerRegistry.get(id)?.mutexId;
}

/**
 * Reset the serializer registry (for testing).
 */
export function resetSerializerRegistry(): void {
  serializerRegistry.clear();
  nextSerializerId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Reset all sync registries
// ─────────────────────────────────────────────────────────────────

/**
 * Reset all synchronization registries (for testing).
 */
export function resetAllSyncRegistries(): void {
  resetMutexRegistry();
  resetIVarRegistry();
  resetChannelRegistry();
  resetSerializerRegistry();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/concurrency/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/concurrency/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 13: SICP-style concurrency types

import type { Val, FiberId, FiberVal, MutexVal, IVarVal, ChannelVal, ActorVal, SchedulerView } from "../eval/values";
import type { State } from "../eval/machine";
import type { Hash } from "../artifacts/hash";

// ─────────────────────────────────────────────────────────────────
// Fiber state
// ─────────────────────────────────────────────────────────────────

/**
 * FiberStatus: Current execution state of a fiber.
 */
export type FiberStatus = "ready" | "running" | "blocked" | "done" | "error";

/**
 * BlockReason: Why a fiber is blocked.
 */
export type BlockReason =
  | { tag: "join"; fiberId: FiberId }
  | { tag: "mutex"; mutexId: string }
  | { tag: "ivar"; ivarId: string }
  | { tag: "channel"; channelId: string; op: "send" | "recv" }
  | { tag: "yield" };

/**
 * FiberState: Internal state of a single fiber.
 */
export type FiberState = {
  /** Unique fiber identifier */
  id: FiberId;
  /** Human-readable name */
  name?: string;
  /** Current CEKS machine state */
  machineState: State;
  /** Current status */
  status: FiberStatus;
  /** Reason for blocking (if blocked) */
  blockReason?: BlockReason;
  /** Result value (if done) */
  result?: Val;
  /** Error message (if error) */
  error?: string;
  /** Step count within this fiber */
  stepCount: number;
  /** Parent fiber ID (if spawned by another fiber) */
  parentId?: FiberId;
  /** Child fiber IDs */
  children: FiberId[];
  /** Creation timestamp */
  createdAt: number;
};

// ─────────────────────────────────────────────────────────────────
// Scheduling policies
// ─────────────────────────────────────────────────────────────────

/**
 * SchedulePolicy: Strategy for selecting the next fiber to run.
 */
export type SchedulePolicy =
  | { tag: "RoundRobin"; decisions?: number[] }
  | { tag: "FairRR"; quantum: number; decisions?: number[] }
  | { tag: "Random"; seed: number; decisions?: number[] }
  | { tag: "Replay"; decisions: number[] };

/**
 * ScheduleDecision: Record of a scheduling choice.
 */
export type ScheduleDecision = {
  /** Hash of ready set at decision time */
  readySetHash: Hash;
  /** Chosen fiber ID */
  chosenFiberId: FiberId;
  /** Index in ready set */
  decisionIndex: number;
  /** Global step count */
  stepCount: number;
  /** Timestamp */
  timestamp: number;
};

// ─────────────────────────────────────────────────────────────────
// Scheduler state
// ─────────────────────────────────────────────────────────────────

/**
 * SchedulerState: Global state of the fiber scheduler.
 */
export type SchedulerState = {
  /** All fibers by ID */
  fibers: Map<FiberId, FiberState>;
  /** Ready queue (fiber IDs) */
  readyQueue: FiberId[];
  /** Currently running fiber */
  running?: FiberId;
  /** Scheduling policy */
  policy: SchedulePolicy;
  /** Global step count */
  stepCount: number;
  /** Schedule decisions for replay */
  decisions: ScheduleDecision[];
  /** Replay index (if replaying) */
  replayIndex: number;
  /** Random number generator state (for Random policy) */
  rngState?: number;
};

/**
 * SchedulerStatus: Current state of the scheduler.
 */
export type SchedulerStatus =
  | { tag: "running"; fiberId: FiberId }
  | { tag: "idle" }
  | { tag: "deadlock"; blocked: FiberId[] }
  | { tag: "done"; results: Map<FiberId, Val> }
  | { tag: "error"; fiberId: FiberId; message: string };

// ─────────────────────────────────────────────────────────────────
// Synchronization primitive states
// ─────────────────────────────────────────────────────────────────

/**
 * MutexState: Internal state of a mutex.
 */
export type MutexState = {
  /** Mutex ID */
  id: string;
  /** Name */
  name?: string;
  /** Fiber holding the lock (if any) */
  holder?: FiberId;
  /** Queue of fibers waiting for the lock */
  waitQueue: FiberId[];
  /** Acquisition count (for deadlock detection) */
  acquisitionCount: number;
};

/**
 * IVarState: Internal state of an IVar.
 */
export type IVarState = {
  /** IVar ID */
  id: string;
  /** Name */
  name?: string;
  /** Value (if written) */
  value?: Val;
  /** Whether value has been written */
  isFull: boolean;
  /** Fibers waiting for the value */
  waitQueue: FiberId[];
};

/**
 * ChannelState: Internal state of a channel.
 */
export type ChannelState = {
  /** Channel ID */
  id: string;
  /** Name */
  name?: string;
  /** Buffer size (0 = unbuffered) */
  bufferSize: number;
  /** Buffered values */
  buffer: Val[];
  /** Fibers waiting to send */
  sendQueue: Array<{ fiberId: FiberId; value: Val }>;
  /** Fibers waiting to receive */
  recvQueue: FiberId[];
  /** Whether channel is closed */
  closed: boolean;
};

/**
 * ActorState: Internal state of an actor.
 */
export type ActorState = {
  /** Actor ID */
  id: string;
  /** Name */
  name?: string;
  /** Underlying fiber ID */
  fiberId: FiberId;
  /** Mailbox (message queue) */
  mailbox: Val[];
  /** Whether actor is processing a message */
  processing: boolean;
};

// ─────────────────────────────────────────────────────────────────
// Concurrency event ledger
// ─────────────────────────────────────────────────────────────────

/**
 * ConcurrencyEvent: Record of a concurrency operation.
 */
export type ConcurrencyEvent =
  | { tag: "spawn"; fiberId: FiberId; parentId?: FiberId; timestamp: number }
  | { tag: "yield"; fiberId: FiberId; timestamp: number }
  | { tag: "join"; fiberId: FiberId; targetId: FiberId; timestamp: number }
  | { tag: "done"; fiberId: FiberId; valueHash: Hash; timestamp: number }
  | { tag: "error"; fiberId: FiberId; message: string; timestamp: number }
  | { tag: "schedule"; decision: ScheduleDecision }
  | { tag: "mutexLock"; fiberId: FiberId; mutexId: string; timestamp: number }
  | { tag: "mutexUnlock"; fiberId: FiberId; mutexId: string; timestamp: number }
  | { tag: "mutexBlock"; fiberId: FiberId; mutexId: string; timestamp: number }
  | { tag: "ivarPut"; fiberId: FiberId; ivarId: string; valueHash: Hash; timestamp: number }
  | { tag: "ivarTake"; fiberId: FiberId; ivarId: string; timestamp: number }
  | { tag: "ivarBlock"; fiberId: FiberId; ivarId: string; timestamp: number }
  | { tag: "chanSend"; fiberId: FiberId; channelId: string; valueHash: Hash; timestamp: number }
  | { tag: "chanRecv"; fiberId: FiberId; channelId: string; timestamp: number }
  | { tag: "deadlock"; blocked: FiberId[]; timestamp: number };

// ─────────────────────────────────────────────────────────────────
// Concurrency budget
// ─────────────────────────────────────────────────────────────────

/**
 * ConcurrencyBudget: Resource limits for concurrent execution.
 */
export type ConcurrencyBudget = {
  /** Maximum fibers that can be spawned */
  maxSpawns: number;
  /** Maximum yield operations */
  maxYields: number;
  /** Maximum total steps across all fibers */
  maxTotalSteps: number;
  /** Maximum steps per fiber before forced yield */
  maxStepsPerFiber: number;
  /** Maximum mutex operations */
  maxMutexOps: number;
  /** Maximum IVar operations */
  maxIVarOps: number;
};

export const DEFAULT_CONCURRENCY_BUDGET: ConcurrencyBudget = {
  maxSpawns: 100,
  maxYields: 10000,
  maxTotalSteps: 1000000,
  maxStepsPerFiber: 10000,
  maxMutexOps: 10000,
  maxIVarOps: 10000,
};

// ─────────────────────────────────────────────────────────────────
// Type guards and helpers
// ─────────────────────────────────────────────────────────────────

export function isFiber(v: Val): v is FiberVal {
  return v.tag === "Fiber";
}

export function isMutex(v: Val): v is MutexVal {
  return v.tag === "Mutex";
}

export function isIVar(v: Val): v is IVarVal {
  return v.tag === "IVar";
}

export function isChannel(v: Val): v is ChannelVal {
  return v.tag === "Channel";
}

export function isActor(v: Val): v is ActorVal {
  return v.tag === "Actor";
}

/**
 * Create a FiberVal.
 */
export function makeFiber(id: FiberId, name?: string): FiberVal {
  return { tag: "Fiber", id, name };
}

/**
 * Create a MutexVal.
 */
export function makeMutex(id: string, name?: string): MutexVal {
  return { tag: "Mutex", id, name };
}

/**
 * Create an IVarVal.
 */
export function makeIVar(id: string, name?: string): IVarVal {
  return { tag: "IVar", id, name };
}

/**
 * Create a ChannelVal.
 */
export function makeChannel(id: string, bufferSize: number, name?: string): ChannelVal {
  return { tag: "Channel", id, bufferSize, name };
}

/**
 * Create an ActorVal.
 */
export function makeActor(id: string, fiberId: FiberId, name?: string): ActorVal {
  return { tag: "Actor", id, fiberId, name };
}

/**
 * Create a SchedulerView from SchedulerState.
 */
export function createSchedulerView(state: SchedulerState): SchedulerView {
  const ready: FiberId[] = [];
  const blocked: Array<{ id: FiberId; on: string }> = [];
  const done: Array<{ id: FiberId; valueHash: Hash }> = [];

  for (const [id, fiber] of state.fibers) {
    if (fiber.status === "ready") {
      ready.push(id);
    } else if (fiber.status === "blocked" && fiber.blockReason) {
      blocked.push({ id, on: blockReasonToString(fiber.blockReason) });
    } else if (fiber.status === "done") {
      done.push({ id, valueHash: fiber.result ? hashVal(fiber.result) : "" });
    }
  }

  return {
    running: state.running,
    ready,
    blocked,
    done,
    stepCount: state.stepCount,
    policy: policyToString(state.policy),
  };
}

function blockReasonToString(reason: BlockReason): string {
  switch (reason.tag) {
    case "join": return `join:${reason.fiberId}`;
    case "mutex": return `mutex:${reason.mutexId}`;
    case "ivar": return `ivar:${reason.ivarId}`;
    case "channel": return `channel:${reason.op}:${reason.channelId}`;
    case "yield": return "yield";
  }
}

function policyToString(policy: SchedulePolicy): string {
  return policy.tag;
}

function hashVal(v: Val): Hash {
  try {
    return JSON.stringify(v).slice(0, 16);
  } catch {
    return v.tag;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/conditions/frames.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Env } from "../eval/env";
import type { Store } from "../eval/store";
import type { Frame, HandlerFrame } from "../eval/machine";
import type { ConditionHandler, RestartBinding, ConditionVal } from "./types";

export type KHandlerBindFrame = { tag: "KHandlerBind"; handlers: ConditionHandler[] };

export type KRestartBindFrame = {
  tag: "KRestartBind";
  restarts: RestartBinding[];
  savedKont: Frame[];
  env: Env;
  store: Store;
  handlers: HandlerFrame[];
};

export type KSignalingFrame = { tag: "KSignaling"; condition: ConditionVal; required: boolean };

export type ConditionFrame = KHandlerBindFrame | KRestartBindFrame | KSignalingFrame;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/conditions/prims.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Env } from "../eval/env";
import type { Store } from "../eval/store";
import type { State, Frame, HandlerFrame, StepOutcome } from "../eval/machine";
import type { Val } from "../eval/values";
import { VFalse, VTrue, VUnit } from "../eval/values";
import type { ConditionHandler, RestartBinding, ConditionVal, RestartPoint, CallableVal } from "./types";

export class UnhandledConditionError extends Error {
  condition: ConditionVal;

  constructor(condition: ConditionVal) {
    super(`Unhandled condition: ${String(condition.type)} - ${condition.message}`);
    this.name = "UnhandledConditionError";
    this.condition = condition;
  }
}

export type ConditionPrimHelpers = {
  applyProcedure: (proc: Val, procArgs: Val[], state: State) => State | StepOutcome;
  ensureArity: (proc: Val, expected: number, name: string) => void;
  isCallable: (proc: Val) => proc is Val;
};

type ActiveRestart = RestartBinding & {
  savedKont: Frame[];
  env: Env;
  store: Store;
  handlers: HandlerFrame[];
};

function asSymbolName(v: Val): string {
  if (v.tag === "Sym") return v.name;
  if (v.tag === "Str") return v.s;
  throw new Error("expected symbol");
}

function asSymbol(v: Val): symbol {
  return Symbol.for(asSymbolName(v));
}

function asString(v: Val): string {
  if (v.tag === "Str") return v.s;
  if (v.tag === "Sym") return v.name;
  if (v.tag === "Num") return String(v.n);
  if (v.tag === "Bool") return v.b ? "true" : "false";
  if (v.tag === "Unit") return "";
  throw new Error("expected string");
}

function listFromArray(items: Val[]): Val {
  let result: Val = VUnit;
  for (let i = items.length - 1; i >= 0; i--) {
    result = { tag: "Vector", items: [items[i], result] };
  }
  return result;
}

function listToArray(list: Val): Val[] {
  const out: Val[] = [];
  let cur: Val = list;
  while (cur.tag === "Vector" && cur.items.length === 2) {
    out.push(cur.items[0]);
    cur = cur.items[1];
  }
  if (cur.tag !== "Unit") {
    throw new Error("expected proper list");
  }
  return out;
}

function parseHandlerList(list: Val, helpers: ConditionPrimHelpers): ConditionHandler[] {
  if (list.tag === "Unit") return [];
  const entries = listToArray(list);
  const handlers: ConditionHandler[] = [];
  for (const entry of entries) {
    if (entry.tag !== "Vector" || entry.items.length < 2) {
      throw new Error("handler-bind: expected (type handler) pair");
    }
    const [typeVal, handlerVal] = entry.items;
    if (!helpers.isCallable(handlerVal)) {
      throw new Error("handler-bind: handler must be procedure");
    }
    const name = asSymbolName(typeVal);
    handlers.push({ type: name === "*" ? "*" : Symbol.for(name), handler: handlerVal });
  }
  return handlers;
}

function parseRestartList(list: Val, helpers: ConditionPrimHelpers): RestartBinding[] {
  if (list.tag === "Unit") return [];
  const entries = listToArray(list);
  const restarts: RestartBinding[] = [];
  for (const entry of entries) {
    if (entry.tag !== "Vector" || entry.items.length < 2) {
      throw new Error("restart-bind: expected (name fn) pair");
    }
    const [nameVal, fnVal] = entry.items;
    if (!helpers.isCallable(fnVal)) {
      throw new Error("restart-bind: restart must be procedure");
    }
    restarts.push({ name: asSymbol(nameVal), fn: fnVal });
  }
  return restarts;
}

function isHandlerFrame(fr: Frame): fr is { tag: "KHandlerBind"; handlers: ConditionHandler[] } {
  return (fr as any).tag === "KHandlerBind";
}

function isRestartFrame(fr: Frame): fr is { tag: "KRestartBind"; restarts: RestartBinding[]; savedKont: Frame[]; env: Env; store: Store; handlers: HandlerFrame[] } {
  return (fr as any).tag === "KRestartBind";
}

export function findConditionHandler(type: symbol, kont: Frame[]): ConditionHandler | null {
  for (let i = kont.length - 1; i >= 0; i--) {
    const fr = kont[i];
    if (isHandlerFrame(fr)) {
      for (const h of fr.handlers) {
        if (h.type === "*" || h.type === type) return h;
      }
    }
  }
  return null;
}

export function findRestart(name: symbol, kont: Frame[]): ActiveRestart | null {
  for (let i = kont.length - 1; i >= 0; i--) {
    const fr = kont[i];
    if (isRestartFrame(fr)) {
      const found = fr.restarts.find(r => r.name === name);
      if (found) {
        return { ...found, savedKont: fr.savedKont.slice(), env: fr.env, store: fr.store, handlers: fr.handlers.slice() };
      }
    }
  }
  return null;
}

export function collectActiveRestarts(state: State): RestartPoint[] {
  const points: RestartPoint[] = [];
  for (let i = state.kont.length - 1; i >= 0; i--) {
    const fr = state.kont[i];
    if (isRestartFrame(fr)) {
      for (const r of fr.restarts) {
        points.push({
          name: r.name,
          description: r.description,
          kont: fr.savedKont.slice(),
          env: fr.env,
          store: fr.store,
          handlers: fr.handlers.slice(),
        });
      }
    }
  }
  return points;
}

function makeCondition(args: Val[], state: State): ConditionVal {
  const [typeVal, messageVal, data] = args;
  return {
    tag: "Condition",
    type: asSymbol(typeVal),
    message: asString(messageVal),
    data,
    restarts: collectActiveRestarts(state),
  };
}

export function registerConditionPrims(def: (name: string, v: Val) => void, helpers: ConditionPrimHelpers): void {
  // (signal type message data)
  def("signal", {
    tag: "Native",
    name: "signal",
    arity: 3,
    fn: (args, state) => {
      const condition = makeCondition(args, state);
      const handler = findConditionHandler(condition.type, state.kont);
      if (!handler) {
        return { ...state, control: { tag: "Val", v: VUnit } };
      }
      const kont = state.kont.concat([{ tag: "KSignaling", condition, required: false } as Frame]);
      return helpers.applyProcedure(handler.handler, [condition], { ...state, kont });
    },
  });

  // (error type message data)
  def("error", {
    tag: "Native",
    name: "error",
    arity: 3,
    fn: (args, state) => {
      const condition = makeCondition(args, state);
      const handler = findConditionHandler(condition.type, state.kont);
      if (!handler) {
        throw new UnhandledConditionError(condition);
      }
      const kont = state.kont.concat([{ tag: "KSignaling", condition, required: true } as Frame]);
      return helpers.applyProcedure(handler.handler, [condition], { ...state, kont });
    },
  });

  // (handler-bind ((type handler) ...) thunk)
  def("handler-bind", {
    tag: "Native",
    name: "handler-bind",
    arity: 2,
    fn: (args, state) => {
      const [handlersVal, thunk] = args;
      if (!helpers.isCallable(thunk)) {
        throw new Error("handler-bind: expected thunk");
      }
      helpers.ensureArity(thunk, 0, "handler-bind");
      const handlers = parseHandlerList(handlersVal, helpers);
      const kont = state.kont.concat([{ tag: "KHandlerBind", handlers } as Frame]);
      return helpers.applyProcedure(thunk, [], { ...state, kont });
    },
  });

  // (restart-bind ((name fn) ...) thunk)
  def("restart-bind", {
    tag: "Native",
    name: "restart-bind",
    arity: 2,
    fn: (args, state) => {
      const [restartsVal, thunk] = args;
      if (!helpers.isCallable(thunk)) {
        throw new Error("restart-bind: expected thunk");
      }
      helpers.ensureArity(thunk, 0, "restart-bind");
      const restarts = parseRestartList(restartsVal, helpers);
      const frame: Frame = {
        tag: "KRestartBind",
        restarts,
        savedKont: state.kont.slice(),
        env: state.env,
        store: state.store,
        handlers: state.handlers.slice(),
      } as Frame;
      const kont = state.kont.concat([frame]);
      return helpers.applyProcedure(thunk, [], { ...state, kont });
    },
  });

  // (invoke-restart name value...)
  def("invoke-restart", {
    tag: "Native",
    name: "invoke-restart",
    arity: "variadic",
    fn: (args, state) => {
      if (args.length < 1) throw new Error("invoke-restart: expected at least 1 argument");
      const [nameVal, ...rest] = args;
      const restart = findRestart(asSymbol(nameVal), state.kont);
      if (!restart) {
        throw new Error(`invoke-restart: no restart named ${asSymbolName(nameVal)}`);
      }
      const jumpState: State = {
        ...state,
        env: restart.env,
        store: restart.store,
        kont: restart.savedKont,
        handlers: restart.handlers,
      };
      return helpers.applyProcedure(restart.fn, rest, jumpState);
    },
  });

  // (find-restart name)
  def("find-restart", {
    tag: "Native",
    name: "find-restart",
    arity: 1,
    fn: (args, state) => {
      const restart = findRestart(asSymbol(args[0]), state.kont);
      return { ...state, control: { tag: "Val", v: restart ? VTrue : VFalse } };
    },
  });

  // (compute-restarts)
  def("compute-restarts", {
    tag: "Native",
    name: "compute-restarts",
    arity: 0,
    fn: (_args, state) => {
      const names = collectActiveRestarts(state).map(r => ({ tag: "Sym", name: Symbol.keyFor(r.name) ?? String(r.name) } as Val));
      const list = listFromArray(names);
      return { ...state, control: { tag: "Val", v: list } };
    },
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/conditions/types.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Env } from "../eval/env";
import type { Store } from "../eval/store";
import type { Val } from "../eval/values";
import type { Frame, HandlerFrame } from "../eval/machine";

// Callable procedures used by handlers and restarts
export type CallableVal = Val;

export type ConditionVal = {
  tag: "Condition";
  type: symbol;
  message: string;
  data: Val;
  restarts: RestartPoint[];
};

export type RestartPoint = {
  name: symbol;
  description?: string;
  kont: Frame[];
  env: Env;
  store: Store;
  handlers: HandlerFrame[];
};

export type ConditionHandler = {
  type: symbol | "*";
  handler: CallableVal;
};

export type RestartBinding = {
  name: symbol;
  fn: CallableVal;
  description?: string;
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/config/config.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/config/config.ts
// Configuration system for OmegaLLM
// Based on LambdaRLM's config system

import * as fs from "fs";
import * as path from "path";

// =========================================================================
// Configuration Types
// =========================================================================

export type OracleProvider = "anthropic" | "openai" | "ollama";

export type LLMConfig = {
  /** LLM provider: anthropic, openai, or ollama */
  provider: OracleProvider;
  /** Model name (provider-specific) */
  model: string;
  /** API key (optional, can use env vars) */
  apiKey?: string;
  /** API base URL (for ollama or custom endpoints) */
  baseUrl?: string;
  /** Request timeout in milliseconds */
  timeoutMs: number;
  /** Maximum tokens for responses */
  maxTokens: number;
  /** System prompt override */
  systemPrompt?: string;
};

export type RuntimeConfig = {
  /** Maximum oracle turns before termination */
  maxOracleTurns: number;
  /** Maximum eval steps per operation */
  maxEvalSteps: number;
  /** Maximum tool calls */
  maxToolCalls: number;
  /** Maximum nested depth */
  maxNestedDepth: number;
};

export type OmegaConfig = {
  llm: LLMConfig;
  runtime: RuntimeConfig;
};

// =========================================================================
// Default Configuration
// =========================================================================

export const DEFAULT_MODELS: Record<OracleProvider, string> = {
  anthropic: "claude-sonnet-4-20250514",
  openai: "gpt-4o",
  ollama: "llama3.1",
};

export const DEFAULT_BASE_URLS: Partial<Record<OracleProvider, string>> = {
  ollama: "http://localhost:11434",
};

export const DEFAULT_LLM_CONFIG: LLMConfig = {
  provider: "anthropic",
  model: DEFAULT_MODELS.anthropic,
  timeoutMs: 120_000,
  maxTokens: 4096,
};

export const DEFAULT_RUNTIME_CONFIG: RuntimeConfig = {
  maxOracleTurns: 10_000,
  maxEvalSteps: 500_000,
  maxToolCalls: 1000,
  maxNestedDepth: 16,
};

export const DEFAULT_CONFIG: OmegaConfig = {
  llm: DEFAULT_LLM_CONFIG,
  runtime: DEFAULT_RUNTIME_CONFIG,
};

// =========================================================================
// Configuration Loading
// =========================================================================

/**
 * Get API key for provider from environment variables.
 * Checks both generic and provider-specific env vars.
 */
export function getApiKeyFromEnv(provider: OracleProvider): string | undefined {
  // Check generic env var first
  const generic = process.env.OMEGA_API_KEY;
  if (generic) return generic;

  // Check provider-specific env vars
  switch (provider) {
    case "anthropic":
      return process.env.ANTHROPIC_API_KEY;
    case "openai":
      return process.env.OPENAI_API_KEY;
    case "ollama":
      // Ollama doesn't need an API key for local instance
      return undefined;
  }
}

/**
 * Load configuration from environment variables.
 */
export function configFromEnv(prefix = "OMEGA"): OmegaConfig {
  const provider = (process.env[`${prefix}_PROVIDER`] as OracleProvider) || DEFAULT_LLM_CONFIG.provider;
  const model = process.env[`${prefix}_MODEL`] || DEFAULT_MODELS[provider] || DEFAULT_LLM_CONFIG.model;
  const apiKey = process.env[`${prefix}_API_KEY`] || getApiKeyFromEnv(provider);
  const baseUrl = process.env[`${prefix}_BASE_URL`] || DEFAULT_BASE_URLS[provider];
  const timeoutMs = parseInt(process.env[`${prefix}_TIMEOUT_MS`] || "", 10) || DEFAULT_LLM_CONFIG.timeoutMs;
  const maxTokens = parseInt(process.env[`${prefix}_MAX_TOKENS`] || "", 10) || DEFAULT_LLM_CONFIG.maxTokens;

  const maxOracleTurns = parseInt(process.env[`${prefix}_MAX_ORACLE_TURNS`] || "", 10) || DEFAULT_RUNTIME_CONFIG.maxOracleTurns;
  const maxEvalSteps = parseInt(process.env[`${prefix}_MAX_EVAL_STEPS`] || "", 10) || DEFAULT_RUNTIME_CONFIG.maxEvalSteps;
  const maxToolCalls = parseInt(process.env[`${prefix}_MAX_TOOL_CALLS`] || "", 10) || DEFAULT_RUNTIME_CONFIG.maxToolCalls;
  const maxNestedDepth = parseInt(process.env[`${prefix}_MAX_NESTED_DEPTH`] || "", 10) || DEFAULT_RUNTIME_CONFIG.maxNestedDepth;

  return {
    llm: {
      provider,
      model,
      apiKey,
      baseUrl,
      timeoutMs,
      maxTokens,
    },
    runtime: {
      maxOracleTurns,
      maxEvalSteps,
      maxToolCalls,
      maxNestedDepth,
    },
  };
}

/**
 * Load configuration from a JSON or YAML file.
 */
export function configFromFile(filePath: string): OmegaConfig {
  if (!fs.existsSync(filePath)) {
    throw new Error(`Config file not found: ${filePath}`);
  }

  const content = fs.readFileSync(filePath, "utf8");
  const ext = path.extname(filePath).toLowerCase();

  let data: Record<string, unknown>;

  if (ext === ".json") {
    data = JSON.parse(content);
  } else if (ext === ".yaml" || ext === ".yml") {
    // Simple YAML parser for basic configs
    data = parseSimpleYaml(content);
  } else {
    throw new Error(`Unsupported config file format: ${ext}`);
  }

  return configFromObject(data);
}

/**
 * Create configuration from a plain object (e.g., from parsed JSON/YAML).
 */
export function configFromObject(data: Record<string, unknown>): OmegaConfig {
  const llmData = (data.llm as Record<string, unknown>) || {};
  const runtimeData = (data.runtime as Record<string, unknown>) || {};

  const provider = (llmData.provider as OracleProvider) || DEFAULT_LLM_CONFIG.provider;

  return {
    llm: {
      provider,
      model: (llmData.model as string) || DEFAULT_MODELS[provider] || DEFAULT_LLM_CONFIG.model,
      apiKey: (llmData.apiKey as string) || (llmData.api_key as string),
      baseUrl: (llmData.baseUrl as string) || (llmData.base_url as string) || DEFAULT_BASE_URLS[provider],
      timeoutMs: (llmData.timeoutMs as number) || (llmData.timeout_ms as number) || DEFAULT_LLM_CONFIG.timeoutMs,
      maxTokens: (llmData.maxTokens as number) || (llmData.max_tokens as number) || DEFAULT_LLM_CONFIG.maxTokens,
      systemPrompt: (llmData.systemPrompt as string) || (llmData.system_prompt as string),
    },
    runtime: {
      maxOracleTurns: (runtimeData.maxOracleTurns as number) || (runtimeData.max_oracle_turns as number) || DEFAULT_RUNTIME_CONFIG.maxOracleTurns,
      maxEvalSteps: (runtimeData.maxEvalSteps as number) || (runtimeData.max_eval_steps as number) || DEFAULT_RUNTIME_CONFIG.maxEvalSteps,
      maxToolCalls: (runtimeData.maxToolCalls as number) || (runtimeData.max_tool_calls as number) || DEFAULT_RUNTIME_CONFIG.maxToolCalls,
      maxNestedDepth: (runtimeData.maxNestedDepth as number) || (runtimeData.max_nested_depth as number) || DEFAULT_RUNTIME_CONFIG.maxNestedDepth,
    },
  };
}

/**
 * Merge configs with later ones overriding earlier ones.
 */
export function mergeConfigs(...configs: Partial<OmegaConfig>[]): OmegaConfig {
  let result = { ...DEFAULT_CONFIG };

  for (const cfg of configs) {
    if (cfg.llm) {
      result.llm = { ...result.llm, ...cfg.llm };
    }
    if (cfg.runtime) {
      result.runtime = { ...result.runtime, ...cfg.runtime };
    }
  }

  return result;
}

/**
 * Auto-detect and load configuration.
 * Priority: CLI args > config file > environment > defaults
 */
export function loadConfig(options?: {
  configFile?: string;
  overrides?: Partial<OmegaConfig>;
}): OmegaConfig {
  // Start with env config (includes defaults)
  let config = configFromEnv();

  // Load file config if specified
  if (options?.configFile) {
    const fileConfig = configFromFile(options.configFile);
    config = mergeConfigs(config, fileConfig);
  } else {
    // Try to find default config files
    const defaultPaths = ["omega.config.json", "omega.config.yaml", "omega.config.yml", "config.json", "config.yaml"];
    for (const p of defaultPaths) {
      if (fs.existsSync(p)) {
        const fileConfig = configFromFile(p);
        config = mergeConfigs(config, fileConfig);
        break;
      }
    }
  }

  // Apply overrides
  if (options?.overrides) {
    config = mergeConfigs(config, options.overrides);
  }

  // Resolve API key from environment if not set
  if (!config.llm.apiKey) {
    config.llm.apiKey = getApiKeyFromEnv(config.llm.provider);
  }

  return config;
}

// =========================================================================
// Simple YAML Parser (for basic configs only)
// =========================================================================

function parseSimpleYaml(content: string): Record<string, unknown> {
  const result: Record<string, unknown> = {};
  const stack: Array<{ obj: Record<string, unknown>; indent: number }> = [{ obj: result, indent: -1 }];

  const lines = content.split("\n");

  for (const rawLine of lines) {
    // Skip empty lines and comments
    const trimmed = rawLine.trim();
    if (!trimmed || trimmed.startsWith("#")) continue;

    // Calculate indentation
    const indent = rawLine.search(/\S/);
    if (indent < 0) continue;

    // Pop stack to find parent at correct indent level
    while (stack.length > 1 && stack[stack.length - 1]!.indent >= indent) {
      stack.pop();
    }

    const parent = stack[stack.length - 1]!.obj;

    // Parse key: value
    const colonIdx = trimmed.indexOf(":");
    if (colonIdx < 0) continue;

    const key = trimmed.slice(0, colonIdx).trim();
    let value: string | number | boolean | Record<string, unknown> = trimmed.slice(colonIdx + 1).trim();

    if (value === "") {
      // Nested object
      const nested: Record<string, unknown> = {};
      parent[key] = nested;
      stack.push({ obj: nested, indent });
    } else {
      // Parse value
      if (value === "true") {
        parent[key] = true;
      } else if (value === "false") {
        parent[key] = false;
      } else if (value === "null") {
        parent[key] = null;
      } else if (/^-?\d+$/.test(value)) {
        parent[key] = parseInt(value, 10);
      } else if (/^-?\d+\.\d+$/.test(value)) {
        parent[key] = parseFloat(value);
      } else if ((value.startsWith('"') && value.endsWith('"')) || (value.startsWith("'") && value.endsWith("'"))) {
        parent[key] = value.slice(1, -1);
      } else {
        parent[key] = value;
      }
    }
  }

  return result;
}

// =========================================================================
// Config Validation
// =========================================================================

export type ConfigValidation = {
  valid: boolean;
  errors: string[];
  warnings: string[];
};

export function validateConfig(config: OmegaConfig): ConfigValidation {
  const errors: string[] = [];
  const warnings: string[] = [];

  // Check API key for non-ollama providers
  if (config.llm.provider !== "ollama" && !config.llm.apiKey) {
    errors.push(`Missing API key for provider: ${config.llm.provider}. Set ${config.llm.provider.toUpperCase()}_API_KEY or OMEGA_API_KEY`);
  }

  // Check reasonable limits
  if (config.runtime.maxOracleTurns < 1) {
    errors.push("maxOracleTurns must be at least 1");
  }
  if (config.runtime.maxEvalSteps < 100) {
    warnings.push("maxEvalSteps is very low, may cause premature termination");
  }

  return {
    valid: errors.length === 0,
    errors,
    warnings,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/config/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/config/index.ts
// Configuration system exports

export {
  type OracleProvider,
  type LLMConfig,
  type RuntimeConfig,
  type OmegaConfig,
  type ConfigValidation,
  DEFAULT_MODELS,
  DEFAULT_BASE_URLS,
  DEFAULT_LLM_CONFIG,
  DEFAULT_RUNTIME_CONFIG,
  DEFAULT_CONFIG,
  getApiKeyFromEnv,
  configFromEnv,
  configFromFile,
  configFromObject,
  mergeConfigs,
  loadConfig,
  validateConfig,
} from "./config";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/diagnosis.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/diagnosis.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: Diagnosis API for constraint networks (unsat core, explanation extraction)

import type { Val, NetRefVal, ConnRefVal, ContradictionVal, ExplanationVal } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import {
  type NetworkState,
  type PropagatorState,
  type ConnectorState,
} from "./types";
import { getNetwork } from "./network";

// ─────────────────────────────────────────────────────────────────
// Unsat core extraction
// ─────────────────────────────────────────────────────────────────

/**
 * UnsatCore: A minimal set of constraints that are in conflict.
 */
export type UnsatCore = {
  /** IDs of constraints in the core */
  constraintIds: string[];
  /** IDs of connectors involved */
  connectorIds: string[];
  /** Assumptions (initial values) in the core */
  assumptions: Array<{ connId: string; valueHash: Hash }>;
  /** The explanation graph leading to contradiction */
  explanation: ExplanationVal;
};

/**
 * Extract the unsat core from a contradiction.
 * Uses the explanation graph to find the minimal set of constraints.
 */
export function extractUnsatCore(
  netRef: NetRefVal,
  contradiction: ContradictionVal
): UnsatCore {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);

  const constraintIds = new Set<string>();
  const connectorIds = new Set<string>();
  const assumptions: Array<{ connId: string; valueHash: Hash }> = [];

  // Traverse explanation graph to collect contributors
  collectFromExplanation(contradiction.explanation, constraintIds, connectorIds, assumptions, net);

  return {
    constraintIds: Array.from(constraintIds),
    connectorIds: Array.from(connectorIds),
    assumptions,
    explanation: contradiction.explanation,
  };
}

/**
 * Recursively collect constraints and connectors from an explanation.
 */
function collectFromExplanation(
  expl: ExplanationVal,
  constraintIds: Set<string>,
  connectorIds: Set<string>,
  assumptions: Array<{ connId: string; valueHash: Hash }>,
  net: NetworkState
): void {
  switch (expl.kind) {
    case "assumption":
      connectorIds.add(expl.conn.id);
      assumptions.push({ connId: expl.conn.id, valueHash: expl.valueHash });
      break;

    case "derived":
      connectorIds.add(expl.conn.id);
      // Find the propagator that produced this
      for (const [propId, prop] of net.propagators) {
        if (prop.name === expl.rule) {
          if (prop.isConstraint) {
            constraintIds.add(propId);
          }
          break;
        }
      }
      // Recurse into dependencies
      for (const dep of expl.deps) {
        collectFromExplanation(dep, constraintIds, connectorIds, assumptions, net);
      }
      break;

    case "conflict":
      connectorIds.add(expl.conn.id);
      collectFromExplanation(expl.left, constraintIds, connectorIds, assumptions, net);
      collectFromExplanation(expl.right, constraintIds, connectorIds, assumptions, net);
      break;

    case "denied":
      // No connectors/constraints for denied operations
      break;
  }
}

// ─────────────────────────────────────────────────────────────────
// Explanation graph traversal
// ─────────────────────────────────────────────────────────────────

/**
 * ExplanationVisitor: Callbacks for traversing an explanation graph.
 */
export type ExplanationVisitor = {
  onAssumption?: (conn: ConnRefVal, valueHash: Hash, because: Val) => void;
  onDerived?: (conn: ConnRefVal, valueHash: Hash, rule: string, deps: ExplanationVal[]) => void;
  onConflict?: (conn: ConnRefVal, left: ExplanationVal, right: ExplanationVal, message?: string) => void;
  onDenied?: (op: string, reason: string, profile?: string) => void;
};

/**
 * Traverse an explanation graph with a visitor.
 */
export function traverseExplanation(
  expl: ExplanationVal,
  visitor: ExplanationVisitor
): void {
  switch (expl.kind) {
    case "assumption":
      visitor.onAssumption?.(expl.conn, expl.valueHash, expl.because);
      break;

    case "derived":
      visitor.onDerived?.(expl.conn, expl.valueHash, expl.rule, expl.deps);
      for (const dep of expl.deps) {
        traverseExplanation(dep, visitor);
      }
      break;

    case "conflict":
      visitor.onConflict?.(expl.conn, expl.left, expl.right, expl.message);
      traverseExplanation(expl.left, visitor);
      traverseExplanation(expl.right, visitor);
      break;

    case "denied":
      visitor.onDenied?.(expl.op, expl.reason, expl.profile);
      break;
  }
}

/**
 * Get all connectors mentioned in an explanation.
 */
export function getExplanationConnectors(expl: ExplanationVal): ConnRefVal[] {
  const connectors: ConnRefVal[] = [];
  traverseExplanation(expl, {
    onAssumption: (conn) => connectors.push(conn),
    onDerived: (conn) => connectors.push(conn),
    onConflict: (conn) => connectors.push(conn),
  });
  return connectors;
}

/**
 * Get all rules (propagator names) mentioned in an explanation.
 */
export function getExplanationRules(expl: ExplanationVal): string[] {
  const rules: string[] = [];
  traverseExplanation(expl, {
    onDerived: (_, __, rule) => rules.push(rule),
  });
  return rules;
}

/**
 * Get the depth of an explanation graph.
 */
export function getExplanationDepth(expl: ExplanationVal): number {
  switch (expl.kind) {
    case "assumption":
    case "denied":
      return 1;

    case "derived": {
      const depDepths = expl.deps.map(getExplanationDepth);
      return 1 + Math.max(0, ...depDepths);
    }

    case "conflict":
      return 1 + Math.max(getExplanationDepth(expl.left), getExplanationDepth(expl.right));
  }
}

/**
 * Serialize an explanation to a string for display.
 */
export function explanationToString(expl: ExplanationVal, indent = 0): string {
  const pad = "  ".repeat(indent);

  switch (expl.kind) {
    case "assumption":
      return `${pad}[assumption] ${expl.conn.name ?? expl.conn.id} = ${expl.valueHash}`;

    case "derived":
      return [
        `${pad}[derived by ${expl.rule}] ${expl.conn.name ?? expl.conn.id} = ${expl.valueHash}`,
        ...expl.deps.map(d => explanationToString(d, indent + 1)),
      ].join("\n");

    case "conflict":
      return [
        `${pad}[CONFLICT] ${expl.message ?? "conflicting values"}`,
        `${pad}  left:`,
        explanationToString(expl.left, indent + 2),
        `${pad}  right:`,
        explanationToString(expl.right, indent + 2),
      ].join("\n");

    case "denied":
      return `${pad}[DENIED] ${expl.op}: ${expl.reason}`;
  }
}

/**
 * Hash an explanation for comparison.
 */
export function hashExplanation(expl: ExplanationVal): Hash {
  return sha256JSON(expl).slice(0, 16);
}

// ─────────────────────────────────────────────────────────────────
// Constraint analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Get all constraints from a network.
 */
export function getConstraints(netRef: NetRefVal): PropagatorState[] {
  const net = getNetwork(netRef.id);
  if (!net) return [];
  return Array.from(net.propagators.values()).filter(p => p.isConstraint);
}

/**
 * Get all propagators that contributed to a connector's value.
 */
export function getContributingPropagators(
  netRef: NetRefVal,
  connRef: ConnRefVal
): PropagatorState[] {
  const net = getNetwork(netRef.id);
  if (!net) return [];
  const conn = net.connectors.get(connRef.id);
  if (!conn) return [];

  // Find all propagators that write to this connector
  const writers = Array.from(conn.writers);
  return writers
    .map(id => net.propagators.get(id))
    .filter((p): p is PropagatorState => p !== undefined);
}

/**
 * Find propagators that could potentially resolve a contradiction.
 * These are propagators that write to connectors in the unsat core
 * but are not themselves in the core.
 */
export function findPotentialResolvers(
  netRef: NetRefVal,
  core: UnsatCore
): PropagatorState[] {
  const net = getNetwork(netRef.id);
  if (!net) return [];

  const coreConstraints = new Set(core.constraintIds);
  const coreConnectors = new Set(core.connectorIds);
  const resolvers: PropagatorState[] = [];

  for (const [propId, prop] of net.propagators) {
    // Skip if in core
    if (coreConstraints.has(propId)) continue;

    // Check if outputs include core connectors
    const writesToCore = prop.outputs.some(connId => coreConnectors.has(connId));
    if (writesToCore) {
      resolvers.push(prop);
    }
  }

  return resolvers;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/engine.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/engine.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: Propagation engine for constraint networks

import type { Val, NetRefVal, ConnRefVal, ContradictionVal, ExplanationVal } from "../eval/values";
import { VUnit, VTrue, VFalse } from "../eval/values";
import type { Runtime } from "../eval/runtime";
import type { State } from "../eval/machine";
import {
  type NetworkState,
  type NetworkStatus,
  type PropagatorState,
  type PropagationConfig,
  type PropagationBudget,
  DEFAULT_PROPAGATION_CONFIG,
  makeContradiction,
  makeDenied,
} from "./types";
import {
  getNetwork,
  setNetwork,
  connectorHasValue,
  connectorGetValue,
  connectorGetExplanation,
  connectorSetValue,
  cloneNetwork,
} from "./network";

// ─────────────────────────────────────────────────────────────────
// Propagation result types
// ─────────────────────────────────────────────────────────────────

/**
 * PropagationResult: Result of running propagation.
 */
export type PropagationResult = {
  /** Final network status */
  status: NetworkStatus;
  /** Number of propagator firings */
  firings: number;
  /** Number of connector sets */
  sets: number;
  /** Whether budget was exhausted */
  budgetExhausted: boolean;
  /** Contradiction (if any) */
  contradiction?: ContradictionVal;
};

// ─────────────────────────────────────────────────────────────────
// Propagator execution context
// ─────────────────────────────────────────────────────────────────

/**
 * PropagatorContext: Context for executing a propagator.
 */
export type PropagatorContext = {
  /** Input values (keyed by connector ID) */
  inputs: Map<string, Val>;
  /** Input explanations (keyed by connector ID) */
  inputExplanations: Map<string, ExplanationVal>;
  /** Propagator name (for explanation building) */
  propagatorName: string;
  /** Network reference */
  netRef: NetRefVal;
};

/**
 * PropagatorOutput: Output from a propagator execution.
 */
export type PropagatorOutput =
  | { tag: "values"; values: Map<string, Val> }
  | { tag: "contradiction"; message: string }
  | { tag: "noChange" }
  | { tag: "suspend"; op: string; args: Val[] };

// ─────────────────────────────────────────────────────────────────
// Scripted propagator registry (for testing)
// ─────────────────────────────────────────────────────────────────

/**
 * ScriptedPropagator: A propagator with scripted behavior for testing.
 */
export type ScriptedPropagator = {
  name: string;
  execute: (ctx: PropagatorContext) => PropagatorOutput;
};

const scriptedPropagators = new Map<string, ScriptedPropagator>();

/**
 * Register a scripted propagator.
 */
export function registerScriptedPropagator(prop: ScriptedPropagator): void {
  scriptedPropagators.set(prop.name, prop);
}

/**
 * Clear all scripted propagators.
 */
export function clearScriptedPropagators(): void {
  scriptedPropagators.clear();
}

/**
 * Get a scripted propagator by name.
 */
export function getScriptedPropagator(name: string): ScriptedPropagator | undefined {
  return scriptedPropagators.get(name);
}

// ─────────────────────────────────────────────────────────────────
// Propagation engine
// ─────────────────────────────────────────────────────────────────

/**
 * Run propagation on a network until quiescence or contradiction.
 */
export async function runPropagation(
  netRef: NetRefVal,
  config: Partial<PropagationConfig> = {}
): Promise<PropagationResult> {
  const fullConfig: PropagationConfig = {
    ...DEFAULT_PROPAGATION_CONFIG,
    ...config,
    budget: { ...DEFAULT_PROPAGATION_CONFIG.budget, ...config.budget },
  };

  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);

  let firings = 0;
  let sets = 0;
  let budgetExhausted = false;

  // Main propagation loop
  while (net.agenda.length > 0) {
    // Check budget
    if (firings >= fullConfig.budget.maxFirings) {
      budgetExhausted = true;
      net.status = { tag: "budgetExhausted", resource: "firings" };
      break;
    }
    if (sets >= fullConfig.budget.maxSets) {
      budgetExhausted = true;
      net.status = { tag: "budgetExhausted", resource: "sets" };
      break;
    }

    // Select next propagator
    const propId = selectNextPropagator(net, fullConfig);
    if (!propId) break;

    const prop = net.propagators.get(propId);
    if (!prop) continue;

    // Check if all inputs are ready
    const allInputsReady = prop.inputs.every(connId => {
      const conn = net.connectors.get(connId);
      return conn && conn.value !== undefined;
    });

    if (!allInputsReady) continue;

    // Execute propagator
    firings++;
    prop.fireCount++;
    net.stepCount++;

    // Record fire event
    if (fullConfig.recordLedger) {
      net.ledger.push({
        type: "fire",
        timestamp: Date.now(),
        propId,
        stepCount: net.stepCount,
      });
    }

    const output = await executePropagator(prop, net, netRef);

    // Handle output
    if (output.tag === "values") {
      for (const [connId, value] of output.values) {
        const conn = net.connectors.get(connId);
        if (!conn) continue;

        const connRef: ConnRefVal = {
          tag: "ConnRef",
          id: connId,
          netId: netRef.id,
          name: conn.name,
        };

        // Build dependencies for explanation
        const deps: ExplanationVal[] = prop.inputs
          .map(inputId => net.connectors.get(inputId)?.explanation)
          .filter((e): e is ExplanationVal => e !== undefined);

        const contradiction = connectorSetValue(
          connRef,
          value,
          { tag: "Str", s: `set by ${prop.name}` },
          prop.name,
          deps
        );

        if (contradiction) {
          return {
            status: net.status,
            firings,
            sets,
            budgetExhausted: false,
            contradiction,
          };
        }
        sets++;
      }
    } else if (output.tag === "contradiction") {
      // Constraint violation
      const connRef: ConnRefVal = prop.outputs.length > 0
        ? { tag: "ConnRef", id: prop.outputs[0], netId: netRef.id }
        : { tag: "ConnRef", id: prop.inputs[0], netId: netRef.id };

      const deps: ExplanationVal[] = prop.inputs
        .map(inputId => net.connectors.get(inputId)?.explanation)
        .filter((e): e is ExplanationVal => e !== undefined);

      const explanation: ExplanationVal = {
        tag: "Explanation",
        kind: "conflict",
        conn: connRef,
        left: deps[0] ?? { tag: "Explanation", kind: "assumption", conn: connRef, valueHash: "", because: VUnit },
        right: { tag: "Explanation", kind: "assumption", conn: connRef, valueHash: "", because: { tag: "Str", s: output.message } },
        message: output.message,
      };

      const contradiction = makeContradiction(explanation, prop.id, netRef.id);
      net.contradictions.push(contradiction);
      net.status = { tag: "contradiction", contradiction };

      return {
        status: net.status,
        firings,
        sets,
        budgetExhausted: false,
        contradiction,
      };
    } else if (output.tag === "suspend") {
      // Oracle needed
      net.status = { tag: "suspended", op: output.op, args: output.args };
      return {
        status: net.status,
        firings,
        sets,
        budgetExhausted: false,
      };
    }
    // noChange: continue

    // Update status
    if (net.agenda.length === 0) {
      net.status = { tag: "quiescent" };
    } else {
      net.status = { tag: "pending", count: net.agenda.length };
    }
  }

  // Final status
  if (!budgetExhausted && net.status.tag !== "contradiction" && net.status.tag !== "suspended") {
    net.status = { tag: "quiescent" };
  }

  return {
    status: net.status,
    firings,
    sets,
    budgetExhausted,
  };
}

/**
 * Select the next propagator from the agenda.
 */
function selectNextPropagator(
  net: NetworkState,
  config: PropagationConfig
): string | undefined {
  if (net.agenda.length === 0) return undefined;

  switch (config.schedulingStrategy) {
    case "fifo":
      return net.agenda.shift();

    case "priority": {
      // Sort by priority (lower = higher priority)
      let bestIdx = 0;
      let bestPriority = Infinity;
      for (let i = 0; i < net.agenda.length; i++) {
        const prop = net.propagators.get(net.agenda[i]);
        if (prop && prop.priority < bestPriority) {
          bestPriority = prop.priority;
          bestIdx = i;
        }
      }
      return net.agenda.splice(bestIdx, 1)[0];
    }

    case "random": {
      const idx = Math.floor(Math.random() * net.agenda.length);
      return net.agenda.splice(idx, 1)[0];
    }

    default:
      return net.agenda.shift();
  }
}

/**
 * Execute a propagator.
 */
async function executePropagator(
  prop: PropagatorState,
  net: NetworkState,
  netRef: NetRefVal
): Promise<PropagatorOutput> {
  // Build context
  const inputs = new Map<string, Val>();
  const inputExplanations = new Map<string, ExplanationVal>();

  for (const connId of prop.inputs) {
    const conn = net.connectors.get(connId);
    if (conn && conn.value !== undefined) {
      inputs.set(connId, conn.value);
      if (conn.explanation) {
        inputExplanations.set(connId, conn.explanation);
      }
    }
  }

  const ctx: PropagatorContext = {
    inputs,
    inputExplanations,
    propagatorName: prop.name,
    netRef,
  };

  // Try scripted propagator first
  const scripted = getScriptedPropagator(prop.name);
  if (scripted) {
    return scripted.execute(ctx);
  }

  // Built-in propagators
  return executeBuiltinPropagator(prop, ctx);
}

/**
 * Execute a built-in propagator.
 */
function executeBuiltinPropagator(
  prop: PropagatorState,
  ctx: PropagatorContext
): PropagatorOutput {
  // Identity propagator (for testing)
  if (prop.name === "identity" && prop.inputs.length === 1 && prop.outputs.length === 1) {
    const inputVal = ctx.inputs.get(prop.inputs[0]);
    if (inputVal !== undefined) {
      return { tag: "values", values: new Map([[prop.outputs[0], inputVal]]) };
    }
  }

  // Boolean constraint: value must be true
  if (prop.name === "mustBeTrue" && prop.isConstraint) {
    const inputVal = ctx.inputs.get(prop.inputs[0]);
    if (inputVal && inputVal.tag === "Bool" && !inputVal.b) {
      return { tag: "contradiction", message: "Constraint 'mustBeTrue' violated: value is false" };
    }
    return { tag: "noChange" };
  }

  // Default: no change
  return { tag: "noChange" };
}

// ─────────────────────────────────────────────────────────────────
// Constraint-directed operations
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a network has a contradiction.
 */
export function hasContradiction(netRef: NetRefVal): boolean {
  const net = getNetwork(netRef.id);
  if (!net) return false;
  return net.status.tag === "contradiction";
}

/**
 * Get the latest contradiction from a network.
 */
export function getContradiction(netRef: NetRefVal): ContradictionVal | undefined {
  const net = getNetwork(netRef.id);
  if (!net) return undefined;
  if (net.status.tag === "contradiction") {
    return net.status.contradiction;
  }
  return net.contradictions[net.contradictions.length - 1];
}

/**
 * Check if a network is quiescent.
 */
export function isQuiescent(netRef: NetRefVal): boolean {
  const net = getNetwork(netRef.id);
  if (!net) return false;
  return net.status.tag === "quiescent";
}

/**
 * Get the number of pending propagators.
 */
export function getPendingCount(netRef: NetRefVal): number {
  const net = getNetwork(netRef.id);
  if (!net) return 0;
  return net.agenda.length;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: Constraint propagation networks (SICP 3.3.5 style)

export * from "./types";
export * from "./network";
export * from "./engine";
export * from "./diagnosis";
export * from "./repair";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/network.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/network.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: Constraint network implementation

import type { Val, ConnRefVal, NetRefVal, ExplanationVal, ContradictionVal } from "../eval/values";
import { VUnit } from "../eval/values";
import { sha256JSON } from "../artifacts/hash";
import type { Hash } from "../artifacts/hash";
import {
  type ConnectorState,
  type PropagatorState,
  type NetworkState,
  type NetworkStatus,
  type PropagationEvent,
  type PropagationConfig,
  type PropagatorKind,
  DEFAULT_PROPAGATION_CONFIG,
  makeConnRef,
  makeNetRef,
  makeAssumption,
  makeDerived,
  makeConflict,
  makeContradiction,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// ID generation
// ─────────────────────────────────────────────────────────────────

let networkCounter = 0;
let connectorCounter = 0;
let propagatorCounter = 0;

function makeNetworkId(): string {
  return `net_${++networkCounter}`;
}

function makeConnectorId(): string {
  return `conn_${++connectorCounter}`;
}

function makePropagatorId(): string {
  return `prop_${++propagatorCounter}`;
}

/** Reset counters for testing. */
export function resetConstraintCounters(): void {
  networkCounter = 0;
  connectorCounter = 0;
  propagatorCounter = 0;
}

// ─────────────────────────────────────────────────────────────────
// Network registry (global store for networks)
// ─────────────────────────────────────────────────────────────────

const networkRegistry = new Map<string, NetworkState>();

/**
 * Get a network by ID.
 */
export function getNetwork(id: string): NetworkState | undefined {
  return networkRegistry.get(id);
}

/**
 * Set a network in the registry.
 */
export function setNetwork(net: NetworkState): void {
  networkRegistry.set(net.id, net);
}

/**
 * Delete a network from the registry.
 */
export function deleteNetwork(id: string): boolean {
  return networkRegistry.delete(id);
}

/**
 * Clear all networks (for testing).
 */
export function clearNetworks(): void {
  networkRegistry.clear();
}

// ─────────────────────────────────────────────────────────────────
// Network creation and management
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new constraint network.
 */
export function createNetwork(name?: string): NetRefVal {
  const id = makeNetworkId();
  const state: NetworkState = {
    id,
    name,
    connectors: new Map(),
    propagators: new Map(),
    agenda: [],
    status: { tag: "quiescent" },
    stepCount: 0,
    contradictions: [],
    ledger: [],
  };
  setNetwork(state);
  return makeNetRef(id, name);
}

/**
 * Get network status.
 */
export function getNetworkStatus(netRef: NetRefVal): NetworkStatus {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);
  return net.status;
}

/**
 * Clone a network state for forking.
 */
export function cloneNetwork(net: NetworkState): NetworkState {
  const newId = makeNetworkId();
  const clone: NetworkState = {
    id: newId,
    name: net.name ? `${net.name}_clone` : undefined,
    connectors: new Map(
      Array.from(net.connectors.entries()).map(([k, v]) => [
        k,
        {
          ...v,
          readers: new Set(v.readers),
          writers: new Set(v.writers),
        },
      ])
    ),
    propagators: new Map(
      Array.from(net.propagators.entries()).map(([k, v]) => [k, { ...v }])
    ),
    agenda: [...net.agenda],
    status: { ...net.status },
    stepCount: net.stepCount,
    contradictions: [...net.contradictions],
    ledger: [...net.ledger],
  };
  setNetwork(clone);
  return clone;
}

// ─────────────────────────────────────────────────────────────────
// Connector operations
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new connector in a network.
 */
export function createConnector(netRef: NetRefVal, name?: string): ConnRefVal {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);

  const id = makeConnectorId();
  const state: ConnectorState = {
    id,
    netId: netRef.id,
    name,
    readers: new Set(),
    writers: new Set(),
  };
  net.connectors.set(id, state);
  return makeConnRef(id, netRef.id, name);
}

/**
 * Check if a connector has a value.
 */
export function connectorHasValue(connRef: ConnRefVal): boolean {
  const net = getNetwork(connRef.netId);
  if (!net) throw new Error(`Network not found: ${connRef.netId}`);
  const conn = net.connectors.get(connRef.id);
  if (!conn) throw new Error(`Connector not found: ${connRef.id}`);
  return conn.value !== undefined;
}

/**
 * Get the value of a connector.
 */
export function connectorGetValue(connRef: ConnRefVal): Val {
  const net = getNetwork(connRef.netId);
  if (!net) throw new Error(`Network not found: ${connRef.netId}`);
  const conn = net.connectors.get(connRef.id);
  if (!conn) throw new Error(`Connector not found: ${connRef.id}`);
  if (conn.value === undefined) return VUnit;
  return conn.value;
}

/**
 * Get the explanation for a connector's value.
 */
export function connectorGetExplanation(connRef: ConnRefVal): ExplanationVal | undefined {
  const net = getNetwork(connRef.netId);
  if (!net) throw new Error(`Network not found: ${connRef.netId}`);
  const conn = net.connectors.get(connRef.id);
  if (!conn) throw new Error(`Connector not found: ${connRef.id}`);
  return conn.explanation;
}

/**
 * Compute hash of a value for explanation tracking.
 */
function hashValue(v: Val): Hash {
  try {
    return sha256JSON(v).slice(0, 16);
  } catch {
    return `${v.tag}_hash`;
  }
}

/**
 * Check if two values are equal (deep comparison).
 */
function valuesEqual(a: Val, b: Val): boolean {
  // Simple comparison - could be improved
  try {
    return JSON.stringify(a) === JSON.stringify(b);
  } catch {
    return false;
  }
}

/**
 * Set the value of a connector with provenance.
 * Returns contradiction if value conflicts with existing value.
 */
export function connectorSetValue(
  connRef: ConnRefVal,
  value: Val,
  because: Val,
  rule?: string,
  deps?: ExplanationVal[]
): ContradictionVal | undefined {
  const net = getNetwork(connRef.netId);
  if (!net) throw new Error(`Network not found: ${connRef.netId}`);
  const conn = net.connectors.get(connRef.id);
  if (!conn) throw new Error(`Connector not found: ${connRef.id}`);

  const newHash = hashValue(value);

  // Build explanation
  const explanation: ExplanationVal = deps && deps.length > 0
    ? makeDerived(connRef, newHash, rule ?? "propagator", deps)
    : makeAssumption(connRef, newHash, because);

  // Check for conflict
  if (conn.value !== undefined) {
    if (!valuesEqual(conn.value, value)) {
      // Contradiction: different values for same connector
      const conflict = makeConflict(
        connRef,
        conn.explanation!,
        explanation,
        `Connector ${connRef.name ?? connRef.id} has conflicting values`
      );
      const contradiction = makeContradiction(conflict, undefined, connRef.netId);
      net.contradictions.push(contradiction);
      net.status = { tag: "contradiction", contradiction };
      return contradiction;
    }
    // Same value, no change needed
    return undefined;
  }

  // Set the value
  conn.value = value;
  conn.valueHash = newHash;
  conn.explanation = explanation;

  // Record event
  net.ledger.push({
    type: "set",
    timestamp: Date.now(),
    connId: connRef.id,
    valueHash: newHash,
    stepCount: net.stepCount,
  });

  // Schedule dependent propagators
  for (const propId of conn.readers) {
    if (!net.agenda.includes(propId)) {
      net.agenda.push(propId);
    }
  }

  // Update status
  if (net.agenda.length > 0 && net.status.tag === "quiescent") {
    net.status = { tag: "pending", count: net.agenda.length };
  }

  return undefined;
}

/**
 * Forget (clear) the value of a connector.
 */
export function connectorForgetValue(connRef: ConnRefVal, because: Val): void {
  const net = getNetwork(connRef.netId);
  if (!net) throw new Error(`Network not found: ${connRef.netId}`);
  const conn = net.connectors.get(connRef.id);
  if (!conn) throw new Error(`Connector not found: ${connRef.id}`);

  conn.value = undefined;
  conn.valueHash = undefined;
  conn.explanation = undefined;

  // Record event
  net.ledger.push({
    type: "forget",
    timestamp: Date.now(),
    connId: connRef.id,
    stepCount: net.stepCount,
  });
}

// ─────────────────────────────────────────────────────────────────
// Propagator operations
// ─────────────────────────────────────────────────────────────────

/**
 * Register a propagator in a network.
 */
export function registerPropagator(
  netRef: NetRefVal,
  name: string,
  inputs: ConnRefVal[],
  outputs: ConnRefVal[],
  proc: Val,
  options: {
    kind?: PropagatorKind;
    isConstraint?: boolean;
    priority?: number;
    requiresOracle?: boolean;
  } = {}
): string {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);

  const id = makePropagatorId();
  const state: PropagatorState = {
    id,
    name,
    kind: options.kind ?? "extensional",
    inputs: inputs.map(c => c.id),
    outputs: outputs.map(c => c.id),
    procRef: proc,
    isConstraint: options.isConstraint ?? false,
    priority: options.priority ?? 0,
    fireCount: 0,
    requiresOracle: options.requiresOracle ?? false,
  };

  net.propagators.set(id, state);

  // Register as reader/writer on connectors
  for (const connRef of inputs) {
    const conn = net.connectors.get(connRef.id);
    if (conn) conn.readers.add(id);
  }
  for (const connRef of outputs) {
    const conn = net.connectors.get(connRef.id);
    if (conn) conn.writers.add(id);
  }

  // Schedule if all inputs have values
  const allInputsReady = inputs.every(c => connectorHasValue(c));
  if (allInputsReady && !net.agenda.includes(id)) {
    net.agenda.push(id);
    if (net.status.tag === "quiescent") {
      net.status = { tag: "pending", count: net.agenda.length };
    }
  }

  return id;
}

/**
 * Register a constraint (propagator + invariant).
 */
export function registerConstraint(
  netRef: NetRefVal,
  name: string,
  inputs: ConnRefVal[],
  proc: Val,
  options: {
    priority?: number;
    requiresOracle?: boolean;
  } = {}
): string {
  return registerPropagator(netRef, name, inputs, [], proc, {
    kind: "constraint",
    isConstraint: true,
    priority: options.priority ?? -10, // Constraints have high priority
    requiresOracle: options.requiresOracle,
  });
}

/**
 * Get propagator state by ID.
 */
export function getPropagator(netRef: NetRefVal, propId: string): PropagatorState | undefined {
  const net = getNetwork(netRef.id);
  if (!net) return undefined;
  return net.propagators.get(propId);
}

/**
 * Remove a propagator from a network.
 */
export function removePropagator(netRef: NetRefVal, propId: string): boolean {
  const net = getNetwork(netRef.id);
  if (!net) return false;

  const prop = net.propagators.get(propId);
  if (!prop) return false;

  // Remove from connector readers/writers
  for (const connId of prop.inputs) {
    const conn = net.connectors.get(connId);
    if (conn) conn.readers.delete(propId);
  }
  for (const connId of prop.outputs) {
    const conn = net.connectors.get(connId);
    if (conn) conn.writers.delete(propId);
  }

  // Remove from agenda
  const agendaIdx = net.agenda.indexOf(propId);
  if (agendaIdx >= 0) {
    net.agenda.splice(agendaIdx, 1);
  }

  net.propagators.delete(propId);
  return true;
}

// ─────────────────────────────────────────────────────────────────
// Network snapshot/restore for COW semantics
// ─────────────────────────────────────────────────────────────────

/**
 * Create a snapshot of network state.
 */
export function snapshotNetwork(netRef: NetRefVal): NetworkState {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);
  return cloneNetwork(net);
}

/**
 * Restore network from snapshot.
 */
export function restoreNetwork(snapshot: NetworkState): NetRefVal {
  setNetwork(snapshot);
  return makeNetRef(snapshot.id, snapshot.name);
}

/**
 * Get network digest for content-addressing.
 */
export function getNetworkDigest(netRef: NetRefVal): Hash {
  const net = getNetwork(netRef.id);
  if (!net) throw new Error(`Network not found: ${netRef.id}`);

  // Create a serializable representation
  const connectors = Array.from(net.connectors.entries()).map(([id, c]) => ({
    id,
    name: c.name,
    valueHash: c.valueHash,
  }));
  const propagators = Array.from(net.propagators.entries()).map(([id, p]) => ({
    id,
    name: p.name,
    kind: p.kind,
    inputs: p.inputs,
    outputs: p.outputs,
  }));

  return sha256JSON({ connectors, propagators, status: net.status.tag });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/repair.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/repair.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: Repair synthesis via amb search for constraint contradictions

import type { Val, NetRefVal, ConnRefVal, ContradictionVal } from "../eval/values";
import { VUnit, VTrue } from "../eval/values";
import type { DistVal, DistItem } from "../eval/dist";
import { distFrom } from "../eval/dist";
import {
  type RepairOption,
  type RepairResult,
  type NetworkState,
  type PropagatorState,
} from "./types";
import {
  getNetwork,
  setNetwork,
  cloneNetwork,
  removePropagator,
  connectorForgetValue,
  connectorSetValue,
  registerPropagator,
} from "./network";
import {
  runPropagation,
  type PropagationResult,
} from "./engine";
import {
  extractUnsatCore,
  type UnsatCore,
} from "./diagnosis";

// ─────────────────────────────────────────────────────────────────
// Repair option generation
// ─────────────────────────────────────────────────────────────────

/**
 * Generate repair options from an unsat core.
 */
export function generateRepairOptions(
  netRef: NetRefVal,
  core: UnsatCore
): RepairOption[] {
  const net = getNetwork(netRef.id);
  if (!net) return [];

  const options: RepairOption[] = [];

  // Option 1: Drop constraints in the core
  for (const constraintId of core.constraintIds) {
    const prop = net.propagators.get(constraintId);
    if (prop && prop.isConstraint) {
      options.push({ tag: "dropConstraint", constraintId });
    }
  }

  // Option 2: Retry with different values for assumptions
  for (const assumption of core.assumptions) {
    // This would need alternative values - for now just mark as option
    options.push({
      tag: "retryWithValue",
      connId: assumption.connId,
      newValue: VUnit, // Placeholder - caller should provide alternatives
    });
  }

  return options;
}

/**
 * Add custom repair options to the list.
 */
export function addRepairOption(options: RepairOption[], option: RepairOption): RepairOption[] {
  return [...options, option];
}

// ─────────────────────────────────────────────────────────────────
// Repair execution
// ─────────────────────────────────────────────────────────────────

/**
 * Try a single repair option on a network.
 * Returns the result with success/failure and new state.
 */
export async function tryRepair(
  netRef: NetRefVal,
  option: RepairOption
): Promise<RepairResult> {
  const net = getNetwork(netRef.id);
  if (!net) {
    return {
      option,
      success: false,
    };
  }

  // Clone the network for this repair attempt
  const cloned = cloneNetwork(net);
  const clonedRef: NetRefVal = { tag: "NetRef", id: cloned.id, name: cloned.name };

  // Apply the repair
  const applied = applyRepairOption(clonedRef, option);
  if (!applied) {
    return {
      option,
      success: false,
    };
  }

  // Run propagation on the repaired network
  const result = await runPropagation(clonedRef);

  if (result.status.tag === "quiescent") {
    return {
      option,
      success: true,
      newNetwork: getNetwork(clonedRef.id),
    };
  } else if (result.status.tag === "contradiction") {
    return {
      option,
      success: false,
      newContradiction: result.contradiction,
    };
  } else {
    return {
      option,
      success: false,
    };
  }
}

/**
 * Apply a repair option to a network.
 */
function applyRepairOption(netRef: NetRefVal, option: RepairOption): boolean {
  const net = getNetwork(netRef.id);
  if (!net) return false;

  switch (option.tag) {
    case "dropConstraint": {
      return removePropagator(netRef, option.constraintId);
    }

    case "relaxConstraint": {
      // TODO: Implement constraint relaxation
      return false;
    }

    case "swapPropagator": {
      // Remove old propagator
      const oldProp = net.propagators.get(option.oldId);
      if (!oldProp) return false;

      removePropagator(netRef, option.oldId);

      // Add new propagator with same inputs/outputs
      const inputs = oldProp.inputs.map(id => {
        const conn = net.connectors.get(id);
        return { tag: "ConnRef" as const, id, netId: netRef.id, name: conn?.name };
      });
      const outputs = oldProp.outputs.map(id => {
        const conn = net.connectors.get(id);
        return { tag: "ConnRef" as const, id, netId: netRef.id, name: conn?.name };
      });

      registerPropagator(netRef, `${oldProp.name}_replaced`, inputs, outputs, option.newProcRef, {
        kind: oldProp.kind,
        isConstraint: oldProp.isConstraint,
        priority: oldProp.priority,
        requiresOracle: false, // New proc might not need oracle
      });
      return true;
    }

    case "addValidator": {
      const inputs = option.inputs.map(id => {
        const conn = net.connectors.get(id);
        return { tag: "ConnRef" as const, id, netId: netRef.id, name: conn?.name };
      });

      registerPropagator(netRef, "validator", inputs, [], option.validatorProc, {
        kind: "validator",
        isConstraint: true,
        priority: -5,
      });
      return true;
    }

    case "retryWithValue": {
      const conn = net.connectors.get(option.connId);
      if (!conn) return false;

      const connRef: ConnRefVal = {
        tag: "ConnRef",
        id: option.connId,
        netId: netRef.id,
        name: conn.name,
      };

      // Clear old value
      connectorForgetValue(connRef, { tag: "Str", s: "repair retry" });

      // Set new value (if provided and not Unit)
      if (option.newValue.tag !== "Unit") {
        connectorSetValue(connRef, option.newValue, { tag: "Str", s: "repair value" });
      }
      return true;
    }

    default:
      return false;
  }
}

// ─────────────────────────────────────────────────────────────────
// Search-based repair (amb-style exploration)
// ─────────────────────────────────────────────────────────────────

/**
 * RepairSearchConfig: Configuration for repair search.
 */
export type RepairSearchConfig = {
  /** Maximum number of repair attempts */
  maxAttempts: number;
  /** Search strategy */
  strategy: "bfs" | "dfs" | "beam";
  /** Beam width (for beam search) */
  beamWidth?: number;
  /** Scoring function for repairs (higher = better) */
  scoreFn?: (result: RepairResult) => number;
};

export const DEFAULT_REPAIR_SEARCH_CONFIG: RepairSearchConfig = {
  maxAttempts: 10,
  strategy: "bfs",
};

/**
 * RepairSearchResult: Result of searching for repairs.
 */
export type RepairSearchResult = {
  /** Did we find a successful repair? */
  found: boolean;
  /** The successful repair (if found) */
  successfulRepair?: RepairResult;
  /** All repair attempts */
  attempts: RepairResult[];
  /** Number of attempts made */
  attemptCount: number;
  /** Distribution of repair options with scores */
  repairDist?: DistVal;
};

/**
 * Search for a valid repair using amb-style exploration.
 */
export async function searchRepairs(
  netRef: NetRefVal,
  contradiction: ContradictionVal,
  options: RepairOption[],
  config: Partial<RepairSearchConfig> = {}
): Promise<RepairSearchResult> {
  const fullConfig: RepairSearchConfig = {
    ...DEFAULT_REPAIR_SEARCH_CONFIG,
    ...config,
  };

  const attempts: RepairResult[] = [];
  let attemptCount = 0;
  let successfulRepair: RepairResult | undefined;

  // Generate frontier based on strategy
  const frontier: RepairOption[] = [...options];

  while (frontier.length > 0 && attemptCount < fullConfig.maxAttempts) {
    // Select next option based on strategy
    let option: RepairOption;
    switch (fullConfig.strategy) {
      case "dfs":
        option = frontier.pop()!;
        break;
      case "bfs":
      default:
        option = frontier.shift()!;
        break;
    }

    attemptCount++;
    const result = await tryRepair(netRef, option);
    attempts.push(result);

    if (result.success) {
      successfulRepair = result;
      break;
    }

    // If beam search, prune based on scores
    if (fullConfig.strategy === "beam" && fullConfig.beamWidth) {
      // Score remaining options and keep top k
      // (simplified - in full implementation would score based on partial results)
    }
  }

  // Build distribution of repair options
  const scoreFn = fullConfig.scoreFn ?? ((r: RepairResult) => r.success ? 1 : 0);
  const items: DistItem[] = attempts.map(r => ({
    v: repairOptionToVal(r.option),
    w: scoreFn(r),
  }));

  return {
    found: successfulRepair !== undefined,
    successfulRepair,
    attempts,
    attemptCount,
    repairDist: distFrom(items, { kind: "repair-search" }),
  };
}

/**
 * Convert a repair option to a Val for distribution.
 */
function repairOptionToVal(option: RepairOption): Val {
  return {
    tag: "Map",
    entries: [
      [{ tag: "Sym", name: "tag" }, { tag: "Str", s: option.tag }],
      ...Object.entries(option)
        .filter(([k]) => k !== "tag")
        .map(([k, v]): [Val, Val] => [
          { tag: "Sym", name: k },
          typeof v === "string" ? { tag: "Str", s: v } : (v as Val),
        ]),
    ],
  };
}

// ─────────────────────────────────────────────────────────────────
// High-level repair API
// ─────────────────────────────────────────────────────────────────

/**
 * Repair a network contradiction automatically.
 * Extracts unsat core, generates options, and searches for a fix.
 */
export async function repair(
  netRef: NetRefVal,
  contradiction: ContradictionVal,
  additionalOptions: RepairOption[] = [],
  config: Partial<RepairSearchConfig> = {}
): Promise<RepairSearchResult> {
  // Extract unsat core
  const core = extractUnsatCore(netRef, contradiction);

  // Generate repair options
  const options = generateRepairOptions(netRef, core);

  // Add additional options
  const allOptions = [...options, ...additionalOptions];

  // Search for repairs
  return searchRepairs(netRef, contradiction, allOptions, config);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/constraints/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/constraints/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 12: SICP-style constraint propagation networks for semantic pipelines

import type { Val, ConnRefVal, NetRefVal, ExplanationVal, ContradictionVal } from "../eval/values";
import type { Hash } from "../artifacts/hash";

// ─────────────────────────────────────────────────────────────────
// Connector: Store-backed cell in a constraint network
// ─────────────────────────────────────────────────────────────────

/**
 * ConnectorState: The internal state of a connector.
 * Stored in the network's connector map.
 */
export type ConnectorState = {
  /** Connector ID */
  id: string;
  /** Network this connector belongs to */
  netId: string;
  /** Human-readable name */
  name?: string;
  /** Current value (undefined if no value set) */
  value?: Val;
  /** Hash of current value (for quick comparison) */
  valueHash?: Hash;
  /** Explanation of how the value was derived */
  explanation?: ExplanationVal;
  /** IDs of propagators that read from this connector */
  readers: Set<string>;
  /** IDs of propagators that write to this connector */
  writers: Set<string>;
};

// ─────────────────────────────────────────────────────────────────
// Propagator: Procedure that reads inputs and writes outputs
// ─────────────────────────────────────────────────────────────────

/**
 * PropagatorKind: Classification of propagator behavior.
 */
export type PropagatorKind = "extensional" | "oracle" | "constraint" | "validator";

/**
 * PropagatorState: The internal state of a propagator.
 */
export type PropagatorState = {
  /** Propagator ID */
  id: string;
  /** Human-readable name */
  name: string;
  /** Kind of propagator */
  kind: PropagatorKind;
  /** IDs of input connectors */
  inputs: string[];
  /** IDs of output connectors */
  outputs: string[];
  /** The procedure to execute (stored as closure or reference) */
  procRef?: Val;
  /** Is this propagator a hard constraint? */
  isConstraint: boolean;
  /** Priority for scheduling (lower = higher priority) */
  priority: number;
  /** Number of times this propagator has fired */
  fireCount: number;
  /** Whether this propagator requires oracle calls */
  requiresOracle: boolean;
};

// ─────────────────────────────────────────────────────────────────
// Network: Container for connectors, propagators, and constraints
// ─────────────────────────────────────────────────────────────────

/**
 * NetworkStatus: Current state of the network.
 */
export type NetworkStatus =
  | { tag: "quiescent" }                                // No pending work
  | { tag: "pending"; count: number }                   // Propagators waiting to fire
  | { tag: "contradiction"; contradiction: ContradictionVal }  // Constraint violation
  | { tag: "suspended"; op: string; args: Val[] }       // Waiting for oracle
  | { tag: "budgetExhausted"; resource: string };       // Ran out of fuel

/**
 * NetworkState: The internal state of a constraint network.
 */
export type NetworkState = {
  /** Network ID */
  id: string;
  /** Human-readable name */
  name?: string;
  /** Connectors by ID */
  connectors: Map<string, ConnectorState>;
  /** Propagators by ID */
  propagators: Map<string, PropagatorState>;
  /** IDs of propagators that need to fire (scheduling queue) */
  agenda: string[];
  /** Current network status */
  status: NetworkStatus;
  /** Step counter for budgeting */
  stepCount: number;
  /** Contradiction history (for diagnosis) */
  contradictions: ContradictionVal[];
  /** Ledger of propagation events (for replay) */
  ledger: PropagationEvent[];
};

/**
 * PropagationEvent: Record of a single propagation step.
 */
export type PropagationEvent = {
  /** Event type */
  type: "set" | "derive" | "conflict" | "forget" | "fire";
  /** Timestamp */
  timestamp: number;
  /** Connector ID (if applicable) */
  connId?: string;
  /** Propagator ID (if applicable) */
  propId?: string;
  /** Value hash (if applicable) */
  valueHash?: Hash;
  /** Step count at time of event */
  stepCount: number;
};

// ─────────────────────────────────────────────────────────────────
// Propagation budget and configuration
// ─────────────────────────────────────────────────────────────────

/**
 * PropagationBudget: Resource limits for propagation.
 */
export type PropagationBudget = {
  /** Maximum propagator firings */
  maxFirings: number;
  /** Maximum connector sets */
  maxSets: number;
  /** Maximum oracle calls */
  maxOracleCalls: number;
  /** Maximum depth of explanation graphs */
  maxExplanationDepth: number;
};

export const DEFAULT_PROPAGATION_BUDGET: PropagationBudget = {
  maxFirings: 10000,
  maxSets: 5000,
  maxOracleCalls: 100,
  maxExplanationDepth: 50,
};

/**
 * PropagationConfig: Configuration for propagation engine.
 */
export type PropagationConfig = {
  /** Budget limits */
  budget: PropagationBudget;
  /** Strategy for selecting next propagator */
  schedulingStrategy: "fifo" | "priority" | "random";
  /** Whether to record ledger events */
  recordLedger: boolean;
  /** Seed for deterministic scheduling (if random) */
  seed?: number;
};

export const DEFAULT_PROPAGATION_CONFIG: PropagationConfig = {
  budget: DEFAULT_PROPAGATION_BUDGET,
  schedulingStrategy: "fifo",
  recordLedger: true,
};

// ─────────────────────────────────────────────────────────────────
// Repair options for constraint-directed backtracking
// ─────────────────────────────────────────────────────────────────

/**
 * RepairOption: A single repair strategy.
 */
export type RepairOption =
  | { tag: "dropConstraint"; constraintId: string }
  | { tag: "relaxConstraint"; constraintId: string; newSpec: Val }
  | { tag: "swapPropagator"; oldId: string; newProcRef: Val }
  | { tag: "addValidator"; inputs: string[]; validatorProc: Val }
  | { tag: "retryWithValue"; connId: string; newValue: Val };

/**
 * RepairResult: Result of attempting a repair.
 */
export type RepairResult = {
  /** The repair option that was tried */
  option: RepairOption;
  /** Whether the repair succeeded */
  success: boolean;
  /** New network state (if successful) */
  newNetwork?: NetworkState;
  /** New contradiction (if failed) */
  newContradiction?: ContradictionVal;
};

// ─────────────────────────────────────────────────────────────────
// Type guards and helpers
// ─────────────────────────────────────────────────────────────────

export function isConnRef(v: Val): v is ConnRefVal {
  return v.tag === "ConnRef";
}

export function isNetRef(v: Val): v is NetRefVal {
  return v.tag === "NetRef";
}

export function isExplanation(v: Val): v is ExplanationVal {
  return v.tag === "Explanation";
}

export function isContradiction(v: Val): v is ContradictionVal {
  return v.tag === "Contradiction";
}

/**
 * Create a ConnRefVal.
 */
export function makeConnRef(id: string, netId: string, name?: string): ConnRefVal {
  return { tag: "ConnRef", id, netId, name };
}

/**
 * Create a NetRefVal.
 */
export function makeNetRef(id: string, name?: string): NetRefVal {
  return { tag: "NetRef", id, name };
}

/**
 * Create an assumption explanation.
 */
export function makeAssumption(
  conn: ConnRefVal,
  valueHash: Hash,
  because: Val
): ExplanationVal {
  return { tag: "Explanation", kind: "assumption", conn, valueHash, because };
}

/**
 * Create a derived explanation.
 */
export function makeDerived(
  conn: ConnRefVal,
  valueHash: Hash,
  rule: string,
  deps: ExplanationVal[]
): ExplanationVal {
  return { tag: "Explanation", kind: "derived", conn, valueHash, rule, deps };
}

/**
 * Create a conflict explanation.
 */
export function makeConflict(
  conn: ConnRefVal,
  left: ExplanationVal,
  right: ExplanationVal,
  message?: string
): ExplanationVal {
  return { tag: "Explanation", kind: "conflict", conn, left, right, message };
}

/**
 * Create a denied explanation (for capability denial).
 */
export function makeDenied(op: string, reason: string, profile?: string): ExplanationVal {
  return { tag: "Explanation", kind: "denied", op, reason, profile };
}

/**
 * Create a contradiction value.
 */
export function makeContradiction(
  explanation: ExplanationVal,
  constraintId?: string,
  netId?: string
): ContradictionVal {
  return { tag: "Contradiction", explanation, constraintId, netId };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/ctx/ctx.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/ctx/ctx.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// First-class Context: cid, caps, constraints, sealed, evidence, budgets

import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type { CapSet } from "../governance/caps";
import type { BudgetLimits } from "../governance/budgets";
import type { Profile } from "../governance/profile";
import type { StoreAddr } from "../eval/store";

// Use StoreAddr as our Addr type
export type Addr = StoreAddr;

/**
 * Constraints are runtime-enforceable semantic invariants (Design by Contract at the context boundary).
 */
export type Constraint =
  | { tag: "NoNewFacts" }
  | { tag: "DeterministicEnvelope" }
  | { tag: "Sealed" };

/**
 * ProjectionSchema: Controls what parts of context can be observed by the oracle.
 *
 * This is the "privacy firewall" between code execution and oracle observation.
 * Different profiles can use different schemas to restrict what the oracle sees.
 *
 * Prompt 10: ReqObserve uses this to determine what's visible.
 */
export type ProjectionSchema = {
  /** Maximum number of frame keys to include (default: 200) */
  maxKeys?: number;
  /** Include cid (content address)? */
  includeCid?: boolean;
  /** Include parent chain depth? */
  includeDepth?: boolean;
  /** Include capability set? (may be redacted for security) */
  includeCaps?: boolean;
  /** Include budget information? */
  includeBudgets?: boolean;
  /** Include constraint tags? */
  includeConstraints?: boolean;
  /** Include evidence count? */
  includeEvidenceCount?: boolean;
  /** Include sealed status? */
  includeSealed?: boolean;
  /** Redact sensitive keys (regex patterns) */
  redactKeys?: string[];
  /** Maximum total size in bytes (for compression estimation) */
  maxSizeBytes?: number;
};

/**
 * Default projection schema - permissive for debugging.
 */
export const DEFAULT_PROJECTION_SCHEMA: ProjectionSchema = {
  maxKeys: 200,
  includeCid: true,
  includeDepth: true,
  includeCaps: true,
  includeBudgets: true,
  includeConstraints: true,
  includeEvidenceCount: true,
  includeSealed: true,
};

/**
 * Restricted projection schema - for airgap/strict profiles.
 */
export const RESTRICTED_PROJECTION_SCHEMA: ProjectionSchema = {
  maxKeys: 50,
  includeCid: true,
  includeDepth: true,
  includeCaps: false,  // Caps redacted for security
  includeBudgets: false,
  includeConstraints: false,
  includeEvidenceCount: false,
  includeSealed: true,
  redactKeys: ["secret", "token", "password", "key", "auth"],
};

/**
 * Evidence is append-only metadata used by truth regimes, receipts, and provenance.
 * Keep it JSON-safe.
 */
export type Evidence =
  | { tag: "Note"; text: string }
  | { tag: "ReceiptRef"; rid: Hash }
  | { tag: "ToolRef"; callId: Hash };

/**
 * Ctx is the lexical environment + governance capsule.
 * This is the object that makes inference "first class" rather than "an API call".
 */
export type Ctx = {
  tag: "Ctx";

  // Content address of this ctx node (parent+frame+governance metadata)
  cid: Hash;

  // Lexical scoping
  parent?: Ctx;
  frame: Map<string, Addr>;

  // Governance surface
  profile: string;
  caps: CapSet;
  budgets: BudgetLimits;
  constraints: Constraint[];
  sealed: boolean;

  // Provenance
  evidence: Evidence[];
};

/** Stable JSON projection for hashing. */
function ctxStableJSON(ctx: Omit<Ctx, "cid">): unknown {
  const frame = Array.from(ctx.frame.entries()).sort(([a], [b]) => (a < b ? -1 : a > b ? 1 : 0));
  const caps = Array.from(ctx.caps).slice().sort();
  const constraints = ctx.constraints.map(c => c.tag);

  return {
    parent: ctx.parent ? ctx.parent.cid : null,
    frame,
    profile: ctx.profile,
    caps,
    budgets: ctx.budgets,
    constraints,
    sealed: ctx.sealed,
    evidence: ctx.evidence,
  };
}

export function ctxRehash(ctx: Omit<Ctx, "cid">): Ctx {
  const cid = sha256JSON(ctxStableJSON(ctx));
  return { ...ctx, cid } as Ctx;
}

export function ctxRootFromProfile(p: Profile): Ctx {
  const constraints: Constraint[] = [];
  if ((p as any).noNewFacts) constraints.push({ tag: "NoNewFacts" });
  if ((p as any).deterministicEnvelope) constraints.push({ tag: "DeterministicEnvelope" });

  const base: Omit<Ctx, "cid"> = {
    tag: "Ctx",
    parent: undefined,
    frame: new Map<string, Addr>(),
    profile: p.name,
    caps: p.caps,
    budgets: p.budgets,
    constraints,
    sealed: false,
    evidence: [],
  };
  return ctxRehash(base);
}

export function ctxLookup(ctx: Ctx, name: string): Addr | undefined {
  for (let cur: Ctx | undefined = ctx; cur; cur = cur.parent) {
    const hit = cur.frame.get(name);
    if (hit !== undefined) return hit;
  }
  return undefined;
}

/**
 * Define/bind into the *current* frame (not a new child frame).
 * This is what Scheme's internal definition mechanics want.
 */
export function ctxDefine(ctx: Ctx, name: string, addr: Addr): Ctx {
  if (ctx.sealed) throw new Error(`ctxDefine denied: context is sealed (name=${name})`);
  const frame = new Map(ctx.frame);
  frame.set(name, addr);
  return ctxRehash({ ...ctx, frame });
}

/**
 * Extend: create a new child frame (lexical block / call frame).
 */
export function ctxExtend(ctx: Ctx, binds: Array<[string, Addr]>): Ctx {
  const frame = new Map<string, Addr>();
  for (const [k, a] of binds) frame.set(k, a);

  // child inherits governance by default (you can later implement "cap attenuation" here).
  return ctxRehash({
    tag: "Ctx",
    parent: ctx,
    frame,
    profile: ctx.profile,
    caps: ctx.caps,
    budgets: ctx.budgets,
    constraints: ctx.constraints,
    sealed: ctx.sealed,
    evidence: ctx.evidence,
  });
}

/**
 * Seal: freeze the context so operations that mutate bindings/state can be forbidden.
 * We enforce seal on ctxDefine and on set! at eval time.
 */
export function ctxSeal(ctx: Ctx): Ctx {
  if (ctx.sealed) return ctx;
  const constraints = ctx.constraints.some(c => c.tag === "Sealed")
    ? ctx.constraints
    : [...ctx.constraints, { tag: "Sealed" } as Constraint];

  return ctxRehash({ ...ctx, sealed: true, constraints });
}

export function ctxAddEvidence(ctx: Ctx, ev: Evidence): Ctx {
  return ctxRehash({ ...ctx, evidence: [...ctx.evidence, ev] });
}

// ─────────────────────────────────────────────────────────────────
// Capability Attenuation (Prompt 10)
// ─────────────────────────────────────────────────────────────────

/**
 * Attenuate capabilities: create a child context with restricted caps.
 * Caps can only be restricted, never expanded (monotonic attenuation).
 *
 * This is the core security primitive for sandboxing.
 */
export function ctxAttenuateCaps(ctx: Ctx, newCaps: CapSet): Ctx {
  // Intersection: newCaps must be subset of ctx.caps
  const attenuated = intersectCaps(ctx.caps, newCaps);
  return ctxRehash({ ...ctx, caps: attenuated });
}

/**
 * Create a child context with attenuated capabilities and bindings.
 * This is the secure version of ctxExtend for cross-trust-boundary calls.
 */
export function ctxExtendAttenuated(
  ctx: Ctx,
  binds: Array<[string, Addr]>,
  newCaps: CapSet
): Ctx {
  const frame = new Map<string, Addr>();
  for (const [k, a] of binds) frame.set(k, a);

  // Attenuate caps (can only restrict)
  const attenuated = intersectCaps(ctx.caps, newCaps);

  return ctxRehash({
    tag: "Ctx",
    parent: ctx,
    frame,
    profile: ctx.profile,
    caps: attenuated,
    budgets: ctx.budgets,
    constraints: ctx.constraints,
    sealed: ctx.sealed,
    evidence: ctx.evidence,
  });
}

/**
 * Check if a capability is held by the context.
 */
export function ctxHasCap(ctx: Ctx, cap: string): boolean {
  if (ctx.caps.includes("*")) return true;
  if (ctx.caps.includes(cap)) return true;
  const domain = cap.split(".")[0];
  return ctx.caps.includes(`${domain}.*`);
}

/**
 * Require a capability, throwing if not present.
 */
export function ctxRequireCap(ctx: Ctx, cap: string, context: string): void {
  if (!ctxHasCap(ctx, cap)) {
    throw new Error(`capability denied: ${cap} (context: ${context})`);
  }
}

// ─────────────────────────────────────────────────────────────────
// Module Sealing (Prompt 10)
// ─────────────────────────────────────────────────────────────────

/**
 * Create a sealed module from a context.
 * The module captures the context at seal-time with specified exports.
 *
 * Returns: { moduleId, sealedCtx, exports }
 */
export function ctxSealAsModule(
  ctx: Ctx,
  exportNames: string[],
  meta?: { name?: string; version?: string; description?: string }
): { moduleId: Hash; sealedCtx: Ctx; exports: Set<string>; meta?: typeof meta } {
  // Seal the context
  const sealed = ctxSeal(ctx);

  // Compute module ID from cid + exports
  const moduleId = sha256JSON({
    cid: sealed.cid,
    exports: exportNames.slice().sort(),
    meta,
  });

  return {
    moduleId,
    sealedCtx: sealed,
    exports: new Set(exportNames),
    meta,
  };
}

/**
 * Import a binding from a sealed module into current context.
 * This is the only way to access module internals.
 */
export function ctxImportFromModule(
  ctx: Ctx,
  sealedCtx: Ctx,
  exportedNames: Set<string>,
  name: string
): Addr | undefined {
  if (!exportedNames.has(name)) {
    throw new Error(`module import denied: '${name}' is not exported`);
  }
  return ctxLookup(sealedCtx, name);
}

/**
 * Apply a profile as a restriction (caps intersect, budgets min).
 * This is a Policy Object application (GoF Strategy/Policy).
 */
export function ctxApplyProfile(ctx: Ctx, p: Profile): Ctx {
  const caps = intersectCaps(ctx.caps, p.caps);
  const budgets: BudgetLimits = {
    maxOracleTurns: Math.min(ctx.budgets.maxOracleTurns, p.budgets.maxOracleTurns),
    maxEvalSteps: Math.min(ctx.budgets.maxEvalSteps, p.budgets.maxEvalSteps),
    maxToolCalls: Math.min(ctx.budgets.maxToolCalls, p.budgets.maxToolCalls),
  };

  // constraints: merge
  const constraints = [...ctx.constraints];
  if ((p as any).noNewFacts && !constraints.some(c => c.tag === "NoNewFacts"))
    constraints.push({ tag: "NoNewFacts" });
  if ((p as any).deterministicEnvelope && !constraints.some(c => c.tag === "DeterministicEnvelope"))
    constraints.push({ tag: "DeterministicEnvelope" });

  return ctxRehash({
    ...ctx,
    profile: p.name,
    caps,
    budgets,
    constraints,
  });
}

function intersectCaps(a: CapSet, b: CapSet): CapSet {
  // conservative intersection with wildcard handling
  if (a.includes("*") && b.includes("*")) return ["*"];
  if (a.includes("*")) return b;
  if (b.includes("*")) return a;
  const setB = new Set(b);
  return a.filter(x => setB.has(x));
}

/**
 * Projection for oracle observation/debugging — avoid exfiltrating the entire store.
 * Now uses ProjectionSchema for fine-grained control (Prompt 10).
 */
export function ctxProject(ctx: Ctx, schema: ProjectionSchema = DEFAULT_PROJECTION_SCHEMA): unknown {
  const maxKeys = schema.maxKeys ?? 200;
  let keys = Array.from(ctx.frame.keys()).slice().sort();

  // Apply redaction patterns if specified
  if (schema.redactKeys && schema.redactKeys.length > 0) {
    const patterns = schema.redactKeys.map(p => new RegExp(p, "i"));
    keys = keys.filter(k => !patterns.some(p => p.test(k)));
  }

  const clipped = keys.length > maxKeys ? keys.slice(0, maxKeys).concat(["…"]) : keys;

  const projection: Record<string, unknown> = {
    tag: "CtxProjection",
    profile: ctx.profile,
  };

  if (schema.includeCid !== false) projection.cid = ctx.cid;
  if (schema.includeSealed !== false) projection.sealed = ctx.sealed;
  if (schema.includeCaps !== false) projection.caps = Array.from(ctx.caps).slice().sort();
  if (schema.includeBudgets !== false) projection.budgets = ctx.budgets;
  if (schema.includeConstraints !== false) projection.constraints = ctx.constraints.map(c => c.tag);
  if (schema.includeDepth !== false) projection.depth = ctxDepth(ctx);
  if (schema.includeEvidenceCount !== false) projection.evidenceCount = ctx.evidence.length;

  projection.frameKeys = clipped;

  return projection;
}

/**
 * Estimate the byte size of a context projection.
 * Used for compression decisions and budget tracking.
 */
export function ctxEstimateSize(ctx: Ctx): number {
  // Rough estimation: count bindings and parent chain
  let size = 0;
  for (let cur: Ctx | undefined = ctx; cur; cur = cur.parent) {
    size += cur.frame.size * 100; // ~100 bytes per binding estimate
    size += 200; // overhead per frame
  }
  size += ctx.evidence.length * 50; // ~50 bytes per evidence entry
  return size;
}

function ctxDepth(ctx: Ctx): number {
  let d = 0;
  for (let cur: Ctx | undefined = ctx; cur; cur = cur.parent) d++;
  return d;
}

/**
 * Check if ctx is a Ctx (vs old-style Map)
 */
export function isCtx(x: unknown): x is Ctx {
  return typeof x === "object" && x !== null && (x as any).tag === "Ctx";
}

// ─────────────────────────────────────────────────────────────────
// Compression & Hydration (Prompt 10)
// ─────────────────────────────────────────────────────────────────

/**
 * Compressed context representation for oracle transmission.
 * This is what gets sent over the wire instead of full Ctx.
 */
export type CompressedCtx = {
  tag: "CompressedCtx";
  /** Content address of original context */
  cid: Hash;
  /** Profile name */
  profile: string;
  /** Sealed status */
  sealed: boolean;
  /** Summary of capabilities (not full set, for privacy) */
  capSummary: "full" | "restricted" | "none";
  /** Number of bindings in current frame */
  frameSize: number;
  /** Depth of parent chain */
  depth: number;
  /** Estimated size in bytes */
  estimatedBytes: number;
  /** Evidence count */
  evidenceCount: number;
  /** Constraint tags */
  constraints: string[];
};

/**
 * Compress a context for oracle transmission.
 * Returns a lightweight representation that can be hydrated later.
 */
export function ctxCompress(ctx: Ctx): CompressedCtx {
  const capSummary: "full" | "restricted" | "none" =
    ctx.caps.includes("*") ? "full" :
    ctx.caps.length > 0 ? "restricted" : "none";

  return {
    tag: "CompressedCtx",
    cid: ctx.cid,
    profile: ctx.profile,
    sealed: ctx.sealed,
    capSummary,
    frameSize: ctx.frame.size,
    depth: ctxDepth(ctx),
    estimatedBytes: ctxEstimateSize(ctx),
    evidenceCount: ctx.evidence.length,
    constraints: ctx.constraints.map(c => c.tag),
  };
}

/**
 * Context store for hydration.
 * Maps cid -> Ctx for rehydrating compressed contexts.
 */
export class CtxStore {
  private store = new Map<Hash, Ctx>();

  /** Store a context, returning its cid. */
  put(ctx: Ctx): Hash {
    this.store.set(ctx.cid, ctx);
    return ctx.cid;
  }

  /** Retrieve a context by cid. */
  get(cid: Hash): Ctx | undefined {
    return this.store.get(cid);
  }

  /** Check if a context is stored. */
  has(cid: Hash): boolean {
    return this.store.has(cid);
  }

  /** Clear the store. */
  clear(): void {
    this.store.clear();
  }

  /** Get store size. */
  size(): number {
    return this.store.size;
  }
}

/** Global context store for hydration. */
export const globalCtxStore = new CtxStore();

/**
 * Hydrate a compressed context back to full Ctx.
 * Requires the original context to be in the store.
 *
 * @throws Error if context not found in store
 */
export function ctxHydrate(compressed: CompressedCtx, store: CtxStore = globalCtxStore): Ctx {
  const ctx = store.get(compressed.cid);
  if (!ctx) {
    throw new Error(`ctxHydrate failed: context ${compressed.cid} not found in store`);
  }
  return ctx;
}

/**
 * Hydrate by cid directly.
 */
export function ctxHydrateById(cid: Hash, store: CtxStore = globalCtxStore): Ctx {
  const ctx = store.get(cid);
  if (!ctx) {
    throw new Error(`ctxHydrate failed: context ${cid} not found in store`);
  }
  return ctx;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/capture.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Val } from "../eval/values";
import type { State } from "../eval/machine";
import type { Resumption } from "./opcall";

function uuid(): string {
  return Math.random().toString(16).slice(2) + "-" + Date.now().toString(16);
}

export function captureValueResumption(state: State): Resumption {
  const rid = uuid();
  const base: State = {
    ...state,
    store: state.store.snapshot(),
    // IMPORTANT: env and kont and handlers must be treated as immutable; do not mutate in place.
  };

  return {
    rid,
    base,
    invoke: (v: Val) => ({
      ...base,
      control: { tag: "Val", v },
      // base.store is already a snapshot; if you use mutable stores, snapshot again here.
    }),
    digest: () =>
      JSON.stringify({
        rid,
        store: base.store.digest(),
        kontDepth: base.kont.length,
        handlersDepth: base.handlers.length,
      }),
  };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/nondet/frontier.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-3.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Job } from "./types";

export interface Frontier {
  push(job: Job): void;
  pop(): Job | undefined;
  size(): number;
  clear(): void;
}

export class StackFrontier implements Frontier {
  private xs: Job[] = [];
  push(job: Job) { this.xs.push(job); }
  pop() { return this.xs.pop(); }
  size() { return this.xs.length; }
  clear() { this.xs = []; }
}

export class QueueFrontier implements Frontier {
  private xs: Job[] = [];
  private head = 0;
  push(job: Job) { this.xs.push(job); }
  pop() {
    if (this.head >= this.xs.length) return undefined;
    const j = this.xs[this.head];
    this.head += 1;
    // compact occasionally
    if (this.head > 1024 && this.head * 2 > this.xs.length) {
      this.xs = this.xs.slice(this.head);
      this.head = 0;
    }
    return j;
  }
  size() { return this.xs.length - this.head; }
  clear() { this.xs = []; this.head = 0; }
}

export class PriorityFrontier implements Frontier {
  // Max-heap by job.score (reference grade)
  private heap: Job[] = [];
  push(job: Job) { heapPush(this.heap, job); }
  pop() { return heapPop(this.heap); }
  size() { return this.heap.length; }
  clear() { this.heap = []; }
}

function heapPush(heap: Job[], job: Job) {
  heap.push(job);
  let i = heap.length - 1;
  while (i > 0) {
    const p = Math.floor((i - 1) / 2);
    if (heap[p].score >= heap[i].score) break;
    [heap[p], heap[i]] = [heap[i], heap[p]];
    i = p;
  }
}

function heapPop(heap: Job[]): Job | undefined {
  if (heap.length === 0) return undefined;
  const top = heap[0];
  const last = heap.pop()!;
  if (heap.length > 0) {
    heap[0] = last;
    let i = 0;
    while (true) {
      const l = 2 * i + 1, r = 2 * i + 2;
      let m = i;
      if (l < heap.length && heap[l].score > heap[m].score) m = l;
      if (r < heap.length && heap[r].score > heap[m].score) m = r;
      if (m === i) break;
      [heap[i], heap[m]] = [heap[m], heap[i]];
      i = m;
    }
  }
  return top;
}

export class BeamFrontier implements Frontier {
  private heap: Job[] = [];
  constructor(private readonly width: number) {}
  push(job: Job) {
    heapPush(this.heap, job);
    if (this.heap.length > this.width) {
      // drop worst by rebuilding heap after removing min:
      // reference-grade: sort descending, truncate, rebuild
      this.heap.sort((a, b) => b.score - a.score);
      this.heap.length = this.width;
      this.heap = this.heap.slice();
      // rebuild heap structure
      const xs = this.heap.slice().sort((a, b) => a.score - b.score);
      this.heap = [];
      for (const j of xs) heapPush(this.heap, j);
    }
  }
  pop() { return heapPop(this.heap); }
  size() { return this.heap.length; }
  clear() { this.heap = []; }
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/nondet/runner.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Runtime } from "../../eval/runtime";
import type { State } from "../../eval/machine";
import type { Val } from "../../eval/values";
import { stepOnce } from "../../eval/machineStep";

export type NondetMode = "first" | "all";
export type Frontier = "bfs" | "dfs";

export type NondetOptions = {
  mode: NondetMode;
  frontier: Frontier;
  quantumSteps: number;
  maxTotalSteps: number;
  maxJobs: number;
};

export type NondetResult =
  | { tag: "None" }
  | { tag: "One"; value: Val }
  | { tag: "Many"; values: Val[] };

type Job = { state: State };

function isVectorVal(v: Val): v is { tag: "Vector"; items: Val[] } {
  return v.tag === "Vector";
}

function enqueue(frontier: Frontier, q: Job[], j: Job): Job[] {
  if (frontier === "bfs") return q.concat([j]);
  // dfs
  return [j].concat(q);
}

export async function runNondet(runtime: Runtime, initial: State, opts: NondetOptions): Promise<NondetResult> {
  let queue: Job[] = [{ state: initial }];
  const solutions: Val[] = [];
  let totalSteps = 0;

  while (queue.length > 0) {
    if (queue.length > opts.maxJobs) throw new Error("runNondet: maxJobs exceeded");

    const job = queue[0];
    queue = queue.slice(1);

    let st = job.state;

    for (let q = 0; q < opts.quantumSteps; q++) {
      totalSteps++;
      if (totalSteps > opts.maxTotalSteps) throw new Error("runNondet: maxTotalSteps exceeded");

      const out = stepOnce(st);

      if (out.tag === "State") {
        st = out.state;
        continue;
      }

      if (out.tag === "Done") {
        solutions.push(out.value);
        if (opts.mode === "first") return { tag: "One", value: out.value };
        break; // finish this job
      }

      if (out.tag === "Op") {
        const op = out.opcall.op;

        if (op === "amb.op") {
          // Convention: amb.op args:
          //   either a single Vector of choices, or a variadic list of choices.
          let choices: Val[] = [];
          if (out.opcall.args.length === 1 && isVectorVal(out.opcall.args[0])) {
            choices = out.opcall.args[0].items;
          } else {
            choices = out.opcall.args;
          }

          // Fork: each choice resumes the continuation with that choice as the op result.
          for (const ch of choices) {
            const child = out.opcall.resumption.invoke(ch);
            queue = enqueue(opts.frontier, queue, { state: child });
          }
          break; // stop current job; replaced by children
        }

        const handled = await runtime.dispatch(out.state, out.opcall);
        if (handled === "Uncaught") throw new Error(`Uncaught op: ${out.opcall.op}`);
        st = handled;
        continue;
      }
    }

    // If quantum expired and we still have a running state, requeue it (fair scheduling).
    if (st.control.tag !== "Val" || st.kont.length > 0) {
      queue = enqueue(opts.frontier, queue, { state: st });
    }
  }

  if (solutions.length === 0) return { tag: "None" };
  return { tag: "Many", values: solutions };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/nondet/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-3.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { State } from "../../eval/machine";
import type { Val } from "../../eval/values";

export type NondetMode = "first" | "all" | "best" | "sample";

export type ChoiceVec = Val[]; // amb.op passes choices as already-evaluated values (CBV). CBN can pass thunks.

export type ConstraintObs =
  | { tag: "Require"; predSyntaxHash: string; ok?: boolean }
  | { tag: "Note"; msg: string };

export type Job = {
  jid: string;
  state: State;
  depth: number;
  score: number;
  constraints: ConstraintObs[];
};

export type FrontierKind = "dfs" | "bfs" | "best" | "beam" | "sample";

export type NondetPolicy = {
  mode: NondetMode;
  frontier: FrontierKind;

  /** Fair scheduling quantum (steps per job). Required for BFS fairness under divergence. */
  quantumSteps: number;

  /** Beam width if frontier="beam". */
  beamWidth?: number;

  /** For best/sample: compute job score; can call inference (budgeted) */
  scoreChoice?: (ctx: { constraints: ConstraintObs[]; depth: number }, choice: Val) => Promise<number> | number;

  /** For pruning: return true to prune choice/job before exploring. */
  pruneChoice?: (ctx: { constraints: ConstraintObs[]; depth: number; score: number }, choice: Val) => Promise<boolean> | boolean;

  /** For best-solution aggregation: score complete results */
  scoreResult?: (v: Val) => Promise<number> | number;

  /** Optional RNG seed for sampling. */
  seed?: number;

  /** Step and wall budgets to bound explosion. */
  maxJobs?: number;
  maxTotalSteps?: number;
};

export type NondetResult =
  | { tag: "None" }
  | { tag: "One"; value: Val }
  | { tag: "Many"; values: Val[] };
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/opcall.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Val } from "../eval/values";
import type { State } from "../eval/machine";

export type Resumption = {
  readonly rid: string;
  readonly base: State;             // store MUST be snapshotted/persistent
  invoke(v: Val): State;            // inject v as effect result
  digest(): string;
};

export type OpCall = {
  readonly op: string;
  readonly args: Val[];
  readonly ctxDigest: string;
  readonly resumption: Resumption;
};
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/runtimeImpl.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set B: int.op/infer.op/rewrite.op as distinct kernel forms
// Patch Set D: Governance (caps, budgets, commit barrier)

import type { Runtime, DispatchResult } from "../eval/runtime";
import type { State, HandlerFrame } from "../eval/machine";
import type { OpCall } from "./opcall";
import type { Val } from "../eval/values";
import { VUnit } from "../eval/values";
import { envSet } from "../eval/env";
import type { Resumption } from "./opcall";

// AMB: Alternative tracking for backtracking search
type AmbAlternative = {
  thunk: Val;           // Closure to invoke
  resumption: Resumption; // Continuation to resume with thunk's result
};

export type AmbStrategy = "DFS" | "FAIR";

// Oracle Protocol imports
import type { OracleAdapter } from "../oracle/adapter";
import type { SnapshotRepo } from "../oracle/snapshots";
import type { ReceiptStore } from "../oracle/receipts";
import { PortalImpl } from "../oracle/portalImpl";
import { runOracleSession } from "../oracle/driver";
import { isMeaning, meaning as mkMeaning, type MeaningVal, type Obligation, type Evidence } from "../oracle/meaning";
import { matchAST } from "../oracle/match";
import { distFrom, type DistVal } from "../eval/dist";
import { computeSourceHash, type OracleEvidence } from "../provenance/evidence";
import type { StoredReceipt } from "../provenance/store/interface";
import { sha256JSON } from "../artifacts/hash";

// Governance imports
import type { Profile } from "../governance/profile";
import { DEFAULT_PROFILE } from "../governance/profile";
import { capRequire, capHas, type CapSet } from "../governance/caps";
import type { BudgetTracker } from "../governance/budgets";

// Pipeline imports for parsing text to expressions
import { compileTextToExpr } from "../pipeline/compileText";
import { runToCompletionWithState } from "../eval/run";

export interface CommitAdapter {
  commit(payload: Val, ctxDigest: string): Promise<Val>;
}

function requireCommitCapability(caps: CapSet, required: string, context: string): void {
  if (capHas(caps, "commit.*")) return;
  capRequire(caps, required, context);
}

function findBoundaryIndex(kont: State["kont"], hid: string): number {
  for (let i = kont.length - 1; i >= 0; i--) {
    const fr = kont[i];
    if (fr.tag === "KHandleBoundary" && fr.hid === hid) return i;
  }
  return -1;
}

type InferKind = "int" | "search" | "rewrite";

function intSamplesFromPayload(payload: Val, fallback: number): number {
  // Optional convention: payload may be (map (("n" . <num>)) ...)
  try {
    if (payload.tag === "Map") {
      for (const [k, v] of payload.entries) {
        if (k.tag === "Str" && k.s === "n" && v.tag === "Num") return Math.max(1, Math.floor(v.n));
      }
    }
  } catch {}
  return fallback;
}

function obligationSatisfied(m: MeaningVal): boolean {
  // Convention: obligation = {tag:"Obligation", status:"satisfied"} or Bool true.
  const o = m?.obligation;
  if (!o) return false;
  if ((o as any).tag === "Bool") return !!(o as any).b;
  if ((o as any).tag === "Obligation" && (o as any).status === "satisfied") return true;
  return false;
}

function needsProvenance(state: State): boolean {
  return !!state.provenanceGraph || !!state.provenanceStore;
}

async function attachOracleEvidence(meaning: MeaningVal, payload: Val, state: State): Promise<MeaningVal> {
  if (!needsProvenance(state)) return meaning;

  const timestamp = Date.now();
  const receiptId = sha256JSON({ payload, timestamp });
  const evidence: OracleEvidence = {
    tag: "OracleEvidence",
    receiptId,
    sourceHash: computeSourceHash(payload),
    timestamp,
  };

  state.provenanceGraph?.addNode(evidence);

  if (state.provenanceStore) {
    const receipt: StoredReceipt = { id: receiptId, timestamp, request: payload, response: meaning };
    await state.provenanceStore.storeReceipt(receipt);
  }

  const evidenceList = meaning.evidence ? meaning.evidence.concat([evidence]) : [evidence];
  return { ...meaning, evidence: evidenceList };
}

export class RuntimeImpl implements Runtime {
  private profile: Profile;
  private budget?: BudgetTracker;

  // AMB: Backtracking state
  private ambAlternatives: AmbAlternative[] = [];
  private ambStrategy: AmbStrategy = "DFS";

  constructor(
    private readonly oracle: OracleAdapter,
    private readonly snapshots: SnapshotRepo,
    private readonly receipts: ReceiptStore,
    private readonly commit: CommitAdapter,
    profile?: Profile,
    budget?: BudgetTracker
  ) {
    this.profile = profile ?? DEFAULT_PROFILE;
    this.budget = budget;
  }

  /** Set the budget tracker (allows sharing with run loop). */
  setBudget(budget: BudgetTracker): void {
    this.budget = budget;
  }

  /** Set the amb search strategy (DFS or FAIR). */
  setAmbStrategy(strategy: AmbStrategy): void {
    this.ambStrategy = strategy;
  }

  /** Reset amb state (clears all pending alternatives). */
  resetAmb(): void {
    this.ambAlternatives = [];
  }

  /** Check if there are pending amb alternatives. */
  hasAmbAlternatives(): boolean {
    return this.ambAlternatives.length > 0;
  }

  /** Extract test thunks from a list/vector value. */
  private extractTestThunks(v: Val): Val[] {
    const result: Val[] = [];
    // Handle cons-cell list
    let cur = v;
    while ((cur as any).tag === "Vector" && (cur as any).items?.length === 2) {
      result.push((cur as any).items[0]);
      cur = (cur as any).items[1];
    }
    // Handle flat vector
    if ((cur as any).tag === "Vector" && (cur as any).items?.length > 0 && result.length === 0) {
      return (cur as any).items;
    }
    return result;
  }

  async dispatch(state: State, opcall: OpCall): Promise<DispatchResult> {
    // 1) Try language-level handlers (deep handlers; nearest enclosing clause wins).
    for (let hi = state.handlers.length - 1; hi >= 0; hi--) {
      const hf = state.handlers[hi];
      const clause = hf.on.get(opcall.op);
      if (!clause) continue;

      // The handler for opcall.op is hf at index hi.
      // Clause executes *outside* any inner handlers above hf (those are inside the suspended continuation).
      const handlersTrunc = state.handlers.slice(0, hi + 1);

      // Compute delimiter boundary location in the suspended continuation.
      const boundaryIndex = findBoundaryIndex(state.kont, hf.hid);
      if (boundaryIndex < 0) throw new Error(`dispatch: boundary not found for handler ${hf.hid}`);

      // Truncate continuation to delimiter boundary (discard frames inside handle body).
      // Keep the boundary itself so clause return aborts to it and triggers return clause logic.
      const kontTrunc = state.kont.slice(0, boundaryIndex + 1);

      // Construct k as a ContVal.
      const kVal: Val = { tag: "Cont", hid: hf.hid, boundaryIndex, resumption: opcall.resumption };

      // Bind params and k into handler lexical env.
      let store = state.store;
      let env = hf.env;

      // Bind operation parameters
      if (clause.params.length !== opcall.args.length) {
        throw new Error(`dispatch: op arity mismatch for ${clause.op}`);
      }
      for (let i = 0; i < clause.params.length; i++) {
        const [store2, addr] = store.alloc(opcall.args[i]);
        store = store2;
        env = envSet(env, clause.params[i], addr);
      }

      // Bind k
      {
        const [store2, addr] = store.alloc(kVal);
        store = store2;
        env = envSet(env, clause.k, addr);
      }

      // Evaluate handler clause body.
      const st2: State = {
        ...state,
        control: { tag: "Expr", e: clause.body },
        env,
        store,
        kont: kontTrunc,
        handlers: handlersTrunc,
      };
      return st2;
    }

    // 2) Built-in fallback handlers using the Oracle Protocol.
    const opName = opcall.op;

    // Patch Set B: Three distinct intensional forms
    // - infer.op: backward compatible, returns denotation directly
    // - int.op: returns full Meaning
    // - rewrite.op: returns full Meaning (expects rewrite field)
    // - search.op: returns Dist<Meaning> for multi-shot search
    if (opName === "int.op" || opName === "infer.op" || opName === "rewrite.op" || opName === "search.op") {
      const kind: InferKind = opName === "search.op" ? "search" : opName === "rewrite.op" ? "rewrite" : "int";
      const needProv = needsProvenance(state);

      // Consume oracle turn budget
      this.budget?.consumeOracleTurn();

      // Minimal caps: oracle must be able to re-enter eval/apply/observe to be "first class".
      capRequire(this.profile.caps, "eval", `start ${opName}`);
      capRequire(this.profile.caps, "apply", `start ${opName}`);
      capRequire(this.profile.caps, "observe", `start ${opName}`);

      const payload: Val = opcall.args[0] ?? ({ tag: "Unit" } as Val);

      // Snapshot current state for oracle introspection
      const envRef = this.snapshots.putEnv({ env: state.env, store: state.store });
      const stateRef = this.snapshots.putState({ state });

      // Create portal for oracle to REPL back into evaluator
      const portal = new PortalImpl(this as any, this.snapshots, this.receipts, {
        maxEvalSteps: 100_000,
        parseText: (src: string) => compileTextToExpr(src),
      });

      // SEARCH: search.op - multi-shot oracle sampling returns Dist<Meaning>
      if (kind === "search") {
        const n = intSamplesFromPayload(payload, 8);
        const items: { v: Val; w: number }[] = [];

        for (let i = 0; i < n; i++) {
          const session = this.oracle.startSession({
            tag: "Infer",
            payload,
            envRef,
            stateRef,
          });

          const meaning = await runOracleSession(session, portal);
          const enriched = needProv ? await attachOracleEvidence(meaning as MeaningVal, payload, state) : meaning;
          items.push({ v: enriched as Val, w: 1 });
        }

        const d: DistVal = distFrom(items, { kind: "search", note: `n=${n}` });
        return opcall.resumption.invoke(d as Val);
      }

      // int.op, infer.op, rewrite.op: Run ONE oracle session
      const session = this.oracle.startSession({
        tag: "Infer",
        payload,
        envRef,
        stateRef,
      });

      const meaning = await runOracleSession(session, portal);
      let enrichedMeaning = meaning as MeaningVal;
      if (needProv) {
        enrichedMeaning = await attachOracleEvidence(enrichedMeaning, payload, state);
      }

      // Optional: if oracle asked to adopt a modified env, patch state
      const adoptEnv = portal.consumeAdoptEnvRef() ?? meaning.adoptEnvRef;
      let st2 = state;
      if (adoptEnv) {
        const snap = this.snapshots.getEnv(adoptEnv);
        st2 = { ...st2, env: snap.env, store: snap.store };
      }

      // int.op and rewrite.op: Return the full Meaning as a first-class value
      if (opName === "int.op" || opName === "rewrite.op") {
        // runOracleSession always returns Meaning (MeaningVal), which is a Val
        return opcall.resumption.invoke(enrichedMeaning as Val);
      }

      // infer.op: Return the denotation directly (backward compatible)
      const resultVal = enrichedMeaning.denotation ?? ({ tag: "Unit" } as Val);
      return opcall.resumption.invoke(resultVal);
    }

    // oracle.apply.op: LLM in apply position (unchanged)
    if (opcall.op === "oracle.apply.op") {
      // Consume oracle turn budget
      this.budget?.consumeOracleTurn();
      const needProv = needsProvenance(state);

      // Capability checks for oracle apply
      capRequire(this.profile.caps, "eval", "oracle.apply.op");
      capRequire(this.profile.caps, "apply", "oracle.apply.op");
      capRequire(this.profile.caps, "observe", "oracle.apply.op");

      const proc = opcall.args[0]; // OracleProc
      const argVec = opcall.args[1];
      if (argVec.tag !== "Vector") throw new Error("oracle.apply.op expects (OracleProc, Vector)");

      // Snapshot current state
      const envRef = this.snapshots.putEnv({ env: state.env, store: state.store });
      const stateRef = this.snapshots.putState({ state });

      // Create portal
      const portal = new PortalImpl(this as any, this.snapshots, this.receipts, {
        maxEvalSteps: 100_000,
        parseText: (src: string) => compileTextToExpr(src),
      });

      // Start apply session
      const session = this.oracle.startSession({
        tag: "Apply",
        proc,
        args: argVec.items,
        envRef,
        stateRef,
      });

      // Drive session
      const meaning = await runOracleSession(session, portal);

      let enrichedMeaning = meaning as MeaningVal;
      if (needProv) {
        const payload: Val = {
          tag: "Vector",
          items: [((proc as any).spec ?? ({ tag: "Unit" } as Val)) as Val, argVec as Val],
        };
        enrichedMeaning = await attachOracleEvidence(enrichedMeaning, payload, state);
      }

      const v = enrichedMeaning.denotation ?? ({ tag: "Unit" } as Val);

      // Optional adoption
      const adoptEnv = portal.consumeAdoptEnvRef() ?? meaning.adoptEnvRef;
      let st2 = state;
      if (adoptEnv) {
        const snap = this.snapshots.getEnv(adoptEnv);
        st2 = { ...st2, env: snap.env, store: snap.store };
      }

      return opcall.resumption.invoke(v);
    }

    // Patch Set D: commit.op with truth regime enforcement
    if (opcall.op === "commit.op") {
      requireCommitCapability(this.profile.caps, "commit.method", "commit");

      const kind = opcall.args[0]?.tag === "Str" ? (opcall.args[0] as any).s : "unknown";
      const payload = opcall.args[1] ?? opcall.args[0] ?? { tag: "Unit" };

      if (this.profile.truth === "speculative") {
        throw new Error(`commit rejected in speculative truth regime (kind=${kind})`);
      }

      if (this.profile.truth === "test-certified" || this.profile.truth === "proof-certified") {
        if (isMeaning(payload)) {
          if (!obligationSatisfied(payload)) {
            throw new Error("commit requires satisfied obligations under non-speculative regimes");
          }
        }
      }

      const res = await this.commit.commit(payload, opcall.ctxDigest);
      return opcall.resumption.invoke(res);
    }

    // Patch Set 5: commit-tested.op - commit with test barrier
    // Args: (kind: Str, payload: Val, tests: Vec<Closure>) or (payload, tests)
    // Runs each test thunk; all must return truthy for commit to proceed
    if (opcall.op === "commit-tested.op") {
      requireCommitCapability(this.profile.caps, "commit.method", "commit-tested");
      capRequire(this.profile.caps, "test", "commit-tested");

      // Parse arguments: (kind payload tests) or (payload tests)
      let kind = "tested";
      let payload: Val;
      let tests: Val[];

      if (opcall.args.length >= 3 && opcall.args[0]?.tag === "Str") {
        kind = (opcall.args[0] as any).s;
        payload = opcall.args[1];
        tests = this.extractTestThunks(opcall.args[2]);
      } else if (opcall.args.length >= 2) {
        payload = opcall.args[0];
        tests = this.extractTestThunks(opcall.args[1]);
      } else {
        throw new Error("commit-tested.op: expected (kind payload tests) or (payload tests)");
      }

      // Run each test thunk - they must be closures returning truthy values
      const envRef = this.snapshots.putEnv({ env: state.env, store: state.store });
      const portal = new PortalImpl(this as any, this.snapshots, this.receipts, {
        maxEvalSteps: 100_000,
        parseText: (src: string) => compileTextToExpr(src),
        caps: this.profile.caps,
      });

      // Evaluate each test
      for (let i = 0; i < tests.length; i++) {
        const testThunk = tests[i];
        if (testThunk.tag !== "Closure") {
          throw new Error(`commit-tested.op: test ${i} is not a closure`);
        }

        // Evaluate test thunk body in its closure environment
        const { env, store } = this.snapshots.getEnv(envRef);
        const testState: State = {
          control: { tag: "Expr", e: testThunk.body },
          env: testThunk.env,
          store,
          kont: [],
          handlers: [],
        };

        try {
          const { value } = await runToCompletionWithState(this as any, testState, 100_000);
          const passed = value.tag === "Bool" ? value.b : (value.tag !== "Unit");
          if (!passed) {
            throw new Error(`commit-tested.op: test ${i} failed (returned ${value.tag})`);
          }
        } catch (e: any) {
          throw new Error(`commit-tested.op: test ${i} threw: ${e?.message ?? e}`);
        }
      }

      // All tests passed, now check truth regime
      if (this.profile.truth === "speculative") {
        throw new Error(`commit rejected in speculative truth regime (kind=${kind})`);
      }

      // Mark obligation as satisfied since tests passed
      const result = await this.commit.commit(payload, opcall.ctxDigest);
      return opcall.resumption.invoke(result);
    }

    // Patch Set 6: commit/rewrite.op - commit a Meaning with obligation discharge
    // Args: (meaning: MeaningVal) where meaning has .rewrite and .obligations
    // Discharges obligations, records evidence, then commits if all pass
    if (opcall.op === "commit/rewrite.op") {
      requireCommitCapability(this.profile.caps, "commit.rewrite", "commit/rewrite");

      const meaningArg = opcall.args[0];
      if (!meaningArg || !isMeaning(meaningArg)) {
        throw new Error("commit/rewrite.op: expected Meaning value");
      }

      const meaning = meaningArg as MeaningVal;
      const obligations = meaning.obligations ?? [];
      const evidence: Evidence[] = [];

      // Set up portal for running tests
      const envRef = this.snapshots.putEnv({ env: state.env, store: state.store });
      const portal = new PortalImpl(this as any, this.snapshots, this.receipts, {
        maxEvalSteps: 100_000,
        parseText: (src: string) => compileTextToExpr(src),
        caps: this.profile.caps,
      });

      // Discharge each obligation
      for (const obl of obligations) {
        if (obl.tag === "OblTests") {
          // Run test expressions, all must return truthy
          let passed = 0;
          const total = obl.tests.length;

          for (const testExpr of obl.tests) {
            const { env, store } = this.snapshots.getEnv(obl.envRef ?? envRef);
            const testState: State = {
              control: { tag: "Expr", e: testExpr },
              env,
              store,
              kont: [],
              handlers: [],
            };

            try {
              const { value } = await runToCompletionWithState(this as any, testState, 100_000);
              const ok = value.tag === "Bool" ? value.b : (value.tag !== "Unit");
              if (ok) passed++;
              else throw new Error(`OblTests: test failed`);
            } catch (e: any) {
              throw new Error(`commit/rewrite.op: OblTests failed: ${e?.message ?? e}`);
            }
          }

          evidence.push({ tag: "TestEvidence", passed, total });
        }

        if (obl.tag === "OblNoMatch") {
          const targets: Val[] = [];
          const unwrap = (v: Val): unknown => {
            if ((v as any)?.tag === "Syntax" && "stx" in (v as any)) return (v as any).stx;
            return v;
          };
          if (obl.scope === "all") {
            if (meaning.rewrite) targets.push(meaning.rewrite);
            if (meaning.residual) targets.push(meaning.residual);
          } else if (meaning.rewrite) {
            targets.push(meaning.rewrite);
          }

          for (const target of targets) {
            const { ok } = matchAST(obl.pattern, unwrap(target));
            if (ok) {
              throw new Error(`commit/rewrite.op: OblNoMatch failed - pattern found in ${obl.scope}`);
            }
          }

          evidence.push({
            tag: "NoMatchEvidence",
            pattern: obl.pattern,
            searched: targets.length,
            found: 0,
          });
        }

        if (obl.tag === "OblEqExt") {
          // Run extensional equivalence tests: original(input) === candidate(input) for all tests
          let allPassed = true;
          const failures: Array<{ input: Val; expected: Val; got: Val }> = [];

          for (const testExpr of obl.tests) {
            const { env, store } = this.snapshots.getEnv(obl.envRef ?? envRef);

            // Evaluate original with test input
            const origState: State = {
              control: { tag: "Expr", e: { tag: "App", fn: obl.original, args: [testExpr] } },
              env,
              store,
              kont: [],
              handlers: [],
            };
            const { value: expected } = await runToCompletionWithState(this as any, origState, 100_000);

            // Evaluate candidate with same input
            const candState: State = {
              control: { tag: "Expr", e: { tag: "App", fn: obl.candidate, args: [testExpr] } },
              env,
              store,
              kont: [],
              handlers: [],
            };
            const { value: got } = await runToCompletionWithState(this as any, candState, 100_000);

            // Compare (simple structural equality for now)
            const eq = JSON.stringify(expected) === JSON.stringify(got);
            if (!eq) {
              allPassed = false;
              failures.push({ input: { tag: "Syntax", stx: testExpr } as any, expected, got });
            }
          }

          if (!allPassed) {
            throw new Error(`commit/rewrite.op: OblEqExt failed - ${failures.length} test(s) differ`);
          }
          evidence.push({ tag: "EqExtEvidence", tests: obl.tests.length, allPassed, failures: failures.length > 0 ? failures : undefined });
        }
      }

      // All obligations discharged - check truth regime
      if (this.profile.truth === "speculative") {
        throw new Error(`commit/rewrite rejected in speculative truth regime`);
      }

      // Create result Meaning with evidence
      const resultMeaning: MeaningVal = {
        ...meaning,
        evidence,
      };

      // Commit the rewrite (the actual binding update)
      const payload = meaning.rewrite ?? meaning.residual ?? meaning.denotation ?? { tag: "Unit" };
      const result = await this.commit.commit(payload as Val, opcall.ctxDigest);

      // Return the Meaning with evidence attached
      return opcall.resumption.invoke(resultMeaning as Val);
    }

    // AMB: amb.choose - pick first thunk, save rest as pending alternatives
    if (opcall.op === "amb.choose") {
      const thunks = opcall.args[0];
      if (!thunks || thunks.tag !== "Vector") {
        throw new Error("amb.choose: expected vector of thunks");
      }

      // Convert cons-cell list to flat array
      function consToArray(v: Val): Val[] {
        const result: Val[] = [];
        let cur = v;
        while (cur.tag === "Vector" && cur.items.length === 2) {
          result.push(cur.items[0]);
          cur = cur.items[1];
        }
        // Handle flat vectors too
        if (cur.tag === "Vector" && cur.items.length > 2) {
          return cur.items;
        }
        return result;
      }

      const items = consToArray(thunks);
      if (items.length === 0) {
        // No alternatives - immediately fail
        return this.dispatch(state, {
          op: "amb.fail",
          args: [{ tag: "Str", s: "amb: no alternatives" } as Val],
          resumption: opcall.resumption,
          ctxDigest: opcall.ctxDigest,
        });
      }

      // Save remaining alternatives (based on strategy)
      // DFS: push to stack (most recent first when we pop)
      // FAIR: add to queue (oldest first when we shift)
      for (let i = 1; i < items.length; i++) {
        const alt: AmbAlternative = {
          thunk: items[i],
          resumption: opcall.resumption,
        };
        if (this.ambStrategy === "DFS") {
          this.ambAlternatives.push(alt);
        } else {
          // FAIR: add to end of queue
          this.ambAlternatives.push(alt);
        }
      }

      // Debit budget for amb attempt
      this.budget?.consumeAmbAttempt?.();

      // Invoke first thunk: apply it with no arguments
      const firstThunk = items[0];
      if (firstThunk.tag !== "Closure") {
        throw new Error("amb.choose: thunk must be a closure");
      }

      // Build a state that evaluates the thunk with resumption's frames
      // The thunk is a zero-arg closure - inline its body evaluation
      const baseState: State | "Uncaught" | "OutOfBudget" =
        opcall.resumption.invoke({ tag: "Unit" } as Val);
      if (baseState === ("Uncaught" as any) || baseState === ("OutOfBudget" as any)) {
        return baseState;
      }

      // Inline the closure: evaluate body with closure's env
      // The kont from baseState has the continuation waiting for the result
      return {
        ...baseState,
        control: { tag: "Expr", e: firstThunk.body },
        env: firstThunk.env,
      } as State;
    }

    // AMB: amb.fail - backtrack to next pending alternative
    if (opcall.op === "amb.fail") {
      if (this.ambAlternatives.length === 0) {
        // No more alternatives - propagate failure
        throw new Error("amb: all alternatives exhausted");
      }

      // Debit budget for backtrack
      this.budget?.consumeAmbAttempt?.();

      // Pick next alternative based on strategy
      // Both DFS and FAIR try alternatives in order (first added = first tried)
      // The difference is in how fairness interleaves with continuation
      let alt: AmbAlternative;
      alt = this.ambAlternatives.shift()!;  // FIFO: try in order added

      // Resume with this alternative's thunk
      const thunk = alt.thunk;
      const resumption = alt.resumption;

      // Same as amb.choose: we need to evaluate the thunk and resume with result
      const baseState: State | "Uncaught" | "OutOfBudget" =
        resumption.invoke({ tag: "Unit" } as Val);
      if (baseState === ("Uncaught" as any) || baseState === ("OutOfBudget" as any)) {
        return baseState;
      }

      // We need to actually call the thunk. Let's inline it properly.
      // The thunk is a Closure. We want to evaluate its body with its env.
      if (thunk.tag === "Closure") {
        return {
          ...baseState,
          control: { tag: "Expr", e: thunk.body },
          env: thunk.env,
        } as State;
      } else if (thunk.tag === "Native") {
        // Native thunk - call it with empty args
        // This is tricky... for now assume thunks are Closures
        throw new Error("amb: Native thunks not yet supported");
      }

      throw new Error(`amb: invalid thunk type ${thunk.tag}`);
    }

    // amb.* passthrough: if not handled by a language handler or a dedicated nondet runner, it is uncaught.

    // shell.op: Execute a shell command and return the output
    // Args: (command: Str) -> Str (stdout) or throws on error
    if (opcall.op === "shell.op") {
      capRequire(this.profile.caps, "shell", "shell.op");

      const cmdArg = opcall.args[0];
      if (!cmdArg || cmdArg.tag !== "Str") {
        throw new Error("shell.op: expected string command");
      }

      const command = cmdArg.s;

      // Execute command using child_process
      const { execSync } = await import("child_process");
      try {
        const stdout = execSync(command, {
          encoding: "utf-8",
          maxBuffer: 10 * 1024 * 1024, // 10MB
          timeout: 300000, // 5 minutes
        });
        return opcall.resumption.invoke({ tag: "Str", s: stdout.trim() } as Val);
      } catch (e: any) {
        // Return error as a structured value rather than throwing
        const stderr = e.stderr?.toString?.() ?? "";
        const message = e.message ?? "command failed";
        throw new Error(`shell.op failed: ${message}\n${stderr}`);
      }
    }

    // file.read.op: Read a file and return its contents
    // Args: (path: Str) -> Str
    if (opcall.op === "file.read.op") {
      capRequire(this.profile.caps, "file.read", "file.read.op");

      const pathArg = opcall.args[0];
      if (!pathArg || pathArg.tag !== "Str") {
        throw new Error("file.read.op: expected string path");
      }

      const { readFileSync } = await import("fs");
      try {
        const content = readFileSync(pathArg.s, "utf-8");
        return opcall.resumption.invoke({ tag: "Str", s: content } as Val);
      } catch (e: any) {
        throw new Error(`file.read.op failed: ${e.message}`);
      }
    }

    // file.write.op: Write content to a file
    // Args: (path: Str, content: Str) -> Unit
    if (opcall.op === "file.write.op") {
      capRequire(this.profile.caps, "file.write", "file.write.op");

      const pathArg = opcall.args[0];
      const contentArg = opcall.args[1];
      if (!pathArg || pathArg.tag !== "Str") {
        throw new Error("file.write.op: expected string path as first arg");
      }
      if (!contentArg || contentArg.tag !== "Str") {
        throw new Error("file.write.op: expected string content as second arg");
      }

      const { writeFileSync } = await import("fs");
      try {
        writeFileSync(pathArg.s, contentArg.s, "utf-8");
        return opcall.resumption.invoke({ tag: "Unit" } as Val);
      } catch (e: any) {
        throw new Error(`file.write.op failed: ${e.message}`);
      }
    }

    return "Uncaught";
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/search/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/effects/search/index.ts
// Prompt 11: Search module exports

export * from "./types";
export * from "./runner";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/search/runner.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/effects/search/runner.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 11: Search runner with DFS/BFS/Beam/MCTS strategies

import type { Runtime } from "../../eval/runtime";
import type { State } from "../../eval/machine";
import type { Val } from "../../eval/values";
import { VUnit } from "../../eval/values";
import { stepOnce } from "../../eval/machineStep";
import { dist, distFrom, type DistVal, type DistItem } from "../../eval/dist";
import { sha256JSON } from "../../artifacts/hash";
import {
  type SearchConfig,
  type SearchBudget,
  type SearchJob,
  type SearchDecision,
  type SearchLedger,
  type SearchResult,
  type SearchStats,
  type WeightedChoice,
  type MCTSNode,
  DEFAULT_SEARCH_BUDGET,
  SearchBudgetExceeded,
  parseAmbArgs,
  createMCTSNode,
  ucb1,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Deterministic PRNG for reproducible search
// ─────────────────────────────────────────────────────────────────

function mulberry32(seed: number): () => number {
  let t = seed >>> 0;
  return () => {
    t += 0x6D2B79F5;
    let x = t;
    x = Math.imul(x ^ (x >>> 15), x | 1);
    x ^= x + Math.imul(x ^ (x >>> 7), x | 61);
    return ((x ^ (x >>> 14)) >>> 0) / 4294967296;
  };
}

// ─────────────────────────────────────────────────────────────────
// Search runner
// ─────────────────────────────────────────────────────────────────

let jobCounter = 0;

function makeJobId(): string {
  return `job_${++jobCounter}`;
}

function isVectorVal(v: Val): v is { tag: "Vector"; items: Val[] } {
  return v.tag === "Vector";
}

function valDigest(v: Val): string {
  try {
    return sha256JSON(v).slice(0, 16);
  } catch {
    return `tag:${v.tag}`;
  }
}

/**
 * Run search with the specified configuration.
 * Returns a DistVal of solutions with search statistics.
 */
export async function runSearch(
  runtime: Runtime,
  initial: State,
  config: SearchConfig
): Promise<SearchResult> {
  const startTime = Date.now();
  const seed = config.seed ?? Date.now();
  const rng = mulberry32(seed);

  // Initialize budget
  const budget: SearchBudget = {
    ...DEFAULT_SEARCH_BUDGET,
    ...config.budget,
  };

  // Initialize ledger
  const ledger: SearchLedger = {
    decisions: [],
    seed,
    strategy: config.strategy,
  };

  // Initialize stats
  const stats: SearchStats = {
    nodesExpanded: 0,
    maxDepthReached: 0,
    solutionsFound: 0,
    backtracks: 0,
    elapsedMs: 0,
  };

  // Solutions with weights
  const solutions: DistItem[] = [];

  // Run appropriate strategy
  let dist: DistVal;

  switch (config.strategy) {
    case "dfs":
      dist = await runDFS(runtime, initial, budget, ledger, stats, solutions, config);
      break;
    case "bfs":
      dist = await runBFS(runtime, initial, budget, ledger, stats, solutions, config);
      break;
    case "beam":
      dist = await runBeam(runtime, initial, budget, ledger, stats, solutions, config, rng);
      break;
    case "mcts":
      dist = await runMCTS(runtime, initial, budget, ledger, stats, solutions, config, rng);
      break;
    default:
      throw new Error(`Unknown search strategy: ${config.strategy}`);
  }

  stats.elapsedMs = Date.now() - startTime;

  return { dist, ledger, stats };
}

// ─────────────────────────────────────────────────────────────────
// C1) DFS - Depth-First Search (stack frontier)
// ─────────────────────────────────────────────────────────────────

async function runDFS(
  runtime: Runtime,
  initial: State,
  budget: SearchBudget,
  ledger: SearchLedger,
  stats: SearchStats,
  solutions: DistItem[],
  config: SearchConfig
): Promise<DistVal> {
  const stack: SearchJob[] = [{
    id: makeJobId(),
    state: initial,
    depth: 0,
    cost: 0,
  }];

  while (stack.length > 0 && budget.searchNodesLeft > 0 && budget.solutionsLeft > 0) {
    const job = stack.pop()!;

    // Consume budget for each job processed (node expansion)
    budget.searchNodesLeft--;
    stats.nodesExpanded++;

    stats.maxDepthReached = Math.max(stats.maxDepthReached, job.depth);

    if (job.depth > budget.searchDepthLeft) {
      stats.backtracks++;
      continue;
    }

    const result = await runJobToChoiceNoBudget(runtime, job, ledger);

    if (result.tag === "done") {
      solutions.push({ v: result.value, w: 1 / (1 + job.cost) });
      stats.solutionsFound++;
      budget.solutionsLeft--;
    } else if (result.tag === "choice") {
      // DFS: push children in reverse order (so first choice is popped first)
      for (let i = result.children.length - 1; i >= 0; i--) {
        stack.push(result.children[i]);
      }
    } else if (result.tag === "fail") {
      stats.backtracks++;
    }
  }

  return distFrom(solutions, { kind: "dfs-search" });
}

// ─────────────────────────────────────────────────────────────────
// C2) BFS - Breadth-First Search (queue frontier)
// ─────────────────────────────────────────────────────────────────

async function runBFS(
  runtime: Runtime,
  initial: State,
  budget: SearchBudget,
  ledger: SearchLedger,
  stats: SearchStats,
  solutions: DistItem[],
  config: SearchConfig
): Promise<DistVal> {
  const queue: SearchJob[] = [{
    id: makeJobId(),
    state: initial,
    depth: 0,
    cost: 0,
  }];

  while (queue.length > 0 && budget.searchNodesLeft > 0 && budget.solutionsLeft > 0) {
    const job = queue.shift()!;

    // Consume budget for each job processed (node expansion)
    budget.searchNodesLeft--;
    stats.nodesExpanded++;

    stats.maxDepthReached = Math.max(stats.maxDepthReached, job.depth);

    if (job.depth > budget.searchDepthLeft) {
      stats.backtracks++;
      continue;
    }

    const result = await runJobToChoiceNoBudget(runtime, job, ledger);

    if (result.tag === "done") {
      solutions.push({ v: result.value, w: 1 / (1 + job.cost) });
      stats.solutionsFound++;
      budget.solutionsLeft--;
    } else if (result.tag === "choice") {
      // BFS: append children to queue
      for (const child of result.children) {
        queue.push(child);
      }
    } else if (result.tag === "fail") {
      stats.backtracks++;
    }
  }

  return distFrom(solutions, { kind: "bfs-search" });
}

// ─────────────────────────────────────────────────────────────────
// C3) Beam Search (priority queue with bounded width)
// ─────────────────────────────────────────────────────────────────

async function runBeam(
  runtime: Runtime,
  initial: State,
  budget: SearchBudget,
  ledger: SearchLedger,
  stats: SearchStats,
  solutions: DistItem[],
  config: SearchConfig,
  rng: () => number
): Promise<DistVal> {
  const beamWidth = config.beamWidth ?? 3;
  const scoreFn = config.scoreFn ?? (() => 0);

  let frontier: SearchJob[] = [{
    id: makeJobId(),
    state: initial,
    depth: 0,
    cost: 0,
    score: 0,
  }];

  while (frontier.length > 0 && budget.searchNodesLeft > 0 && budget.solutionsLeft > 0) {
    const nextFrontier: SearchJob[] = [];

    for (const job of frontier) {
      if (budget.searchNodesLeft <= 0 || budget.solutionsLeft <= 0) break;

      // Consume budget for each job processed (node expansion)
      budget.searchNodesLeft--;
      stats.nodesExpanded++;

      stats.maxDepthReached = Math.max(stats.maxDepthReached, job.depth);

      if (job.depth > budget.searchDepthLeft) {
        stats.backtracks++;
        continue;
      }

      const result = await runJobToChoiceNoBudget(runtime, job, ledger);

      if (result.tag === "done") {
        const score = scoreFn(result.value);
        solutions.push({ v: result.value, w: Math.exp(score) });
        stats.solutionsFound++;
        budget.solutionsLeft--;
      } else if (result.tag === "choice") {
        // Score children and add to next frontier
        for (const child of result.children) {
          child.score = child.cost; // Can be improved with heuristic
          nextFrontier.push(child);
        }
      } else if (result.tag === "fail") {
        stats.backtracks++;
      }
    }

    // Beam: keep only top-k by score (lower cost = better)
    nextFrontier.sort((a, b) => (a.score ?? 0) - (b.score ?? 0));
    frontier = nextFrontier.slice(0, beamWidth);

    // Record pruned jobs
    if (nextFrontier.length > beamWidth) {
      stats.backtracks += nextFrontier.length - beamWidth;
    }
  }

  return distFrom(solutions, { kind: "beam-search" });
}

// ─────────────────────────────────────────────────────────────────
// C4) MCTS - Monte Carlo Tree Search (simplified: UCB1 selection on priority queue)
// ─────────────────────────────────────────────────────────────────

async function runMCTS(
  runtime: Runtime,
  initial: State,
  budget: SearchBudget,
  ledger: SearchLedger,
  stats: SearchStats,
  solutions: DistItem[],
  config: SearchConfig,
  rng: () => number
): Promise<DistVal> {
  const exploration = config.mctsExploration ?? Math.sqrt(2);
  const scoreFn = config.scoreFn ?? (() => 0);

  // Track visit counts for UCB1 selection
  const visitCounts = new Map<string, number>();
  const totalRewards = new Map<string, number>();
  let totalVisits = 0;

  // Priority queue with UCB1-based selection
  const frontier: SearchJob[] = [{
    id: makeJobId(),
    state: initial,
    depth: 0,
    cost: 0,
  }];

  while (frontier.length > 0 && budget.searchNodesLeft > 0 && budget.solutionsLeft > 0) {
    // Select job using UCB1 (or random if no visits)
    totalVisits++;
    let selectedIdx = 0;

    if (totalVisits > frontier.length) {
      // UCB1 selection
      let bestUCB = -Infinity;
      for (let i = 0; i < frontier.length; i++) {
        const job = frontier[i];
        const visits = visitCounts.get(job.id) ?? 1;
        const reward = totalRewards.get(job.id) ?? 0;
        const exploit = reward / visits;
        const explore = exploration * Math.sqrt(Math.log(totalVisits) / visits);
        const ucb = exploit + explore;

        if (ucb > bestUCB) {
          bestUCB = ucb;
          selectedIdx = i;
        }
      }
    } else {
      // Random selection during initial exploration
      selectedIdx = Math.floor(rng() * frontier.length);
    }

    const job = frontier.splice(selectedIdx, 1)[0];

    // Consume budget
    budget.searchNodesLeft--;
    stats.nodesExpanded++;

    stats.maxDepthReached = Math.max(stats.maxDepthReached, job.depth);

    if (job.depth > budget.searchDepthLeft) {
      stats.backtracks++;
      continue;
    }

    const result = await runJobToChoiceNoBudget(runtime, job, ledger);

    if (result.tag === "done") {
      const score = scoreFn(result.value);
      solutions.push({ v: result.value, w: Math.exp(score) });
      stats.solutionsFound++;
      budget.solutionsLeft--;

      // Update visit counts and rewards for backpropagation
      const visits = visitCounts.get(job.id) ?? 0;
      visitCounts.set(job.id, visits + 1);
      const reward = totalRewards.get(job.id) ?? 0;
      totalRewards.set(job.id, reward + score);
    } else if (result.tag === "choice") {
      // Add children to frontier
      for (const child of result.children) {
        frontier.push(child);
        // Initialize visit counts
        visitCounts.set(child.id, 1);
        totalRewards.set(child.id, 0);
      }
    } else if (result.tag === "fail") {
      stats.backtracks++;
      // Negative reward for failed branches
      const visits = visitCounts.get(job.id) ?? 0;
      visitCounts.set(job.id, visits + 1);
      const reward = totalRewards.get(job.id) ?? 0;
      totalRewards.set(job.id, reward - 1);
    }
  }

  return distFrom(solutions, { kind: "mcts-search" });
}

// ─────────────────────────────────────────────────────────────────
// Core: run a job until it hits a choice point, terminal, or error
// ─────────────────────────────────────────────────────────────────

type JobResult =
  | { tag: "done"; value: Val }
  | { tag: "choice"; choices: WeightedChoice[]; children: SearchJob[]; ambTag?: string }
  | { tag: "fail"; reason: string };

const MAX_STEPS_PER_JOB = 10000;

/**
 * Run a job until it hits a choice point, terminal, or error.
 * Does not consume budget internally - budget tracking happens in the main loop.
 */
async function runJobToChoiceNoBudget(
  runtime: Runtime,
  job: SearchJob,
  ledger: SearchLedger
): Promise<JobResult> {
  let st = job.state;
  let steps = 0;

  while (steps < MAX_STEPS_PER_JOB) {
    steps++;

    try {
      const out = stepOnce(st);

      if (out.tag === "State") {
        st = out.state;
        continue;
      }

      if (out.tag === "Done") {
        return { tag: "done", value: out.value };
      }

      if (out.tag === "Op") {
        const op = out.opcall.op;

        // Handle amb.choose effect
        if (op === "amb.choose" || op === "amb.op") {
          // Parse choices
          const payload = parseAmbArgs(out.opcall.args);
          const choices = payload.choices;

          if (choices.length === 0) {
            return { tag: "fail", reason: "amb with no choices" };
          }

          // Record decision for replay
          const decision: SearchDecision = {
            tag: payload.tag,
            choiceDigests: choices.map(c => valDigest(c.v)),
            selectedIndex: -1, // Will be set by strategy
            timestamp: Date.now(),
          };
          ledger.decisions.push(decision);

          // Create child jobs for each choice
          const children: SearchJob[] = choices.map((choice, idx) => {
            const cv = choice.v;
            let childState: State;

            if (cv.tag === "Closure") {
              if (cv.params.length !== 0) {
                throw new Error("amb.choose: thunk closure must take no arguments");
              }
              // Resume continuation, then evaluate thunk body in its lexical env
              const baseState = out.opcall.resumption.invoke(VUnit);
              childState = { ...baseState, control: { tag: "Expr", e: cv.body }, env: cv.env };
            } else {
              childState = out.opcall.resumption.invoke(cv);
            }
            return {
              id: makeJobId(),
              state: childState,
              depth: job.depth + 1,
              cost: job.cost + (1 - choice.w), // Higher weight = lower cost
              parentId: job.id,
              choiceIndex: idx,
            };
          });

          return { tag: "choice", choices, children, ambTag: payload.tag };
        }

        // Handle amb.fail effect
        if (op === "amb.fail") {
          return { tag: "fail", reason: "explicit fail" };
        }

        // Dispatch other effects to runtime
        const handled = await runtime.dispatch(out.state, out.opcall);
        if (handled === "Uncaught") {
          return { tag: "fail", reason: `Uncaught op: ${op}` };
        }
        st = handled;
        continue;
      }
    } catch (e) {
      if (e instanceof SearchBudgetExceeded) {
        throw e;
      }
      return { tag: "fail", reason: String(e) };
    }
  }

  return { tag: "fail", reason: "max steps exceeded" };
}

// ─────────────────────────────────────────────────────────────────
// A5) Deterministic replay
// ─────────────────────────────────────────────────────────────────

/**
 * Replay a search from a recorded ledger.
 * Uses the same decisions to produce identical results.
 */
export async function replaySearch(
  runtime: Runtime,
  initial: State,
  ledger: SearchLedger
): Promise<SearchResult> {
  const startTime = Date.now();
  const budget = { ...DEFAULT_SEARCH_BUDGET };
  const stats: SearchStats = {
    nodesExpanded: 0,
    maxDepthReached: 0,
    solutionsFound: 0,
    backtracks: 0,
    elapsedMs: 0,
  };

  const solutions: DistItem[] = [];
  let decisionIdx = 0;

  // Simple replay: follow the recorded decisions
  let st = initial;
  let steps = 0;

  while (steps < MAX_STEPS_PER_JOB * 100) {
    steps++;

    try {
      const out = stepOnce(st);

      if (out.tag === "State") {
        st = out.state;
        continue;
      }

      if (out.tag === "Done") {
        solutions.push({ v: out.value, w: 1 });
        stats.solutionsFound++;
        break;
      }

      if (out.tag === "Op") {
        const op = out.opcall.op;

        if (op === "amb.choose" || op === "amb.op") {
          if (decisionIdx >= ledger.decisions.length) {
            throw new Error("Replay exhausted: no more recorded decisions");
          }

          const decision = ledger.decisions[decisionIdx++];
          const payload = parseAmbArgs(out.opcall.args);

          if (decision.selectedIndex < 0 || decision.selectedIndex >= payload.choices.length) {
            throw new Error(`Replay error: invalid choice index ${decision.selectedIndex}`);
          }

          const choice = payload.choices[decision.selectedIndex];
          st = out.opcall.resumption.invoke(choice.v);
          stats.nodesExpanded++;
          continue;
        }

        if (op === "amb.fail") {
          stats.backtracks++;
          break;
        }

        const handled = await runtime.dispatch(out.state, out.opcall);
        if (handled === "Uncaught") {
          throw new Error(`Uncaught op during replay: ${op}`);
        }
        st = handled;
        continue;
      }
    } catch (e) {
      throw new Error(`Replay failed: ${e}`);
    }
  }

  stats.elapsedMs = Date.now() - startTime;

  return {
    dist: distFrom(solutions, { kind: "replay" }),
    ledger,
    stats,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/effects/search/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/effects/search/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 11: Search types for amb.choose and nondeterministic evaluation

import type { Val } from "../../eval/values";
import type { State } from "../../eval/machine";
import type { Resumption } from "../opcall";
import type { DistVal, DistItem } from "../../eval/dist";
import type { Hash } from "../../artifacts/hash";

// ─────────────────────────────────────────────────────────────────
// A2) amb.choose payload
// ─────────────────────────────────────────────────────────────────

/**
 * Weighted choice for amb.choose.
 * Weight defaults to 1 if not specified.
 */
export type WeightedChoice = {
  v: Val;
  w: number;
};

/**
 * AmbPayload: payload for the amb.choose effect.
 */
export type AmbPayload = {
  /** Choices with optional weights (default weight 1) */
  choices: WeightedChoice[];
  /** Callsite label for replay determinism */
  tag?: string;
  /** Optional metadata for scoring/heuristics */
  meta?: {
    heuristic?: (v: Val) => number;
    costEstimate?: number;
  };
};

/**
 * Convert cons-cell list to flat array.
 * A cons-cell is a 2-element Vector where items[1] is another cons or Unit.
 */
function consToArray(v: Val): Val[] {
  const result: Val[] = [];
  let cur: Val = v;
  while (cur.tag === "Vector" && cur.items.length === 2) {
    result.push(cur.items[0]);
    cur = cur.items[1];
  }
  // If terminated by Unit, it's a proper list
  // If not, the last element is the improper tail (ignore for now)
  return result;
}

/**
 * Check if value is a cons-cell list (Vector with 2 items where items[1] is cons or Unit)
 */
function isConsList(v: Val): boolean {
  if (v.tag !== "Vector") return false;
  if (v.items.length !== 2) return false;
  // Check if it terminates in Unit (proper list) or is a chain
  let cur: Val = v;
  while (cur.tag === "Vector" && cur.items.length === 2) {
    cur = cur.items[1];
  }
  return cur.tag === "Unit";
}

/**
 * Parse amb arguments into AmbPayload.
 * Supports both weighted and unweighted choices.
 * Handles both flat Vectors and cons-cell lists.
 */
export function parseAmbArgs(args: Val[]): AmbPayload {
  const choices: WeightedChoice[] = [];
  let tag: string | undefined;

  for (const arg of args) {
    if (arg.tag === "Vector") {
      // Check if it's a cons-cell list (from datumToVal of arrays)
      if (isConsList(arg)) {
        const items = consToArray(arg);
        for (const item of items) {
          if (item.tag === "Pair" && item.car.tag === "Num") {
            // Weighted: (weight . value)
            choices.push({ v: item.cdr, w: item.car.n });
          } else {
            choices.push({ v: item, w: 1 });
          }
        }
      } else {
        // Flat vector of choices
        for (const item of arg.items) {
          if (item.tag === "Pair" && item.car.tag === "Num") {
            // Weighted: (weight . value)
            choices.push({ v: item.cdr, w: item.car.n });
          } else {
            choices.push({ v: item, w: 1 });
          }
        }
      }
    } else if (arg.tag === "Map") {
      // Map with special keys
      for (const [k, v] of arg.entries) {
        if (k.tag === "Sym" && k.name === "tag" && v.tag === "Str") {
          tag = v.s;
        } else if (k.tag === "Sym" && k.name === "choices" && v.tag === "Vector") {
          const items = isConsList(v) ? consToArray(v) : v.items;
          for (const item of items) {
            choices.push({ v: item, w: 1 });
          }
        }
      }
    } else {
      // Single choice
      choices.push({ v: arg, w: 1 });
    }
  }

  return { choices, tag };
}

// ─────────────────────────────────────────────────────────────────
// A6) Search budget extensions
// ─────────────────────────────────────────────────────────────────

/**
 * SearchBudget: runtime limits specific to search.
 */
export type SearchBudget = {
  /** Maximum branch expansions */
  searchNodesLeft: number;
  /** Maximum search depth */
  searchDepthLeft: number;
  /** Maximum solutions to collect */
  solutionsLeft: number;
  /** Maximum active frontier size (for beam) */
  maxFrontierSize: number;
};

/**
 * Default search budget.
 */
export const DEFAULT_SEARCH_BUDGET: SearchBudget = {
  searchNodesLeft: 1000,
  searchDepthLeft: 100,
  solutionsLeft: 100,
  maxFrontierSize: 1000,
};

/**
 * BudgetExceeded error for search.
 */
export class SearchBudgetExceeded extends Error {
  constructor(
    public readonly kind: keyof SearchBudget,
    public readonly limit: number
  ) {
    super(`SearchBudgetExceeded: ${kind} limit (${limit}) exceeded`);
    this.name = "SearchBudgetExceeded";
  }
}

// ─────────────────────────────────────────────────────────────────
// Search strategies
// ─────────────────────────────────────────────────────────────────

/**
 * Search strategy type.
 */
export type SearchStrategy = "dfs" | "bfs" | "beam" | "mcts";

/**
 * SearchConfig: configuration for with-search.
 */
export type SearchConfig = {
  strategy: SearchStrategy;
  budget: Partial<SearchBudget>;
  /** Seed for deterministic replay */
  seed?: number;
  /** Beam width (for beam strategy) */
  beamWidth?: number;
  /** MCTS exploration constant */
  mctsExploration?: number;
  /** MCTS rollout depth */
  mctsRolloutDepth?: number;
  /** Score function for beam/mcts */
  scoreFn?: (val: Val) => number;
};

// ─────────────────────────────────────────────────────────────────
// Search job and frontier
// ─────────────────────────────────────────────────────────────────

/**
 * SearchJob: a branch in the search tree.
 */
export type SearchJob = {
  /** Unique job ID */
  id: string;
  /** Machine state for this branch */
  state: State;
  /** Depth in search tree */
  depth: number;
  /** Accumulated cost/weight */
  cost: number;
  /** Parent job ID (for tree reconstruction) */
  parentId?: string;
  /** Choice index that led here */
  choiceIndex?: number;
  /** Heuristic score (for beam/mcts) */
  score?: number;
};

/**
 * SearchDecision: recorded decision for replay.
 */
export type SearchDecision = {
  /** Callsite tag */
  tag?: string;
  /** Choice digests (for privacy) */
  choiceDigests: string[];
  /** Selected index */
  selectedIndex: number;
  /** Timestamp */
  timestamp: number;
};

/**
 * SearchLedger: records all decisions for replay.
 */
export type SearchLedger = {
  decisions: SearchDecision[];
  seed: number;
  strategy: SearchStrategy;
};

// ─────────────────────────────────────────────────────────────────
// Search result
// ─────────────────────────────────────────────────────────────────

/**
 * SearchResult: the output of with-search.
 */
export type SearchResult = {
  /** Distribution of solutions (DistVal) */
  dist: DistVal;
  /** Ledger for replay */
  ledger: SearchLedger;
  /** Statistics */
  stats: SearchStats;
};

/**
 * SearchStats: statistics about the search.
 */
export type SearchStats = {
  /** Total nodes expanded */
  nodesExpanded: number;
  /** Maximum depth reached */
  maxDepthReached: number;
  /** Solutions found */
  solutionsFound: number;
  /** Backtracks (failed branches) */
  backtracks: number;
  /** Time elapsed (ms) */
  elapsedMs: number;
};

// ─────────────────────────────────────────────────────────────────
// MCTS node (for MCTS strategy)
// ─────────────────────────────────────────────────────────────────

/**
 * MCTSNode: node in the MCTS tree.
 */
export type MCTSNode = {
  /** Node ID */
  id: string;
  /** Parent node ID */
  parentId?: string;
  /** State at this node */
  state: State;
  /** Visit count */
  visits: number;
  /** Total reward from this node */
  totalReward: number;
  /** Children keyed by choice index */
  children: Map<number, MCTSNode>;
  /** Is this a terminal node? */
  terminal: boolean;
  /** Terminal value (if terminal) */
  terminalValue?: Val;
  /** Unexplored actions */
  unexploredActions: number[];
};

/**
 * Create a new MCTS node.
 */
export function createMCTSNode(
  id: string,
  state: State,
  parentId?: string
): MCTSNode {
  return {
    id,
    parentId,
    state,
    visits: 0,
    totalReward: 0,
    children: new Map(),
    terminal: false,
    unexploredActions: [],
  };
}

/**
 * UCB1 selection formula.
 */
export function ucb1(
  node: MCTSNode,
  parentVisits: number,
  exploration: number = Math.sqrt(2)
): number {
  if (node.visits === 0) return Infinity;
  const exploitation = node.totalReward / node.visits;
  const exploration_term = exploration * Math.sqrt(Math.log(parentVisits) / node.visits);
  return exploitation + exploration_term;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/dist.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/eval/dist.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set A1: Dist<Val> as first-class value

import type { Val } from "./values";

/**
 * A minimal discrete distribution (finite support).
 * This is intentionally "first-order" (no sampling effects); policies/handlers decide how to use it.
 */
export type DistItem<T = Val> = { v: T; w: number };

export type DistVal = {
  tag: "Dist";
  support: DistItem[];     // NOT necessarily normalized
  normalized?: boolean;
  meta?: { kind?: string; note?: string };
};

export function dist(v: Val): DistVal {
  return { tag: "Dist", support: [{ v, w: 1 }], normalized: true };
}

export function distFail(note: string): DistVal {
  return { tag: "Dist", support: [], normalized: true, meta: { kind: "fail", note } };
}

export function distFrom(items: DistItem[], meta?: DistVal["meta"]): DistVal {
  return { tag: "Dist", support: items.slice(), normalized: false, meta };
}

export function distNormalize(d: DistVal): DistVal {
  const sum = d.support.reduce((a, it) => a + it.w, 0);
  if (sum <= 0) return { ...d, normalized: true, support: [] };
  return {
    ...d,
    normalized: true,
    support: d.support.map(it => ({ v: it.v, w: it.w / sum })),
  };
}

export function distMap(d: DistVal, f: (v: Val) => Val): DistVal {
  return { ...d, support: d.support.map(it => ({ v: f(it.v), w: it.w })), normalized: d.normalized };
}

export function distBind(d: DistVal, f: (v: Val) => DistVal): DistVal {
  const out: DistItem[] = [];
  for (const it of d.support) {
    const d2 = f(it.v);
    for (const it2 of d2.support) {
      out.push({ v: it2.v, w: it.w * it2.w });
    }
  }
  return distFrom(out, { kind: "bind" });
}

/** Deterministic PRNG for reproducible sampling. */
function mulberry32(seed: number): () => number {
  let t = seed >>> 0;
  return () => {
    t += 0x6D2B79F5;
    let x = t;
    x = Math.imul(x ^ (x >>> 15), x | 1);
    x ^= x + Math.imul(x ^ (x >>> 7), x | 61);
    return ((x ^ (x >>> 14)) >>> 0) / 4294967296;
  };
}

export function distSample(d0: DistVal, seed: number): Val {
  const d = d0.normalized ? d0 : distNormalize(d0);
  const r = mulberry32(seed)();
  let acc = 0;
  for (const it of d.support) {
    acc += it.w;
    if (r <= acc) return it.v;
  }
  // fallback to last if rounding
  if (d.support.length === 0) throw new Error("distSample: empty support");
  return d.support[d.support.length - 1].v;
}

export function distTopK(d0: DistVal, k: number): DistVal {
  const d = d0.normalized ? d0 : distNormalize(d0);
  const support = d.support.slice().sort((a, b) => b.w - a.w).slice(0, Math.max(0, k));
  return { ...d, support };
}

export function isDist(v: Val): v is DistVal {
  return typeof v === "object" && v !== null && (v as any).tag === "Dist";
}

// ─────────────────────────────────────────────────────────────────
// Prompt 11: Extended Dist algebra for search
// ─────────────────────────────────────────────────────────────────

/**
 * Filter distribution by predicate.
 * Keeps only items where predicate returns true.
 */
export function distFilter(d: DistVal, p: (v: Val) => boolean): DistVal {
  const filtered = d.support.filter(it => p(it.v));
  return { ...d, support: filtered, normalized: false, meta: { kind: "filter" } };
}

/**
 * Take first n items from distribution (by weight order).
 */
export function distTake(d: DistVal, n: number): DistVal {
  const sorted = d.support.slice().sort((a, b) => b.w - a.w);
  const taken = sorted.slice(0, Math.max(0, n));
  return { ...d, support: taken, normalized: false, meta: { kind: "take" } };
}

/**
 * Get best item from distribution (highest weight).
 */
export function distBest(d: DistVal): Val | undefined {
  if (d.support.length === 0) return undefined;
  let best = d.support[0];
  for (const it of d.support) {
    if (it.w > best.w) best = it;
  }
  return best.v;
}

/**
 * Get best k items from distribution with custom score function.
 */
export function distBestK(d: DistVal, k: number, scoreFn?: (v: Val) => number): DistVal {
  const score = scoreFn ?? ((v: Val) => {
    const it = d.support.find(i => i.v === v);
    return it?.w ?? 0;
  });

  const scored = d.support.map(it => ({ ...it, score: score(it.v) }));
  scored.sort((a, b) => b.score - a.score);

  const support = scored.slice(0, Math.max(0, k)).map(({ v, w }) => ({ v, w }));
  return { ...d, support, normalized: false, meta: { kind: "bestK" } };
}

/**
 * Concatenate two distributions.
 */
export function distConcat(d1: DistVal, d2: DistVal): DistVal {
  return {
    tag: "Dist",
    support: [...d1.support, ...d2.support],
    normalized: false,
    meta: { kind: "concat" },
  };
}

/**
 * Check if distribution is empty.
 */
export function distIsEmpty(d: DistVal): boolean {
  return d.support.length === 0;
}

/**
 * Get the size of the distribution support.
 */
export function distSize(d: DistVal): number {
  return d.support.length;
}

/**
 * Get all values from distribution (ignoring weights).
 */
export function distValues(d: DistVal): Val[] {
  return d.support.map(it => it.v);
}

/**
 * Create uniform distribution from array of values.
 */
export function distUniform(values: Val[]): DistVal {
  const w = values.length > 0 ? 1 / values.length : 0;
  return {
    tag: "Dist",
    support: values.map(v => ({ v, w })),
    normalized: true,
    meta: { kind: "uniform" },
  };
}

/**
 * Create weighted distribution from value-weight pairs.
 */
export function distWeighted(pairs: Array<[Val, number]>): DistVal {
  return {
    tag: "Dist",
    support: pairs.map(([v, w]) => ({ v, w })),
    normalized: false,
    meta: { kind: "weighted" },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/env.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/eval/env.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-17.md
// Env is Ctx.

import type { StoreAddr } from "./store";
import type { Ctx } from "../ctx/ctx";
import { ctxLookup, ctxDefine, ctxExtend, ctxRootFromProfile } from "../ctx/ctx";
import { DEFAULT_PROFILE } from "../governance/profile";

/**
 * Env *is* Ctx in runtime, but we allow any here for compatibility with tests and stubs.
 */
export type Env = any;

export function envEmpty(): Env {
  return ctxRootFromProfile(DEFAULT_PROFILE);
}

export function envSet(env: Env, name: string, addr: StoreAddr): Env {
  return ctxDefine(env, name, addr);
}

export function envGet(env: Env, name: string): StoreAddr | undefined {
  return ctxLookup(env, name);
}

export function envExtend(env: Env, binds: Array<[string, StoreAddr]>): Env {
  return ctxExtend(env, binds);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/machine.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.
// Prompt 9: Add runtime governance (profile, budget, security)

import type { Expr, HandlerExpr, Pattern } from "../ast";
import type { Env } from "./env";
import type { Store } from "./store";
import type { Val } from "./values";
import type { OpCall } from "../effects/opcall";
import type { Profile, RuntimeBudget, RuntimeSecurity } from "../governance/profile";
import type { ConditionHandler, RestartBinding, ConditionVal } from "../conditions/types";
import type { ProvenanceGraph, SourceChecker } from "../provenance/graph";
import type { ProvenanceStore } from "../provenance/store/interface";

export type Control =
  | { tag: "Expr"; e: Expr }
  | { tag: "Val"; v: Val };

export type Frame =
  | { tag: "KIf"; conseq: Expr; alt: Expr; env: Env }
  | { tag: "KBegin"; rest: Expr[]; env: Env }
  | { tag: "KDefine"; name: string; env: Env }
  | { tag: "KSet"; name: string; env: Env }
  | { tag: "KAppFun"; args: Expr[]; env: Env }
  | { tag: "KAppArg"; fnVal: Val; pending: Expr[]; acc: Val[]; env: Env }
  | { tag: "KAppArgLazy"; fnVal: Val; pending: Array<{ expr: Expr; idx: number }>; acc: Array<{ idx: number; val: Val }>; env: Env; totalArgs: number; currentIdx: number }
  | { tag: "KCall"; savedEnv: Env }                                  // restore env after closure body
  | { tag: "KEffect"; op: string; pending: Expr[]; acc: Val[]; env: Env }
  | { tag: "KHandleBoundary"; hid: string; savedHandlersDepth: number; resumeTo?: { kont: Frame[]; handlersDepth: number } }
  | { tag: "KHandleReturn"; mode: "exit" | "resume"; hid: string; targetKont: Frame[]; targetHandlersDepth: number; savedHandlersDepth: number }
  | { tag: "KPrompt"; promptTag: Val; handler: Val; env: Env; savedKont: Frame[]; savedHandlersDepth: number }
  | { tag: "KMatch"; clauses: Array<{ pat: Pattern; body: Expr }>; env: Env }
  | { tag: "KOracleLambda"; params: string[]; env: Env }  // oracle-lambda: waiting for spec to evaluate
  | { tag: "KBind"; fn: Val; env: Env }
  | { tag: "KHandlerBind"; handlers: ConditionHandler[] }
  | { tag: "KRestartBind"; restarts: RestartBinding[]; savedKont: Frame[]; env: Env; store: Store; handlers: HandlerFrame[] }
  | { tag: "KSignaling"; condition: ConditionVal; required: boolean };

export type HandlerFrame = {
  hid: string;
  env: Env;
  on: Map<string, { op: string; params: string[]; k: string; body: Expr }>;
  ret?: { v: string; body: Expr };
  fin?: { body: Expr };
};

export type State = {
  control: Control;
  /** Legacy alias used in a few tests */
  ctrl?: Control;
  env: Env;
  store: Store;
  kont: Frame[];           // bottom->top, push/pop at end
  handlers: HandlerFrame[]; // bottom->top, push/pop at end

  // ─────────────────────────────────────────────────────────────────
  // Prompt 9: Runtime Governance
  // ─────────────────────────────────────────────────────────────────

  /** Active profile - determines what effects/ops/requests are allowed */
  profile?: Profile;

  /** Mutable budget counters - decremented on each operation */
  budget?: RuntimeBudget;

  /** Current security context - intersection of profile caps and context caps */
  sec?: RuntimeSecurity;

  // Provenance graph + receipt store (optional)
  provenanceGraph?: ProvenanceGraph;
  provenanceStore?: ProvenanceStore;
  provenanceSourceChecker?: SourceChecker;
};

export type StepOutcome =
  | { tag: "State"; state: State; value?: undefined; opcall?: undefined }
  | { tag: "Done"; value: Val; state: State; opcall?: undefined }
  | { tag: "Op"; opcall: OpCall; state: State; value?: Val };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/machineStep.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.
// Prompt 9: Integrated governance enforcement at chokepoints

import type { Expr, HandlerExpr, Pattern } from "../ast";
import type { State, StepOutcome, Frame, HandlerFrame } from "./machine";
import type { Env } from "./env";
import { envGet, envSet } from "./env";
import type { Val } from "./values";
import { VUnit, VFalse, VTrue } from "./values";
import { captureValueResumption } from "../effects/capture";
import {
  checkEffectAllowed,
  debitEffect,
  checkStepBudget,
  debitStep,
} from "../governance/enforcement";
import { UnhandledConditionError } from "../conditions/prims";

// Compatibility export for tests that expected StepResult alias
export type StepResult = StepOutcome;

function uuid(): string {
  return Math.random().toString(16).slice(2) + "-" + Date.now().toString(16);
}

function ctxDigest(env: Env): string {
  // Ctx has a content-addressed cid - use it directly
  return env.cid;
}

function push(kont: Frame[], fr: Frame): Frame[] {
  const k2 = kont.slice();
  k2.push(fr);
  return k2;
}

function pop(kont: Frame[]): [Frame | undefined, Frame[]] {
  if (kont.length === 0) return [undefined, kont];
  const k2 = kont.slice();
  const fr = k2.pop();
  return [fr, k2];
}

function isBool(v: Val): v is { tag: "Bool"; b: boolean } {
  return v.tag === "Bool";
}

function findHandlerIndexByHid(handlers: HandlerFrame[], hid: string): number {
  for (let i = handlers.length - 1; i >= 0; i--) {
    if (handlers[i].hid === hid) return i;
  }
  return -1;
}

/** Convert quoted datum to runtime value (minimal). Extend as needed.
 * Arrays are converted to proper cons-cell lists (Vector with 2 items each)
 * for compatibility with the list primitives (car, cdr, length, etc.)
 */
function datumToVal(d: unknown): Val {
  if (d === null) return { tag: "Unit" };
  if (typeof d === "number") return { tag: "Num", n: d };
  if (typeof d === "string") return { tag: "Str", s: d };
  if (typeof d === "boolean") return { tag: "Bool", b: d };
  if (Array.isArray(d)) {
    // Build proper cons-cell list: (a b c) -> [a, [b, [c, Unit]]]
    let result: Val = { tag: "Unit" };
    for (let i = d.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [datumToVal(d[i]), result] };
    }
    return result;
  }
  // symbols in datum: represent as {tag:"Sym"} if encoded as {sym:"x"}
  if (typeof d === "object" && d !== null && "sym" in d) {
    return { tag: "Sym", name: (d as { sym: string }).sym };
  }
  return { tag: "Str", s: JSON.stringify(d) };
}

function buildHandlerFrame(handler: HandlerExpr, env: Env): HandlerFrame {
  const hid = uuid();
  const on = new Map<string, { op: string; params: string[]; k: string; body: Expr }>();
  for (const c of handler.on) on.set(c.op, c);
  return { hid, env, on, ret: handler.ret, fin: handler.fin };
}

/** Pattern matching helper for Match expressions */
function matchPatternValue(p: Pattern, v: Val, env = new Map<string, Val>()): Map<string, Val> | null {
  switch (p.tag) {
    case "PWild":
      return env;

    case "PVar": {
      const prev = env.get(p.name);
      if (!prev) {
        const e2 = new Map(env);
        e2.set(p.name, v);
        return e2;
      }
      // Same var bound twice: check equality
      return valEq(prev, v) ? env : null;
    }

    case "PLit": {
      if (p.value === null) return v.tag === "Unit" ? env : null;
      if (typeof p.value === "number") return v.tag === "Num" && v.n === p.value ? env : null;
      if (typeof p.value === "boolean") return v.tag === "Bool" && v.b === p.value ? env : null;
      if (typeof p.value === "string") {
        // String pattern can match either Str or Sym
        if (v.tag === "Str" && v.s === p.value) return env;
        if (v.tag === "Sym" && v.name === p.value) return env;
        return null;
      }
      return null;
    }

    case "PVector": {
      if (v.tag !== "Vector") return null;

      // Direct vector match (flat vectors)
      if (v.items.length === p.items.length) {
        let ecur: Map<string, Val> | null = env;
        for (let i = 0; i < p.items.length; i++) {
          ecur = matchPatternValue(p.items[i], v.items[i], ecur!);
          if (!ecur) return null;
        }
        return ecur;
      }

      // Try cons-cell list match: Vector[a, Vector[b, Vector[c, Unit]]] matches pattern (a b c)
      // A cons-cell is a 2-element vector where items[1] is another cons or Unit
      if (p.items.length > 0 && v.items.length === 2) {
        // Convert cons-cell list to flat array for matching
        const flatList: Val[] = [];
        let cur: Val = v;
        while (cur.tag === "Vector" && cur.items.length === 2) {
          flatList.push(cur.items[0]);
          cur = cur.items[1];
        }
        // Check if terminated by Unit (proper list)
        if (cur.tag !== "Unit") return null;

        // Now match pattern items against flat list
        if (flatList.length !== p.items.length) return null;
        let ecur: Map<string, Val> | null = env;
        for (let i = 0; i < p.items.length; i++) {
          ecur = matchPatternValue(p.items[i], flatList[i], ecur!);
          if (!ecur) return null;
        }
        return ecur;
      }

      return null;
    }
  }
}

function valEq(a: Val, b: Val): boolean {
  if (a.tag !== b.tag) return false;
  switch (a.tag) {
    case "Unit": return true;
    case "Num": return (b as any).n === a.n;
    case "Bool": return (b as any).b === a.b;
    case "Str": return (b as any).s === a.s;
    case "Sym": return (b as any).name === a.name;
    case "Vector": {
      const bb = b as any;
      if (bb.items.length !== a.items.length) return false;
      for (let i = 0; i < a.items.length; i++) if (!valEq(a.items[i], bb.items[i])) return false;
      return true;
    }
    default:
      return JSON.stringify(a) === JSON.stringify(b);
  }
}

/**
 * Apply a value as a function (closure/native/cont/oracle-proc).
 * Returns StepOutcome: either a state transition or an effect operation.
 */
function applyVal(fnVal: Val, args: Val[], st: State): StepOutcome {
  // Cont: delimited resumption call
  if (fnVal.tag === "Cont") {
    if (args.length !== 1) throw new Error(`Cont apply arity mismatch: got ${args.length}`);
    const callerKont = st.kont;               // continuation expecting result of the (k arg) call
    const callerHandlersDepth = st.handlers.length;

    const baseResumed = fnVal.resumption.invoke(args[0]); // resumes at op site with effect result = args[0]

    // Patch the handle boundary in resumed kont to "resume mode" returning to callerKont.
    const k = baseResumed.kont.slice();
    const idx = fnVal.boundaryIndex;
    const fr = k[idx];
    if (!fr || fr.tag !== "KHandleBoundary" || fr.hid !== fnVal.hid) {
      throw new Error("Cont invoke: boundary frame mismatch");
    }

    k[idx] = {
      ...fr,
      resumeTo: { kont: callerKont, handlersDepth: callerHandlersDepth },
    };

    return {
      tag: "State",
      state: {
        ...baseResumed,
        kont: k,
        // handlers remain as captured at op site; boundary frame will truncate on resume-return
      },
    };
  }

  // First-class continuation (call/cc, prompts)
  if (fnVal.tag === "Continuation") {
    if (args.length !== 1) {
      throw new Error(`Continuation apply arity mismatch: expected 1, got ${args.length}`);
    }
    return {
      tag: "State",
      state: {
        ...st,
        control: { tag: "Val", v: args[0] },
        env: fnVal.env,
        // Use the current store to preserve mutations performed before invoking the continuation.
        store: st.store,
        kont: fnVal.kont.slice(),
        handlers: fnVal.handlers.slice(),
      },
    };
  }

  // Native function: host-implemented (primitives, etc.)
  if (fnVal.tag === "Native") {
    const result = fnVal.fn(args, st);
    if ((result as any).tag === "State" || (result as any).tag === "Op" || (result as any).tag === "Done") {
      return result as StepOutcome;
    }
    return { tag: "State", state: result as State };
  }

  // Closure
  if (fnVal.tag === "Closure") {
    if (args.length !== fnVal.params.length) {
      throw new Error(`Closure apply arity mismatch: expected ${fnVal.params.length}, got ${args.length}`);
    }
    // allocate params in store
    let store = st.store;
    let env = fnVal.env;
    for (let i = 0; i < fnVal.params.length; i++) {
      const [store2, addr] = store.alloc(args[i]);
      store = store2;
      env = envSet(env, fnVal.params[i], addr);
    }
    // push call-return frame to restore env after body
    const kont = push(st.kont, { tag: "KCall", savedEnv: st.env });
    return {
      tag: "State",
      state: {
        ...st,
        control: { tag: "Expr", e: fnVal.body },
        env,
        store,
        kont,
      },
    };
  }

  // OracleProc: LLM in apply position - emit oracle.apply.op
  if (fnVal.tag === "OracleProc") {
    const suspended: State = { ...st, control: { tag: "Val", v: VUnit } };
    const resumption = captureValueResumption(suspended);
    const opcall = {
      op: "oracle.apply.op",
      args: [fnVal, { tag: "Vector", items: args } as Val],
      ctxDigest: ctxDigest(st.env),
      resumption,
    };
    return { tag: "Op", opcall, state: suspended };
  }

  throw new Error(`Attempted to apply non-callable value: ${fnVal.tag}`);
}

function applyFrame(fr: Frame, v: Val, st: State): StepOutcome {
  switch (fr.tag) {
    case "KIf": {
      if (!isBool(v)) throw new Error("if test must be boolean");
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: v.b ? fr.conseq : fr.alt },
          env: fr.env,
        },
      };
    }

    case "KBegin": {
      if (fr.rest.length === 0) {
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }
      const [e0, ...rest] = fr.rest;
      // IMPORTANT: Use st.env (not fr.env) to preserve bindings from define
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: e0 },
          env: st.env,
          kont: push(st.kont, { tag: "KBegin", rest, env: st.env }),
        },
      };
    }

    case "KDefine": {
      // define returns Unit
      const addr0 = envGet(fr.env, fr.name);
      if (addr0 !== undefined) {
        const store2 = st.store.write(addr0, v);
        return {
          tag: "State",
          state: { ...st, control: { tag: "Val", v: VUnit }, env: fr.env, store: store2 },
        };
      } else {
        const [store2, addr] = st.store.alloc(v);
        const env2 = envSet(fr.env, fr.name, addr);
        return {
          tag: "State",
          state: { ...st, control: { tag: "Val", v: VUnit }, env: env2, store: store2 },
        };
      }
    }

    case "KSet": {
      // Enforce seal: set! denied if context is sealed
      if (fr.env.sealed) {
        throw new Error(`set! denied: context is sealed (name=${fr.name})`);
      }
      const addr = envGet(fr.env, fr.name);
      if (addr === undefined) throw new Error(`set!: unbound var ${fr.name}`);
      const store2 = st.store.write(addr, v);
      return {
        tag: "State",
        state: { ...st, control: { tag: "Val", v: VUnit }, env: fr.env, store: store2 },
      };
    }

    case "KAppFun": {
      // Native with lazy argument indices: wrap specified args as zero-arg thunks (closures)
      if (v.tag === "Native" && Array.isArray((v as any).lazyArgs) && (v as any).lazyArgs.length > 0) {
        const lazyIdx: number[] = (v as any).lazyArgs;
        const totalArgs = fr.args.length;
        const acc: Array<{ idx: number; val: Val }> = [];
        const pending: Array<{ expr: Expr; idx: number }> = [];

        fr.args.forEach((arg, idx) => {
          if (lazyIdx.includes(idx)) {
            const thunk: Val = { tag: "Closure", params: [], body: arg, env: fr.env };
            acc.push({ idx, val: thunk });
          } else {
            pending.push({ expr: arg, idx });
          }
        });

        if (pending.length === 0) {
          const ordered: Val[] = new Array(totalArgs);
          for (const { idx, val } of acc) ordered[idx] = val;
          return applyVal(v, ordered, { ...st, env: fr.env });
        }

        const [next, ...rest] = pending;
        const kontFrame: Frame = {
          tag: "KAppArgLazy",
          fnVal: v,
          pending: rest,
          acc,
          env: fr.env,
          totalArgs,
          currentIdx: next.idx,
        };
        return {
          tag: "State",
          state: {
            ...st,
            control: { tag: "Expr", e: next.expr },
            env: fr.env,
            kont: push(st.kont, kontFrame),
          },
        };
      }

      if (fr.args.length === 0) {
        // apply immediately - applyVal returns StepOutcome directly
        return applyVal(v, [], { ...st, env: fr.env });
      }
      const [a0, ...rest] = fr.args;
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: a0 },
          env: fr.env,
          kont: push(st.kont, { tag: "KAppArg", fnVal: v, pending: rest, acc: [], env: fr.env }),
        },
      };
    }

    case "KAppArg": {
      const acc2 = fr.acc.concat([v]);
      if (fr.pending.length === 0) {
        // apply fnVal to accumulated args - applyVal returns StepOutcome directly
        return applyVal(fr.fnVal, acc2, { ...st, env: fr.env });
      }
      const [a0, ...rest] = fr.pending;
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: a0 },
          env: fr.env,
          kont: push(st.kont, { tag: "KAppArg", fnVal: fr.fnVal, pending: rest, acc: acc2, env: fr.env }),
        },
      };
    }

    case "KAppArgLazy": {
      const acc2 = fr.acc.concat([{ idx: fr.currentIdx, val: v }]);
      if (fr.pending.length === 0) {
        const ordered: Val[] = new Array(fr.totalArgs);
        for (const { idx, val } of acc2) ordered[idx] = val;
        return applyVal(fr.fnVal, ordered, { ...st, env: fr.env });
      }
      const [next, ...rest] = fr.pending;
      const kontFrame: Frame = {
        ...fr,
        pending: rest,
        acc: acc2,
        currentIdx: next.idx,
      };
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: next.expr },
          env: fr.env,
          kont: push(st.kont, kontFrame),
        },
      };
    }

    case "KCall": {
      // restore environment after closure body returns
      return { tag: "State", state: { ...st, control: { tag: "Val", v }, env: fr.savedEnv } };
    }

    case "KEffect": {
      const acc2 = fr.acc.concat([v]);
      if (fr.pending.length === 0) {
        // Prompt 9 Chokepoint A: Debit the effect when emitting
        const stDebited = debitEffect(st, fr.op);
        // perform operation now: emit OpCall with a multi-shot resumption
        const suspended: State = { ...stDebited, control: { tag: "Val", v: VUnit }, env: fr.env }; // placeholder
        const resumption = captureValueResumption(suspended);
        const opcall = { op: fr.op, args: acc2, ctxDigest: ctxDigest(fr.env), resumption };
        return { tag: "Op", opcall, state: suspended };
      }
      const [e0, ...rest] = fr.pending;
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Expr", e: e0 },
          env: fr.env,
          kont: push(st.kont, { tag: "KEffect", op: fr.op, pending: rest, acc: acc2, env: fr.env }),
        },
      };
    }

    case "KHandleBoundary": {
      // Body (or clause) has returned a value v to the handler boundary.
      const hIdx = findHandlerIndexByHid(st.handlers, fr.hid);
      if (hIdx < 0) throw new Error("KHandleBoundary: handler not found");
      const hf = st.handlers[hIdx];

      // Determine whether we are exiting handle or resuming to a caller continuation.
      const mode: "exit" | "resume" = fr.resumeTo ? "resume" : "exit";
      const targetKont = mode === "resume" ? fr.resumeTo!.kont : st.kont; // st.kont already has outer continuation after pop
      const targetHandlersDepth = mode === "resume" ? fr.resumeTo!.handlersDepth : fr.savedHandlersDepth;

      // Apply return clause (if any) by evaluating it under handler env with v bound.
      if (hf.ret) {
        const param = hf.ret.v;
        const body = hf.ret.body;

        // allocate param in store
        let store = st.store;
        const [store2, addr] = store.alloc(v);
        store = store2;
        const env2 = envSet(hf.env, param, addr);

        // After ret body computes v2, KHandleReturn decides whether to exit or resume.
        return {
          tag: "State",
          state: {
            ...st,
            control: { tag: "Expr", e: body },
            env: env2,
            store,
            kont: push(targetKont, {
              tag: "KHandleReturn",
              mode,
              hid: fr.hid,
              targetKont,
              targetHandlersDepth,
              savedHandlersDepth: fr.savedHandlersDepth,
            }),
            // handlers remain as-is during return-clause evaluation; KHandleReturn will truncate.
          },
        };
      }

      // No return clause: direct value
      const st2: State = {
        ...st,
        control: { tag: "Val", v },
        kont: targetKont,
        handlers: st.handlers.slice(0, targetHandlersDepth),
      };
      return { tag: "State", state: st2 };
    }

    case "KHandleReturn": {
      // v is result of return clause evaluation
      const st2: State = {
        ...st,
        control: { tag: "Val", v },
        kont: fr.targetKont,
        handlers: st.handlers.slice(0, fr.targetHandlersDepth),
      };
      return { tag: "State", state: st2 };
    }

    case "KMatch": {
      // v is the scrutinee; try each clause
      for (const cl of fr.clauses) {
        const binds = matchPatternValue(cl.pat, v);
        if (!binds) continue;

        // Bind matched values in env
        let store = st.store;
        let env2 = fr.env;
        for (const [name, val] of binds.entries()) {
          const [s2, addr] = store.alloc(val);
          store = s2;
          env2 = envSet(env2, name, addr);
        }

        return {
          tag: "State",
          state: { ...st, control: { tag: "Expr", e: cl.body }, env: env2, store },
        };
      }
      throw new Error("match: no clause matched");
    }

    case "KOracleLambda": {
      // v is the evaluated spec; create an OracleProc capturing lexical env
      const oracleProc: Val = {
        tag: "OracleProc",
        params: fr.params,
        spec: v,
        env: fr.env,
      };
      return { tag: "State", state: { ...st, control: { tag: "Val", v: oracleProc } } };
    }

    case "KPrompt": {
      const handlersTrunc = st.handlers.slice(0, fr.savedHandlersDepth);
      return {
        tag: "State",
        state: {
          ...st,
          control: { tag: "Val", v },
          env: fr.env,
          kont: fr.savedKont,
          handlers: handlersTrunc,
        },
      };
    }

    case "KHandlerBind": {
      return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
    }

    case "KRestartBind": {
      return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
    }

    case "KSignaling": {
      if (fr.required) {
        throw new UnhandledConditionError(fr.condition);
      }
      return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
    }

    case "KBind": {
      return applyVal(fr.fn, [v], { ...st, env: fr.env });
    }

    default: {
      const _exh: never = fr;
      return _exh;
    }
  }
}

export function stepOnce(st: State): StepOutcome {
  // Prompt 9: Check step budget before each step
  checkStepBudget(st);

  // Expr step
  if (st.control.tag === "Expr") {
    const e = st.control.e;

    switch (e.tag) {
      case "Lit": {
        const v: Val =
          e.value === null ? VUnit :
          typeof e.value === "number" ? { tag: "Num", n: e.value } :
          typeof e.value === "boolean" ? { tag: "Bool", b: e.value } :
          { tag: "Str", s: String(e.value) };
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }

      case "Var": {
        const addr = envGet(st.env, e.name);
        if (addr === undefined) throw new Error(`unbound var ${e.name}`);
        const v = st.store.read(addr);
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }

      case "Lambda": {
        const v: Val = { tag: "Closure", params: e.params, body: e.body, env: st.env };
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }

      case "OracleLambda": {
        // oracle-lambda creates an OracleProc that captures the lexical environment
        // The spec is evaluated to a value that the oracle will use as its goal/prompt
        const kont = push(st.kont, { tag: "KOracleLambda", params: e.params, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.spec }, kont } };
      }

      case "If": {
        const kont = push(st.kont, { tag: "KIf", conseq: e.conseq, alt: e.alt, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.test }, kont } };
      }

      case "Begin": {
        if (e.exprs.length === 0) return { tag: "State", state: { ...st, control: { tag: "Val", v: VUnit } } };
        const [e0, ...rest] = e.exprs;
        const kont = push(st.kont, { tag: "KBegin", rest, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e0 }, kont } };
      }

      case "Define": {
        // Pre-allocate binding with placeholder to support recursive definitions
        // This ensures lambda bodies capture an env that includes the binding
        const existingAddr = envGet(st.env, e.name);
        if (existingAddr !== undefined) {
          // Already allocated (re-definition) - just evaluate RHS and overwrite
          const kont = push(st.kont, { tag: "KDefine", name: e.name, env: st.env });
          return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.rhs }, kont } };
        }
        // Allocate placeholder, add to env, then evaluate RHS
        const placeholder: Val = { tag: "Unit" }; // will be overwritten
        const [store2, addr] = st.store.alloc(placeholder);
        const env2 = envSet(st.env, e.name, addr);
        const kont = push(st.kont, { tag: "KDefine", name: e.name, env: env2 });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.rhs }, env: env2, store: store2, kont } };
      }

      case "Set": {
        const kont = push(st.kont, { tag: "KSet", name: e.name, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.rhs }, kont } };
      }

      case "App": {
        const kont = push(st.kont, { tag: "KAppFun", args: e.args, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.fn }, kont } };
      }

      case "Quote": {
        const v = datumToVal(e.datum);
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }

      case "Effect": {
        // Prompt 9 Chokepoint A: Check effect is allowed before emission
        checkEffectAllowed(st, e.op);

        if (e.args.length === 0) {
          // Debit the effect before emitting
          const stDebited = debitEffect(st, e.op);
          const suspended: State = { ...stDebited, control: { tag: "Val", v: VUnit } };
          const resumption = captureValueResumption(suspended);
          const opcall = { op: e.op, args: [], ctxDigest: ctxDigest(st.env), resumption };
          return { tag: "Op", opcall, state: suspended };
        }
        const [a0, ...rest] = e.args;
        const kont = push(st.kont, { tag: "KEffect", op: e.op, pending: rest, acc: [], env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: a0 }, kont } };
      }

      case "Handle": {
        const hf = buildHandlerFrame(e.handler, st.env);
        const savedHandlersDepth = st.handlers.length;
        const handlers2 = st.handlers.concat([hf]);
        const boundary: Frame = { tag: "KHandleBoundary", hid: hf.hid, savedHandlersDepth };
        const kont2 = push(st.kont, boundary);
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.body }, handlers: handlers2, kont: kont2 } };
      }

      case "Match": {
        // Evaluate the scrutinee first, then apply pattern matching in KMatch frame
        const kont = push(st.kont, { tag: "KMatch", clauses: e.clauses, env: st.env });
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: e.scrutinee }, kont } };
      }

      case "QuoteSyntax": {
        const v: Val = { tag: "Str", s: JSON.stringify(e.datum) };
        return { tag: "State", state: { ...st, control: { tag: "Val", v } } };
      }

      case "Let":
      case "Letrec": {
        // Minimal handling: evaluate the body assuming bindings already processed elsewhere.
        return { tag: "State", state: { ...st, control: { tag: "Expr", e: (e as any).body } } };
      }

      default: {
        return { tag: "State", state: st };
      }
    }
  }

  // Val step: apply continuation frame or finish
  const v = st.control.v;
  const [fr, kont2] = pop(st.kont);
  if (!fr) {
    return { tag: "Done", value: v, state: st };
  }

  const st2: State = { ...st, kont: kont2 };
  return applyFrame(fr, v, st2);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/run.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { State } from "./machine";
import type { Runtime } from "./runtime";
import type { Val } from "./values";
import { stepOnce } from "./machineStep";
import type { BudgetTracker } from "../governance/budgets";

export type RunOptions = {
  maxSteps?: number;
  budget?: BudgetTracker;
};

export async function runToCompletion(
  runtime: Runtime,
  initial: State,
  optionsOrMaxSteps: RunOptions | number = {}
): Promise<Val> {
  // Backward compatibility: accept number as maxSteps
  const options: RunOptions = typeof optionsOrMaxSteps === "number"
    ? { maxSteps: optionsOrMaxSteps }
    : optionsOrMaxSteps;

  const maxSteps = options.maxSteps ?? 1_000_000;
  const budget = options.budget;

  let st = initial;
  for (let i = 0; i < maxSteps; i++) {
    // Consume one eval step if budget tracking is enabled
    budget?.consumeEvalStep();

    const out = stepOnce(st);

    if (out.tag === "State") {
      st = out.state;
      continue;
    }
    if (out.tag === "Done") {
      return out.value;
    }
    if (out.tag === "Op") {
      const handled = await runtime.dispatch(out.state, out.opcall);
      if (handled === "Uncaught") {
        throw new Error(`Uncaught op: ${out.opcall.op}`);
      }
      st = handled;
      continue;
    }
  }
  throw new Error("runToCompletion: step budget exceeded");
}

/**
 * Like runToCompletion but returns both value AND final state.
 * Required by PortalImpl for oracle REPL re-entry.
 */
export async function runToCompletionWithState(
  runtime: Runtime,
  st0: State,
  optionsOrMaxSteps: RunOptions | number = {}
): Promise<{ value: Val; state: State }> {
  // Backward compatibility: accept number as maxSteps
  const options: RunOptions = typeof optionsOrMaxSteps === "number"
    ? { maxSteps: optionsOrMaxSteps }
    : optionsOrMaxSteps;

  const maxSteps = options.maxSteps ?? 1_000_000;
  const budget = options.budget;

  let st = st0;

  for (let i = 0; i < maxSteps; i++) {
    // Consume one eval step if budget tracking is enabled
    budget?.consumeEvalStep();

    const out = stepOnce(st);

    if (out.tag === "State") {
      st = out.state;
      continue;
    }

    if (out.tag === "Done") {
      return { value: out.value, state: (out.state ?? st) as any };
    }

    if (out.tag === "Op") {
      const handled = await runtime.dispatch(out.state, out.opcall);
      if (handled === "Uncaught") throw new Error(`Uncaught op: ${out.opcall.op}`);
      st = handled;
      continue;
    }

    throw new Error(`unknown stepOnce output: ${(out as any).tag}`);
  }

  throw new Error(`runToCompletionWithState exceeded maxSteps=${maxSteps}`);
}

// ============================================================================
// TRACING INFRASTRUCTURE
// ============================================================================

export type TraceEntry = {
  step: number;
  controlTag: string;
  controlDetail: string;
  stackDepth: number;
  stackTags: string[];
  outcome: "state" | "done" | "op";
  opName?: string;
};

export type TraceOptions = RunOptions & {
  trace?: boolean;
  onStep?: (entry: TraceEntry) => void;
};

function controlToString(control: State["control"]): { tag: string; detail: string } {
  if (control.tag === "Val") {
    const v = control.v;
    if (v.tag === "Num") return { tag: "Val", detail: `Num(${v.n})` };
    if (v.tag === "Str") return { tag: "Val", detail: `Str("${v.s.slice(0, 20)}${v.s.length > 20 ? "..." : ""}")` };
    if (v.tag === "Bool") return { tag: "Val", detail: `Bool(${v.b})` };
    if (v.tag === "Unit") return { tag: "Val", detail: "Unit" };
    if (v.tag === "Closure") return { tag: "Val", detail: `Closure(${(v as any).params?.join(",") || "?"})` };
    if (v.tag === "Native") return { tag: "Val", detail: "Native" };
    return { tag: "Val", detail: v.tag };
  }
  if (control.tag === "Expr") {
    const e = control.e;
    if (e.tag === "Lit") {
      if (typeof e.value === "number") return { tag: "Expr", detail: `Lit(${e.value})` };
      if (typeof e.value === "string") return { tag: "Expr", detail: `Lit("${e.value.slice(0, 15)}")` };
      return { tag: "Expr", detail: `Lit(${e.value})` };
    }
    if (e.tag === "Var") return { tag: "Expr", detail: `Var(${e.name})` };
    if (e.tag === "App") return { tag: "Expr", detail: `App(${(e as any).fn?.tag || "?"})` };
    if (e.tag === "If") return { tag: "Expr", detail: "If" };
    if (e.tag === "Lambda") return { tag: "Expr", detail: `Lambda(${(e as any).params?.length || 0} params)` };
    if (e.tag === "Begin") return { tag: "Expr", detail: `Begin(${(e as any).exprs?.length || 0} exprs)` };
    if (e.tag === "Define") return { tag: "Expr", detail: `Define(${(e as any).name || "?"})` };
    if (e.tag === "Effect") return { tag: "Expr", detail: `Effect(${(e as any).op || "?"})` };
    return { tag: "Expr", detail: e.tag };
  }
  return { tag: (control as any).tag ?? "?", detail: "?" };
}

/**
 * Run to completion with full execution tracing.
 * Returns value, final state, and trace log.
 */
export async function runWithTrace(
  runtime: Runtime,
  initial: State,
  optionsOrMaxSteps: TraceOptions | number = {}
): Promise<{ value: Val; state: State; trace: TraceEntry[] }> {
  const options: TraceOptions = typeof optionsOrMaxSteps === "number"
    ? { maxSteps: optionsOrMaxSteps, trace: true }
    : { trace: true, ...optionsOrMaxSteps };

  const maxSteps = options.maxSteps ?? 1_000_000;
  const budget = options.budget;
  const trace: TraceEntry[] = [];

  let st = initial;

  for (let i = 0; i < maxSteps; i++) {
    budget?.consumeEvalStep();

    const { tag, detail } = controlToString(st.control);
    const stackTags = st.kont.map(fr => (fr as any).tag || "?");

    const out = stepOnce(st);

    const entry: TraceEntry = {
      step: i,
      controlTag: tag,
      controlDetail: detail,
      stackDepth: st.kont.length,
      stackTags,
      outcome: out.tag === "State" ? "state" : out.tag === "Done" ? "done" : "op",
      opName: out.tag === "Op" ? out.opcall.op : undefined,
    };

    trace.push(entry);
    options.onStep?.(entry);

    if (out.tag === "State") {
      st = out.state;
      continue;
    }

    if (out.tag === "Done") {
      return { value: out.value, state: (out.state ?? st) as any, trace };
    }

    if (out.tag === "Op") {
      const handled = await runtime.dispatch(out.state, out.opcall);
      if (handled === "Uncaught") throw new Error(`Uncaught op: ${out.opcall.op}`);
      st = handled;
      continue;
    }

    throw new Error(`unknown stepOnce output: ${(out as any).tag}`);
  }

  throw new Error(`runWithTrace exceeded maxSteps=${maxSteps}`);
}

/**
 * Format trace for human-readable output
 */
export function formatTrace(trace: TraceEntry[], options?: { compact?: boolean }): string {
  if (options?.compact) {
    return trace.map(e =>
      `[${e.step}] ${e.controlTag}:${e.controlDetail} | stack=${e.stackDepth}${e.opName ? ` | OP=${e.opName}` : ""}`
    ).join("\n");
  }

  const lines: string[] = [];
  for (const e of trace) {
    lines.push(`Step ${e.step}:`);
    lines.push(`  Control: ${e.controlTag} - ${e.controlDetail}`);
    lines.push(`  Stack depth: ${e.stackDepth}`);
    if (e.stackTags.length > 0) {
      lines.push(`  Stack frames: [${e.stackTags.join(" <- ")}]`);
    }
    if (e.opName) {
      lines.push(`  >>> EFFECT: ${e.opName}`);
    }
    lines.push("");
  }
  return lines.join("\n");
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/runtime.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-4.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { State } from "./machine";
import type { OpCall } from "../effects/opcall";

export type DispatchResult = State | "Uncaught";

export interface Runtime {
  dispatch(state: State, opcall: OpCall): Promise<DispatchResult>;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/store.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-3.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Val } from "./values";

/**
 * StoreAddr is an explicit location (CESK-style). This enables mutation without
 * destroying lexical environment persistence.
 */
export type StoreAddr = number;

/**
 * Store is required to be *persistent* with respect to captured continuations.
 * "Persistent" here means: any snapshot referenced by a resumption must not
 * be affected by future writes in other branches.
 */
export interface Store {
  readonly next: number;

  /** Allocate a new cell initialized with v. Returns [newStore, addr]. */
  alloc(v: Val): [Store, StoreAddr];

  /** Read cell at addr; must throw on invalid addr in strict mode. */
  read(addr: StoreAddr): Val;

  /** Write cell; returns a new Store (or same Store if structural sharing). */
  write(addr: StoreAddr, v: Val): Store;

  /** Snapshot suitable for storing inside a multi-shot resumption. */
  snapshot(): Store;

  /** Debug: stable digest for receipts/differential tests (content-addressed). */
  digest(): string;
}

/**
 * Reference-grade Store implementation: copy-on-write Map snapshot.
 * Correct semantics, not fast. Replace with HAMT for production.
 */
export class COWStore implements Store {
  public readonly next: number;
  private readonly cells: Map<StoreAddr, Val>;

  constructor(next = 0, cells?: Map<StoreAddr, Val>) {
    this.next = next;
    this.cells = cells ?? new Map();
  }

  alloc(v: Val): [Store, StoreAddr] {
    const addr = this.next;
    const cells2 = new Map(this.cells);
    cells2.set(addr, v);
    return [new COWStore(addr + 1, cells2), addr];
  }

  read(addr: StoreAddr): Val {
    const v = this.cells.get(addr);
    if (v === undefined) {
      throw new Error(`Store.read: invalid addr ${addr}`);
    }
    return v;
  }

  write(addr: StoreAddr, v: Val): Store {
    if (!this.cells.has(addr)) {
      throw new Error(`Store.write: invalid addr ${addr}`);
    }
    const cells2 = new Map(this.cells);
    cells2.set(addr, v);
    return new COWStore(this.next, cells2);
  }

  snapshot(): Store {
    // Deep enough: Val is assumed immutable by convention; if not, you must deep-clone Val.
    return new COWStore(this.next, new Map(this.cells));
  }

  digest(): string {
    // Deterministic (slow) digest for testing.
    const entries = Array.from(this.cells.entries()).sort((a, b) => a[0] - b[0]);
    return JSON.stringify({ next: this.next, entries });
  }
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/syntaxPrims.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-8.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Val } from "./values";
import type { State } from "./machine";
import { VTrue, VFalse, VUnit } from "./values";
import type { Syntax } from "../syntax/syntax";
import { addScope, isIdent, isList } from "../syntax/syntax";

function isSyntaxVal(v: Val): v is { tag: "Syntax"; stx: Syntax } {
  return v.tag === "Syntax";
}

function valToDatum(v: Val): unknown {
  switch (v.tag) {
    case "Unit": return null;
    case "Num": return v.n;
    case "Bool": return v.b;
    case "Str": return v.s;
    case "Sym": return { sym: v.name };
    case "Vector": return v.items.map(valToDatum);
    case "Syntax": return syntaxToDatum(v.stx);
    default:
      return { opaque: v.tag };
  }
}

function datumToVal(d: unknown): Val {
  if (d === null) return { tag: "Unit" };
  if (typeof d === "number") return { tag: "Num", n: d };
  if (typeof d === "string") return { tag: "Str", s: d };
  if (typeof d === "boolean") return { tag: "Bool", b: d };
  if (typeof d === "object" && d !== null && !Array.isArray(d) && "sym" in d) {
    return { tag: "Sym", name: (d as any).sym };
  }
  if (Array.isArray(d)) return { tag: "Vector", items: d.map(datumToVal) };
  return { tag: "Str", s: JSON.stringify(d) };
}

function syntaxToDatum(stx: Syntax): unknown {
  if (stx.tag === "Atom") return stx.value;
  if (stx.tag === "Ident") return { sym: stx.name };
  return stx.items.map(syntaxToDatum);
}

function datumToSyntaxWithScopes(d: unknown, scopes: string[]): Syntax {
  if (d === null || typeof d === "number" || typeof d === "string" || typeof d === "boolean") {
    return { tag: "Atom", value: d as any, scopes: scopes.slice() };
  }
  if (typeof d === "object" && d !== null && !Array.isArray(d) && "sym" in d) {
    return { tag: "Ident", name: (d as any).sym, scopes: scopes.slice() };
  }
  if (Array.isArray(d)) {
    return { tag: "List", items: d.map(x => datumToSyntaxWithScopes(x, scopes)), scopes: scopes.slice() };
  }
  // fallback
  return { tag: "Atom", value: JSON.stringify(d), scopes: scopes.slice() };
}

export function syntaxPrims(): Array<{ name: string; arity: number | "variadic"; fn: (args: Val[], st: State) => State }> {
  return [
    {
      name: "syntax?",
      arity: 1,
      fn: ([v], st) => ({ ...st, control: { tag: "Val", v: isSyntaxVal(v) ? VTrue : VFalse } }),
    },
    {
      name: "syntax->datum",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v)) throw new Error("syntax->datum: expected Syntax");
        return { ...st, control: { tag: "Val", v: datumToVal(syntaxToDatum(v.stx)) } };
      },
    },
    {
      name: "datum->syntax",
      arity: 2,
      fn: ([ctx, dat], st) => {
        if (!isSyntaxVal(ctx)) throw new Error("datum->syntax: ctx must be Syntax");
        const scopes = ctx.stx.scopes;
        const d = valToDatum(dat);
        const out: Syntax = datumToSyntaxWithScopes(d, scopes);
        return { ...st, control: { tag: "Val", v: { tag: "Syntax", stx: out } } };
      },
    },
    {
      name: "syntax-ident?",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v)) return { ...st, control: { tag: "Val", v: VFalse } };
        return { ...st, control: { tag: "Val", v: isIdent(v.stx) ? VTrue : VFalse } };
      },
    },
    {
      name: "syntax-list?",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v)) return { ...st, control: { tag: "Val", v: VFalse } };
        return { ...st, control: { tag: "Val", v: isList(v.stx) ? VTrue : VFalse } };
      },
    },
    {
      name: "syntax-ident-name",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v) || v.stx.tag !== "Ident") throw new Error("syntax-ident-name: expected identifier syntax");
        return { ...st, control: { tag: "Val", v: { tag: "Str", s: v.stx.name } } };
      },
    },
    {
      name: "syntax-list-items",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v) || v.stx.tag !== "List") throw new Error("syntax-list-items: expected list syntax");
        const items: Val[] = v.stx.items.map(it => ({ tag: "Syntax", stx: it }));
        return { ...st, control: { tag: "Val", v: { tag: "Vector", items } } };
      },
    },
    {
      name: "syntax-add-scope",
      arity: 2,
      fn: ([v, sc], st) => {
        if (!isSyntaxVal(v)) throw new Error("syntax-add-scope: expected Syntax");
        if (sc.tag !== "Str") throw new Error("syntax-add-scope: expected string scope");
        return { ...st, control: { tag: "Val", v: { tag: "Syntax", stx: addScope(v.stx, sc.s) } } };
      },
    },
    {
      name: "syntax-scopes",
      arity: 1,
      fn: ([v], st) => {
        if (!isSyntaxVal(v)) throw new Error("syntax-scopes: expected Syntax");
        return { ...st, control: { tag: "Val", v: { tag: "Vector", items: v.stx.scopes.map(s => ({ tag: "Str", s })) } } };
      },
    },
    {
      name: "syntax-local-introduce",
      arity: 1,
      fn: ([v], st) => {
        // reference-grade: identity; in a full system this would add the current introducer scope.
        if (!isSyntaxVal(v)) throw new Error("syntax-local-introduce: expected Syntax");
        return { ...st, control: { tag: "Val", v } };
      },
    },
    {
      name: "unit",
      arity: 0,
      fn: (_args, st) => ({ ...st, control: { tag: "Val", v: VUnit } }),
    },
  ];
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/eval/values.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set A3: Extend Val union with Dist and Meaning
// Patch Set A4: Add MachineVal for reified execution state (Prompt 8)
// Prompt 9: Add ProfileVal for first-class governance

import type { Expr } from "../ast";
import type { Env } from "./env";
import type { Store } from "./store";
import type { Resumption } from "../effects/opcall";
import type { State, StepOutcome, Frame, HandlerFrame } from "./machine";
import type { Syntax } from "../syntax/syntax";
import type { DistVal } from "./dist";
import type { MeaningVal } from "../oracle/meaning";
import type { Profile, TruthRegime, OracleReqTag } from "../governance/profile";
import type { Ctx } from "../ctx/ctx";
import type { Hash } from "../artifacts/hash";
import type { ConditionVal } from "../conditions/types";
type SolverApplyFn = (proc: Val, args: Val[], state: State) => State | StepOutcome;

/**
 * MachineVal: Reified execution state as a first-class value.
 *
 * Enables:
 * - machine-step: Single-step execution
 * - machine-run: Run to completion or breakpoint
 * - machine-fork: Clone for multi-shot exploration
 * - machine-stack: Inspect continuation stack
 * - machine-eval-at: Evaluate expression in machine's environment
 * - machine-resume: Resume from effect with provided value
 *
 * The machine captures the full CESK state for time-travel debugging,
 * breakpoint-based inspection, and parallel exploration of execution paths.
 */
export type MachineVal = {
  tag: "Machine";
  state: State;
  /** Optional label for debugging */
  label?: string;
  /** Step count since creation */
  stepCount: number;
  /** Breakpoints: effect names that pause execution */
  breakOnOps?: Set<string>;
  /** Breakpoints: AST patterns (as JSON) that pause execution */
  breakOnPatterns?: string[];
  /** Last step outcome (for inspection after step) */
  lastOutcome?: StepOutcome;
  /** True if machine has reached terminal state */
  isDone: boolean;
  /** Parent machine ID (for fork tracking) */
  parentId?: string;
  /** Unique machine ID */
  machineId: string;
};

/**
 * ContinuationVal: First-class undelimited continuation.
 *
 * Captures the current continuation stack plus dynamic handler stack so it can
 * be invoked later (possibly multiple times).
 */
export type ContinuationVal = {
  tag: "Continuation";
  kont: Frame[];
  env: Env;
  store: Store;
  handlers: HandlerFrame[];
};

/**
 * ProfileVal: First-class governance configuration.
 *
 * Profiles are "evaluator configurations" (SICP-style) that determine:
 * - What effects can be emitted
 * - What oracle requests are legal
 * - What capabilities are granted
 * - Resource budgets
 * - Truth regime for commits
 *
 * Different profiles = different languages.
 * strict/pragmatic/explore/airgap are semantic regimes.
 *
 * Used with:
 * - (with-profile prof body) - install profile for dynamic extent
 * - (profile-name p) - get profile name
 * - (profile-allows? p op) - check if operation allowed
 * - (profile-budget p kind) - get budget limit
 */
export type ProfileVal = {
  tag: "Profile";
  /** The underlying profile configuration */
  profile: Profile;
  /** Unique ID for this profile instance */
  profileId: string;
};

/**
 * CtxVal: Reified context as a first-class value.
 *
 * Enables:
 * - (ctx/snapshot) - capture current context
 * - (ctx/sealed? ctx) - check if context is sealed
 * - (ctx/caps ctx) - get capability set
 * - (ctx/with-caps ctx caps body) - run body with attenuated caps
 * - (ctx/compress ctx) - compress for oracle transmission
 * - (ctx/hydrate ref) - hydrate from receipt reference
 *
 * Contexts are content-addressed (cid) and can be sealed to prevent
 * mutation. Sealing is used for module boundaries.
 */
export type CtxVal = {
  tag: "Ctx";
  /** The underlying context */
  ctx: Ctx;
};

/**
 * ModuleVal: Sealed module with attenuated capabilities.
 *
 * A module is a sealed context with:
 * - Attenuated caps (can only restrict, never expand)
 * - Exported bindings (public interface)
 * - Module ID (content-address of exports + cid)
 *
 * Used for:
 * - Sandboxed code execution
 * - Capability attenuation across trust boundaries
 * - Package/library isolation
 *
 * Module creation:
 * (module/seal ctx exports) - seal context and create module
 *
 * Module usage:
 * (module/import mod name) - import binding from module
 * (module/caps mod) - get module's capability set
 */
export type ModuleVal = {
  tag: "Module";
  /** Unique module ID (content-address) */
  moduleId: Hash;
  /** The sealed context (frozen) */
  sealedCtx: Ctx;
  /** Exported binding names */
  exports: Set<string>;
  /** Optional module metadata */
  meta?: {
    name?: string;
    version?: string;
    description?: string;
  };
};

/**
 * ReceiptRefVal: Reference to a receipt in the receipt store.
 *
 * Receipts track operations for provenance:
 * - ctx.snapshot receipts
 * - ctx.compress receipts
 * - commit receipts (from truth regime)
 *
 * Used for:
 * - Hydrating compressed contexts
 * - Audit trails
 * - Reproducibility
 */
export type ReceiptRefVal = {
  tag: "ReceiptRef";
  /** Receipt ID (content-address) */
  rid: Hash;
  /** Kind of receipt */
  kind: "snapshot" | "compress" | "commit";
};

// ─────────────────────────────────────────────────────────────────
// Prompt 12: Constraint propagation network values (SICP 3.3.5 style)
// ─────────────────────────────────────────────────────────────────

/**
 * ConnRef: Reference to a connector in a constraint network.
 *
 * Connectors are store-backed cells that participate in propagation.
 * They track:
 * - Current value (if any)
 * - Explanation of how the value was derived
 * - Connected propagators
 *
 * Used with:
 * - (conn/new net name?) - create new connector
 * - (conn/has? c) - check if connector has a value
 * - (conn/get c) - get connector value
 * - (conn/set! c v :because reason) - set value with provenance
 * - (conn/forget! c :because reason) - clear value for backtracking
 * - (conn/why c) - get explanation graph
 */
export type ConnRefVal = {
  tag: "ConnRef";
  /** Stable unique identifier */
  id: string;
  /** Network this connector belongs to */
  netId: string;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * NetRef: Reference to a constraint propagation network.
 *
 * Networks contain:
 * - Connectors (store-backed cells)
 * - Propagators (procedures that read inputs and write outputs)
 * - Constraints (propagators + invariants that must hold)
 *
 * Used with:
 * - (net/new) - create new network
 * - (net/run net :fuel N) - propagate to fixpoint with budget
 * - (net/status net) - get network status (quiescent/contradiction/pending)
 * - (net/unsat-core net contradiction) - get conflicting constraints
 */
export type NetRefVal = {
  tag: "NetRef";
  /** Stable unique identifier */
  id: string;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * Explanation: First-class explanation graph for constraint propagation.
 *
 * Explanations form a DAG that traces how values were derived or why
 * contradictions occurred. This enables:
 * - "Why did it fail?" queries
 * - Unsat core extraction
 * - Repair synthesis
 *
 * Three kinds:
 * - Assumption: Initial value set by user/input
 * - Derived: Value computed by a propagator from dependencies
 * - Conflict: Contradiction between incompatible derivations
 */
export type ExplanationVal =
  | {
      tag: "Explanation";
      kind: "assumption";
      conn: ConnRefVal;
      valueHash: Hash;
      because: Val;
    }
  | {
      tag: "Explanation";
      kind: "derived";
      conn: ConnRefVal;
      valueHash: Hash;
      rule: string;
      deps: ExplanationVal[];
    }
  | {
      tag: "Explanation";
      kind: "conflict";
      conn: ConnRefVal;
      left: ExplanationVal;
      right: ExplanationVal;
      message?: string;
    }
  | {
      tag: "Explanation";
      kind: "denied";
      op: string;
      reason: string;
      profile?: string;
    };

/**
 * ContradictionVal: First-class contradiction value (not an exception).
 *
 * Contradictions are returned from constraint networks when invariants
 * are violated. They carry explanation graphs for diagnosis and repair.
 *
 * Used with:
 * - (contradiction? v) - check if value is contradiction
 * - (contradiction-explain c) - get explanation graph
 * - (repair net contradiction :options opts) - synthesize repairs via amb
 */
export type ContradictionVal = {
  tag: "Contradiction";
  /** The explanation graph showing why the contradiction occurred */
  explanation: ExplanationVal;
  /** Optional identifier for the violated constraint */
  constraintId?: string;
  /** Optional network reference */
  netId?: string;
};

// ─────────────────────────────────────────────────────────────────
// Prompt 13: Concurrency primitives (fibers, scheduler, synchronization)
// ─────────────────────────────────────────────────────────────────

export type FiberId = number;

/**
 * FiberVal: Reference to a fiber (lightweight concurrent execution unit).
 *
 * Fibers are cooperatively scheduled CEKS states that can:
 * - Run semantic operations concurrently
 * - Yield control explicitly
 * - Join (wait) for other fibers
 * - Share state via synchronized primitives
 *
 * Used with:
 * - (fiber/spawn thunk) - create new fiber
 * - (fiber/yield) - yield control
 * - (fiber/join fiber) - wait for fiber completion
 * - (fiber/id) - get current fiber's ID
 */
export type FiberVal = {
  tag: "Fiber";
  /** Unique fiber identifier */
  id: FiberId;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * SchedulerView: Observable state of the fiber scheduler.
 *
 * Provides a snapshot of all fibers and their states for:
 * - Oracle inspection (ReqObserve)
 * - Debugging and REPL
 * - Deterministic replay verification
 */
export type SchedulerView = {
  /** Currently running fiber (if any) */
  running?: FiberId;
  /** Fibers ready to run */
  ready: FiberId[];
  /** Blocked fibers with their block reasons */
  blocked: Array<{ id: FiberId; on: string }>;
  /** Completed fibers with their result hashes */
  done: Array<{ id: FiberId; valueHash: Hash }>;
  /** Current step count */
  stepCount: number;
  /** Scheduling policy name */
  policy: string;
};

/**
 * MutexVal: Reference to a mutex for mutual exclusion.
 *
 * Used with SICP-style serializers:
 * - (mutex/new) - create mutex
 * - (mutex/lock m) - acquire lock (may block)
 * - (mutex/unlock m) - release lock
 */
export type MutexVal = {
  tag: "Mutex";
  /** Unique mutex identifier */
  id: string;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * IVarVal: Reference to a write-once synchronization variable.
 *
 * IVars enable singleflight memoization:
 * - First reader creates IVar and starts computation
 * - Other readers block on IVar
 * - Writer puts result, unblocks all readers
 *
 * Used with:
 * - (ivar/new) - create empty IVar
 * - (ivar/put! iv val) - write value (once only)
 * - (ivar/take iv) - read value (blocks if empty)
 * - (ivar/full? iv) - check if written
 */
export type IVarVal = {
  tag: "IVar";
  /** Unique IVar identifier */
  id: string;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * ChannelVal: Reference to a communication channel.
 *
 * Channels enable fiber communication:
 * - (chan/new) - create unbuffered channel
 * - (chan/send ch val) - send value (may block)
 * - (chan/recv ch) - receive value (blocks if empty)
 */
export type ChannelVal = {
  tag: "Channel";
  /** Unique channel identifier */
  id: string;
  /** Buffer size (0 = unbuffered) */
  bufferSize: number;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * ActorVal: Reference to an actor (fiber with mailbox).
 *
 * Actors avoid shared state by message passing:
 * - (actor/spawn handler) - create actor with handler proc
 * - (actor/send actor msg) - send message (async)
 */
export type ActorVal = {
  tag: "Actor";
  /** Unique actor identifier */
  id: string;
  /** Underlying fiber ID */
  fiberId: FiberId;
  /** Human-readable name (optional) */
  name?: string;
};

// ─────────────────────────────────────────────────────────────────
// Prompt 14: Generic Operations (data-directed programming + coercion towers)
// ─────────────────────────────────────────────────────────────────

/**
 * TaggedVal: SICP-style tagged value with explicit type tag.
 *
 * Tagged values implement data abstraction barriers:
 * - Type tags identify semantic types (Text/Plain, Doc/Email, etc.)
 * - Payloads carry the actual data
 * - Generic dispatch uses tags for method selection
 *
 * Used with:
 * - (attach-tag typeTag payload) - create tagged value
 * - (type-tag v) - get type tag (or unit for untagged)
 * - (contents v) - unwrap payload
 */
export type TaggedVal = {
  tag: "Tagged";
  /** Semantic type tag (e.g., "Text/Plain", "Doc/Email") */
  typeTag: string;
  /** The actual data */
  payload: Val;
};

/**
 * GenericRegistryVal: Reference to a generic operations registry.
 *
 * Registries contain:
 * - Method table: op × signature → procedure
 * - Coercion table: fromTag × toTag → procedure
 * - Metadata for governance and commit tracking
 *
 * Used with:
 * - (registry/new) - create new registry
 * - (defgeneric op :arity n :registry reg) - define generic operation
 * - (defmethod op (types...) proc :registry reg) - install method
 * - (defcoercion from -> to proc :registry reg) - install coercion
 * - (apply-generic op args... :registry reg) - dispatch to method
 */
export type GenericRegistryVal = {
  tag: "GenericRegistry";
  /** Unique registry identifier */
  id: string;
  /** Human-readable name (optional) */
  name?: string;
};

/**
 * GenericMissVal: First-class miss value for unresolved generic dispatch.
 *
 * When method resolution fails, instead of an error, we get a miss value
 * that can be handled by the inference/search plane to synthesize methods.
 *
 * Used with:
 * - (generic.miss? v) - check if value is a miss
 * - (generic.miss-op v) - get the operation that missed
 * - (generic.miss-sig v) - get the type signature
 */
export type GenericMissVal = {
  tag: "GenericMiss";
  /** The operation that couldn't be resolved */
  op: string;
  /** The type signature (list of type tags) */
  signature: string[];
  /** Preview of arguments (possibly redacted) */
  argsPreview: Val[];
  /** Registry where the miss occurred */
  registryId: string;
  /** Profile under which dispatch was attempted */
  profileName?: string;
};

// ─────────────────────────────────────────────────────────────────
// Prompt 16: Streams + Laziness (memoized promises)
// ─────────────────────────────────────────────────────────────────

export type PromiseId = string;

/**
 * PromiseVal: Reference to a memoized promise/thunk.
 *
 * Promises are the foundation for lazy evaluation and streams:
 * - A promise wraps a thunk (nullary closure) for deferred computation
 * - Forcing a promise evaluates the thunk exactly once (memoization)
 * - Concurrent forces share the same in-flight evaluation (singleflight)
 *
 * Used with:
 * - (delay e) - macro that creates (promise/new (lambda () e))
 * - (force p) - force the promise, returning memoized value
 * - (promise? v) - check if value is a promise
 * - (promise/forced? p) - check if already forced
 *
 * Streams are built on promises:
 * - (cons-stream a b) = (cons a (delay b))
 * - stream-cdr forces the tail promise
 */
export type PromiseVal = {
  tag: "Promise";
  /** Unique promise identifier */
  id: PromiseId;
  /** Optional label for debugging */
  label?: string;
};

/**
 * StreamVal: First-class stream marker for stream-specific operations.
 *
 * While streams are represented as (head . promise) pairs, this marker
 * enables stream-specific introspection and analysis.
 *
 * Used with:
 * - (stream? v) - check if value is a stream
 * - (stream-null? s) - check if empty stream
 * - (stream-car s) - get head
 * - (stream-cdr s) - force and get tail
 */
export type StreamVal = {
  tag: "Stream";
  /** Whether this is the empty stream */
  isEmpty: boolean;
  /** Head value (if not empty) */
  head?: Val;
  /** Tail promise or receipt ref (if not empty) */
  tail?: Val;
};

// ─────────────────────────────────────────────────────────────────
// Prompt 17: Compiler Pipeline (IR values)
// ─────────────────────────────────────────────────────────────────

/**
 * IRVal: First-class compiled artifact (intermediate representation).
 *
 * IR values represent compiled programs that can be executed by the
 * bytecode VM while preserving all semantic effects (infer.op, amb.choose,
 * tool.op, etc.). They are content-addressed and carry source maps for
 * debugging and obligations for verification.
 *
 * Used with:
 * - (compile qexpr :target 'anf|'bytecode :policy P) -> IR
 * - (run-ir ir :args args) -> Val
 * - (ir? v) -> Bool
 * - (ir-source-map ir ip) -> source location
 */
export type IRVal = {
  tag: "IR";
  /** The IR form: 'anf' or 'bytecode' */
  form: "anf" | "bytecode";
  /** Content-addressed digest of the IR */
  digest: string;
  /** Reference to the IR program data (stored separately) */
  irRef: string;
  /** Optional label for debugging */
  label?: string;
};

// ─────────────────────────────────────────────────────────────────
// Solver layer values (Job 008)
// ─────────────────────────────────────────────────────────────────

export type BudgetVal = {
  tag: "Budget";
  tokens: number;
  calls: number;
  time: number;
};

export type ResultVal = {
  tag: "Result";
  kind: "success" | "partial" | "failure" | string;
  solution?: Val;
  remaining?: Val;
  reason?: string;
  cost: number;
};

export type CostEstimateVal = {
  tag: "CostEstimate";
  minCost: number;
  maxCost: number;
  expectedCost: number;
  confidence: number;
};

export type SolverVal = {
  tag: "Solver";
  name: string;
  solve: (problem: Val, budget: BudgetVal, state: State, apply: SolverApplyFn) => { results: ResultVal[]; state: State };
  estimate: (problem: Val, state: State, apply: SolverApplyFn) => { estimate: CostEstimateVal; state: State };
};

export type FactStoreVal = {
  tag: "FactStore";
  facts: Map<string, Val>;
};

// Compatibility tagged values used by stream and demo code
export type IntVal = { tag: "Int"; value: bigint };
export type ListVal = { tag: "List"; elements: Val[] };
export type ErrVal = { tag: "Err"; message?: string };

export type Val =
  | { tag: "Unit" }
  | { tag: "Uninit" }
  | { tag: "Num"; n: number }
  | IntVal
  | { tag: "Bool"; b: boolean }
  | { tag: "Str"; s: string }
  | { tag: "Sym"; name: string }
  | ConditionVal
  | ListVal
  | { tag: "Pair"; car: Val; cdr: Val }
  | { tag: "Vector"; items: Val[] }
  | { tag: "Map"; entries: Array<[Val, Val]> }
  | { tag: "Syntax"; stx: Syntax }
  | { tag: "Closure"; params: string[]; body: Expr; env: Env }
  | { tag: "Native"; name: string; arity: number | "variadic"; lazyArgs?: number[]; fn: (args: Val[], st: State) => State | StepOutcome }
  | { tag: "Cont"; hid: string; boundaryIndex: number; resumption: Resumption }
  | { tag: "OracleProc"; params: string[]; spec: Val; env: Env; policyDigest?: string }
  | ContinuationVal   // First-class continuation (call/cc, prompts)
  | MachineVal      // Patch Set A4: Reified machine state for debugging/stepping
  | DistVal         // Patch Set A: Distributions for nondeterministic LLM results
  | MeaningVal      // Patch Set A: Structured semantic artifacts
  | ProfileVal      // Prompt 9: First-class governance configuration
  | CtxVal          // Prompt 10: Reified context as first-class value
  | ModuleVal       // Prompt 10: Sealed module with attenuated caps
  | ReceiptRefVal   // Prompt 10: Receipt reference for provenance
  | ConnRefVal      // Prompt 12: Connector reference in constraint network
  | NetRefVal       // Prompt 12: Network reference for constraint propagation
  | ExplanationVal  // Prompt 12: First-class explanation graph
  | ContradictionVal // Prompt 12: First-class contradiction value
  | ErrVal
  | FiberVal        // Prompt 13: Fiber reference for concurrent execution
  | MutexVal        // Prompt 13: Mutex for mutual exclusion
  | IVarVal         // Prompt 13: Write-once synchronization variable
  | ChannelVal      // Prompt 13: Communication channel
  | ActorVal        // Prompt 13: Actor with mailbox
  | TaggedVal       // Prompt 14: Tagged value with semantic type
  | GenericRegistryVal // Prompt 14: Generic operations registry
  | GenericMissVal  // Prompt 14: Unresolved generic dispatch
  | PromiseVal      // Prompt 16: Memoized promise/thunk for laziness
  | StreamVal       // Prompt 16: Stream marker for stream operations
  | IRVal           // Prompt 17: Compiled IR artifact
  | BudgetVal       // Job 008: First-class budgets for solvers
  | ResultVal       // Job 008: Solver result
  | CostEstimateVal // Job 008: Cost estimate for solvers
  | SolverVal       // Job 008: First-class solver
  | FactStoreVal;   // Job 008: Monotone fact store

export const VUnit: Val = { tag: "Unit" };
export const VTrue: Val = { tag: "Bool", b: true };
export const VFalse: Val = { tag: "Bool", b: false };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/expand/syntaxRules.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Syntax, SIdent } from "../syntax/syntax";
import { isIdent, isList, addScope, freshScope } from "../syntax/syntax";
import type { Env } from "../syntax/binding";
import { freeIdentifierEq } from "../syntax/binding";

export type SRRule = { pat: Syntax; tmpl: Syntax };

export type SRTransformer = {
  phaseOut: number;
  envDefOut: Env;
  literals: SIdent[];
  rules: SRRule[];
};

export function compileSyntaxRules(
  phaseOut: number,
  envDefOut: Env,
  literals: SIdent[],
  rules: SRRule[]
): SRTransformer {
  return { phaseOut, envDefOut, literals, rules };
}

type SubstVal =
  | { tag: "One"; stx: Syntax }
  | { tag: "Many"; items: Array<{ tag: "One"; stx: Syntax }> };

type Subst = Map<string, SubstVal>;

function isEllipsis(stx: Syntax): boolean {
  return isIdent(stx) && stx.name === "...";
}

function isWildcard(id: SIdent): boolean {
  return id.name === "_";
}

function isLiteralIdent(id: SIdent, tr: SRTransformer, envUseOut: Env): boolean {
  for (const lit of tr.literals) {
    if (freeIdentifierEq(lit, tr.envDefOut, tr.phaseOut, id, envUseOut)) return true;
  }
  return false;
}

function extendOne(σ: Subst, name: string, stx: Syntax): Subst | null {
  const prev = σ.get(name);
  if (!prev) {
    const σ2 = new Map(σ);
    σ2.set(name, { tag: "One", stx });
    return σ2;
  }
  if (prev.tag === "One") {
    // same binding required
    // for minimal soundness, accept structural equality by JSON
    if (JSON.stringify(prev.stx) !== JSON.stringify(stx)) return null;
    return σ;
  }
  // previously Many, cannot unify with One
  return null;
}

function extendMany(σ: Subst, name: string, one: { tag: "One"; stx: Syntax }): Subst {
  const prev = σ.get(name);
  const σ2 = new Map(σ);
  if (!prev) {
    σ2.set(name, { tag: "Many", items: [one] });
    return σ2;
  }
  if (prev.tag === "Many") {
    σ2.set(name, { tag: "Many", items: prev.items.concat([one]) });
    return σ2;
  }
  // prev One: upgrade to Many(One, newOne) is unsound in general; treat as error
  throw new Error(`syntax-rules: variable ${name} used inconsistently with ellipses`);
}

function matchPattern(
  pat: Syntax,
  inp: Syntax,
  σ: Subst,
  tr: SRTransformer,
  envUseOut: Env
): Subst | null {
  if (pat.tag === "Atom") {
    if (inp.tag !== "Atom") return null;
    return JSON.stringify(pat.value) === JSON.stringify(inp.value) ? σ : null;
  }

  if (pat.tag === "Ident") {
    if (isWildcard(pat)) return σ;

    if (isLiteralIdent(pat, tr, envUseOut)) {
      if (inp.tag !== "Ident") return null;
      return freeIdentifierEq(pat, tr.envDefOut, tr.phaseOut, inp, envUseOut) ? σ : null;
    }

    // pattern variable
    return extendOne(σ, pat.name, inp);
  }

  // list pattern
  if (pat.tag === "List") {
    if (inp.tag !== "List") return null;
    return matchList(pat.items, inp.items, σ, tr, envUseOut);
  }

  return null;
}

function matchList(
  pats: Syntax[],
  inps: Syntax[],
  σ: Subst,
  tr: SRTransformer,
  envUseOut: Env
): Subst | null {
  // Support only suffix ellipses for baseline correctness:
  //   (a b ... c) is complex; implement the common (x ...) and nested forms used in practice.

  let pi = 0;
  let ii = 0;
  let σcur: Subst | null = σ;

  while (pi < pats.length) {
    const p = pats[pi];
    const pNext = pats[pi + 1];

    if (pNext && isEllipsis(pNext)) {
      // repeating segment p* matches zero or more input items (greedy but safe if only at end)
      // For correctness with nested ellipses, we allow it anywhere but require that remaining pattern
      // after ellipsis is empty (suffix ellipses). If not, throw for now.
      if (pi + 2 < pats.length) {
        throw new Error("syntax-rules: non-suffix ellipses not supported in this baseline matcher");
      }

      // match the remainder of inps as repeats of p
      while (ii < inps.length) {
        // gather σ segment bindings as Many
        const segσ = matchPattern(p, inps[ii], new Map(), tr, envUseOut);
        if (!segσ) return null;

        // merge segσ into σcur as Many
        for (const [k, v] of segσ.entries()) {
          if (v.tag !== "One") throw new Error("internal: segment match produced Many unexpectedly");
          σcur = extendMany(σcur!, k, v);
        }
        ii++;
      }
      return σcur;
    }

    // non-repeating
    if (ii >= inps.length) return null;
    σcur = matchPattern(p, inps[ii], σcur!, tr, envUseOut);
    if (!σcur) return null;
    pi++;
    ii++;
  }

  return ii === inps.length ? σcur : null;
}

/**
 * Expand template with correct hygiene:
 * - substituted ids: do NOT add introducer scope
 * - introduced ids: add introducer scope
 */
function expandTemplateHygienic(tmpl: Syntax, σ: Subst, introducer: string): Syntax {
  if (tmpl.tag === "Atom") return tmpl;

  if (tmpl.tag === "Ident") {
    const v = σ.get(tmpl.name);
    if (v) {
      if (v.tag !== "One") throw new Error(`template var ${tmpl.name} expected One`);
      return v.stx;
    }
    return addScope(tmpl, introducer) as any;
  }

  // list template with ellipses (suffix only baseline)
  const outItems: Syntax[] = [];
  const items = tmpl.items;

  for (let i = 0; i < items.length; i++) {
    const t0 = items[i];
    const t1 = items[i + 1];

    if (t1 && isEllipsis(t1)) {
      const k = segmentRepLen(t0, σ);
      for (let j = 0; j < k; j++) {
        const σj = substProject(σ, j);
        outItems.push(expandTemplateHygienic(t0, σj, introducer));
      }
      i += 1;
      continue;
    }

    outItems.push(expandTemplateHygienic(t0, σ, introducer));
  }

  return { ...tmpl, items: outItems };
}

function collectTemplateVars(t: Syntax, vars: Set<string>) {
  if (t.tag === "Ident") vars.add(t.name);
  else if (t.tag === "List") for (const it of t.items) collectTemplateVars(it, vars);
}

function segmentRepLen(segment: Syntax, σ: Subst): number {
  const vars = new Set<string>();
  collectTemplateVars(segment, vars);

  let len: number | null = null;
  for (const x of vars) {
    const v = σ.get(x);
    if (!v) continue;
    if (v.tag === "Many") {
      const k = v.items.length;
      if (len === null) len = k;
      else if (len !== k) throw new Error(`ellipsis zip mismatch on ${x}`);
    }
  }
  return len ?? 0;
}

function substProject(σ: Subst, i: number): Subst {
  const out: Subst = new Map();
  for (const [k, v] of σ.entries()) {
    out.set(k, v.tag === "One" ? v : v.items[i]);
  }
  return out;
}

export function applySyntaxRules(
  tr: SRTransformer,
  callStx: Syntax,
  envUseOut: Env,
  scopeCounter: { n: number }
): Syntax {
  const U = freshScope(scopeCounter);
  const callU = addScope(callStx, U);

  for (const rule of tr.rules) {
    const σ0: Subst = new Map();
    const σ = matchPattern(rule.pat, callU, σ0, tr, envUseOut);
    if (!σ) continue;

    const I = freshScope(scopeCounter);
    return expandTemplateHygienic(rule.tmpl, σ, I);
  }

  throw new Error("syntax-rules: no rule matched");
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/expand/transformer.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-8.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { SRTransformer } from "./syntaxRules";

export type TransformerVal =
  | { tag: "SyntaxRules"; tr: SRTransformer }
  | { tag: "ProcRef"; originModule: string; phase: number; internal: string }; // closure stored in module instance at phase
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/coercion.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/coercion.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Coercion graph and path finding for type conversions

import type { Val } from "../eval/values";
import {
  type TypeTag,
  type TypeSignature,
  type CoercionEntry,
  type CoercionPath,
} from "./types";
import {
  getRegistry,
  getCoercionsFrom,
  getAllTypeTags,
  lookupCoercion,
  logGenericEvent,
} from "./registry";

// ─────────────────────────────────────────────────────────────────
// Coercion Graph Construction
// ─────────────────────────────────────────────────────────────────

/**
 * CoercionGraph: Adjacency list representation of the coercion graph.
 */
export type CoercionGraph = Map<TypeTag, Map<TypeTag, CoercionEntry>>;

/**
 * Build the coercion graph from a registry.
 */
export function buildCoercionGraph(registryId: string): CoercionGraph {
  const registry = getRegistry(registryId);
  if (!registry) return new Map();

  return registry.coercions;
}

/**
 * Get all outgoing edges from a type in the graph.
 */
export function getOutgoingCoercions(
  registryId: string,
  fromTag: TypeTag
): CoercionEntry[] {
  return getCoercionsFrom(registryId, fromTag);
}

// ─────────────────────────────────────────────────────────────────
// Path Finding
// ─────────────────────────────────────────────────────────────────

/**
 * Find the shortest coercion path from one type to another.
 * Uses BFS for shortest path, considering costs.
 */
export function findCoercionPath(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag,
  maxDepth: number = 5
): CoercionPath | undefined {
  if (fromTag === toTag) {
    // No coercion needed
    return { steps: [], totalCost: 0, argIndices: [], targetSig: [toTag] };
  }

  // BFS with cost tracking
  const visited = new Set<TypeTag>();
  const queue: Array<{ tag: TypeTag; path: CoercionEntry[]; cost: number }> = [
    { tag: fromTag, path: [], cost: 0 },
  ];

  while (queue.length > 0) {
    // Sort by cost for Dijkstra-like behavior
    queue.sort((a, b) => a.cost - b.cost);
    const current = queue.shift()!;

    if (current.path.length >= maxDepth) {
      continue;
    }

    if (visited.has(current.tag)) {
      continue;
    }
    visited.add(current.tag);

    // Get outgoing edges
    const outgoing = getCoercionsFrom(registryId, current.tag);
    for (const coercion of outgoing) {
      const newPath = [...current.path, coercion];
      const newCost = current.cost + coercion.cost;

      if (coercion.toTag === toTag) {
        // Found path
        return {
          steps: newPath,
          totalCost: newCost,
          argIndices: [],
          targetSig: [toTag],
        };
      }

      if (!visited.has(coercion.toTag)) {
        queue.push({ tag: coercion.toTag, path: newPath, cost: newCost });
      }
    }
  }

  // No path found
  return undefined;
}

/**
 * Find all coercion paths from one type to another.
 * Returns paths sorted by cost.
 */
export function findAllCoercionPaths(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag,
  maxDepth: number = 5,
  maxPaths: number = 10
): CoercionPath[] {
  if (fromTag === toTag) {
    return [{ steps: [], totalCost: 0, argIndices: [], targetSig: [toTag] }];
  }

  const paths: CoercionPath[] = [];

  // DFS to find all paths
  function dfs(
    current: TypeTag,
    path: CoercionEntry[],
    cost: number,
    visited: Set<TypeTag>
  ): void {
    if (paths.length >= maxPaths) return;
    if (path.length >= maxDepth) return;

    const outgoing = getCoercionsFrom(registryId, current);
    for (const coercion of outgoing) {
      if (visited.has(coercion.toTag)) continue;

      const newPath = [...path, coercion];
      const newCost = cost + coercion.cost;

      if (coercion.toTag === toTag) {
        paths.push({
          steps: newPath,
          totalCost: newCost,
          argIndices: [],
          targetSig: [toTag],
        });
      } else {
        const newVisited = new Set(visited);
        newVisited.add(coercion.toTag);
        dfs(coercion.toTag, newPath, newCost, newVisited);
      }
    }
  }

  dfs(fromTag, [], 0, new Set([fromTag]));

  // Sort by cost
  paths.sort((a, b) => a.totalCost - b.totalCost);
  return paths;
}

// ─────────────────────────────────────────────────────────────────
// Signature-Level Coercion
// ─────────────────────────────────────────────────────────────────

/**
 * Find a coercion path for a full signature.
 * Returns paths that coerce the source signature to the target signature.
 */
export function findSignatureCoercion(
  registryId: string,
  sourceSig: TypeSignature,
  targetSig: TypeSignature,
  maxDepth: number = 5
): CoercionPath | undefined {
  if (sourceSig.length !== targetSig.length) {
    return undefined;
  }

  const allSteps: CoercionEntry[] = [];
  const argIndices: number[] = [];
  let totalCost = 0;

  for (let i = 0; i < sourceSig.length; i++) {
    if (sourceSig[i] === targetSig[i]) {
      // No coercion needed for this argument
      continue;
    }

    const path = findCoercionPath(registryId, sourceSig[i], targetSig[i], maxDepth);
    if (!path) {
      // Can't coerce this argument
      return undefined;
    }

    allSteps.push(...path.steps);
    argIndices.push(i);
    totalCost += path.totalCost;
  }

  return {
    steps: allSteps,
    totalCost,
    argIndices,
    targetSig,
  };
}

/**
 * Find all possible target signatures that the source can be coerced to.
 */
export function findReachableSignatures(
  registryId: string,
  sourceSig: TypeSignature,
  maxDepth: number = 3
): Array<{ signature: TypeSignature; path: CoercionPath }> {
  const allTags = getAllTypeTags(registryId);
  const results: Array<{ signature: TypeSignature; path: CoercionPath }> = [];

  // For single-argument signatures, enumerate reachable types
  if (sourceSig.length === 1) {
    for (const targetTag of allTags) {
      const path = findCoercionPath(registryId, sourceSig[0], targetTag, maxDepth);
      if (path) {
        results.push({
          signature: [targetTag],
          path: { ...path, argIndices: [0] },
        });
      }
    }
  }
  // For multi-argument signatures, this becomes combinatorial
  // For now, just return direct coercions
  else {
    // Get all coercions for each position and combine
    const optionsPerArg: TypeTag[][] = [];
    for (let i = 0; i < sourceSig.length; i++) {
      const outgoing = getCoercionsFrom(registryId, sourceSig[i]);
      optionsPerArg.push([sourceSig[i], ...outgoing.map(c => c.toTag)]);
    }

    // Generate combinations (limited to avoid explosion)
    const combinations = generateCombinations(optionsPerArg, 100);
    for (const combo of combinations) {
      const path = findSignatureCoercion(registryId, sourceSig, combo, maxDepth);
      if (path) {
        results.push({ signature: combo, path });
      }
    }
  }

  // Sort by cost
  results.sort((a, b) => a.path.totalCost - b.path.totalCost);
  return results;
}

/**
 * Generate combinations of options (limited count).
 */
function generateCombinations<T>(options: T[][], maxCount: number): T[][] {
  const results: T[][] = [];

  function gen(index: number, current: T[]): void {
    if (results.length >= maxCount) return;
    if (index >= options.length) {
      results.push([...current]);
      return;
    }
    for (const opt of options[index]) {
      current.push(opt);
      gen(index + 1, current);
      current.pop();
    }
  }

  gen(0, []);
  return results;
}

// ─────────────────────────────────────────────────────────────────
// Ambiguity Detection
// ─────────────────────────────────────────────────────────────────

/**
 * Check if there are multiple equally-good coercion paths.
 */
export function detectAmbiguity(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag
): { ambiguous: boolean; paths: CoercionPath[] } {
  const paths = findAllCoercionPaths(registryId, fromTag, toTag, 5, 10);

  if (paths.length <= 1) {
    return { ambiguous: false, paths };
  }

  // Check if multiple paths have the same minimum cost
  const minCost = paths[0].totalCost;
  const minCostPaths = paths.filter(p => p.totalCost === minCost);

  if (minCostPaths.length > 1) {
    logGenericEvent({
      tag: "ambiguity",
      op: "coercion",
      signature: [fromTag, toTag],
      pathCount: minCostPaths.length,
      timestamp: Date.now(),
    });
    return { ambiguous: true, paths: minCostPaths };
  }

  return { ambiguous: false, paths };
}

/**
 * Check for ambiguity at the signature level.
 */
export function detectSignatureAmbiguity(
  registryId: string,
  sourceSig: TypeSignature,
  targetSig: TypeSignature
): { ambiguous: boolean; paths: CoercionPath[] } {
  const paths: CoercionPath[] = [];

  // For each argument that needs coercion, check for ambiguity
  for (let i = 0; i < sourceSig.length; i++) {
    if (sourceSig[i] !== targetSig[i]) {
      const { ambiguous, paths: argPaths } = detectAmbiguity(
        registryId,
        sourceSig[i],
        targetSig[i]
      );

      if (ambiguous) {
        // Found ambiguity in this argument
        for (const p of argPaths) {
          paths.push({ ...p, argIndices: [i] });
        }
        return { ambiguous: true, paths };
      }
    }
  }

  return { ambiguous: false, paths: [] };
}

// ─────────────────────────────────────────────────────────────────
// Coercion Application
// ─────────────────────────────────────────────────────────────────

/**
 * CoercionResult: Result of applying a coercion path.
 */
export type CoercionResult =
  | { tag: "success"; value: Val }
  | { tag: "error"; step: number; message: string };

/**
 * Apply a single coercion step.
 * Note: This is a stub that needs integration with the evaluator.
 */
export function applyCoercionStep(
  coercion: CoercionEntry,
  value: Val,
  applyFn: (proc: Val, args: Val[]) => Val
): CoercionResult {
  try {
    const result = applyFn(coercion.proc, [value]);
    return { tag: "success", value: result };
  } catch (error) {
    return {
      tag: "error",
      step: 0,
      message: error instanceof Error ? error.message : String(error),
    };
  }
}

/**
 * Apply a full coercion path.
 */
export function applyCoercionPath(
  path: CoercionPath,
  value: Val,
  applyFn: (proc: Val, args: Val[]) => Val
): CoercionResult {
  let current = value;

  for (let i = 0; i < path.steps.length; i++) {
    const result = applyCoercionStep(path.steps[i], current, applyFn);
    if (result.tag === "error") {
      return { ...result, step: i };
    }
    current = result.value;
  }

  return { tag: "success", value: current };
}

// ─────────────────────────────────────────────────────────────────
// Type Hierarchy Utilities
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a type is a subtype of another (based on coercion path).
 */
export function isSubtype(
  registryId: string,
  subTag: TypeTag,
  superTag: TypeTag
): boolean {
  if (subTag === superTag) return true;
  const path = findCoercionPath(registryId, subTag, superTag);
  return path !== undefined;
}

/**
 * Find the common supertype of two types (if any).
 */
export function findCommonSupertype(
  registryId: string,
  tag1: TypeTag,
  tag2: TypeTag
): TypeTag | undefined {
  if (tag1 === tag2) return tag1;

  const allTags = getAllTypeTags(registryId);

  // Find types reachable from both
  for (const candidate of allTags) {
    const path1 = findCoercionPath(registryId, tag1, candidate);
    const path2 = findCoercionPath(registryId, tag2, candidate);
    if (path1 && path2) {
      return candidate;
    }
  }

  return undefined;
}

/**
 * Get the transitive closure of reachable types from a source type.
 */
export function getReachableTypes(
  registryId: string,
  fromTag: TypeTag,
  maxDepth: number = 5
): Set<TypeTag> {
  const reachable = new Set<TypeTag>([fromTag]);
  const queue: Array<{ tag: TypeTag; depth: number }> = [{ tag: fromTag, depth: 0 }];

  while (queue.length > 0) {
    const { tag, depth } = queue.shift()!;
    if (depth >= maxDepth) continue;

    const outgoing = getCoercionsFrom(registryId, tag);
    for (const coercion of outgoing) {
      if (!reachable.has(coercion.toTag)) {
        reachable.add(coercion.toTag);
        queue.push({ tag: coercion.toTag, depth: depth + 1 });
      }
    }
  }

  return reachable;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/dispatch.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/dispatch.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Generic dispatch (apply-generic) implementation

import type { Val, GenericMissVal } from "../eval/values";
import { VUnit } from "../eval/values";
import {
  type TypeTag,
  type TypeSignature,
  type DispatchResult,
  type CoercionPath,
  type GenericMissPayload,
  type MethodEntry,
  extractSignature,
  getContents,
  isTagged,
  makeGenericMiss,
} from "./types";
import {
  getRegistry,
  lookupMethod,
  getMethodsForOp,
  logGenericEvent,
} from "./registry";
import {
  findSignatureCoercion,
  findReachableSignatures,
  detectSignatureAmbiguity,
  applyCoercionPath,
} from "./coercion";

// ─────────────────────────────────────────────────────────────────
// Dispatch Configuration
// ─────────────────────────────────────────────────────────────────

/**
 * DispatchConfig: Configuration for generic dispatch.
 */
export type DispatchConfig = {
  /** Maximum coercion depth */
  maxCoercionDepth: number;
  /** Whether to allow synthesized methods */
  allowSynthesis: boolean;
  /** Whether to reject on ambiguity */
  rejectAmbiguous: boolean;
  /** Profile name for miss payloads */
  profileName?: string;
  /** Budget limits */
  budgets?: {
    inferOps?: number;
    testRuns?: number;
  };
};

export const DEFAULT_DISPATCH_CONFIG: DispatchConfig = {
  maxCoercionDepth: 5,
  allowSynthesis: true,
  rejectAmbiguous: true,
};

// ─────────────────────────────────────────────────────────────────
// Core Dispatch
// ─────────────────────────────────────────────────────────────────

/**
 * Resolve a generic dispatch: find the method to apply.
 *
 * Resolution order:
 * 1. Exact signature match
 * 2. Coercion path to matching signature
 * 3. Return miss for synthesis
 */
export function resolveDispatch(
  registryId: string,
  op: string,
  args: Val[],
  config: Partial<DispatchConfig> = {}
): DispatchResult {
  const fullConfig = { ...DEFAULT_DISPATCH_CONFIG, ...config };
  const signature = extractSignature(args);

  // Log dispatch attempt
  logGenericEvent({
    tag: "dispatch",
    op,
    signature,
    result: "miss", // Will be updated if found
    timestamp: Date.now(),
  });

  // 1. Try exact match
  const exactMethod = lookupMethod(registryId, op, signature);
  if (exactMethod) {
    return { tag: "found", method: exactMethod };
  }

  // 2. Try coercion
  const coercionResult = tryCoercionDispatch(
    registryId,
    op,
    signature,
    fullConfig
  );
  if (coercionResult) {
    if (coercionResult.tag === "ambiguous" && fullConfig.rejectAmbiguous) {
      return coercionResult;
    }
    if (coercionResult.tag === "coerced") {
      return coercionResult;
    }
  }

  // 3. Return miss
  const missPayload: GenericMissPayload = {
    op,
    signature,
    argsPreview: args.map(redactArgForMiss),
    registryId,
    profileName: fullConfig.profileName,
    budgets: fullConfig.budgets,
  };

  logGenericEvent({
    tag: "miss",
    op,
    signature,
    registryId,
    timestamp: Date.now(),
  });

  return { tag: "miss", miss: missPayload };
}

/**
 * Try to find a method via coercion.
 */
function tryCoercionDispatch(
  registryId: string,
  op: string,
  sourceSig: TypeSignature,
  config: DispatchConfig
): DispatchResult | undefined {
  // Get all methods for this operation
  const methods = getMethodsForOp(registryId, op);
  if (methods.length === 0) {
    return undefined;
  }

  // For each method, check if we can coerce to its signature
  const candidates: Array<{ method: MethodEntry; path: CoercionPath }> = [];

  for (const method of methods) {
    const path = findSignatureCoercion(
      registryId,
      sourceSig,
      method.signature,
      config.maxCoercionDepth
    );

    if (path) {
      candidates.push({ method, path });
    }
  }

  if (candidates.length === 0) {
    return undefined;
  }

  // Sort by cost
  candidates.sort((a, b) => a.path.totalCost - b.path.totalCost);

  // Check for ambiguity (multiple candidates with same min cost)
  const minCost = candidates[0].path.totalCost;
  const minCostCandidates = candidates.filter(c => c.path.totalCost === minCost);

  if (minCostCandidates.length > 1) {
    return {
      tag: "ambiguous",
      paths: minCostCandidates.map(c => c.path),
    };
  }

  return {
    tag: "coerced",
    path: candidates[0].path,
    method: candidates[0].method,
  };
}

/**
 * Redact an argument for inclusion in a miss payload.
 */
function redactArgForMiss(arg: Val): Val {
  // For now, just include type info, not full content
  if (isTagged(arg)) {
    return {
      tag: "Map",
      entries: [
        [{ tag: "Sym", name: "typeTag" }, { tag: "Str", s: arg.typeTag }],
        [{ tag: "Sym", name: "redacted" }, { tag: "Bool", b: true }],
      ],
    };
  }
  // For primitives, include limited info
  switch (arg.tag) {
    case "Str":
      return {
        tag: "Map",
        entries: [
          [{ tag: "Sym", name: "type" }, { tag: "Str", s: "string" }],
          [{ tag: "Sym", name: "length" }, { tag: "Num", n: arg.s.length }],
        ],
      };
    case "Num":
      return arg; // Numbers are safe
    case "Bool":
      return arg; // Booleans are safe
    default:
      return { tag: "Sym", name: arg.tag };
  }
}

// ─────────────────────────────────────────────────────────────────
// Apply Generic
// ─────────────────────────────────────────────────────────────────

/**
 * ApplyResult: Result of applying a generic operation.
 */
export type ApplyResult =
  | { tag: "success"; value: Val }
  | { tag: "miss"; miss: GenericMissVal }
  | { tag: "ambiguous"; paths: CoercionPath[] }
  | { tag: "error"; message: string };

/**
 * Apply a generic operation to arguments.
 *
 * This is the main entry point for generic dispatch.
 */
export function applyGeneric(
  registryId: string,
  op: string,
  args: Val[],
  applyFn: (proc: Val, args: Val[]) => Val,
  config: Partial<DispatchConfig> = {}
): ApplyResult {
  const fullConfig = { ...DEFAULT_DISPATCH_CONFIG, ...config };

  // Resolve dispatch
  const dispatchResult = resolveDispatch(registryId, op, args, fullConfig);

  switch (dispatchResult.tag) {
    case "found": {
      // Direct method application
      try {
        // Extract contents from tagged values
        const unwrappedArgs = args.map(getContents);
        const value = applyFn(dispatchResult.method.proc, unwrappedArgs);
        return { tag: "success", value };
      } catch (error) {
        return {
          tag: "error",
          message: error instanceof Error ? error.message : String(error),
        };
      }
    }

    case "coerced": {
      // Apply coercions then method
      try {
        const coercedArgs = [...args];

        // Apply coercions to relevant arguments
        for (let i = 0; i < args.length; i++) {
          if (dispatchResult.path.argIndices.includes(i)) {
            // Find the coercion steps for this argument
            const argCoercions = dispatchResult.path.steps.filter(
              step => step.fromTag === extractSignature([args[i]])[0]
            );

            if (argCoercions.length > 0) {
              let current = getContents(args[i]);
              for (const step of argCoercions) {
                current = applyFn(step.proc, [current]);
              }
              coercedArgs[i] = current;
            }
          }
        }

        // Apply the method
        const unwrappedArgs = coercedArgs.map(getContents);
        const value = applyFn(dispatchResult.method.proc, unwrappedArgs);
        return { tag: "success", value };
      } catch (error) {
        return {
          tag: "error",
          message: error instanceof Error ? error.message : String(error),
        };
      }
    }

    case "miss": {
      const signature = extractSignature(args);
      const missVal = makeGenericMiss(
        op,
        signature,
        args.map(redactArgForMiss),
        registryId,
        fullConfig.profileName
      );
      return { tag: "miss", miss: missVal };
    }

    case "ambiguous": {
      return { tag: "ambiguous", paths: dispatchResult.paths };
    }

    case "error": {
      return { tag: "error", message: dispatchResult.message };
    }
  }
}

// ─────────────────────────────────────────────────────────────────
// Dispatch with Miss Handler
// ─────────────────────────────────────────────────────────────────

/**
 * MissHandler: Handler for generic misses.
 */
export type MissHandler = (miss: GenericMissPayload) => Promise<MissHandlerResult>;

/**
 * MissHandlerResult: Result of handling a miss.
 */
export type MissHandlerResult =
  | { tag: "resolved"; proc: Val; commit: boolean }
  | { tag: "failed"; reason: string };

/**
 * Apply generic with miss handling.
 */
export async function applyGenericWithMissHandler(
  registryId: string,
  op: string,
  args: Val[],
  applyFn: (proc: Val, args: Val[]) => Val,
  missHandler: MissHandler,
  config: Partial<DispatchConfig> = {}
): Promise<ApplyResult> {
  // First try normal dispatch
  const result = applyGeneric(registryId, op, args, applyFn, config);

  if (result.tag !== "miss") {
    return result;
  }

  // Handle the miss
  const missPayload: GenericMissPayload = {
    op,
    signature: extractSignature(args),
    argsPreview: args.map(redactArgForMiss),
    registryId,
    profileName: config.profileName,
    budgets: config.budgets,
  };

  const handlerResult = await missHandler(missPayload);

  if (handlerResult.tag === "failed") {
    return { tag: "error", message: handlerResult.reason };
  }

  // Apply the resolved procedure
  try {
    const unwrappedArgs = args.map(getContents);
    const value = applyFn(handlerResult.proc, unwrappedArgs);
    return { tag: "success", value };
  } catch (error) {
    return {
      tag: "error",
      message: error instanceof Error ? error.message : String(error),
    };
  }
}

// ─────────────────────────────────────────────────────────────────
// Introspection
// ─────────────────────────────────────────────────────────────────

/**
 * Get dispatch info without actually dispatching.
 */
export function getDispatchInfo(
  registryId: string,
  op: string,
  signature: TypeSignature
): {
  exactMatch: boolean;
  coercionAvailable: boolean;
  candidateCount: number;
  ambiguous: boolean;
} {
  const exactMethod = lookupMethod(registryId, op, signature);
  if (exactMethod) {
    return {
      exactMatch: true,
      coercionAvailable: false,
      candidateCount: 1,
      ambiguous: false,
    };
  }

  const methods = getMethodsForOp(registryId, op);
  let candidateCount = 0;
  let ambiguousPaths = 0;

  for (const method of methods) {
    const path = findSignatureCoercion(registryId, signature, method.signature);
    if (path) {
      candidateCount++;
    }
  }

  return {
    exactMatch: false,
    coercionAvailable: candidateCount > 0,
    candidateCount,
    ambiguous: candidateCount > 1,
  };
}

/**
 * List all applicable methods for a signature (including via coercion).
 */
export function listApplicableMethods(
  registryId: string,
  op: string,
  signature: TypeSignature
): Array<{ method: MethodEntry; path?: CoercionPath }> {
  const results: Array<{ method: MethodEntry; path?: CoercionPath }> = [];

  // Check exact match
  const exactMethod = lookupMethod(registryId, op, signature);
  if (exactMethod) {
    results.push({ method: exactMethod });
  }

  // Check coerced matches
  const methods = getMethodsForOp(registryId, op);
  for (const method of methods) {
    if (method === exactMethod) continue;

    const path = findSignatureCoercion(registryId, signature, method.signature);
    if (path) {
      results.push({ method, path });
    }
  }

  return results;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Generic operations (data-directed programming + coercion towers)

export * from "./types";
export * from "./registry";
export * from "./coercion";
export * from "./dispatch";
export * from "./synthesis";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/registry.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/registry.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Generic registry for method and coercion tables

import type { Val, GenericRegistryVal } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import {
  type TypeTag,
  type TypeSignature,
  type SignatureKey,
  type MethodEntry,
  type MethodTable,
  type CoercionEntry,
  type CoercionTable,
  type GenericOpDef,
  type RegistryState,
  type GenericEvent,
  signatureToKey,
  makeGenericRegistry,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Registry Store
// ─────────────────────────────────────────────────────────────────

const registryStore = new Map<string, RegistryState>();
let nextRegistryId = 0;

/**
 * Generate a unique registry ID.
 */
function genRegistryId(): string {
  return `registry-${nextRegistryId++}`;
}

/**
 * Reset the registry store (for testing).
 */
export function resetRegistryStore(): void {
  registryStore.clear();
  nextRegistryId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Registry Creation and Access
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new generic operations registry.
 */
export function createRegistry(name?: string): GenericRegistryVal {
  const id = genRegistryId();
  const state: RegistryState = {
    id,
    name,
    ops: new Map(),
    methods: new Map(),
    coercions: new Map(),
    stats: {
      methodHits: 0,
      methodMisses: 0,
      coercionHits: 0,
      coercionMisses: 0,
      synthesisCalls: 0,
    },
    createdAt: Date.now(),
  };
  registryStore.set(id, state);
  return makeGenericRegistry(id, name);
}

/**
 * Get a registry by ID.
 */
export function getRegistry(id: string): RegistryState | undefined {
  return registryStore.get(id);
}

/**
 * Clone a registry (for exploration/speculation).
 */
export function cloneRegistry(state: RegistryState): RegistryState {
  const id = genRegistryId();
  const cloned: RegistryState = {
    id,
    name: state.name ? `${state.name}-clone` : undefined,
    ops: new Map(state.ops),
    methods: cloneMethodTable(state.methods),
    coercions: cloneCoercionTable(state.coercions),
    stats: { ...state.stats },
    createdAt: Date.now(),
  };
  registryStore.set(id, cloned);
  return cloned;
}

function cloneMethodTable(table: MethodTable): MethodTable {
  const cloned = new Map<string, Map<SignatureKey, MethodEntry>>();
  for (const [op, sigMap] of table) {
    cloned.set(op, new Map(sigMap));
  }
  return cloned;
}

function cloneCoercionTable(table: CoercionTable): CoercionTable {
  const cloned = new Map<TypeTag, Map<TypeTag, CoercionEntry>>();
  for (const [from, toMap] of table) {
    cloned.set(from, new Map(toMap));
  }
  return cloned;
}

// ─────────────────────────────────────────────────────────────────
// Generic Operation Definition
// ─────────────────────────────────────────────────────────────────

/**
 * Define a generic operation.
 */
export function defGeneric(
  registryId: string,
  name: string,
  arity: number,
  options: { contract?: Val; sealed?: boolean } = {}
): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;

  if (registry.ops.has(name)) {
    // Already defined
    return false;
  }

  const def: GenericOpDef = {
    name,
    arity,
    contract: options.contract,
    sealed: options.sealed ?? false,
    createdAt: Date.now(),
  };

  registry.ops.set(name, def);
  return true;
}

/**
 * Get a generic operation definition.
 */
export function getGenericOp(registryId: string, name: string): GenericOpDef | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;
  return registry.ops.get(name);
}

/**
 * Check if a generic operation is defined.
 */
export function hasGenericOp(registryId: string, name: string): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;
  return registry.ops.has(name);
}

// ─────────────────────────────────────────────────────────────────
// Method Table Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Register a method for a generic operation.
 */
export function defMethod(
  registryId: string,
  op: string,
  signature: TypeSignature,
  proc: Val,
  options: { synthesized?: boolean; commitHash?: Hash; meta?: MethodEntry["meta"] } = {}
): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;

  // Check if operation is sealed
  const opDef = registry.ops.get(op);
  if (opDef?.sealed) {
    return false;
  }

  // Get or create method map for this operation
  let sigMap = registry.methods.get(op);
  if (!sigMap) {
    sigMap = new Map();
    registry.methods.set(op, sigMap);
  }

  const key = signatureToKey(signature);
  const entry: MethodEntry = {
    op,
    signature,
    proc,
    synthesized: options.synthesized ?? false,
    commitHash: options.commitHash,
    createdAt: Date.now(),
    meta: options.meta,
  };

  sigMap.set(key, entry);
  return true;
}

/**
 * Look up a method by operation and signature.
 */
export function lookupMethod(
  registryId: string,
  op: string,
  signature: TypeSignature
): MethodEntry | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;

  const sigMap = registry.methods.get(op);
  if (!sigMap) return undefined;

  const key = signatureToKey(signature);
  const entry = sigMap.get(key);

  // Update stats
  if (entry) {
    registry.stats.methodHits++;
  } else {
    registry.stats.methodMisses++;
  }

  return entry;
}

/**
 * Remove a method.
 */
export function removeMethod(
  registryId: string,
  op: string,
  signature: TypeSignature
): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;

  const sigMap = registry.methods.get(op);
  if (!sigMap) return false;

  const key = signatureToKey(signature);
  return sigMap.delete(key);
}

/**
 * Get all methods for an operation.
 */
export function getMethodsForOp(registryId: string, op: string): MethodEntry[] {
  const registry = registryStore.get(registryId);
  if (!registry) return [];

  const sigMap = registry.methods.get(op);
  if (!sigMap) return [];

  return Array.from(sigMap.values());
}

/**
 * Get all registered operations with their method counts.
 */
export function listOperations(registryId: string): Array<{ op: string; methodCount: number }> {
  const registry = registryStore.get(registryId);
  if (!registry) return [];

  return Array.from(registry.methods.entries()).map(([op, sigMap]) => ({
    op,
    methodCount: sigMap.size,
  }));
}

// ─────────────────────────────────────────────────────────────────
// Coercion Table Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Register a coercion between types.
 */
export function defCoercion(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag,
  proc: Val,
  options: { lossy?: boolean; synthesized?: boolean; commitHash?: Hash; cost?: number } = {}
): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;

  // Get or create coercion map for source type
  let toMap = registry.coercions.get(fromTag);
  if (!toMap) {
    toMap = new Map();
    registry.coercions.set(fromTag, toMap);
  }

  const entry: CoercionEntry = {
    fromTag,
    toTag,
    proc,
    lossy: options.lossy ?? false,
    synthesized: options.synthesized ?? false,
    commitHash: options.commitHash,
    createdAt: Date.now(),
    cost: options.cost ?? 1,
  };

  toMap.set(toTag, entry);
  return true;
}

/**
 * Look up a direct coercion.
 */
export function lookupCoercion(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag
): CoercionEntry | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;

  const toMap = registry.coercions.get(fromTag);
  if (!toMap) return undefined;

  const entry = toMap.get(toTag);

  // Update stats
  if (entry) {
    registry.stats.coercionHits++;
  } else {
    registry.stats.coercionMisses++;
  }

  return entry;
}

/**
 * Remove a coercion.
 */
export function removeCoercion(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag
): boolean {
  const registry = registryStore.get(registryId);
  if (!registry) return false;

  const toMap = registry.coercions.get(fromTag);
  if (!toMap) return false;

  return toMap.delete(toTag);
}

/**
 * Get all coercions from a type.
 */
export function getCoercionsFrom(registryId: string, fromTag: TypeTag): CoercionEntry[] {
  const registry = registryStore.get(registryId);
  if (!registry) return [];

  const toMap = registry.coercions.get(fromTag);
  if (!toMap) return [];

  return Array.from(toMap.values());
}

/**
 * Get all coercions to a type.
 */
export function getCoercionsTo(registryId: string, toTag: TypeTag): CoercionEntry[] {
  const registry = registryStore.get(registryId);
  if (!registry) return [];

  const results: CoercionEntry[] = [];
  for (const toMap of registry.coercions.values()) {
    const entry = toMap.get(toTag);
    if (entry) {
      results.push(entry);
    }
  }
  return results;
}

/**
 * Get all registered type tags (from coercion table).
 */
export function getAllTypeTags(registryId: string): TypeTag[] {
  const registry = registryStore.get(registryId);
  if (!registry) return [];

  const tags = new Set<TypeTag>();
  for (const [from, toMap] of registry.coercions) {
    tags.add(from);
    for (const to of toMap.keys()) {
      tags.add(to);
    }
  }
  return Array.from(tags);
}

// ─────────────────────────────────────────────────────────────────
// Registry Statistics
// ─────────────────────────────────────────────────────────────────

/**
 * Get registry statistics.
 */
export function getRegistryStats(registryId: string): RegistryState["stats"] | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;
  return { ...registry.stats };
}

/**
 * Increment synthesis call count.
 */
export function incrementSynthesisCalls(registryId: string): void {
  const registry = registryStore.get(registryId);
  if (registry) {
    registry.stats.synthesisCalls++;
  }
}

// ─────────────────────────────────────────────────────────────────
// Commit Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Commit a method with a hash.
 */
export function commitMethod(
  registryId: string,
  op: string,
  signature: TypeSignature,
  proc: Val
): Hash | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;

  const commitHash = sha256JSON({ op, signature, proc, timestamp: Date.now() });

  const success = defMethod(registryId, op, signature, proc, {
    synthesized: true,
    commitHash,
    meta: { source: "inferred" },
  });

  return success ? commitHash : undefined;
}

/**
 * Commit a coercion with a hash.
 */
export function commitCoercion(
  registryId: string,
  fromTag: TypeTag,
  toTag: TypeTag,
  proc: Val
): Hash | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;

  const commitHash = sha256JSON({ fromTag, toTag, proc, timestamp: Date.now() });

  const success = defCoercion(registryId, fromTag, toTag, proc, {
    synthesized: true,
    commitHash,
  });

  return success ? commitHash : undefined;
}

// ─────────────────────────────────────────────────────────────────
// Event Logging
// ─────────────────────────────────────────────────────────────────

const eventLog: GenericEvent[] = [];

/**
 * Log a generic event.
 */
export function logGenericEvent(event: GenericEvent): void {
  eventLog.push(event);
}

/**
 * Get recent events.
 */
export function getRecentEvents(limit: number = 100): GenericEvent[] {
  return eventLog.slice(-limit);
}

/**
 * Clear event log (for testing).
 */
export function clearEventLog(): void {
  eventLog.length = 0;
}

/**
 * Count events by type.
 */
export function countEvents(tag: GenericEvent["tag"]): number {
  return eventLog.filter(e => e.tag === tag).length;
}

// ─────────────────────────────────────────────────────────────────
// Registry Introspection
// ─────────────────────────────────────────────────────────────────

/**
 * Get a summary of the registry.
 */
export function getRegistrySummary(registryId: string): {
  id: string;
  name?: string;
  opCount: number;
  methodCount: number;
  coercionCount: number;
  stats: RegistryState["stats"];
} | undefined {
  const registry = registryStore.get(registryId);
  if (!registry) return undefined;

  let methodCount = 0;
  for (const sigMap of registry.methods.values()) {
    methodCount += sigMap.size;
  }

  let coercionCount = 0;
  for (const toMap of registry.coercions.values()) {
    coercionCount += toMap.size;
  }

  return {
    id: registry.id,
    name: registry.name,
    opCount: registry.ops.size,
    methodCount,
    coercionCount,
    stats: { ...registry.stats },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/synthesis.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/synthesis.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Method and coercion synthesis via inference + search

import type { Val } from "../eval/values";
import { VUnit, VTrue, VFalse } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import {
  type TypeTag,
  type TypeSignature,
  type GenericMissPayload,
  type SynthesisCandidate,
  type SynthesisResult,
  type CommitRequest,
  type CommitResult,
  type ObligationRef,
} from "./types";
import {
  getRegistry,
  defMethod,
  defCoercion,
  commitMethod,
  commitCoercion,
  incrementSynthesisCalls,
  logGenericEvent,
} from "./registry";

// ─────────────────────────────────────────────────────────────────
// Singleflight for Synthesis
// ─────────────────────────────────────────────────────────────────

/**
 * SynthesisKey: Key for deduplicating synthesis requests.
 */
export type SynthesisKey = string;

/**
 * Generate a synthesis key from a miss payload.
 */
export function generateSynthesisKey(miss: GenericMissPayload): SynthesisKey {
  return sha256JSON({
    op: miss.op,
    signature: miss.signature,
    registryId: miss.registryId,
  });
}

/**
 * In-flight synthesis tracking for singleflight.
 */
const inFlightSynthesis = new Map<SynthesisKey, {
  promise: Promise<SynthesisResult>;
  startedAt: number;
}>();

/**
 * Check if a synthesis is in-flight.
 */
export function isSynthesisInFlight(key: SynthesisKey): boolean {
  return inFlightSynthesis.has(key);
}

/**
 * Get the in-flight synthesis promise.
 */
export function getInFlightSynthesis(key: SynthesisKey): Promise<SynthesisResult> | undefined {
  return inFlightSynthesis.get(key)?.promise;
}

/**
 * Register an in-flight synthesis.
 */
export function registerInFlightSynthesis(
  key: SynthesisKey,
  promise: Promise<SynthesisResult>
): void {
  inFlightSynthesis.set(key, { promise, startedAt: Date.now() });

  // Clean up after completion
  promise.finally(() => {
    inFlightSynthesis.delete(key);
  });
}

/**
 * Clear in-flight synthesis (for testing).
 */
export function clearInFlightSynthesis(): void {
  inFlightSynthesis.clear();
}

// ─────────────────────────────────────────────────────────────────
// Synthesis Strategies
// ─────────────────────────────────────────────────────────────────

/**
 * SynthesisStrategy: Strategy for generating method candidates.
 */
export type SynthesisStrategy = {
  name: string;
  generateCandidates: (miss: GenericMissPayload) => Promise<SynthesisCandidate[]>;
};

/**
 * Default synthesis strategies.
 */
export const defaultStrategies: SynthesisStrategy[] = [];

/**
 * Register a synthesis strategy.
 */
export function registerStrategy(strategy: SynthesisStrategy): void {
  defaultStrategies.push(strategy);
}

/**
 * Clear strategies (for testing).
 */
export function clearStrategies(): void {
  defaultStrategies.length = 0;
}

// ─────────────────────────────────────────────────────────────────
// Synthesis Orchestration
// ─────────────────────────────────────────────────────────────────

/**
 * SynthesisConfig: Configuration for synthesis.
 */
export type SynthesisConfig = {
  /** Maximum candidates to consider */
  maxCandidates: number;
  /** Minimum confidence threshold */
  minConfidence: number;
  /** Whether to require passing tests before returning */
  requireTests: boolean;
  /** Strategies to use */
  strategies: SynthesisStrategy[];
  /** Test runner function */
  testRunner?: (proc: Val, sig: TypeSignature) => Promise<boolean>;
  /** Inference function */
  inferenceFn?: (prompt: Val) => Promise<Val>;
};

export const DEFAULT_SYNTHESIS_CONFIG: SynthesisConfig = {
  maxCandidates: 5,
  minConfidence: 0.5,
  requireTests: true,
  strategies: [],
};

/**
 * Synthesize a method for a miss.
 */
export async function synthesizeMethod(
  miss: GenericMissPayload,
  config: Partial<SynthesisConfig> = {}
): Promise<SynthesisResult> {
  const fullConfig = { ...DEFAULT_SYNTHESIS_CONFIG, ...config };
  const key = generateSynthesisKey(miss);

  // Check for singleflight
  const existing = getInFlightSynthesis(key);
  if (existing) {
    return existing;
  }

  // Track synthesis call
  incrementSynthesisCalls(miss.registryId);

  // Create promise and register for singleflight
  const promise = doSynthesis(miss, fullConfig);
  registerInFlightSynthesis(key, promise);

  return promise;
}

/**
 * Internal synthesis implementation.
 */
async function doSynthesis(
  miss: GenericMissPayload,
  config: SynthesisConfig
): Promise<SynthesisResult> {
  logGenericEvent({
    tag: "synthesis",
    op: miss.op,
    signature: miss.signature,
    candidateCount: 0,
    timestamp: Date.now(),
  });

  // Collect candidates from all strategies
  const candidates: SynthesisCandidate[] = [];
  const strategies = config.strategies.length > 0 ? config.strategies : defaultStrategies;

  for (const strategy of strategies) {
    try {
      const strategyCandidates = await strategy.generateCandidates(miss);
      candidates.push(...strategyCandidates);
    } catch {
      // Strategy failed, continue with others
    }
  }

  // Filter by confidence
  const viableCandidates = candidates
    .filter(c => c.confidence >= config.minConfidence)
    .sort((a, b) => b.confidence - a.confidence)
    .slice(0, config.maxCandidates);

  if (viableCandidates.length === 0) {
    return {
      tag: "failure",
      reason: "No viable candidates found",
      candidates: candidates.slice(0, 3),
    };
  }

  // Test candidates if required
  if (config.requireTests && config.testRunner) {
    for (const candidate of viableCandidates) {
      const passed = await config.testRunner(candidate.proc, miss.signature);
      if (passed) {
        return {
          tag: "success",
          candidate,
          testsPassed: true,
        };
      }
    }

    return {
      tag: "failure",
      reason: "All candidates failed tests",
      candidates: viableCandidates,
    };
  }

  // Return best candidate without tests
  return {
    tag: "success",
    candidate: viableCandidates[0],
    testsPassed: false,
  };
}

// ─────────────────────────────────────────────────────────────────
// Commitment
// ─────────────────────────────────────────────────────────────────

/**
 * CommitConfig: Configuration for committing synthesized methods.
 */
export type CommitConfig = {
  /** Required capabilities for commit */
  requiredCaps: string[];
  /** Whether to verify obligations before commit */
  verifyObligations: boolean;
  /** Obligation verifier function */
  obligationVerifier?: (obligations: ObligationRef[]) => Promise<ObligationRef[]>;
};

export const DEFAULT_COMMIT_CONFIG: CommitConfig = {
  requiredCaps: ["cap.generic.method.define"],
  verifyObligations: true,
};

/**
 * Commit a synthesized method to the registry.
 */
export async function commitSynthesizedMethod(
  request: CommitRequest,
  availableCaps: Set<string>,
  config: Partial<CommitConfig> = {}
): Promise<CommitResult> {
  const fullConfig = { ...DEFAULT_COMMIT_CONFIG, ...config };

  // Check capabilities
  const missingCaps = fullConfig.requiredCaps.filter(cap => !availableCaps.has(cap));
  if (missingCaps.length > 0) {
    return {
      tag: "denied",
      reason: "Missing required capabilities",
      missingCaps,
    };
  }

  // Verify obligations if required
  if (fullConfig.verifyObligations && fullConfig.obligationVerifier) {
    const verifiedObligations = await fullConfig.obligationVerifier(request.obligations);
    const failedObligations = verifiedObligations.filter(o => !o.satisfied);

    if (failedObligations.length > 0) {
      return {
        tag: "failed",
        failedObligations,
      };
    }
  }

  // Perform commit based on kind
  if (request.kind === "method" && request.op && request.signature) {
    const hash = commitMethod(
      request.registryId,
      request.op,
      request.signature,
      request.proc
    );

    if (!hash) {
      return {
        tag: "denied",
        reason: "Failed to commit method to registry",
      };
    }

    const entry = {
      op: request.op,
      signature: request.signature,
      proc: request.proc,
      synthesized: true,
      commitHash: hash,
      createdAt: Date.now(),
    };

    logGenericEvent({
      tag: "commit",
      kind: "method",
      hash,
      timestamp: Date.now(),
    });

    return { tag: "committed", hash, entry };
  }

  if (request.kind === "coercion" && request.fromTag && request.toTag) {
    const hash = commitCoercion(
      request.registryId,
      request.fromTag,
      request.toTag,
      request.proc
    );

    if (!hash) {
      return {
        tag: "denied",
        reason: "Failed to commit coercion to registry",
      };
    }

    const entry = {
      fromTag: request.fromTag,
      toTag: request.toTag,
      proc: request.proc,
      lossy: false,
      synthesized: true,
      commitHash: hash,
      createdAt: Date.now(),
      cost: 1,
    };

    logGenericEvent({
      tag: "commit",
      kind: "coercion",
      hash,
      timestamp: Date.now(),
    });

    return { tag: "committed", hash, entry };
  }

  return {
    tag: "denied",
    reason: "Invalid commit request",
  };
}

// ─────────────────────────────────────────────────────────────────
// Obligation Management
// ─────────────────────────────────────────────────────────────────

let nextObligationId = 0;

/**
 * Create an obligation reference.
 */
export function createObligation(
  kind: ObligationRef["kind"],
  description?: string
): ObligationRef {
  return {
    id: `obligation-${nextObligationId++}`,
    kind,
    description,
    satisfied: false,
  };
}

/**
 * Mark an obligation as satisfied.
 */
export function satisfyObligation(obligation: ObligationRef): ObligationRef {
  return { ...obligation, satisfied: true };
}

/**
 * Create test obligations for a method.
 */
export function createTestObligations(
  op: string,
  signature: TypeSignature,
  testCases: Array<{ input: Val; expected: Val }>
): ObligationRef[] {
  return testCases.map((tc, i) =>
    createObligation("test", `Test ${i + 1}: ${op}(${signature.join(", ")})`)
  );
}

/**
 * Create metamorphic test obligations.
 */
export function createMetamorphicObligations(
  op: string,
  properties: string[]
): ObligationRef[] {
  return properties.map(prop =>
    createObligation("metamorphic", `Metamorphic: ${prop}`)
  );
}

// ─────────────────────────────────────────────────────────────────
// Cost-Aware Selection
// ─────────────────────────────────────────────────────────────────

/**
 * SelectionCriteria: Criteria for selecting among candidates.
 */
export type SelectionCriteria = {
  /** Weight for confidence score */
  confidenceWeight: number;
  /** Weight for estimated cost */
  costWeight: number;
  /** Weight for complexity */
  complexityWeight: number;
  /** Hard constraints that must be satisfied */
  hardConstraints: Array<(c: SynthesisCandidate) => boolean>;
};

export const DEFAULT_SELECTION_CRITERIA: SelectionCriteria = {
  confidenceWeight: 0.5,
  costWeight: 0.3,
  complexityWeight: 0.2,
  hardConstraints: [],
};

/**
 * Score a candidate based on criteria.
 */
export function scoreCandidate(
  candidate: SynthesisCandidate,
  criteria: Partial<SelectionCriteria> = {}
): number {
  const fullCriteria = { ...DEFAULT_SELECTION_CRITERIA, ...criteria };

  // Check hard constraints
  for (const constraint of fullCriteria.hardConstraints) {
    if (!constraint(candidate)) {
      return -Infinity;
    }
  }

  // Calculate score
  const confidenceScore = candidate.confidence * fullCriteria.confidenceWeight;

  // Estimate cost (lower is better)
  const costEstimate = estimateCandidateCost(candidate);
  const costScore = (1 - Math.min(costEstimate / 10, 1)) * fullCriteria.costWeight;

  // Estimate complexity (lower is better)
  const complexityEstimate = estimateCandidateComplexity(candidate);
  const complexityScore = (1 - Math.min(complexityEstimate / 10, 1)) * fullCriteria.complexityWeight;

  return confidenceScore + costScore + complexityScore;
}

/**
 * Estimate the cost of a candidate (oracle calls, etc.).
 */
function estimateCandidateCost(candidate: SynthesisCandidate): number {
  // This would analyze the procedure to estimate oracle call count
  // For now, return a simple estimate
  return candidate.kind === "coercion" ? 1 : 2;
}

/**
 * Estimate the complexity of a candidate.
 */
function estimateCandidateComplexity(candidate: SynthesisCandidate): number {
  // This would analyze the procedure structure
  // For now, return a simple estimate
  return 1;
}

/**
 * Select the best candidate from a list.
 */
export function selectBestCandidate(
  candidates: SynthesisCandidate[],
  criteria: Partial<SelectionCriteria> = {}
): SynthesisCandidate | undefined {
  if (candidates.length === 0) return undefined;

  const scored = candidates.map(c => ({
    candidate: c,
    score: scoreCandidate(c, criteria),
  }));

  scored.sort((a, b) => b.score - a.score);

  // Return best if score is valid
  if (scored[0].score > -Infinity) {
    return scored[0].candidate;
  }

  return undefined;
}

// ─────────────────────────────────────────────────────────────────
// Profile Integration
// ─────────────────────────────────────────────────────────────────

/**
 * Check if synthesis is allowed under a profile.
 */
export function canSynthesize(
  profileName: string,
  kind: "method" | "coercion"
): boolean {
  // Profile checking would integrate with governance system
  // For now, basic rules:
  switch (profileName) {
    case "explore":
      return true; // Can synthesize but not commit
    case "pragmatic":
      return true; // Can synthesize and commit with tests
    case "strict":
      return true; // Can synthesize with heavy obligations
    case "airgap":
      return false; // No synthesis allowed
    default:
      return true;
  }
}

/**
 * Check if commit is allowed under a profile.
 */
export function canCommit(
  profileName: string,
  kind: "method" | "coercion"
): boolean {
  switch (profileName) {
    case "explore":
      return false; // Cannot commit
    case "pragmatic":
      return true; // Can commit with tests
    case "strict":
      return true; // Can commit with obligations
    case "airgap":
      return false; // No commits allowed
    default:
      return true;
  }
}

/**
 * Get required obligations for a profile.
 */
export function getRequiredObligations(
  profileName: string,
  kind: "method" | "coercion"
): ObligationRef["kind"][] {
  switch (profileName) {
    case "explore":
      return [];
    case "pragmatic":
      return ["test"];
    case "strict":
      return ["test", "metamorphic", "invariant"];
    case "airgap":
      return [];
    default:
      return ["test"];
  }
}

// ─────────────────────────────────────────────────────────────────
// Reset for Testing
// ─────────────────────────────────────────────────────────────────

/**
 * Reset all synthesis state (for testing).
 */
export function resetSynthesisState(): void {
  clearInFlightSynthesis();
  clearStrategies();
  nextObligationId = 0;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/generic/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/generic/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 14: Generic operations types (data-directed programming + coercion towers)

import type { Val, TaggedVal, GenericRegistryVal, GenericMissVal } from "../eval/values";
import type { Hash } from "../artifacts/hash";

// ─────────────────────────────────────────────────────────────────
// Type Tag Types
// ─────────────────────────────────────────────────────────────────

/**
 * TypeTag: A semantic type identifier (e.g., "Text/Plain", "Doc/Email").
 * Uses hierarchical naming convention.
 */
export type TypeTag = string;

/**
 * TypeSignature: A list of type tags representing method signature.
 */
export type TypeSignature = TypeTag[];

/**
 * SignatureKey: Canonical string representation of a signature for table lookup.
 */
export type SignatureKey = string;

/**
 * Convert a signature to a canonical key.
 */
export function signatureToKey(sig: TypeSignature): SignatureKey {
  return sig.join(",");
}

/**
 * Parse a key back to a signature.
 */
export function keyToSignature(key: SignatureKey): TypeSignature {
  return key.split(",").filter(s => s.length > 0);
}

// ─────────────────────────────────────────────────────────────────
// Method Table
// ─────────────────────────────────────────────────────────────────

/**
 * MethodEntry: A registered method for a generic operation.
 */
export type MethodEntry = {
  /** The operation name */
  op: string;
  /** Type signature this method handles */
  signature: TypeSignature;
  /** The implementation procedure */
  proc: Val;
  /** Whether this method was synthesized */
  synthesized: boolean;
  /** Commit hash if committed via truth regime */
  commitHash?: Hash;
  /** Creation timestamp */
  createdAt: number;
  /** Metadata */
  meta?: {
    description?: string;
    source?: "manual" | "inferred" | "coerced";
  };
};

/**
 * MethodTable: Maps op × signature to method entries.
 */
export type MethodTable = Map<string, Map<SignatureKey, MethodEntry>>;

// ─────────────────────────────────────────────────────────────────
// Coercion Table
// ─────────────────────────────────────────────────────────────────

/**
 * CoercionEntry: A registered coercion between types.
 */
export type CoercionEntry = {
  /** Source type tag */
  fromTag: TypeTag;
  /** Target type tag */
  toTag: TypeTag;
  /** The coercion procedure */
  proc: Val;
  /** Whether this coercion is lossy */
  lossy: boolean;
  /** Whether this coercion was synthesized */
  synthesized: boolean;
  /** Commit hash if committed via truth regime */
  commitHash?: Hash;
  /** Creation timestamp */
  createdAt: number;
  /** Cost/priority for path selection (lower = preferred) */
  cost: number;
};

/**
 * CoercionTable: Maps fromTag × toTag to coercion entries.
 */
export type CoercionTable = Map<TypeTag, Map<TypeTag, CoercionEntry>>;

// ─────────────────────────────────────────────────────────────────
// Generic Operation Definition
// ─────────────────────────────────────────────────────────────────

/**
 * GenericOpDef: Definition of a generic operation.
 */
export type GenericOpDef = {
  /** Operation name */
  name: string;
  /** Expected arity */
  arity: number;
  /** Optional contract/spec for validation */
  contract?: Val;
  /** Whether the operation is sealed (no more methods can be added) */
  sealed: boolean;
  /** Creation timestamp */
  createdAt: number;
};

// ─────────────────────────────────────────────────────────────────
// Registry State
// ─────────────────────────────────────────────────────────────────

/**
 * RegistryState: Internal state of a generic operations registry.
 */
export type RegistryState = {
  /** Registry ID */
  id: string;
  /** Human-readable name */
  name?: string;
  /** Generic operation definitions */
  ops: Map<string, GenericOpDef>;
  /** Method table */
  methods: MethodTable;
  /** Coercion table */
  coercions: CoercionTable;
  /** Statistics */
  stats: {
    methodHits: number;
    methodMisses: number;
    coercionHits: number;
    coercionMisses: number;
    synthesisCalls: number;
  };
  /** Creation timestamp */
  createdAt: number;
};

// ─────────────────────────────────────────────────────────────────
// Dispatch Result Types
// ─────────────────────────────────────────────────────────────────

/**
 * DispatchResult: Result of attempting to dispatch a generic operation.
 */
export type DispatchResult =
  | { tag: "found"; method: MethodEntry }
  | { tag: "coerced"; path: CoercionPath; method: MethodEntry }
  | { tag: "miss"; miss: GenericMissPayload }
  | { tag: "ambiguous"; paths: CoercionPath[] }
  | { tag: "error"; message: string };

/**
 * CoercionPath: A sequence of coercions to apply.
 */
export type CoercionPath = {
  /** Steps in the coercion path */
  steps: CoercionEntry[];
  /** Total cost of the path */
  totalCost: number;
  /** Indices of arguments that need coercion */
  argIndices: number[];
  /** Target signature after coercion */
  targetSig: TypeSignature;
};

/**
 * GenericMissPayload: Information about a failed dispatch for synthesis.
 */
export type GenericMissPayload = {
  /** The operation that missed */
  op: string;
  /** The type signature */
  signature: TypeSignature;
  /** Preview of arguments (possibly redacted) */
  argsPreview: Val[];
  /** Registry reference */
  registryId: string;
  /** Environment hash for context */
  envHash?: Hash;
  /** Profile name */
  profileName?: string;
  /** Available budget */
  budgets?: {
    inferOps?: number;
    testRuns?: number;
  };
};

// ─────────────────────────────────────────────────────────────────
// Synthesis Types
// ─────────────────────────────────────────────────────────────────

/**
 * SynthesisCandidate: A candidate method or coercion from inference.
 */
export type SynthesisCandidate = {
  /** Candidate ID */
  id: string;
  /** The candidate procedure */
  proc: Val;
  /** Confidence score (0-1) */
  confidence: number;
  /** Description of the approach */
  description?: string;
  /** Whether this is a method or coercion */
  kind: "method" | "coercion";
  /** For coercion: target type */
  targetType?: TypeTag;
};

/**
 * SynthesisResult: Result of attempting to synthesize a method.
 */
export type SynthesisResult =
  | { tag: "success"; candidate: SynthesisCandidate; testsPassed: boolean }
  | { tag: "failure"; reason: string; candidates?: SynthesisCandidate[] }
  | { tag: "pending"; ivarId: string };

/**
 * CommitRequest: Request to commit a synthesized method or coercion.
 */
export type CommitRequest = {
  /** Type of commit */
  kind: "method" | "coercion";
  /** For method: operation name */
  op?: string;
  /** For method: signature */
  signature?: TypeSignature;
  /** For coercion: from type */
  fromTag?: TypeTag;
  /** For coercion: to type */
  toTag?: TypeTag;
  /** The procedure to commit */
  proc: Val;
  /** Required obligations (tests that must pass) */
  obligations: ObligationRef[];
  /** Registry to commit to */
  registryId: string;
};

/**
 * ObligationRef: Reference to an obligation that must be satisfied.
 */
export type ObligationRef = {
  /** Obligation ID */
  id: string;
  /** Kind of obligation */
  kind: "test" | "invariant" | "metamorphic";
  /** Description */
  description?: string;
  /** Whether satisfied */
  satisfied?: boolean;
};

/**
 * CommitResult: Result of a commit attempt.
 */
export type CommitResult =
  | { tag: "committed"; hash: Hash; entry: MethodEntry | CoercionEntry }
  | { tag: "denied"; reason: string; missingCaps?: string[] }
  | { tag: "failed"; failedObligations: ObligationRef[] };

// ─────────────────────────────────────────────────────────────────
// Event Types (for ledger)
// ─────────────────────────────────────────────────────────────────

/**
 * GenericEvent: Events for the generic operations ledger.
 */
export type GenericEvent =
  | { tag: "dispatch"; op: string; signature: TypeSignature; result: "hit" | "miss" | "coerced"; timestamp: number }
  | { tag: "miss"; op: string; signature: TypeSignature; registryId: string; timestamp: number }
  | { tag: "synthesis"; op: string; signature: TypeSignature; candidateCount: number; timestamp: number }
  | { tag: "commit"; kind: "method" | "coercion"; hash: Hash; timestamp: number }
  | { tag: "ambiguity"; op: string; signature: TypeSignature; pathCount: number; timestamp: number };

// ─────────────────────────────────────────────────────────────────
// Type Guards
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a value is tagged.
 */
export function isTagged(v: Val): v is TaggedVal {
  return v.tag === "Tagged";
}

/**
 * Check if a value is a generic registry.
 */
export function isGenericRegistry(v: Val): v is GenericRegistryVal {
  return v.tag === "GenericRegistry";
}

/**
 * Check if a value is a generic miss.
 */
export function isGenericMiss(v: Val): v is GenericMissVal {
  return v.tag === "GenericMiss";
}

// ─────────────────────────────────────────────────────────────────
// Tagged Value Helpers
// ─────────────────────────────────────────────────────────────────

/**
 * Create a tagged value.
 */
export function attachTag(typeTag: TypeTag, payload: Val): TaggedVal {
  return { tag: "Tagged", typeTag, payload };
}

/**
 * Get the type tag of a value.
 * Returns the typeTag if tagged, or infers a primitive tag otherwise.
 */
export function getTypeTag(v: Val): TypeTag | undefined {
  if (v.tag === "Tagged") {
    return v.typeTag;
  }
  // Infer primitive tags
  switch (v.tag) {
    case "Num": return "Primitive/Num";
    case "Str": return "Primitive/Str";
    case "Bool": return "Primitive/Bool";
    case "Sym": return "Primitive/Sym";
    case "Pair": return "Primitive/Pair";
    case "Vector": return "Primitive/Vector";
    case "Map": return "Primitive/Map";
    default: return undefined;
  }
}

/**
 * Get the contents (payload) of a value.
 * Returns the payload if tagged, or the value itself otherwise.
 */
export function getContents(v: Val): Val {
  if (v.tag === "Tagged") {
    return v.payload;
  }
  return v;
}

/**
 * Extract signature from arguments.
 */
export function extractSignature(args: Val[]): TypeSignature {
  return args.map(arg => getTypeTag(arg) ?? "unknown");
}

// ─────────────────────────────────────────────────────────────────
// Registry Value Helpers
// ─────────────────────────────────────────────────────────────────

/**
 * Create a GenericRegistryVal.
 */
export function makeGenericRegistry(id: string, name?: string): GenericRegistryVal {
  return { tag: "GenericRegistry", id, name };
}

/**
 * Create a GenericMissVal.
 */
export function makeGenericMiss(
  op: string,
  signature: TypeSignature,
  argsPreview: Val[],
  registryId: string,
  profileName?: string
): GenericMissVal {
  return {
    tag: "GenericMiss",
    op,
    signature,
    argsPreview,
    registryId,
    profileName,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/governance/budgets.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/governance/budgets.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set D1: Budget enforcement
// Patch Set D2: Ledger counters for effect emissions (Prompt 8)

export type BudgetLimits = {
  maxOracleTurns: number;
  maxEvalSteps: number;
  maxToolCalls: number;
  maxNestedDepth?: number;
};

/**
 * LedgerEntry: Record of an effect emission
 */
export type LedgerEntry = {
  timestamp: number;
  op: string;
  ctxDigest: string;
  stepCount: number;
  args?: unknown[];
};

/**
 * EffectCounter: Tracks counts per effect operation
 */
export type EffectCounters = Map<string, number>;

export type Budget = {
  limits: BudgetLimits;
  consumed: {
    oracleTurns: number;
    evalSteps: number;
    toolCalls: number;
  };
  /** Ledger: ordered list of effect emissions */
  ledger?: LedgerEntry[];
  /** Effect counters: count per operation */
  effectCounters?: EffectCounters;
};

export function budgetDefault(limits: Partial<BudgetLimits> = {}): Budget {
  return {
    limits: {
      maxOracleTurns: limits.maxOracleTurns ?? 10_000,
      maxEvalSteps: limits.maxEvalSteps ?? 500_000,
      maxToolCalls: limits.maxToolCalls ?? 9999,
      maxNestedDepth: limits.maxNestedDepth ?? 8,
    },
    consumed: {
      oracleTurns: 0,
      evalSteps: 0,
      toolCalls: 0,
    },
  };
}

export function budgetConsumeOracleTurn(b: Budget): Budget {
  const newConsumed = {
    ...b.consumed,
    oracleTurns: b.consumed.oracleTurns + 1,
  };
  if (newConsumed.oracleTurns > b.limits.maxOracleTurns) {
    throw new Error(`budget exhausted: oracleTurns (${newConsumed.oracleTurns} > ${b.limits.maxOracleTurns})`);
  }
  return { ...b, consumed: newConsumed };
}

export function budgetConsumeEvalStep(b: Budget, steps: number = 1): Budget {
  const newConsumed = {
    ...b.consumed,
    evalSteps: b.consumed.evalSteps + steps,
  };
  if (newConsumed.evalSteps > b.limits.maxEvalSteps) {
    throw new Error(`budget exhausted: evalSteps (${newConsumed.evalSteps} > ${b.limits.maxEvalSteps})`);
  }
  return { ...b, consumed: newConsumed };
}

export function budgetConsumeToolCall(b: Budget): Budget {
  const newConsumed = {
    ...b.consumed,
    toolCalls: b.consumed.toolCalls + 1,
  };
  if (newConsumed.toolCalls > b.limits.maxToolCalls) {
    throw new Error(`budget exhausted: toolCalls (${newConsumed.toolCalls} > ${b.limits.maxToolCalls})`);
  }
  return { ...b, consumed: newConsumed };
}

export function budgetRemaining(b: Budget): BudgetLimits {
  return {
    maxOracleTurns: b.limits.maxOracleTurns - b.consumed.oracleTurns,
    maxEvalSteps: b.limits.maxEvalSteps - b.consumed.evalSteps,
    maxToolCalls: b.limits.maxToolCalls - b.consumed.toolCalls,
    maxNestedDepth: b.limits.maxNestedDepth,
  };
}

/**
 * Mutable budget tracker for sharing between eval loop and runtime.
 * Wraps immutable budget functions in a stateful interface.
 * Extended with ledger counters for effect emissions (Prompt 8).
 */
export class BudgetTracker {
  private budget: Budget;
  private ledger: LedgerEntry[] = [];
  private effectCounters: Map<string, number> = new Map();
  private stepCount: number = 0;

  constructor(limits: Partial<BudgetLimits> = {}) {
    this.budget = budgetDefault(limits);
  }

  /** Consume one eval step. Throws if budget exhausted. */
  consumeEvalStep(steps: number = 1): void {
    this.budget = budgetConsumeEvalStep(this.budget, steps);
    this.stepCount += steps;
  }

  /** Consume one oracle turn. Throws if budget exhausted. */
  consumeOracleTurn(): void {
    this.budget = budgetConsumeOracleTurn(this.budget);
  }

  /** Consume one tool call. Throws if budget exhausted. */
  consumeToolCall(): void {
    this.budget = budgetConsumeToolCall(this.budget);
  }

  /** Get remaining budget limits. */
  remaining(): BudgetLimits {
    return budgetRemaining(this.budget);
  }

  /** Get current budget snapshot. */
  snapshot(): Budget {
    return {
      ...this.budget,
      consumed: { ...this.budget.consumed },
      limits: { ...this.budget.limits },
      ledger: this.ledger.slice(),
      effectCounters: new Map(this.effectCounters),
    };
  }

  /** Check if eval steps are exhausted (without throwing). */
  isEvalExhausted(): boolean {
    return this.budget.consumed.evalSteps >= this.budget.limits.maxEvalSteps;
  }

  /** Check if oracle turns are exhausted (without throwing). */
  isOracleExhausted(): boolean {
    return this.budget.consumed.oracleTurns >= this.budget.limits.maxOracleTurns;
  }

  /** Check if tool calls are exhausted (without throwing). */
  isToolExhausted(): boolean {
    return this.budget.consumed.toolCalls >= this.budget.limits.maxToolCalls;
  }

  /**
   * Consume an amb attempt/backtrack (compat shim for nondet runtime).
   * Currently just increments step counter to keep accounting monotonic.
   */
  consumeAmbAttempt(): void {
    this.consumeEvalStep(0);
  }

  // ─────────────────────────────────────────────────────────────────
  // Ledger operations (Prompt 8)
  // ─────────────────────────────────────────────────────────────────

  /**
   * Record an effect emission in the ledger.
   * Increments the counter for this operation type.
   */
  recordEffect(op: string, ctxDigest: string, args?: unknown[]): void {
    const entry: LedgerEntry = {
      timestamp: Date.now(),
      op,
      ctxDigest,
      stepCount: this.stepCount,
      args,
    };
    this.ledger.push(entry);

    // Increment effect counter
    const count = this.effectCounters.get(op) || 0;
    this.effectCounters.set(op, count + 1);
  }

  /**
   * Get the count of emissions for a specific effect operation.
   */
  getEffectCount(op: string): number {
    return this.effectCounters.get(op) || 0;
  }

  /**
   * Get all effect counts as an object.
   */
  getAllEffectCounts(): Record<string, number> {
    const result: Record<string, number> = {};
    for (const [op, count] of this.effectCounters) {
      result[op] = count;
    }
    return result;
  }

  /**
   * Get the total number of effect emissions.
   */
  getTotalEffectCount(): number {
    let total = 0;
    for (const count of this.effectCounters.values()) {
      total += count;
    }
    return total;
  }

  /**
   * Get the ledger entries.
   */
  getLedger(): LedgerEntry[] {
    return this.ledger.slice();
  }

  /**
   * Get ledger entries filtered by operation.
   */
  getLedgerByOp(op: string): LedgerEntry[] {
    return this.ledger.filter(e => e.op === op);
  }

  /**
   * Clear the ledger (for testing/reset).
   */
  clearLedger(): void {
    this.ledger = [];
    this.effectCounters.clear();
  }

  /**
   * Get current step count.
   */
  getStepCount(): number {
    return this.stepCount;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/governance/caps.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/governance/caps.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set D1: Capability enforcement

export type Cap = string;

export type CapSet = Cap[];

export function capRequire(caps: CapSet, required: Cap, context: string): void {
  if (caps.includes("*")) return; // wildcard grants all
  if (caps.includes(required)) return;

  // Check for wildcard in capability domain (e.g., "tool.*" grants "tool.read")
  const domain = required.split(".")[0];
  if (caps.includes(`${domain}.*`)) return;

  throw new Error(`capability denied: ${required} (context: ${context})`);
}

export function capHas(caps: CapSet, cap: Cap): boolean {
  if (caps.includes("*")) return true;
  if (caps.includes(cap)) return true;
  const domain = cap.split(".")[0];
  if (caps.includes(`${domain}.*`)) return true;
  return false;
}

export const DEFAULT_CAPS: CapSet = ["eval", "apply", "observe"];

export const FULL_CAPS: CapSet = ["*"];

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/governance/enforcement.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/governance/enforcement.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 9: Governance enforcement at three chokepoints
//
// This module enforces governance rules at three critical points:
// - Chokepoint A: Effect emission (what effects can be emitted)
// - Chokepoint B: Oracle session loop (what oracle requests are legal)
// - Chokepoint C: Commit barrier (truth regime + obligations)

import type { State } from "../eval/machine";
import type { Val } from "../eval/values";
import type { OpCall } from "../effects/opcall";
import {
  Profile,
  RuntimeBudget,
  RuntimeSecurity,
  TruthRegime,
  OracleReqTag,
  ProfileViolation,
  CapabilityViolation,
  BudgetExceeded,
  TruthRegimeViolation,
  makeRuntimeBudget,
  DEFAULT_PROFILE,
  normalizeProfile,
} from "./profile";

// ─────────────────────────────────────────────────────────────────
// State initialization helpers
// ─────────────────────────────────────────────────────────────────

/**
 * Initialize governance state with a profile.
 * Creates RuntimeBudget and RuntimeSecurity from the profile.
 */
export function initGovernance(state: State, profile: Profile): State {
  const normalized = normalizeProfile(profile);
  return {
    ...state,
    profile: normalized,
    budget: makeRuntimeBudget(normalized),
    sec: { caps: new Set(normalized.allowedCaps) },
  };
}

/**
 * Get effective profile from state (or default).
 */
export function getEffectiveProfile(state: State): Profile {
  return normalizeProfile(state.profile ?? DEFAULT_PROFILE);
}

/**
 * Get effective budget from state.
 */
export function getEffectiveBudget(state: State): RuntimeBudget | undefined {
  return state.budget;
}

/**
 * Get effective security context from state.
 */
export function getEffectiveSecurity(state: State): RuntimeSecurity | undefined {
  return state.sec;
}

// ─────────────────────────────────────────────────────────────────
// Chokepoint A: Effect Emission Enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Built-in kernel operations that are subject to governance.
 * User-defined effects (with custom handlers) are NOT governed here.
 */
const KERNEL_OPS = new Set([
  "infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op",
  "tool.op", "commit.op",
  "amb.op", "amb.choose", "amb.fail",
  "observe.op",
  "ctx.snapshot", "ctx.compress", "ctx.hydrate",
]);

/**
 * Check if an op is a built-in kernel operation (subject to governance).
 */
function isKernelOp(op: string): boolean {
  return KERNEL_OPS.has(op);
}

/**
 * Check if an effect operation is allowed by the current profile.
 * Called when an Effect expression is about to emit an operation.
 *
 * NOTE: Only built-in kernel ops are governed. User-defined effects
 * (e.g., custom handlers like "foo") are allowed through - they will
 * either be caught by a handler or fail at runtime dispatch.
 *
 * @throws ProfileViolation if op is not allowed
 * @throws BudgetExceeded if budget is exhausted
 */
export function checkEffectAllowed(state: State, op: string): void {
  // User-defined effects are not governed - they rely on handlers
  if (!isKernelOp(op)) {
    return;
  }

  const profile = getEffectiveProfile(state);

  // Check if kernel operation is allowed
  if (!profile.allowedOps.has(op)) {
    throw new ProfileViolation(op, profile.name, "effect emission");
  }

  // Check budget based on operation type
  const budget = state.budget;
  if (budget) {
    if (op === "infer.op" || op === "infer.batch.op") {
      if (budget.inferCallsLeft <= 0) {
        throw new BudgetExceeded("inferCalls", profile.budgets.maxOracleTurns);
      }
    } else if (op === "tool.op") {
      if (budget.toolCallsLeft <= 0) {
        throw new BudgetExceeded("toolCalls", profile.budgets.maxToolCalls);
      }
    } else if (op === "commit.op") {
      if (budget.commitLeft <= 0) {
        throw new BudgetExceeded("commit", profile.budgets.maxCommits ?? 100);
      }
    }
  }
}

/**
 * Decrement budget after effect is emitted.
 */
export function debitEffect(state: State, op: string): State {
  const budget = state.budget;
  if (!budget) return state;

  const newBudget = { ...budget };

  if (op === "infer.op" || op === "infer.batch.op") {
    newBudget.inferCallsLeft--;
  } else if (op === "tool.op") {
    newBudget.toolCallsLeft--;
  } else if (op === "commit.op") {
    newBudget.commitLeft--;
  }

  // Always decrement steps
  newBudget.stepsLeft--;

  return { ...state, budget: newBudget };
}

// ─────────────────────────────────────────────────────────────────
// Chokepoint B: Oracle Session Loop Enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Check if an oracle request type is allowed.
 * Called during the oracle session loop when the oracle makes a request.
 *
 * @throws ProfileViolation if request type is not allowed
 * @throws BudgetExceeded if oracle request budget exhausted
 */
export function checkOracleRequestAllowed(state: State, reqTag: OracleReqTag): void {
  const profile = getEffectiveProfile(state);

  // Check if request type is allowed
  if (!profile.allowedOracleReqTags.has(reqTag)) {
    throw new ProfileViolation(reqTag, profile.name, "oracle request");
  }

  // Check oracle request budget
  const budget = state.budget;
  if (budget && budget.oracleReqLeft <= 0) {
    throw new BudgetExceeded(
      "oracleReq",
      profile.budgets.maxOracleReqs ?? profile.budgets.maxOracleTurns
    );
  }

  // Special check: ReqTool requires tool capability
  if (reqTag === "ReqTool") {
    const sec = state.sec;
    if (sec && !sec.caps.has("cap.tool") && !sec.caps.has("*")) {
      throw new CapabilityViolation("ReqTool", "cap.tool", "oracle request");
    }
  }

  // Special check: ReqEval/ReqApply may require eval capability in strict mode
  if (reqTag === "ReqEval" || reqTag === "ReqApply") {
    if (profile.deterministicEnvelope) {
      const sec = state.sec;
      if (sec && !sec.caps.has("cap.eval") && !sec.caps.has("*")) {
        throw new CapabilityViolation(reqTag, "cap.eval", "oracle request in deterministic mode");
      }
    }
  }
}

/**
 * Decrement oracle request budget.
 */
export function debitOracleRequest(state: State): State {
  const budget = state.budget;
  if (!budget) return state;

  return {
    ...state,
    budget: {
      ...budget,
      oracleReqLeft: budget.oracleReqLeft - 1,
    },
  };
}

// ─────────────────────────────────────────────────────────────────
// Chokepoint C: Commit Barrier Enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Obligation evidence for commit verification.
 * Different truth regimes require different evidence.
 */
export type CommitEvidence =
  | { tag: "None" }
  | { tag: "TestResults"; passed: boolean; coverage?: number; testIds?: string[] }
  | { tag: "ProofCertificate"; proofHash: string; verifier: string }
  | { tag: "ConsensusReceipt"; signatures: string[]; threshold: number };

/**
 * Check if a commit is allowed under the current truth regime.
 * Called when code attempts to commit (promote speculative to persistent).
 *
 * @throws TruthRegimeViolation if commit not allowed
 * @throws ProfileViolation if commit.op not allowed
 * @throws BudgetExceeded if commit budget exhausted
 */
export function checkCommitAllowed(
  state: State,
  evidence: CommitEvidence,
  commitType: "rewrite" | "method" | "data"
): void {
  const profile = getEffectiveProfile(state);

  // First check if commit.op is allowed at all
  if (!profile.allowedOps.has("commit.op")) {
    throw new ProfileViolation("commit.op", profile.name, "commit barrier");
  }

  // Check commit budget
  const budget = state.budget;
  if (budget && budget.commitLeft <= 0) {
    throw new BudgetExceeded("commit", profile.budgets.maxCommits ?? 100);
  }

  // Check capability for this commit type
  const sec = state.sec;
  const requiredCap = `cap.commit.${commitType}`;
  if (sec && !sec.caps.has(requiredCap) && !sec.caps.has("cap.commit.*") && !sec.caps.has("*")) {
    throw new CapabilityViolation("commit", requiredCap, "commit barrier");
  }

  // Check truth regime requirements
  const regime = profile.truthRegime;

  switch (regime) {
    case "speculative":
      // Speculative: no commits allowed (unless explicitly overridden)
      throw new TruthRegimeViolation(regime, "commits not allowed in speculative mode");

    case "test-certified":
      // Test-certified: require passing tests
      if (evidence.tag !== "TestResults") {
        throw new TruthRegimeViolation(regime, "test results required for commit");
      }
      if (!evidence.passed) {
        throw new TruthRegimeViolation(regime, "tests must pass for commit");
      }
      break;

    case "proof-certified":
      // Proof-certified: require proof certificate
      if (evidence.tag !== "ProofCertificate") {
        throw new TruthRegimeViolation(regime, "proof certificate required for commit");
      }
      break;

    case "consensus-certified":
      // Consensus-certified: require consensus receipt
      if (evidence.tag !== "ConsensusReceipt") {
        throw new TruthRegimeViolation(regime, "consensus receipt required for commit");
      }
      if (evidence.signatures.length < evidence.threshold) {
        throw new TruthRegimeViolation(
          regime,
          `insufficient signatures: ${evidence.signatures.length} < ${evidence.threshold}`
        );
      }
      break;
  }
}

/**
 * Decrement commit budget.
 */
export function debitCommit(state: State): State {
  const budget = state.budget;
  if (!budget) return state;

  return {
    ...state,
    budget: {
      ...budget,
      commitLeft: budget.commitLeft - 1,
    },
  };
}

// ─────────────────────────────────────────────────────────────────
// General step budget enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Check if we have steps remaining.
 * Called on each evaluation step.
 *
 * @throws BudgetExceeded if step budget exhausted
 */
export function checkStepBudget(state: State): void {
  const budget = state.budget;
  const profile = getEffectiveProfile(state);

  if (budget && budget.stepsLeft <= 0) {
    throw new BudgetExceeded("steps", profile.budgets.maxEvalSteps);
  }
}

/**
 * Decrement step budget.
 */
export function debitStep(state: State): State {
  const budget = state.budget;
  if (!budget) return state;

  return {
    ...state,
    budget: {
      ...budget,
      stepsLeft: budget.stepsLeft - 1,
    },
  };
}

// ─────────────────────────────────────────────────────────────────
// Capability enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a capability is held.
 *
 * @throws CapabilityViolation if capability not held
 */
export function checkCapability(state: State, cap: string, context: string): void {
  const sec = state.sec;
  if (!sec) return; // No security context = no enforcement

  if (sec.caps.has(cap) || sec.caps.has("*")) return;

  // Check domain wildcards (e.g., "cap.tool.*" grants "cap.tool.read")
  const parts = cap.split(".");
  if (parts.length >= 2) {
    const domain = parts.slice(0, -1).join(".");
    if (sec.caps.has(`${domain}.*`)) return;
  }

  throw new CapabilityViolation(context, cap);
}

/**
 * Check if a capability is held (non-throwing version).
 */
export function hasCapability(state: State, cap: string): boolean {
  const sec = state.sec;
  if (!sec) return true; // No security context = granted

  if (sec.caps.has(cap) || sec.caps.has("*")) return true;

  const parts = cap.split(".");
  if (parts.length >= 2) {
    const domain = parts.slice(0, -1).join(".");
    if (sec.caps.has(`${domain}.*`)) return true;
  }

  return false;
}

// ─────────────────────────────────────────────────────────────────
// Profile switching (for with-profile)
// ─────────────────────────────────────────────────────────────────

/**
 * Install a new profile for the dynamic extent.
 * The new profile's caps are intersected with the current caps (can only restrict).
 */
export function withProfile(state: State, newProfile: Profile): State {
  const currentSec = state.sec;

  // Intersect capabilities (new profile can only restrict, not expand)
  let newCaps: Set<string>;
  if (currentSec) {
    newCaps = new Set<string>();
    for (const cap of newProfile.allowedCaps) {
      if (currentSec.caps.has(cap) || currentSec.caps.has("*")) {
        newCaps.add(cap);
      }
    }
  } else {
    newCaps = new Set(newProfile.allowedCaps);
  }

  // Create new budget from profile
  const newBudget = makeRuntimeBudget(newProfile);

  // If there's existing budget, take the minimum
  if (state.budget) {
    newBudget.stepsLeft = Math.min(newBudget.stepsLeft, state.budget.stepsLeft);
    newBudget.inferCallsLeft = Math.min(newBudget.inferCallsLeft, state.budget.inferCallsLeft);
    newBudget.oracleReqLeft = Math.min(newBudget.oracleReqLeft, state.budget.oracleReqLeft);
    newBudget.toolCallsLeft = Math.min(newBudget.toolCallsLeft, state.budget.toolCallsLeft);
    newBudget.commitLeft = Math.min(newBudget.commitLeft, state.budget.commitLeft);
  }

  return {
    ...state,
    profile: newProfile,
    budget: newBudget,
    sec: { caps: newCaps },
  };
}

/**
 * Add capabilities to the current security context.
 * Only works if the profile allows those capabilities.
 */
export function withCaps(state: State, additionalCaps: string[]): State {
  const profile = getEffectiveProfile(state);
  const currentSec = state.sec ?? { caps: new Set<string>() };

  const newCaps = new Set(currentSec.caps);

  for (const cap of additionalCaps) {
    // Can only add caps that the profile allows
    if (profile.allowedCaps.has(cap) || profile.allowedCaps.has("*")) {
      newCaps.add(cap);
    }
  }

  return {
    ...state,
    sec: { caps: newCaps },
  };
}

/**
 * Restrict capabilities (remove from current set).
 */
export function withoutCaps(state: State, capsToRemove: string[]): State {
  const currentSec = state.sec;
  if (!currentSec) return state;

  const newCaps = new Set(currentSec.caps);
  for (const cap of capsToRemove) {
    newCaps.delete(cap);
  }

  return {
    ...state,
    sec: { caps: newCaps },
  };
}

// ─────────────────────────────────────────────────────────────────
// Deterministic envelope enforcement
// ─────────────────────────────────────────────────────────────────

/**
 * Check if running in deterministic envelope.
 */
export function isDeterministic(state: State): boolean {
  const profile = getEffectiveProfile(state);
  return profile.deterministicEnvelope;
}

/**
 * Check if non-deterministic operations are allowed.
 *
 * @throws ProfileViolation if deterministic but non-deterministic op attempted
 */
export function checkNonDeterministicAllowed(state: State, context: string): void {
  if (isDeterministic(state)) {
    const profile = getEffectiveProfile(state);
    throw new ProfileViolation(
      "non-deterministic operation",
      profile.name,
      `${context} - deterministic envelope active`
    );
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/governance/profile.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/governance/profile.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set D: Execution profiles with truth regimes
// Prompt 9: Full governance enforcement

import type { CapSet } from "./caps";
import type { BudgetLimits } from "./budgets";

// ─────────────────────────────────────────────────────────────────
// Truth Regimes: promotion barriers for commit operations
// ─────────────────────────────────────────────────────────────────

export type TruthRegime =
  | "speculative"         // No commits allowed (or explicit override required)
  | "test-certified"      // Requires OblTests / OblEqExt
  | "proof-certified"     // Requires proof evidence (stub for now)
  | "consensus-certified"; // Requires consensus evidence (stub for now)

// ─────────────────────────────────────────────────────────────────
// Oracle Request Tags: what the oracle can ask for
// ─────────────────────────────────────────────────────────────────

export type OracleReqTag =
  | "ReqEval"      // Evaluate expression in current env
  | "ReqApply"     // Apply procedure to arguments
  | "ReqObserve"   // Observe machine state
  | "ReqTool"      // Call external tool
  | "ReqTest"      // Run tests
  | "ReqCommit";   // Request commit (checked separately)

// ─────────────────────────────────────────────────────────────────
// Effect Operations: which effects can be emitted
// ─────────────────────────────────────────────────────────────────

export type EffectOp =
  | "infer.op"     // Oracle inference
  | "tool.op"      // Tool invocation
  | "commit.op"    // Commit to ledger
  | "amb.choose"   // Nondeterministic choice
  | "observe.op";  // Observe state

// ─────────────────────────────────────────────────────────────────
// Budget Profile: runtime resource limits
// ─────────────────────────────────────────────────────────────────

export type BudgetProfile = BudgetLimits & {
  maxOracleReqs?: number;   // Max oracle requests per session
  maxCommits?: number;      // Max commits per session
};

// ─────────────────────────────────────────────────────────────────
// Profile: First-class runtime governance object
// ─────────────────────────────────────────────────────────────────

/**
 * Profile: A complete governance configuration for execution.
 *
 * This is the "evaluator variant" that determines what the language can do.
 * Different profiles = different languages (SICP-style).
 *
 * Enforced at three chokepoints:
 * - Effect emission (what effects can be emitted)
 * - Oracle session loop (what the oracle can request)
 * - Commit barrier (truth regime + obligations)
 */
export type Profile = {
  /** Profile identifier */
  name: string;

  /** Capability envelope - what authorities this profile grants */
  allowedCaps?: Set<string>;

  /** Which effect ops are allowed to be handled */
  allowedOps?: Set<string>;

  /** Which Oracle requests are legal during inference */
  allowedOracleReqTags?: Set<OracleReqTag>;

  /** Budget envelope - hard stops */
  budgets: BudgetProfile;

  /** Truth regime for promotion barriers */
  truthRegime?: TruthRegime;

  /** If true, only scripted/replay oracles allowed */
  deterministicEnvelope?: boolean;

  // Legacy compatibility
  caps?: CapSet;
  truth?: TruthRegime;
  // Demo flags (legacy wow pack)
  allowCommit?: boolean;
  allowPromotion?: boolean;
  requireTests?: boolean;
  inferBudget?: number;
};

/** Fully-populated profile after normalization */
export type NormalizedProfile = Profile & {
  allowedCaps: Set<string>;
  allowedOps: Set<string>;
  allowedOracleReqTags: Set<OracleReqTag>;
  truthRegime: TruthRegime;
  deterministicEnvelope: boolean;
};

const DEFAULT_ALLOWED_OPS = new Set<string>([
  "infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op",
  "amb.op", "amb.choose", "amb.fail", "observe.op", "tool.op", "commit.op",
  // System effects for orchestration
  "shell.op", "file.read.op", "file.write.op",
]);

const DEFAULT_ORACLE_REQS: OracleReqTag[] = [
  "ReqEval",
  "ReqApply",
  "ReqObserve",
  "ReqTool",
  "ReqTest",
  "ReqCommit",
];

function toSet(value?: Set<string> | string[]): Set<string> {
  if (!value) return new Set();
  return value instanceof Set ? new Set(value) : new Set(value);
}

/**
 * Normalize a profile into the fully-populated runtime shape.
 * Accepts legacy profiles that only specify caps/budgets/truth.
 */
export function normalizeProfile(profile: Profile): NormalizedProfile {
  if (
    profile.allowedCaps &&
    profile.allowedOps &&
    profile.allowedOracleReqTags &&
    profile.truthRegime !== undefined &&
    profile.deterministicEnvelope !== undefined
  ) {
    return profile as NormalizedProfile;
  }

  const allowedCaps = toSet(profile.allowedCaps ?? (profile.caps as string[] | undefined));
  const allowedOps = profile.allowedOps ? new Set(profile.allowedOps) : new Set(DEFAULT_ALLOWED_OPS);
  const allowedOracleReqTags = profile.allowedOracleReqTags
    ? new Set(profile.allowedOracleReqTags)
    : new Set(DEFAULT_ORACLE_REQS);
  const truthRegime = profile.truthRegime ?? profile.truth ?? "speculative";
  const deterministicEnvelope = profile.deterministicEnvelope ?? (profile as { deterministic?: boolean }).deterministic ?? false;

  const budgets: BudgetProfile = {
    maxOracleTurns: profile.budgets.maxOracleTurns,
    maxEvalSteps: profile.budgets.maxEvalSteps,
    maxToolCalls: profile.budgets.maxToolCalls,
    maxNestedDepth: profile.budgets.maxNestedDepth ?? 8,
    maxOracleReqs: profile.budgets.maxOracleReqs ?? profile.budgets.maxOracleTurns,
    maxCommits: profile.budgets.maxCommits ?? (profile.allowCommit ? 100 : 0),
  };

  return {
    ...profile,
    allowedCaps,
    allowedOps,
    allowedOracleReqTags,
    truthRegime,
    deterministicEnvelope,
    caps: profile.caps ?? Array.from(allowedCaps),
    truth: truthRegime,
    budgets,
  };
}

// ─────────────────────────────────────────────────────────────────
// Runtime Budget: mutable state for tracking consumption
// ─────────────────────────────────────────────────────────────────

export type RuntimeBudget = {
  stepsLeft: number;
  inferCallsLeft: number;
  oracleReqLeft: number;
  toolCallsLeft: number;
  commitLeft: number;
};

// ─────────────────────────────────────────────────────────────────
// Runtime Security: current authority set
// ─────────────────────────────────────────────────────────────────

export type RuntimeSecurity = {
  /** Current authority set (intersection of context caps + profile allowedCaps) */
  caps: Set<string>;
};

// ─────────────────────────────────────────────────────────────────
// Governance Violation Errors
// ─────────────────────────────────────────────────────────────────

export class ProfileViolation extends Error {
  constructor(
    public readonly op: string,
    public readonly profile: string,
    public readonly context?: string
  ) {
    super(`ProfileViolation: operation '${op}' not allowed in profile '${profile}'${context ? ` (${context})` : ""}`);
    this.name = "ProfileViolation";
  }
}

export class CapabilityViolation extends Error {
  constructor(
    public readonly op: string,
    public readonly requiredCap: string,
    public readonly context?: string
  ) {
    super(`CapabilityViolation: operation '${op}' requires capability '${requiredCap}'${context ? ` (${context})` : ""}`);
    this.name = "CapabilityViolation";
  }
}

export class BudgetExceeded extends Error {
  constructor(
    public readonly kind: "steps" | "inferCalls" | "oracleReq" | "toolCalls" | "commit",
    public readonly limit: number
  ) {
    super(`BudgetExceeded: ${kind} limit (${limit}) exceeded`);
    this.name = "BudgetExceeded";
  }
}

export class TruthRegimeViolation extends Error {
  constructor(
    public readonly regime: TruthRegime,
    public readonly reason: string
  ) {
    super(`TruthRegimeViolation: ${reason} (regime: ${regime})`);
    this.name = "TruthRegimeViolation";
  }
}

// ─────────────────────────────────────────────────────────────────
// Helper: Create Profile from simplified config
// ─────────────────────────────────────────────────────────────────

export function makeProfile(config: {
  name: string;
  caps: string[];
  ops: string[];
  oracleReqs: OracleReqTag[];
  budgets: BudgetProfile;
  truth: TruthRegime;
  deterministic?: boolean;
}): NormalizedProfile {
  // Generate legacy caps that include both new-style (cap.eval) and old-style (eval) names
  // for backward compatibility with existing capRequire calls
  const legacyCaps = [...config.caps];
  for (const cap of config.caps) {
    // If cap starts with "cap.", also add the version without prefix
    if (cap.startsWith("cap.")) {
      const oldStyle = cap.slice(4); // Remove "cap." prefix
      if (!legacyCaps.includes(oldStyle)) {
        legacyCaps.push(oldStyle);
      }
    }
  }

  return normalizeProfile({
    name: config.name,
    allowedCaps: new Set(config.caps),
    allowedOps: new Set(config.ops),
    allowedOracleReqTags: new Set(config.oracleReqs),
    budgets: config.budgets,
    truthRegime: config.truth,
    deterministicEnvelope: config.deterministic ?? false,
    // Legacy - includes both cap.X and X style names for compatibility
    caps: legacyCaps,
    truth: config.truth,
  });
}

// ─────────────────────────────────────────────────────────────────
// Helper: Create RuntimeBudget from Profile
// ─────────────────────────────────────────────────────────────────

export function makeRuntimeBudget(profile: Profile): RuntimeBudget {
  const normalized = normalizeProfile(profile);
  return {
    stepsLeft: normalized.budgets.maxEvalSteps,
    inferCallsLeft: normalized.budgets.maxOracleTurns,
    oracleReqLeft: normalized.budgets.maxOracleReqs ?? normalized.budgets.maxOracleTurns,
    toolCallsLeft: normalized.budgets.maxToolCalls,
    commitLeft: normalized.budgets.maxCommits ?? 100,
  };
}

// ─────────────────────────────────────────────────────────────────
// Canonical Profiles (Prompt 9)
// ─────────────────────────────────────────────────────────────────

/**
 * profile:explore - Rapid exploration without commits
 *
 * - Allowed: infer.op, amb.*, observe
 * - Oracle REPL: ReqEval, ReqApply, ReqObserve
 * - NO commits by default
 * - Generous budgets, but still bounded
 *
 * Use: rapid exploration where you can't accidentally promote
 */
export const PROFILE_EXPLORE: NormalizedProfile = makeProfile({
  name: "explore",
  caps: ["cap.eval", "cap.apply", "cap.observe", "cap.infer"],
  ops: ["infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op", "amb.op", "amb.choose", "amb.fail", "observe.op"],
  oracleReqs: ["ReqEval", "ReqApply", "ReqObserve"],
  budgets: {
    maxOracleTurns: 1000,
    maxEvalSteps: 100_000,
    maxToolCalls: 0,        // No tools in explore
    maxNestedDepth: 8,
    maxOracleReqs: 500,
    maxCommits: 0,          // No commits in explore
  },
  truth: "speculative",
  deterministic: false,
});

/**
 * profile:pragmatic - Real engineering with CI-like discipline
 *
 * - Allow: infer + test + commit
 * - Oracle REPL: full, but tools only if explicitly granted
 * - Truth: test-certified
 * - Required obligations on commit
 *
 * Use: real engineering tasks with CI-like discipline
 */
export const PROFILE_PRAGMATIC: NormalizedProfile = makeProfile({
  name: "pragmatic",
  caps: [
    "cap.eval", "cap.apply", "cap.observe", "cap.infer",
    "cap.test", "cap.commit.rewrite", "cap.commit.method",
    "cap.generic.autofill",
    // System capabilities for orchestration
    "shell", "file.read", "file.write"
  ],
  ops: ["infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op", "amb.op", "amb.choose", "amb.fail", "observe.op", "commit.op", "shell.op", "file.read.op", "file.write.op"],
  oracleReqs: ["ReqEval", "ReqApply", "ReqObserve", "ReqTest", "ReqCommit"],
  budgets: {
    maxOracleTurns: 10_000,
    maxEvalSteps: 500_000,
    maxToolCalls: 100,
    maxNestedDepth: 16,
    maxOracleReqs: 5000,
    maxCommits: 50,
  },
  truth: "test-certified",
  deterministic: false,
});

/**
 * profile:strict - Production semantics
 *
 * - Allow infer only under deterministic envelope (scripted or replay)
 * - Allow ReqTest, ReqEval/Apply only if cap.eval explicitly present
 * - Truth: test-certified with heavier obligations
 * - Forbid ReqTool by default
 * - Require receipts at all promotion boundaries
 *
 * Use: production semantics
 */
export const PROFILE_STRICT: NormalizedProfile = makeProfile({
  name: "strict",
  caps: ["cap.observe", "cap.test", "cap.commit.rewrite", "cap.commit.method"],
  ops: ["infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op", "commit.op"],  // No amb, limited ops
  oracleReqs: ["ReqObserve", "ReqTest"],  // No ReqEval/ReqApply by default
  budgets: {
    maxOracleTurns: 100,
    maxEvalSteps: 50_000,
    maxToolCalls: 10,
    maxNestedDepth: 4,
    maxOracleReqs: 50,
    maxCommits: 10,
  },
  truth: "test-certified",
  deterministic: true,  // Only scripted/replay
});

/**
 * profile:airgap - Private/offline, reproducible semantics
 *
 * - Allow infer.op but FORBID ReqTool
 * - Optionally forbid ReqEval (depending on security stance)
 * - Allow ReqObserve only on redacted projections
 * - Truth: speculative unless tests are hermetic
 * - Tight budgets
 *
 * Use: private/offline, reproducible semantics
 */
export const PROFILE_AIRGAP: NormalizedProfile = makeProfile({
  name: "airgap",
  caps: ["cap.observe", "cap.infer"],
  ops: ["infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op", "observe.op"],  // No tool.op, no commit.op
  oracleReqs: ["ReqObserve"],       // NO ReqTool, NO ReqEval/ReqApply
  budgets: {
    maxOracleTurns: 50,
    maxEvalSteps: 10_000,
    maxToolCalls: 0,               // Airgap: no tools
    maxNestedDepth: 4,
    maxOracleReqs: 25,
    maxCommits: 0,                 // Airgap: no commits
  },
  truth: "speculative",
  deterministic: true,
});

// Legacy profiles (for backward compatibility)
export const PROFILE_SPECULATIVE: NormalizedProfile = PROFILE_EXPLORE;
export const PROFILE_TEST_CERTIFIED: NormalizedProfile = PROFILE_PRAGMATIC;
export const PROFILE_PROOF_CERTIFIED: NormalizedProfile = makeProfile({
  name: "proof-certified",
  caps: ["*"],
  ops: ["infer.op", "int.op", "search.op", "rewrite.op", "oracle.apply.op", "tool.op", "commit.op", "amb.op", "amb.choose", "amb.fail", "observe.op"],
  oracleReqs: ["ReqEval", "ReqApply", "ReqObserve", "ReqTool", "ReqTest", "ReqCommit"],
  budgets: {
    maxOracleTurns: 100_000,
    maxEvalSteps: 5_000_000,
    maxToolCalls: 10_000,
    maxNestedDepth: 32,
    maxOracleReqs: 50_000,
    maxCommits: 1000,
  },
  truth: "proof-certified",
  deterministic: false,
});

export const DEFAULT_PROFILE = PROFILE_PRAGMATIC;

// ─────────────────────────────────────────────────────────────────
// Profile lookup by name
// ─────────────────────────────────────────────────────────────────

const PROFILE_REGISTRY: Map<string, NormalizedProfile> = new Map([
  ["explore", PROFILE_EXPLORE],
  ["pragmatic", PROFILE_PRAGMATIC],
  ["strict", PROFILE_STRICT],
  ["airgap", PROFILE_AIRGAP],
  ["speculative", PROFILE_SPECULATIVE],
  ["test-certified", PROFILE_TEST_CERTIFIED],
  ["proof-certified", PROFILE_PROOF_CERTIFIED],
]);

export function getProfile(name: string): NormalizedProfile | undefined {
  const p = PROFILE_REGISTRY.get(name);
  return p ? normalizeProfile(p) : undefined;
}

export function getProfileOrDefault(name: string): NormalizedProfile {
  return normalizeProfile(PROFILE_REGISTRY.get(name) ?? DEFAULT_PROFILE);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/macro/expander.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/macro/expander.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 15: Macro expansion engine

import type { Syntax, Scope, SIdent, SList } from "../syntax/syntax";
import { isIdent, isList, addScope, freshScope } from "../syntax/syntax";
import type { Env } from "../syntax/binding";
import { resolveIdent } from "../syntax/binding";
import { applySyntaxRules, type SRTransformer } from "../expand/syntaxRules";
import type {
  MacroTransformer,
  MacroEnv,
  MacroBinding,
  ExpansionResult,
  ExpansionContext,
  ExpansionStep,
  ExpansionTrace,
  ObligationRef,
  EvidenceRef,
  MacroProfile,
  SemanticMacroConfig,
  DEFAULT_SEMANTIC_CONFIG,
} from "./types";
import { getMacroProfile, MACRO_PROFILES } from "./types";
import {
  makeUseScope,
  makeIntroducerScope,
  resolveMacroIdent,
  addScopeToSyntax,
  flipScopeOnSyntax,
  collectPatternVariables,
  applyHygiene,
} from "./hygiene";

// ─────────────────────────────────────────────────────────────────
// Expansion State
// ─────────────────────────────────────────────────────────────────

/**
 * Global expansion state for tracking across nested expansions.
 */
let expansionEvents: ExpansionStep[] = [];
let totalExpansionSteps = 0;

/**
 * Clear expansion state (for testing).
 */
export function clearExpansionState(): void {
  expansionEvents = [];
  totalExpansionSteps = 0;
}

/**
 * Get expansion events (for debugging/replay).
 */
export function getExpansionEvents(): ExpansionStep[] {
  return [...expansionEvents];
}

// ─────────────────────────────────────────────────────────────────
// Core Expansion Functions
// ─────────────────────────────────────────────────────────────────

/**
 * Create a default expansion context.
 */
export function makeExpansionContext(
  runtimeEnv: Env,
  macroEnv: MacroEnv,
  profileName: string = "pragmatic"
): ExpansionContext {
  const profile = getMacroProfile(profileName);
  return {
    phase: 1,
    runtimeEnv,
    macroEnv,
    scopeCounter: { n: 0 },
    profileName,
    caps: new Set(["cap.macro.expand"]),
    stepBudget: profile.stepBudget,
    stepCount: 0,
    tracing: false,
    trace: [],
  };
}

/**
 * Expand syntax to fixed point.
 *
 * This is the main entry point for macro expansion.
 */
export function expand(stx: Syntax, ctx: ExpansionContext): ExpansionResult {
  const obligations: ObligationRef[] = [];
  const evidence: EvidenceRef[] = [];
  let semantic = false;
  let current = stx;
  let expanded = true;

  while (expanded && ctx.stepCount < ctx.stepBudget) {
    const result = macroexpand1(current, ctx);
    if (result.expanded === current) {
      expanded = false;
    } else {
      current = result.expanded;
      obligations.push(...result.obligations);
      evidence.push(...result.evidence);
      semantic = semantic || result.semantic;
    }
  }

  // Recursively expand subforms
  const finalResult = expandSubforms(current, ctx);
  obligations.push(...finalResult.obligations);
  evidence.push(...finalResult.evidence);
  semantic = semantic || finalResult.semantic;

  return {
    expanded: finalResult.expanded,
    obligations,
    evidence,
    semantic,
    trace: ctx.tracing ? { steps: ctx.trace, totalSteps: ctx.stepCount, macrosInvoked: [], semanticCalls: 0 } : undefined,
  };
}

/**
 * Perform a single expansion step.
 */
export function macroexpand1(stx: Syntax, ctx: ExpansionContext): ExpansionResult {
  const noChange: ExpansionResult = {
    expanded: stx,
    obligations: [],
    evidence: [],
    semantic: false,
  };

  // Only lists can be macro applications
  if (!isList(stx) || stx.items.length === 0) {
    return noChange;
  }

  const head = stx.items[0];
  if (!isIdent(head)) {
    return noChange;
  }

  // Look up macro binding
  const macroBinding = resolveMacroIdent(head, ctx.macroEnv, ctx.phase);
  if (!macroBinding) {
    return noChange;
  }

  // Check profile permissions
  const profile = getMacroProfile(ctx.profileName ?? "pragmatic");
  const transformer = macroBinding.transformer;

  if (transformer.tag === "SemanticMacro" && !profile.canExpandSemantic) {
    return {
      expanded: stx,
      obligations: [],
      evidence: [],
      semantic: false,
    };
  }

  // Apply the macro transformer
  ctx.stepCount++;
  totalExpansionSteps++;

  const useScope = makeUseScope(macroBinding.name, ctx.scopeCounter);
  const introScope = makeIntroducerScope(macroBinding.name, ctx.scopeCounter);

  // Add use scope to input
  const inputWithScope = addScopeToSyntax(stx, useScope);

  let result: ExpansionResult;

  switch (transformer.tag) {
    case "SyntaxRules":
      result = expandSyntaxRules(
        transformer.transformer,
        inputWithScope,
        useScope,
        introScope,
        ctx
      );
      break;

    case "ProcMacro":
      result = expandProcMacro(
        transformer,
        inputWithScope,
        useScope,
        introScope,
        ctx
      );
      break;

    case "SemanticMacro":
      result = expandSemanticMacro(
        transformer,
        inputWithScope,
        useScope,
        introScope,
        ctx
      );
      break;
  }

  // Record expansion step
  if (ctx.tracing) {
    ctx.trace.push({
      stepNum: ctx.stepCount,
      macro: macroBinding.name,
      input: stx,
      output: result.expanded,
      timestamp: Date.now(),
      semantic: result.semantic,
    });
  }

  expansionEvents.push({
    stepNum: totalExpansionSteps,
    macro: macroBinding.name,
    input: stx,
    output: result.expanded,
    timestamp: Date.now(),
    semantic: result.semantic,
  });

  return result;
}

/**
 * Expand to fixed point.
 */
export function macroexpand(stx: Syntax, ctx: ExpansionContext): ExpansionResult {
  const obligations: ObligationRef[] = [];
  const evidence: EvidenceRef[] = [];
  let semantic = false;
  let current = stx;
  let maxIter = ctx.stepBudget;

  while (maxIter-- > 0) {
    const result = macroexpand1(current, ctx);
    if (result.expanded === current) {
      break;
    }
    current = result.expanded;
    obligations.push(...result.obligations);
    evidence.push(...result.evidence);
    semantic = semantic || result.semantic;
  }

  return {
    expanded: current,
    obligations,
    evidence,
    semantic,
  };
}

// ─────────────────────────────────────────────────────────────────
// Transformer Application
// ─────────────────────────────────────────────────────────────────

/**
 * Expand using syntax-rules transformer.
 */
function expandSyntaxRules(
  tr: SRTransformer,
  input: Syntax,
  useScope: Scope,
  introScope: Scope,
  ctx: ExpansionContext
): ExpansionResult {
  try {
    // Apply syntax-rules (already handles hygiene)
    const output = applySyntaxRules(tr, input, ctx.runtimeEnv, ctx.scopeCounter);

    // Flip use scope and add intro scope
    const hygienic = flipScopeOnSyntax(output, useScope);

    return {
      expanded: hygienic,
      obligations: [],
      evidence: [],
      semantic: false,
    };
  } catch (e) {
    // No rule matched - return unchanged
    return {
      expanded: input,
      obligations: [],
      evidence: [],
      semantic: false,
    };
  }
}

/**
 * Expand using proc macro (procedural macro).
 */
function expandProcMacro(
  transformer: Extract<MacroTransformer, { tag: "ProcMacro" }>,
  input: Syntax,
  useScope: Scope,
  introScope: Scope,
  ctx: ExpansionContext
): ExpansionResult {
  // For now, proc macros are not fully implemented
  // They would invoke the proc closure with the input syntax
  return {
    expanded: input,
    obligations: [],
    evidence: [],
    semantic: false,
  };
}

/**
 * Expand using semantic macro (with inference support).
 */
function expandSemanticMacro(
  transformer: Extract<MacroTransformer, { tag: "SemanticMacro" }>,
  input: Syntax,
  useScope: Scope,
  introScope: Scope,
  ctx: ExpansionContext
): ExpansionResult {
  const profile = getMacroProfile(ctx.profileName ?? "pragmatic");

  // Check if semantic expansion is allowed
  if (!profile.canExpandSemantic) {
    return {
      expanded: input,
      obligations: [{
        id: `denied-${Date.now()}`,
        kind: "contract",
        description: "Semantic macro expansion denied by profile",
        satisfied: false,
      }],
      evidence: [],
      semantic: true,
    };
  }

  // For now, semantic macros return input with obligations
  // Full implementation would invoke inference
  const obligations: ObligationRef[] = [];

  if (transformer.obligations) {
    for (const kind of transformer.obligations.required) {
      obligations.push({
        id: `obligation-${kind}-${Date.now()}`,
        kind,
        description: `Required ${kind} obligation for semantic macro`,
        satisfied: false,
      });
    }
  }

  return {
    expanded: input,
    obligations,
    evidence: [],
    semantic: true,
  };
}

// ─────────────────────────────────────────────────────────────────
// Subform Expansion
// ─────────────────────────────────────────────────────────────────

/**
 * Recursively expand subforms of a syntax tree.
 */
function expandSubforms(stx: Syntax, ctx: ExpansionContext): ExpansionResult {
  switch (stx.tag) {
    case "Atom":
    case "Ident":
      return { expanded: stx, obligations: [], evidence: [], semantic: false };

    case "List": {
      if (stx.items.length === 0) {
        return { expanded: stx, obligations: [], evidence: [], semantic: false };
      }

      const head = stx.items[0];

      // Check for special forms that don't expand their bodies normally
      if (isIdent(head)) {
        const name = head.name;

        // quote doesn't expand its body
        if (name === "quote") {
          return { expanded: stx, obligations: [], evidence: [], semantic: false };
        }

        // define-syntax processes differently
        if (name === "define-syntax") {
          return expandDefineSyntax(stx, ctx);
        }

        // define-syntax/semantic processes differently
        if (name === "define-syntax/semantic") {
          return expandDefineSemanticSyntax(stx, ctx);
        }

        // lambda/define expand their bodies
        if (name === "lambda" || name === "λ") {
          return expandLambda(stx, ctx);
        }

        if (name === "define") {
          return expandDefine(stx, ctx);
        }

        if (name === "let" || name === "let*" || name === "letrec") {
          return expandLet(stx, name, ctx);
        }
      }

      // For other lists, expand all subforms
      const obligations: ObligationRef[] = [];
      const evidence: EvidenceRef[] = [];
      let semantic = false;
      const newItems: Syntax[] = [];

      for (const item of stx.items) {
        const result = expand(item, ctx);
        newItems.push(result.expanded);
        obligations.push(...result.obligations);
        evidence.push(...result.evidence);
        semantic = semantic || result.semantic;
      }

      return {
        expanded: { ...stx, items: newItems },
        obligations,
        evidence,
        semantic,
      };
    }
  }
}

/**
 * Expand define-syntax form.
 */
function expandDefineSyntax(stx: SList, ctx: ExpansionContext): ExpansionResult {
  // (define-syntax name transformer)
  if (stx.items.length < 3) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  const nameStx = stx.items[1];
  const transformerStx = stx.items[2];

  if (!isIdent(nameStx)) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  // For now, just return the form as-is
  // The actual binding happens at a higher level
  return { expanded: stx, obligations: [], evidence: [], semantic: false };
}

/**
 * Expand define-syntax/semantic form.
 */
function expandDefineSemanticSyntax(stx: SList, ctx: ExpansionContext): ExpansionResult {
  // (define-syntax/semantic name transformer :obligations spec)
  return {
    expanded: stx,
    obligations: [{
      id: `semantic-def-${Date.now()}`,
      kind: "test",
      description: "Semantic macro definition requires test obligations",
      satisfied: false,
    }],
    evidence: [],
    semantic: true,
  };
}

/**
 * Expand lambda form with hygiene for parameters.
 */
function expandLambda(stx: SList, ctx: ExpansionContext): ExpansionResult {
  // (lambda (params...) body...)
  if (stx.items.length < 3) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  const paramsStx = stx.items[1];
  const bodyItems = stx.items.slice(2);

  if (!isList(paramsStx)) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  // Expand body forms
  const obligations: ObligationRef[] = [];
  const evidence: EvidenceRef[] = [];
  let semantic = false;
  const expandedBody: Syntax[] = [];

  for (const body of bodyItems) {
    const result = expand(body, ctx);
    expandedBody.push(result.expanded);
    obligations.push(...result.obligations);
    evidence.push(...result.evidence);
    semantic = semantic || result.semantic;
  }

  return {
    expanded: {
      ...stx,
      items: [stx.items[0], paramsStx, ...expandedBody],
    },
    obligations,
    evidence,
    semantic,
  };
}

/**
 * Expand define form.
 */
function expandDefine(stx: SList, ctx: ExpansionContext): ExpansionResult {
  // (define name expr) or (define (name params...) body...)
  if (stx.items.length < 3) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  const secondItem = stx.items[1];

  if (isList(secondItem)) {
    // Function shorthand: (define (name params...) body...)
    const bodyItems = stx.items.slice(2);
    const obligations: ObligationRef[] = [];
    const evidence: EvidenceRef[] = [];
    let semantic = false;
    const expandedBody: Syntax[] = [];

    for (const body of bodyItems) {
      const result = expand(body, ctx);
      expandedBody.push(result.expanded);
      obligations.push(...result.obligations);
      evidence.push(...result.evidence);
      semantic = semantic || result.semantic;
    }

    return {
      expanded: {
        ...stx,
        items: [stx.items[0], secondItem, ...expandedBody],
      },
      obligations,
      evidence,
      semantic,
    };
  }

  // Simple define: (define name expr)
  const exprResult = expand(stx.items[2], ctx);
  return {
    expanded: {
      ...stx,
      items: [stx.items[0], stx.items[1], exprResult.expanded],
    },
    obligations: exprResult.obligations,
    evidence: exprResult.evidence,
    semantic: exprResult.semantic,
  };
}

/**
 * Expand let, let*, and letrec forms.
 */
function expandLet(stx: SList, letKind: string, ctx: ExpansionContext): ExpansionResult {
  // (let ((name val) ...) body...)
  if (stx.items.length < 3) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  const bindingsStx = stx.items[1];
  const bodyItems = stx.items.slice(2);

  if (!isList(bindingsStx)) {
    return { expanded: stx, obligations: [], evidence: [], semantic: false };
  }

  const obligations: ObligationRef[] = [];
  const evidence: EvidenceRef[] = [];
  let semantic = false;

  // Expand binding values
  const expandedBindings: Syntax[] = [];
  for (const binding of bindingsStx.items) {
    if (!isList(binding) || binding.items.length < 2) {
      expandedBindings.push(binding);
      continue;
    }

    const nameStx = binding.items[0];
    const valStx = binding.items[1];
    const valResult = expand(valStx, ctx);

    expandedBindings.push({
      ...binding,
      items: [nameStx, valResult.expanded],
    });
    obligations.push(...valResult.obligations);
    evidence.push(...valResult.evidence);
    semantic = semantic || valResult.semantic;
  }

  // Expand body
  const expandedBody: Syntax[] = [];
  for (const body of bodyItems) {
    const result = expand(body, ctx);
    expandedBody.push(result.expanded);
    obligations.push(...result.obligations);
    evidence.push(...result.evidence);
    semantic = semantic || result.semantic;
  }

  return {
    expanded: {
      ...stx,
      items: [
        stx.items[0],
        { ...bindingsStx, items: expandedBindings },
        ...expandedBody,
      ],
    },
    obligations,
    evidence,
    semantic,
  };
}

// ─────────────────────────────────────────────────────────────────
// Macro Environment Management
// ─────────────────────────────────────────────────────────────────

let nextBindingId = 0;

/**
 * Create an empty macro environment.
 */
export function createMacroEnv(): MacroEnv {
  return new Map();
}

/**
 * Add a macro binding to the environment.
 */
export function addMacroBinding(
  env: MacroEnv,
  name: string,
  transformer: MacroTransformer,
  phase: number,
  scopes: Scope[]
): MacroEnv {
  const bindingId = `macro-${name}-${nextBindingId++}`;
  const binding: MacroBinding = {
    name,
    transformer,
    phase,
    scopes,
    bindingId,
  };

  const newEnv = new Map(env);
  newEnv.set(bindingId, binding);
  return newEnv;
}

/**
 * Reset binding ID counter (for testing).
 */
export function resetBindingIds(): void {
  nextBindingId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Convenience Functions
// ─────────────────────────────────────────────────────────────────

/**
 * Create a syntax-rules macro transformer.
 */
export function makeSyntaxRulesTransformer(
  tr: SRTransformer,
  defScope: Scope,
  name?: string
): MacroTransformer {
  return {
    tag: "SyntaxRules",
    transformer: tr,
    defScope,
    name,
  };
}

/**
 * Create a semantic macro transformer.
 */
export function makeSemanticTransformer(
  proc: import("../eval/values").Val,
  defScope: Scope,
  name?: string,
  obligations?: import("./types").ObligationSpec
): MacroTransformer {
  return {
    tag: "SemanticMacro",
    proc,
    defScope,
    obligations,
    name,
  };
}

/**
 * Check if expansion is cacheable (deterministic).
 */
export function isExpansionCacheable(result: ExpansionResult): boolean {
  // Semantic expansions are not cacheable (involve inference)
  return !result.semantic;
}

/**
 * Generate expansion receipt hash.
 */
export function generateExpansionReceipt(
  input: Syntax,
  result: ExpansionResult
): string {
  // Simple hash for now
  const data = JSON.stringify({
    input,
    output: result.expanded,
    semantic: result.semantic,
  });

  // Simple string hash
  let hash = 0;
  for (let i = 0; i < data.length; i++) {
    hash = ((hash << 5) - hash) + data.charCodeAt(i);
    hash |= 0;
  }
  return `receipt-${Math.abs(hash).toString(16)}`;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/macro/hygiene.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/macro/hygiene.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 15: Set-of-scopes hygiene implementation

import type { Syntax, Scope, SIdent } from "../syntax/syntax";
import { isIdent, isList, addScope, freshScope } from "../syntax/syntax";
import type { Env, Binding, BindingKind } from "../syntax/binding";
import { resolveIdent } from "../syntax/binding";
import type { ScopeId, MacroEnv, MacroBinding, SourceLocation } from "./types";

// ─────────────────────────────────────────────────────────────────
// Scope Management
// ─────────────────────────────────────────────────────────────────

let globalScopeCounter = { n: 0 };

/**
 * Generate a fresh scope ID.
 */
export function freshScopeId(counter?: { n: number }): ScopeId {
  const c = counter ?? globalScopeCounter;
  c.n += 1;
  return `scope#${c.n}`;
}

/**
 * Reset the global scope counter (for testing).
 */
export function resetScopeCounter(): void {
  globalScopeCounter.n = 0;
}

/**
 * Generate a definition scope for a macro.
 */
export function makeDefScope(macroName: string, counter?: { n: number }): ScopeId {
  const c = counter ?? globalScopeCounter;
  c.n += 1;
  return `def#${macroName}#${c.n}`;
}

/**
 * Generate a use scope for a macro invocation.
 */
export function makeUseScope(macroName: string, counter?: { n: number }): ScopeId {
  const c = counter ?? globalScopeCounter;
  c.n += 1;
  return `use#${macroName}#${c.n}`;
}

/**
 * Generate a binding scope for introduced bindings.
 */
export function makeBindScope(binderName: string, counter?: { n: number }): ScopeId {
  const c = counter ?? globalScopeCounter;
  c.n += 1;
  return `bind#${binderName}#${c.n}`;
}

/**
 * Generate an introducer scope for macro-introduced identifiers.
 */
export function makeIntroducerScope(macroName: string, counter?: { n: number }): ScopeId {
  const c = counter ?? globalScopeCounter;
  c.n += 1;
  return `intro#${macroName}#${c.n}`;
}

// ─────────────────────────────────────────────────────────────────
// Scope Set Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Check if scope set A is a subset of scope set B.
 */
export function scopeSubset(a: Scope[], b: Scope[]): boolean {
  const bSet = new Set(b);
  for (const s of a) {
    if (!bSet.has(s)) return false;
  }
  return true;
}

/**
 * Compute intersection of two scope sets.
 */
export function scopeIntersection(a: Scope[], b: Scope[]): Scope[] {
  const bSet = new Set(b);
  return a.filter(s => bSet.has(s));
}

/**
 * Compute union of two scope sets.
 */
export function scopeUnion(a: Scope[], b: Scope[]): Scope[] {
  const result = new Set(a);
  for (const s of b) result.add(s);
  return Array.from(result);
}

/**
 * Compute difference of two scope sets (A - B).
 */
export function scopeDifference(a: Scope[], b: Scope[]): Scope[] {
  const bSet = new Set(b);
  return a.filter(s => !bSet.has(s));
}

/**
 * Check if two scope sets are equal.
 */
export function scopeEqual(a: Scope[], b: Scope[]): boolean {
  if (a.length !== b.length) return false;
  const aSet = new Set(a);
  for (const s of b) {
    if (!aSet.has(s)) return false;
  }
  return true;
}

// ─────────────────────────────────────────────────────────────────
// Syntax Manipulation
// ─────────────────────────────────────────────────────────────────

/**
 * Add a scope to all identifiers in a syntax tree.
 */
export function addScopeToSyntax(stx: Syntax, scope: Scope): Syntax {
  return addScope(stx, scope);
}

/**
 * Remove a scope from all identifiers in a syntax tree.
 */
export function removeScopeFromSyntax(stx: Syntax, scope: Scope): Syntax {
  switch (stx.tag) {
    case "Atom":
      return { ...stx, scopes: stx.scopes.filter(s => s !== scope) };
    case "Ident":
      return { ...stx, scopes: stx.scopes.filter(s => s !== scope) };
    case "List":
      return {
        ...stx,
        scopes: stx.scopes.filter(s => s !== scope),
        items: stx.items.map(it => removeScopeFromSyntax(it, scope)),
      };
  }
}

/**
 * Flip a scope on all identifiers (add if missing, remove if present).
 */
export function flipScopeOnSyntax(stx: Syntax, scope: Scope): Syntax {
  switch (stx.tag) {
    case "Atom": {
      const scopes = stx.scopes.includes(scope)
        ? stx.scopes.filter(s => s !== scope)
        : stx.scopes.concat([scope]);
      return { ...stx, scopes };
    }
    case "Ident": {
      const scopes = stx.scopes.includes(scope)
        ? stx.scopes.filter(s => s !== scope)
        : stx.scopes.concat([scope]);
      return { ...stx, scopes };
    }
    case "List": {
      const scopes = stx.scopes.includes(scope)
        ? stx.scopes.filter(s => s !== scope)
        : stx.scopes.concat([scope]);
      return {
        ...stx,
        scopes,
        items: stx.items.map(it => flipScopeOnSyntax(it, scope)),
      };
    }
  }
}

/**
 * Get the identifier name from a syntax object.
 */
export function syntaxIdentName(stx: Syntax): string | null {
  if (stx.tag === "Ident") return stx.name;
  return null;
}

/**
 * Get the scopes from a syntax object.
 */
export function syntaxScopes(stx: Syntax): Scope[] {
  return stx.scopes;
}

/**
 * Create an identifier syntax with given name and scopes.
 */
export function makeIdent(name: string, scopes: Scope[]): SIdent {
  return { tag: "Ident", name, scopes };
}

/**
 * Create an atom syntax with given value and scopes.
 */
export function makeAtom(value: any, scopes: Scope[]): Syntax {
  return { tag: "Atom", value, scopes };
}

/**
 * Create a list syntax with given items and scopes.
 */
export function makeList(items: Syntax[], scopes: Scope[]): Syntax {
  return { tag: "List", items, scopes };
}

// ─────────────────────────────────────────────────────────────────
// Identifier Resolution
// ─────────────────────────────────────────────────────────────────

/**
 * Resolve an identifier in both value and syntax (macro) environments.
 */
export function resolveIdentFull(
  id: SIdent,
  runtimeEnv: Env,
  macroEnv: MacroEnv,
  phase: number
): { kind: "value"; binding: Binding } | { kind: "syntax"; binding: MacroBinding } | null {
  // First, check macro environment at phase 1
  if (phase === 1) {
    const macroBinding = resolveMacroIdent(id, macroEnv, phase);
    if (macroBinding) {
      return { kind: "syntax", binding: macroBinding };
    }
  }

  // Then check runtime environment
  const runtimeBinding = resolveIdent(id, runtimeEnv, phase);
  if (runtimeBinding) {
    return { kind: "value", binding: runtimeBinding };
  }

  // Check macro environment at any phase for syntax bindings
  const macroBinding = resolveMacroIdent(id, macroEnv, phase);
  if (macroBinding) {
    return { kind: "syntax", binding: macroBinding };
  }

  return null;
}

/**
 * Resolve an identifier in the macro environment.
 */
export function resolveMacroIdent(
  id: SIdent,
  macroEnv: MacroEnv,
  phase: number
): MacroBinding | null {
  const candidates: MacroBinding[] = [];

  for (const [_, binding] of macroEnv) {
    if (
      binding.name === id.name &&
      binding.phase === phase &&
      scopeSubset(binding.scopes, id.scopes)
    ) {
      candidates.push(binding);
    }
  }

  if (candidates.length === 0) return null;

  // Sort by scope set size (most specific first)
  candidates.sort((a, b) => b.scopes.length - a.scopes.length);

  const best = candidates[0];
  const second = candidates[1];

  // Check for ambiguity
  if (second && second.scopes.length === best.scopes.length) {
    throw new Error(`Macro identifier ambiguity: ${id.name} at phase ${phase}`);
  }

  return best;
}

/**
 * Check if two identifiers are free-identifier=? (same binding).
 */
export function freeIdentifierEqual(
  id1: SIdent,
  env1: Env,
  id2: SIdent,
  env2: Env,
  phase: number
): boolean {
  const b1 = resolveIdent(id1, env1, phase);
  const b2 = resolveIdent(id2, env2, phase);

  if (b1 && b2) return b1.bid === b2.bid;
  if (!b1 && !b2) return id1.name === id2.name;
  return false;
}

/**
 * Check if two identifiers are bound-identifier=? (same name and scopes).
 */
export function boundIdentifierEqual(id1: SIdent, id2: SIdent): boolean {
  return id1.name === id2.name && scopeEqual(id1.scopes, id2.scopes);
}

// ─────────────────────────────────────────────────────────────────
// Syntax Conversion
// ─────────────────────────────────────────────────────────────────

/**
 * Convert syntax to datum (strip scopes).
 */
export function syntaxToDatum(stx: Syntax): any {
  switch (stx.tag) {
    case "Atom":
      return stx.value;
    case "Ident":
      return Symbol.for(stx.name);
    case "List":
      return stx.items.map(syntaxToDatum);
  }
}

/**
 * Convert datum to syntax with context from another syntax object.
 */
export function datumToSyntax(ctx: Syntax | null, datum: any, srcloc?: SourceLocation): Syntax {
  const scopes = ctx?.scopes ?? [];

  if (datum === null || datum === undefined) {
    return { tag: "Atom", value: datum, scopes };
  }

  if (typeof datum === "symbol") {
    return { tag: "Ident", name: datum.description ?? String(datum), scopes };
  }

  if (Array.isArray(datum)) {
    return {
      tag: "List",
      items: datum.map(d => datumToSyntax(ctx, d, srcloc)),
      scopes,
    };
  }

  if (typeof datum === "string" && datum.startsWith(":")) {
    // Keyword or identifier starting with :
    return { tag: "Ident", name: datum, scopes };
  }

  // Primitives
  return { tag: "Atom", value: datum, scopes };
}

// ─────────────────────────────────────────────────────────────────
// Hygiene Helpers for Macro Expansion
// ─────────────────────────────────────────────────────────────────

/**
 * Apply hygiene transformation to macro output.
 *
 * This implements the set-of-scopes model:
 * 1. Add useScope to the macro input
 * 2. Apply the macro transformer
 * 3. Add introScope to macro-introduced identifiers
 * 4. Flip useScope on the result (removes from substituted, keeps on introduced)
 */
export function applyHygiene(
  macroName: string,
  input: Syntax,
  output: Syntax,
  useScope: Scope,
  introScope: Scope,
  substitutedVars: Set<string>
): Syntax {
  // The useScope was added to input before transformation.
  // Now flip it on the output to:
  // - Remove from identifiers that came from input (pattern variables)
  // - Add to identifiers introduced by the macro
  const result = flipScopeOnSyntax(output, useScope);

  // Add introScope to truly introduced identifiers
  return addIntroducerToIntroduced(result, introScope, substitutedVars);
}

/**
 * Add introducer scope only to identifiers that weren't substituted.
 */
function addIntroducerToIntroduced(
  stx: Syntax,
  introScope: Scope,
  substitutedVars: Set<string>
): Syntax {
  switch (stx.tag) {
    case "Atom":
      return stx;
    case "Ident":
      // If this identifier was substituted from input, don't add intro scope
      if (substitutedVars.has(stx.name)) {
        return stx;
      }
      return addScope(stx, introScope);
    case "List":
      return {
        ...stx,
        items: stx.items.map(it => addIntroducerToIntroduced(it, introScope, substitutedVars)),
      };
  }
}

/**
 * Track which identifiers in a template are pattern variables.
 */
export function collectPatternVariables(pattern: Syntax): Set<string> {
  const vars = new Set<string>();
  collectPatternVarsRec(pattern, vars);
  return vars;
}

function collectPatternVarsRec(pat: Syntax, vars: Set<string>): void {
  switch (pat.tag) {
    case "Atom":
      return;
    case "Ident":
      // Skip wildcard and ellipsis
      if (pat.name !== "_" && pat.name !== "...") {
        vars.add(pat.name);
      }
      return;
    case "List":
      for (const item of pat.items) {
        collectPatternVarsRec(item, vars);
      }
      return;
  }
}

// ─────────────────────────────────────────────────────────────────
// Alpha Normalization (for testing equality)
// ─────────────────────────────────────────────────────────────────

/**
 * Alpha-normalize a syntax tree for comparison.
 *
 * Replaces all generated scope names with canonical names.
 */
export function alphaNormalize(stx: Syntax): Syntax {
  const scopeMap = new Map<string, string>();
  let counter = 0;

  function normalizeScope(scope: Scope): Scope {
    if (!scopeMap.has(scope)) {
      scopeMap.set(scope, `α${counter++}`);
    }
    return scopeMap.get(scope)!;
  }

  function normalize(s: Syntax): Syntax {
    const normalizedScopes = s.scopes.map(normalizeScope);
    switch (s.tag) {
      case "Atom":
        return { ...s, scopes: normalizedScopes };
      case "Ident":
        return { ...s, scopes: normalizedScopes };
      case "List":
        return {
          ...s,
          scopes: normalizedScopes,
          items: s.items.map(normalize),
        };
    }
  }

  return normalize(stx);
}

/**
 * Check if two syntax trees are alpha-equivalent.
 */
export function alphaEquivalent(stx1: Syntax, stx2: Syntax): boolean {
  const norm1 = alphaNormalize(stx1);
  const norm2 = alphaNormalize(stx2);
  return JSON.stringify(norm1) === JSON.stringify(norm2);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/macro/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/macro/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 15: Hygienic macros + phase separation + semantic macros

export * from "./types";
export * from "./hygiene";
export * from "./expander";
export * from "./semantic";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/macro/semantic.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/macro/semantic.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 15: Semantic macros with inference and commit barriers

import type { Val } from "../eval/values";
import { VUnit, VTrue, VFalse } from "../eval/values";
import type { Syntax, Scope, SIdent, SList } from "../syntax/syntax";
import { isIdent, isList } from "../syntax/syntax";
import type { Env } from "../syntax/binding";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type {
  MacroTransformer,
  MacroEnv,
  ExpansionResult,
  ExpansionContext,
  ObligationRef,
  ObligationKind,
  ObligationSpec,
  EvidenceRef,
  SemanticMacroConfig,
  MacroProfile,
  ReqExpand,
  RespSyntax,
} from "./types";
import { getMacroProfile, DEFAULT_SEMANTIC_CONFIG } from "./types";
import { makeSemanticTransformer, makeExpansionContext } from "./expander";
import { makeDefScope, makeIdent, makeList, makeAtom } from "./hygiene";

// ─────────────────────────────────────────────────────────────────
// Semantic Macro Expansion
// ─────────────────────────────────────────────────────────────────

/**
 * SemanticExpansionState: State during semantic macro expansion.
 */
export type SemanticExpansionState = {
  /** Configuration */
  config: SemanticMacroConfig;
  /** Inference calls made */
  inferenceCalls: number;
  /** Rewrite proposals collected */
  rewriteProposals: RewriteProposal[];
  /** Obligations collected */
  obligations: ObligationRef[];
  /** Evidence collected */
  evidence: EvidenceRef[];
  /** Profile constraints */
  profile: MacroProfile;
  /** Start time for timeout */
  startTime: number;
};

/**
 * RewriteProposal: A proposed expansion from inference.
 */
export type RewriteProposal = {
  id: string;
  expanded: Syntax;
  confidence: number;
  source: "inference" | "rewrite" | "template";
  obligations: ObligationRef[];
};

/**
 * Create semantic expansion state.
 */
export function createSemanticState(
  profileName: string,
  config: Partial<SemanticMacroConfig> = {}
): SemanticExpansionState {
  return {
    config: { ...DEFAULT_SEMANTIC_CONFIG, ...config },
    inferenceCalls: 0,
    rewriteProposals: [],
    obligations: [],
    evidence: [],
    profile: getMacroProfile(profileName),
    startTime: Date.now(),
  };
}

/**
 * Apply a semantic macro.
 */
export async function applySemanticMacro(
  transformer: Extract<MacroTransformer, { tag: "SemanticMacro" }>,
  input: Syntax,
  ctx: ExpansionContext,
  state: SemanticExpansionState
): Promise<ExpansionResult> {
  // Check profile constraints
  if (!state.profile.canExpandSemantic) {
    return {
      expanded: input,
      obligations: [{
        id: `denied-${Date.now()}`,
        kind: "contract",
        description: "Semantic macro expansion denied by profile",
        satisfied: false,
      }],
      evidence: [],
      semantic: true,
    };
  }

  // Check timeout
  if (Date.now() - state.startTime > state.config.timeout) {
    return {
      expanded: input,
      obligations: [{
        id: `timeout-${Date.now()}`,
        kind: "contract",
        description: "Semantic macro expansion timed out",
        satisfied: false,
      }],
      evidence: [],
      semantic: true,
    };
  }

  // Apply the semantic transformer
  // This would typically invoke inference, but for now we return the input
  // with required obligations
  const obligations: ObligationRef[] = [];

  if (transformer.obligations) {
    for (const kind of transformer.obligations.required) {
      obligations.push(createObligation(kind, `Required by semantic macro ${transformer.name}`));
    }
    for (const kind of transformer.obligations.optional) {
      obligations.push(createObligation(kind, `Optional for semantic macro ${transformer.name}`));
    }
  }

  return {
    expanded: input,
    obligations,
    evidence: [],
    semantic: true,
  };
}

// ─────────────────────────────────────────────────────────────────
// Inference Integration
// ─────────────────────────────────────────────────────────────────

/**
 * InferenceFn: Type for inference functions.
 */
export type InferenceFn = (prompt: Val) => Promise<Val>;

/**
 * RewriteFn: Type for rewrite functions.
 */
export type RewriteFn = (pattern: Val, replacement: Val) => Promise<Val>;

/**
 * Request inference for macro expansion.
 */
export async function requestInference(
  state: SemanticExpansionState,
  prompt: Val,
  inferenceFn?: InferenceFn
): Promise<Val | null> {
  // Check if inference is allowed
  if (!state.profile.canInfer) {
    return null;
  }

  // Check inference call limit
  if (state.inferenceCalls >= state.config.maxInferenceCalls) {
    return null;
  }

  state.inferenceCalls++;

  // If no inference function provided, return null
  if (!inferenceFn) {
    return null;
  }

  try {
    return await inferenceFn(prompt);
  } catch {
    return null;
  }
}

/**
 * Request a rewrite proposal.
 */
export async function requestRewrite(
  state: SemanticExpansionState,
  pattern: Syntax,
  replacement: Syntax,
  rewriteFn?: RewriteFn
): Promise<RewriteProposal | null> {
  if (!state.config.allowRewrite) {
    return null;
  }

  const proposal: RewriteProposal = {
    id: `rewrite-${state.rewriteProposals.length}`,
    expanded: replacement,
    confidence: 0.8,
    source: "rewrite",
    obligations: [
      createObligation("test", "Rewrite requires regression tests"),
    ],
  };

  state.rewriteProposals.push(proposal);
  return proposal;
}

// ─────────────────────────────────────────────────────────────────
// Obligation Management
// ─────────────────────────────────────────────────────────────────

let nextObligationId = 0;

/**
 * Create an obligation.
 */
export function createObligation(
  kind: ObligationKind,
  description?: string
): ObligationRef {
  return {
    id: `obligation-${nextObligationId++}`,
    kind,
    description,
    satisfied: false,
  };
}

/**
 * Create obligations from a specification.
 */
export function createObligationsFromSpec(spec: ObligationSpec): ObligationRef[] {
  const obligations: ObligationRef[] = [];

  for (const kind of spec.required) {
    obligations.push(createObligation(kind, `Required: ${kind}`));
  }

  for (const kind of spec.optional) {
    obligations.push(createObligation(kind, `Optional: ${kind}`));
  }

  if (spec.custom) {
    for (const desc of spec.custom) {
      obligations.push(createObligation("contract", desc));
    }
  }

  return obligations;
}

/**
 * Satisfy an obligation with evidence.
 */
export function satisfyObligation(
  obligation: ObligationRef,
  evidence: EvidenceRef
): ObligationRef {
  return {
    ...obligation,
    satisfied: true,
    evidence,
  };
}

/**
 * Check if all obligations are satisfied.
 */
export function allObligationsSatisfied(obligations: ObligationRef[]): boolean {
  return obligations.every(o => o.satisfied);
}

/**
 * Get unsatisfied obligations.
 */
export function getUnsatisfiedObligations(obligations: ObligationRef[]): ObligationRef[] {
  return obligations.filter(o => !o.satisfied);
}

/**
 * Reset obligation ID counter (for testing).
 */
export function resetObligationIds(): void {
  nextObligationId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Evidence Management
// ─────────────────────────────────────────────────────────────────

let nextEvidenceId = 0;

/**
 * Create evidence reference.
 */
export function createEvidence(
  kind: EvidenceRef["kind"],
  description?: string,
  hash?: Hash
): EvidenceRef {
  return {
    id: `evidence-${nextEvidenceId++}`,
    kind,
    description,
    hash,
  };
}

/**
 * Reset evidence ID counter (for testing).
 */
export function resetEvidenceIds(): void {
  nextEvidenceId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Commit Barriers
// ─────────────────────────────────────────────────────────────────

/**
 * CommitRequest: Request to commit a semantic expansion.
 */
export type CommitRequest = {
  expansion: ExpansionResult;
  profileName: string;
  obligations: ObligationRef[];
};

/**
 * CommitResult: Result of commit attempt.
 */
export type CommitResult =
  | { tag: "committed"; hash: Hash }
  | { tag: "denied"; reason: string; missingCaps?: string[] }
  | { tag: "pending"; unsatisfied: ObligationRef[] };

/**
 * Attempt to commit a semantic expansion.
 */
export function commitSemanticExpansion(
  request: CommitRequest,
  availableCaps: Set<string>
): CommitResult {
  const profile = getMacroProfile(request.profileName);

  // Check commit permission
  if (!profile.canCommit) {
    return {
      tag: "denied",
      reason: `Profile '${request.profileName}' does not allow commits`,
    };
  }

  // Check required capabilities
  const requiredCaps = ["cap.macro.commit"];
  const missingCaps = requiredCaps.filter(c => !availableCaps.has(c));
  if (missingCaps.length > 0) {
    return {
      tag: "denied",
      reason: "Missing required capabilities",
      missingCaps,
    };
  }

  // Check obligations
  const unsatisfied = getUnsatisfiedObligations(request.obligations);
  if (unsatisfied.length > 0) {
    return {
      tag: "pending",
      unsatisfied,
    };
  }

  // Generate commit hash
  const hash = sha256JSON({
    expanded: request.expansion.expanded,
    obligations: request.obligations.map(o => o.id),
    timestamp: Date.now(),
  });

  return {
    tag: "committed",
    hash,
  };
}

// ─────────────────────────────────────────────────────────────────
// Oracle Protocol Integration
// ─────────────────────────────────────────────────────────────────

/**
 * ExpandFunctions: Functions passed to handleReqExpand to avoid circular dependency.
 */
export type ExpandFunctions = {
  expand: (stx: Syntax, ctx: ExpansionContext) => ExpansionResult;
  macroexpand1: (stx: Syntax, ctx: ExpansionContext) => ExpansionResult;
};

/**
 * Handle ReqExpand from oracle protocol.
 *
 * Note: expandFns must be provided to avoid circular dependency.
 * If not provided, returns the input unchanged.
 */
export function handleReqExpand(
  req: ReqExpand,
  runtimeEnv: Env,
  macroEnv: MacroEnv,
  expandFns?: ExpandFunctions
): RespSyntax {
  const ctx = makeExpansionContext(runtimeEnv, macroEnv, req.profileName);

  // If no expand functions provided, return input unchanged
  if (!expandFns) {
    return {
      tag: "RespSyntax",
      stx: req.qstx,
      obligations: [],
    };
  }

  let result: ExpansionResult;
  if (req.mode === "1") {
    result = expandFns.macroexpand1(req.qstx, ctx);
  } else {
    result = expandFns.expand(req.qstx, ctx);
  }

  return {
    tag: "RespSyntax",
    stx: result.expanded,
    obligations: result.obligations,
    trace: result.trace,
  };
}

// ─────────────────────────────────────────────────────────────────
// Semantic Function Definition
// ─────────────────────────────────────────────────────────────────

/**
 * SemanticFunctionSpec: Specification for a semantic function.
 */
export type SemanticFunctionSpec = {
  name: string;
  params: string[];
  goal: GoalSpec;
  contract?: string;
  fallback?: Val;
};

/**
 * GoalSpec: Specification for a semantic goal.
 */
export type GoalSpec = {
  kind: string;
  forbid?: string[];
  require?: string[];
};

/**
 * Parse a defsemantic form.
 */
export function parseDefSemantic(stx: SList): SemanticFunctionSpec | null {
  // (defsemantic (name params...) :goal {...} :contract name :fallback expr)
  if (stx.items.length < 3) return null;

  const head = stx.items[0];
  if (!isIdent(head) || head.name !== "defsemantic") return null;

  const sig = stx.items[1];
  if (!isList(sig) || sig.items.length < 1) return null;

  const nameStx = sig.items[0];
  if (!isIdent(nameStx)) return null;

  const params: string[] = [];
  for (let i = 1; i < sig.items.length; i++) {
    const p = sig.items[i];
    if (!isIdent(p)) return null;
    params.push(p.name);
  }

  // Parse keyword arguments
  let goal: GoalSpec = { kind: "generic" };
  let contract: string | undefined;
  let fallback: Val | undefined;

  for (let i = 2; i < stx.items.length; i++) {
    const item = stx.items[i];
    if (isIdent(item)) {
      const kw = item.name;
      const nextItem = stx.items[i + 1];

      if (kw === ":goal" && nextItem && isList(nextItem)) {
        goal = parseGoalSpec(nextItem);
        i++;
      } else if (kw === ":contract" && nextItem && isIdent(nextItem)) {
        contract = nextItem.name;
        i++;
      } else if (kw === ":fallback" && nextItem) {
        // Fallback would be parsed as Val elsewhere
        i++;
      }
    }
  }

  return {
    name: nameStx.name,
    params,
    goal,
    contract,
    fallback,
  };
}

/**
 * Parse a goal specification.
 */
function parseGoalSpec(stx: SList): GoalSpec {
  const goal: GoalSpec = { kind: "generic" };

  for (let i = 0; i < stx.items.length; i++) {
    const item = stx.items[i];
    if (isIdent(item)) {
      const key = item.name;
      const nextItem = stx.items[i + 1];

      if (key === "kind" && nextItem && (nextItem.tag === "Atom" || isIdent(nextItem))) {
        goal.kind = nextItem.tag === "Atom" ? String(nextItem.value) : nextItem.name;
        i++;
      } else if (key === "forbid" && nextItem && isList(nextItem)) {
        goal.forbid = nextItem.items
          .filter(isIdent)
          .map(id => id.name);
        i++;
      } else if (key === "require" && nextItem && isList(nextItem)) {
        goal.require = nextItem.items
          .filter(isIdent)
          .map(id => id.name);
        i++;
      }
    }
  }

  return goal;
}

/**
 * Create a semantic function transformer.
 */
export function createSemanticFunction(
  spec: SemanticFunctionSpec,
  scopeCounter: { n: number }
): MacroTransformer {
  const defScope = makeDefScope(spec.name, scopeCounter);

  const obligations: ObligationSpec = {
    required: ["test"],
    optional: ["metamorphic"],
    custom: spec.contract ? [`Contract: ${spec.contract}`] : undefined,
  };

  // Create a placeholder proc
  const proc: Val = {
    tag: "Closure",
    params: spec.params,
    body: { tag: "Lit", value: null },
    env: {} as any,
  };

  return makeSemanticTransformer(proc, defScope, spec.name, obligations);
}

// ─────────────────────────────────────────────────────────────────
// Expansion Replay
// ─────────────────────────────────────────────────────────────────

/**
 * ExpansionReceipt: Receipt for replaying an expansion.
 */
export type ExpansionReceipt = {
  id: string;
  inputHash: Hash;
  outputHash: Hash;
  profileName: string;
  semantic: boolean;
  obligations: string[];
  timestamp: number;
};

/**
 * Create an expansion receipt.
 */
export function createExpansionReceipt(
  input: Syntax,
  result: ExpansionResult,
  profileName: string
): ExpansionReceipt {
  return {
    id: `receipt-${Date.now()}`,
    inputHash: sha256JSON(input),
    outputHash: sha256JSON(result.expanded),
    profileName,
    semantic: result.semantic,
    obligations: result.obligations.map(o => o.id),
    timestamp: Date.now(),
  };
}

/**
 * Verify an expansion against a receipt.
 */
export function verifyExpansionReceipt(
  input: Syntax,
  result: ExpansionResult,
  receipt: ExpansionReceipt
): boolean {
  const inputHash = sha256JSON(input);
  const outputHash = sha256JSON(result.expanded);

  return inputHash === receipt.inputHash && outputHash === receipt.outputHash;
}

// ─────────────────────────────────────────────────────────────────
// Pipeline Macro Support
// ─────────────────────────────────────────────────────────────────

/**
 * PipelineStage: A stage in a semantic pipeline.
 */
export type PipelineStage = {
  name: string;
  kind: "plan" | "fetch" | "act" | "verify";
  capabilities?: string[];
  snapshot?: boolean;
};

/**
 * Parse a pipeline macro definition.
 */
export function parsePipelineMacro(stx: SList): PipelineStage[] | null {
  // (pipeline (stage1 :kind plan) (stage2 :kind fetch) ...)
  if (!isList(stx) || stx.items.length < 2) return null;

  const head = stx.items[0];
  if (!isIdent(head) || head.name !== "pipeline") return null;

  const stages: PipelineStage[] = [];

  for (let i = 1; i < stx.items.length; i++) {
    const stageStx = stx.items[i];
    if (!isList(stageStx) || stageStx.items.length < 1) continue;

    const nameStx = stageStx.items[0];
    if (!isIdent(nameStx)) continue;

    const stage: PipelineStage = {
      name: nameStx.name,
      kind: "act",
    };

    // Parse stage options
    for (let j = 1; j < stageStx.items.length; j++) {
      const opt = stageStx.items[j];
      if (isIdent(opt) && opt.name.startsWith(":")) {
        const key = opt.name.slice(1);
        const val = stageStx.items[j + 1];

        if (key === "kind" && val && isIdent(val)) {
          const kindVal = val.name as PipelineStage["kind"];
          if (["plan", "fetch", "act", "verify"].includes(kindVal)) {
            stage.kind = kindVal;
          }
          j++;
        } else if (key === "snapshot" && val && val.tag === "Atom") {
          stage.snapshot = Boolean(val.value);
          j++;
        }
      }
    }

    stages.push(stage);
  }

  return stages;
}

// ─────────────────────────────────────────────────────────────────
// Reset State (for testing)
// ─────────────────────────────────────────────────────────────────

/**
 * Reset all semantic macro state.
 */
export function resetSemanticState(): void {
  resetObligationIds();
  resetEvidenceIds();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/macro/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/macro/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 15: Hygienic macros + phase separation + semantic macros

import type { Val } from "../eval/values";
import type { Syntax, Scope } from "../syntax/syntax";
import type { Env, Binding } from "../syntax/binding";
import type { Hash } from "../artifacts/hash";
import type { SRTransformer } from "../expand/syntaxRules";

// ─────────────────────────────────────────────────────────────────
// Core Macro Types
// ─────────────────────────────────────────────────────────────────

/**
 * ScopeId: Unique identifier for a scope in set-of-scopes hygiene.
 */
export type ScopeId = string;

/**
 * SourceLocation: Source file location for syntax objects.
 */
export type SourceLocation = {
  file?: string;
  line?: number;
  col?: number;
  span?: number;
};

/**
 * MacroTransformer: A macro transformer (pure or semantic).
 *
 * Pure macros (syntax-rules) are deterministic syntax-to-syntax transforms.
 * Semantic macros can invoke inference/rewrite under governance.
 */
export type MacroTransformer =
  | {
      tag: "SyntaxRules";
      transformer: SRTransformer;
      defScope: ScopeId;
      name?: string;
    }
  | {
      tag: "ProcMacro";
      proc: Val;
      defScope: ScopeId;
      allowInfer: boolean;
      name?: string;
    }
  | {
      tag: "SemanticMacro";
      proc: Val;
      defScope: ScopeId;
      obligations?: ObligationSpec;
      name?: string;
    };

/**
 * MacroEnv: Compile-time environment mapping macro names to transformers.
 *
 * Separate from runtime Env (phase separation).
 */
export type MacroEnv = Map<string, MacroBinding>;

/**
 * MacroBinding: A binding in the macro environment.
 */
export type MacroBinding = {
  name: string;
  transformer: MacroTransformer;
  phase: number;
  scopes: Scope[];
  bindingId: string;
};

// ─────────────────────────────────────────────────────────────────
// Expansion Types
// ─────────────────────────────────────────────────────────────────

/**
 * ExpansionResult: Result of macro expansion.
 *
 * Includes expanded syntax and any obligations/evidence for semantic macros.
 */
export type ExpansionResult = {
  /** The expanded syntax */
  expanded: Syntax;
  /** Obligations generated during expansion (for semantic macros) */
  obligations: ObligationRef[];
  /** Evidence collected during expansion */
  evidence: EvidenceRef[];
  /** Whether expansion was semantic (involved inference) */
  semantic: boolean;
  /** Expansion trace for debugging/replay */
  trace?: ExpansionTrace;
};

/**
 * ExpansionTrace: Trace of macro expansion steps for debugging/replay.
 */
export type ExpansionTrace = {
  steps: ExpansionStep[];
  totalSteps: number;
  macrosInvoked: string[];
  semanticCalls: number;
};

/**
 * ExpansionStep: A single step in macro expansion.
 */
export type ExpansionStep = {
  /** Step number */
  stepNum: number;
  /** Macro name invoked */
  macro: string;
  /** Input syntax (before expansion) */
  input: Syntax;
  /** Output syntax (after expansion) */
  output: Syntax;
  /** Timestamp */
  timestamp: number;
  /** Whether this was a semantic expansion */
  semantic: boolean;
  /** Source location */
  srcloc?: SourceLocation;
};

/**
 * ExpansionContext: Context for macro expansion.
 */
export type ExpansionContext = {
  /** Current phase (0 = runtime, 1 = macro expansion) */
  phase: number;
  /** Runtime environment */
  runtimeEnv: Env;
  /** Macro environment */
  macroEnv: MacroEnv;
  /** Scope counter for generating fresh scopes */
  scopeCounter: { n: number };
  /** Profile name for governance */
  profileName?: string;
  /** Capabilities for this expansion */
  caps: Set<string>;
  /** Budget for expansion steps */
  stepBudget: number;
  /** Current step count */
  stepCount: number;
  /** Whether to trace expansion */
  tracing: boolean;
  /** Accumulated trace */
  trace: ExpansionStep[];
};

// ─────────────────────────────────────────────────────────────────
// Obligation Types (for semantic macros)
// ─────────────────────────────────────────────────────────────────

/**
 * ObligationSpec: Specification of obligations for a semantic macro.
 */
export type ObligationSpec = {
  /** Required obligation kinds */
  required: ObligationKind[];
  /** Optional obligation kinds */
  optional: ObligationKind[];
  /** Custom obligation descriptions */
  custom?: string[];
};

/**
 * ObligationKind: Kind of obligation.
 */
export type ObligationKind =
  | "test"
  | "metamorphic"
  | "invariant"
  | "type-check"
  | "contract"
  | "review";

/**
 * ObligationRef: Reference to an obligation.
 */
export type ObligationRef = {
  id: string;
  kind: ObligationKind;
  description?: string;
  satisfied: boolean;
  evidence?: EvidenceRef;
};

/**
 * EvidenceRef: Reference to evidence supporting an obligation.
 */
export type EvidenceRef = {
  id: string;
  kind: "test-pass" | "proof" | "review" | "inference";
  hash?: Hash;
  description?: string;
};

// ─────────────────────────────────────────────────────────────────
// Oracle Protocol Types (for semantic macro expansion)
// ─────────────────────────────────────────────────────────────────

/**
 * ReqExpand: Request to expand syntax (for Oracle protocol).
 */
export type ReqExpand = {
  tag: "ReqExpand";
  qstx: Syntax;
  envRef: Hash;
  mode: "1" | "*";
  profileName?: string;
};

/**
 * RespSyntax: Response with expanded syntax.
 */
export type RespSyntax = {
  tag: "RespSyntax";
  stx: Syntax;
  obligations?: ObligationRef[];
  trace?: ExpansionTrace;
};

// ─────────────────────────────────────────────────────────────────
// Macro Definition Types
// ─────────────────────────────────────────────────────────────────

/**
 * MacroDefinition: Parsed macro definition.
 */
export type MacroDefinition = {
  name: string;
  kind: "syntax-rules" | "proc-macro" | "semantic";
  transformer: MacroTransformer;
  defSite?: SourceLocation;
};

/**
 * SemanticMacroConfig: Configuration for semantic macro expansion.
 */
export type SemanticMacroConfig = {
  /** Allow inference during expansion */
  allowInfer: boolean;
  /** Allow rewrite proposals during expansion */
  allowRewrite: boolean;
  /** Require tests before commit */
  requireTests: boolean;
  /** Maximum inference calls */
  maxInferenceCalls: number;
  /** Timeout for expansion (ms) */
  timeout: number;
};

export const DEFAULT_SEMANTIC_CONFIG: SemanticMacroConfig = {
  allowInfer: true,
  allowRewrite: true,
  requireTests: true,
  maxInferenceCalls: 5,
  timeout: 30000,
};

// ─────────────────────────────────────────────────────────────────
// Profile Integration Types
// ─────────────────────────────────────────────────────────────────

/**
 * MacroProfile: Profile-specific macro expansion settings.
 */
export type MacroProfile = {
  name: string;
  /** Can expand pure macros */
  canExpandPure: boolean;
  /** Can expand semantic macros */
  canExpandSemantic: boolean;
  /** Can commit expanded definitions */
  canCommit: boolean;
  /** Can invoke inference */
  canInfer: boolean;
  /** Step budget */
  stepBudget: number;
};

/**
 * Default macro profiles.
 */
export const MACRO_PROFILES: Record<string, MacroProfile> = {
  "explore": {
    name: "explore",
    canExpandPure: true,
    canExpandSemantic: true,
    canCommit: false,
    canInfer: true,
    stepBudget: 1000,
  },
  "pragmatic": {
    name: "pragmatic",
    canExpandPure: true,
    canExpandSemantic: true,
    canCommit: true,
    canInfer: true,
    stepBudget: 5000,
  },
  "strict": {
    name: "strict",
    canExpandPure: true,
    canExpandSemantic: true,
    canCommit: true,
    canInfer: true,
    stepBudget: 10000,
  },
  "airgap": {
    name: "airgap",
    canExpandPure: true,
    canExpandSemantic: false,
    canCommit: false,
    canInfer: false,
    stepBudget: 100,
  },
  "macro/pure": {
    name: "macro/pure",
    canExpandPure: true,
    canExpandSemantic: false,
    canCommit: false,
    canInfer: false,
    stepBudget: 1000,
  },
  "macro/semantic": {
    name: "macro/semantic",
    canExpandPure: true,
    canExpandSemantic: true,
    canCommit: false,
    canInfer: true,
    stepBudget: 5000,
  },
};

/**
 * Get macro profile by name.
 */
export function getMacroProfile(name: string): MacroProfile {
  return MACRO_PROFILES[name] ?? MACRO_PROFILES["pragmatic"];
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/dsl.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/dsl.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: DSL Definition and Interpretation

import type {
  Omega0Expr,
  Omega0Val,
  Omega0Env,
  Omega0Meaning,
  Omega0Prim,
  EvalContext,
} from "./types";
import {
  makePrim,
  makeMeaning,
  omega0ToString,
  createEvalContext,
  isSymbol,
  isPair,
  sym,
  arrayToList,
  listToArray,
} from "./types";
import { defineVar, extendEnv, emptyEnv } from "./env";
import { eval0, parseSimpleSExpr } from "./eval0";
import { int0, createIntContext, createFallbackOracle } from "./int0";
import type { IntContext, OracleHandler } from "./int0";
import { createBaseEnv } from "./primitives";

// ─────────────────────────────────────────────────────────────────
// DSL Types
// ─────────────────────────────────────────────────────────────────

/**
 * DSL syntax rule - defines how to parse/recognize a form.
 */
export type SyntaxRule = {
  /** Pattern to match (symbol for keyword, or structure) */
  pattern: Omega0Expr;
  /** Names of bound variables in the pattern */
  bindings: string[];
  /** Description of this syntax form */
  description: string;
};

/**
 * DSL semantic rule - defines meaning of a form.
 */
export type SemanticRule = {
  /** Name of the syntax form this handles */
  formName: string;
  /** Extensional semantics: transform to Ω₀ */
  extensional: (args: Omega0Val[], env: Omega0Env) => Omega0Expr;
  /** Intensional semantics: predict meaning */
  intensional?: (args: Omega0Val[], env: Omega0Env, ctx: IntContext) => Omega0Meaning;
};

/**
 * DSL definition - a complete language specification.
 */
export type DSLDefinition = {
  /** Name of the DSL */
  name: string;
  /** Description */
  description: string;
  /** Syntax rules */
  syntax: SyntaxRule[];
  /** Semantic rules */
  semantics: SemanticRule[];
  /** Base environment additions */
  baseEnv?: Map<string, Omega0Val>;
  /** Parent DSL (for extension) */
  parent?: DSLDefinition;
};

/**
 * DSL instance - a language ready for use.
 */
export type DSLInstance = {
  /** The definition */
  definition: DSLDefinition;
  /** Compiled environment */
  env: Omega0Env;
  /** Syntax matcher */
  match: (expr: Omega0Expr) => SyntaxMatch | null;
  /** Extensional evaluator */
  eval: (expr: Omega0Expr, env?: Omega0Env) => Omega0Val;
  /** Intensional evaluator */
  int: (expr: Omega0Expr, env?: Omega0Env, ctx?: IntContext) => Omega0Meaning;
};

/**
 * Result of syntax matching.
 */
export type SyntaxMatch = {
  rule: SyntaxRule;
  bindings: Map<string, Omega0Val>;
  semanticRule: SemanticRule;
};

// ─────────────────────────────────────────────────────────────────
// DSL Builder
// ─────────────────────────────────────────────────────────────────

/**
 * Create a new DSL definition.
 */
export function defineDSL(
  name: string,
  description: string,
  parent?: DSLDefinition
): DSLDefinition {
  return {
    name,
    description,
    syntax: parent ? [...parent.syntax] : [],
    semantics: parent ? [...parent.semantics] : [],
    baseEnv: parent?.baseEnv ? new Map(parent.baseEnv) : new Map(),
    parent,
  };
}

/**
 * Add a syntax rule to a DSL.
 */
export function addSyntax(
  dsl: DSLDefinition,
  pattern: string | Omega0Expr,
  bindings: string[],
  description: string
): DSLDefinition {
  const parsedPattern = typeof pattern === "string"
    ? parseSimpleSExpr(pattern)
    : pattern;

  return {
    ...dsl,
    syntax: [
      ...dsl.syntax,
      { pattern: parsedPattern, bindings, description },
    ],
  };
}

/**
 * Add a semantic rule to a DSL.
 */
export function addSemantics(
  dsl: DSLDefinition,
  formName: string,
  extensional: (args: Omega0Val[], env: Omega0Env) => Omega0Expr,
  intensional?: (args: Omega0Val[], env: Omega0Env, ctx: IntContext) => Omega0Meaning
): DSLDefinition {
  return {
    ...dsl,
    semantics: [
      ...dsl.semantics,
      { formName, extensional, intensional },
    ],
  };
}

/**
 * Add a base binding to a DSL.
 */
export function addBinding(
  dsl: DSLDefinition,
  name: string,
  value: Omega0Val
): DSLDefinition {
  const newBaseEnv = new Map(dsl.baseEnv);
  newBaseEnv.set(name, value);
  return {
    ...dsl,
    baseEnv: newBaseEnv,
  };
}

/**
 * Add a primitive to a DSL.
 */
export function addPrimitive(
  dsl: DSLDefinition,
  name: string,
  fn: (args: Omega0Val[]) => Omega0Val
): DSLDefinition {
  return addBinding(dsl, name, makePrim(name, fn));
}

// ─────────────────────────────────────────────────────────────────
// DSL Instantiation
// ─────────────────────────────────────────────────────────────────

/**
 * Instantiate a DSL definition, creating a usable language.
 */
export function instantiateDSL(definition: DSLDefinition): DSLInstance {
  // Create base environment
  let env = createBaseEnv();

  // Add DSL-specific bindings
  if (definition.baseEnv) {
    for (const [name, value] of definition.baseEnv) {
      env = defineVar(env, name, value);
    }
  }

  // Create syntax matcher
  const match = (expr: Omega0Expr): SyntaxMatch | null => {
    for (const rule of definition.syntax) {
      const bindings = matchPattern(rule.pattern, expr, rule.bindings);
      if (bindings) {
        const semanticRule = definition.semantics.find(
          s => s.formName === getFormName(rule.pattern)
        );
        if (semanticRule) {
          return { rule, bindings, semanticRule };
        }
      }
    }
    return null;
  };

  // Create extensional evaluator
  const evalFn = (expr: Omega0Expr, customEnv?: Omega0Env): Omega0Val => {
    const evalEnv = customEnv ?? env;
    const matched = match(expr);

    if (matched) {
      const args = matched.rule.bindings.map(
        b => matched.bindings.get(b) ?? null
      );
      const transformed = matched.semanticRule.extensional(args, evalEnv);
      return eval0(transformed, evalEnv, createEvalContext());
    }

    // Fall back to base Ω₀ evaluation
    return eval0(expr, evalEnv, createEvalContext());
  };

  // Create intensional evaluator
  const intFn = (
    expr: Omega0Expr,
    customEnv?: Omega0Env,
    ctx?: IntContext
  ): Omega0Meaning => {
    const evalEnv = customEnv ?? env;
    const intCtx = ctx ?? createIntContext(createFallbackOracle());
    const matched = match(expr);

    if (matched && matched.semanticRule.intensional) {
      const args = matched.rule.bindings.map(
        b => matched.bindings.get(b) ?? null
      );
      return matched.semanticRule.intensional(args, evalEnv, intCtx);
    }

    if (matched) {
      // Use extensional semantics with meaning wrapper
      const args = matched.rule.bindings.map(
        b => matched.bindings.get(b) ?? null
      );
      const transformed = matched.semanticRule.extensional(args, evalEnv);
      return int0(transformed, evalEnv, intCtx);
    }

    // Fall back to base Ω₀ intensional evaluation
    return int0(expr, evalEnv, intCtx);
  };

  return {
    definition,
    env,
    match,
    eval: evalFn,
    int: intFn,
  };
}

/**
 * Get the form name from a pattern (first symbol).
 */
function getFormName(pattern: Omega0Expr): string {
  if (Array.isArray(pattern) && pattern.length > 0 && isSymbol(pattern[0])) {
    return pattern[0].name;
  }
  if (isSymbol(pattern)) {
    return pattern.name;
  }
  return "";
}

/**
 * Match a pattern against an expression, extracting bindings.
 */
function matchPattern(
  pattern: Omega0Expr,
  expr: Omega0Expr,
  bindingNames: string[]
): Map<string, Omega0Val> | null {
  const bindings = new Map<string, Omega0Val>();

  function match(p: Omega0Expr, e: Omega0Expr): boolean {
    // Symbol in pattern: check if it's a binding variable
    if (isSymbol(p)) {
      if (bindingNames.includes(p.name)) {
        bindings.set(p.name, e as Omega0Val);
        return true;
      }
      // Otherwise must match exactly
      return isSymbol(e) && p.name === e.name;
    }

    // Primitive types must match exactly
    if (typeof p === "number" || typeof p === "string" || typeof p === "boolean") {
      return p === e;
    }

    // Null matches null
    if (p === null) {
      return e === null;
    }

    // Array patterns
    if (Array.isArray(p) && Array.isArray(e)) {
      if (p.length !== e.length) return false;
      for (let i = 0; i < p.length; i++) {
        if (!match(p[i], e[i])) return false;
      }
      return true;
    }

    return false;
  }

  return match(pattern, expr) ? bindings : null;
}

// ─────────────────────────────────────────────────────────────────
// Built-in DSL: Simple Calculator
// ─────────────────────────────────────────────────────────────────

/**
 * Create a simple calculator DSL for demonstration.
 */
export function createCalculatorDSL(): DSLInstance {
  let dsl = defineDSL("calculator", "Simple arithmetic calculator");

  // Syntax: (calc expr)
  dsl = addSyntax(dsl, "(calc x)", ["x"], "Calculate an arithmetic expression");

  // Semantics: transform to direct evaluation
  dsl = addSemantics(
    dsl,
    "calc",
    (args) => args[0] as Omega0Expr,
    (args, env, ctx) => {
      // Intensional: predict with high confidence for simple arithmetic
      const expr = args[0] as Omega0Expr;
      return int0(expr, env, ctx);
    }
  );

  return instantiateDSL(dsl);
}

// ─────────────────────────────────────────────────────────────────
// Built-in DSL: Query Language
// ─────────────────────────────────────────────────────────────────

/**
 * Create a simple query DSL.
 */
export function createQueryDSL(): DSLInstance {
  let dsl = defineDSL("query", "Simple query language");

  // Syntax: (select fields from source where pred)
  dsl = addSyntax(
    dsl,
    "(select fields from source where pred)",
    ["fields", "source", "pred"],
    "Select fields from a source where predicate holds"
  );

  // Syntax: (select fields from source)
  dsl = addSyntax(
    dsl,
    "(select fields from source)",
    ["fields", "source"],
    "Select fields from a source"
  );

  // Semantics for select-where
  dsl = addSemantics(
    dsl,
    "select",
    (args, _env) => {
      const [fields, _from, source, _where, pred] = args;
      // Transform to filter + map
      return [
        sym("map"),
        [sym("lambda"), [sym("item")],
          [sym("list"), ...(listToArray(fields as Omega0Val).map(f =>
            [sym("item"), f]
          ))]
        ],
        [sym("filter"), pred, source]
      ] as Omega0Expr;
    }
  );

  // Add filter primitive
  dsl = addPrimitive(dsl, "filter", (args) => {
    if (args.length < 2) return null;
    // Simplified filter - in real impl would apply predicate
    return args[1];
  });

  return instantiateDSL(dsl);
}

// ─────────────────────────────────────────────────────────────────
// Built-in DSL: State Machine
// ─────────────────────────────────────────────────────────────────

/**
 * Create a state machine DSL.
 */
export function createStateMachineDSL(): DSLInstance {
  let dsl = defineDSL("state-machine", "Simple state machine language");

  // Syntax: (machine name initial-state transitions)
  dsl = addSyntax(
    dsl,
    "(machine name initial transitions)",
    ["name", "initial", "transitions"],
    "Define a state machine"
  );

  // Syntax: (transition from event to)
  dsl = addSyntax(
    dsl,
    "(transition from on to)",
    ["from", "on", "to"],
    "Define a state transition"
  );

  // Semantics: machine creates a closure
  dsl = addSemantics(
    dsl,
    "machine",
    (args) => {
      const [name, initial, transitions] = args;
      // Create a closure that tracks state
      return [
        sym("lambda"), [sym("event")],
        [sym("begin"),
          [sym("display"), [sym("string-append"),
            "Machine ", omega0ToString(name as Omega0Val),
            " processing: ", [sym("event")]
          ]],
          initial  // Simplified: just return initial state
        ]
      ] as Omega0Expr;
    }
  );

  return instantiateDSL(dsl);
}

// ─────────────────────────────────────────────────────────────────
// DSL Composition
// ─────────────────────────────────────────────────────────────────

/**
 * Compose two DSLs into a new one.
 */
export function composeDSLs(
  name: string,
  description: string,
  ...dsls: DSLDefinition[]
): DSLDefinition {
  const composed: DSLDefinition = {
    name,
    description,
    syntax: [],
    semantics: [],
    baseEnv: new Map(),
  };

  for (const dsl of dsls) {
    composed.syntax.push(...dsl.syntax);
    composed.semantics.push(...dsl.semantics);
    if (dsl.baseEnv) {
      for (const [k, v] of dsl.baseEnv) {
        composed.baseEnv!.set(k, v);
      }
    }
  }

  return composed;
}

// ─────────────────────────────────────────────────────────────────
// DSL Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Analyze a DSL definition for potential issues.
 */
export function analyzeDSL(dsl: DSLDefinition): DSLAnalysis {
  const issues: string[] = [];
  const stats = {
    syntaxRules: dsl.syntax.length,
    semanticRules: dsl.semantics.length,
    hasIntensional: 0,
    baseBindings: dsl.baseEnv?.size ?? 0,
  };

  // Check for syntax rules without semantics
  for (const syntax of dsl.syntax) {
    const formName = getFormName(syntax.pattern);
    const hasSemantics = dsl.semantics.some(s => s.formName === formName);
    if (!hasSemantics) {
      issues.push(`Syntax rule '${formName}' has no semantic rule`);
    }
  }

  // Count intensional rules
  stats.hasIntensional = dsl.semantics.filter(s => s.intensional).length;

  // Check for semantic rules without syntax
  for (const sem of dsl.semantics) {
    const hasSyntax = dsl.syntax.some(
      s => getFormName(s.pattern) === sem.formName
    );
    if (!hasSyntax) {
      issues.push(`Semantic rule '${sem.formName}' has no syntax rule`);
    }
  }

  return { dsl, issues, stats };
}

/**
 * DSL analysis result.
 */
export type DSLAnalysis = {
  dsl: DSLDefinition;
  issues: string[];
  stats: {
    syntaxRules: number;
    semanticRules: number;
    hasIntensional: number;
    baseBindings: number;
  };
};

// ─────────────────────────────────────────────────────────────────
// DSL Serialization
// ─────────────────────────────────────────────────────────────────

/**
 * Serialize a DSL definition (without functions) for storage/transmission.
 */
export function serializeDSL(dsl: DSLDefinition): object {
  return {
    name: dsl.name,
    description: dsl.description,
    syntaxCount: dsl.syntax.length,
    semanticsCount: dsl.semantics.length,
    syntax: dsl.syntax.map(s => ({
      pattern: omega0ToString(s.pattern as Omega0Val),
      bindings: s.bindings,
      description: s.description,
    })),
    // Note: semantic functions cannot be serialized
    semanticNames: dsl.semantics.map(s => s.formName),
  };
}

/**
 * Create a DSL documentation string.
 */
export function documentDSL(dsl: DSLDefinition): string {
  const lines: string[] = [];

  lines.push(`# ${dsl.name}`);
  lines.push(`${dsl.description}`);
  lines.push("");
  lines.push("## Syntax Forms");

  for (const syntax of dsl.syntax) {
    lines.push(`- ${omega0ToString(syntax.pattern as Omega0Val)}`);
    lines.push(`  ${syntax.description}`);
    if (syntax.bindings.length > 0) {
      lines.push(`  Bindings: ${syntax.bindings.join(", ")}`);
    }
  }

  if (dsl.baseEnv && dsl.baseEnv.size > 0) {
    lines.push("");
    lines.push("## Built-in Bindings");
    for (const [name] of dsl.baseEnv) {
      lines.push(`- ${name}`);
    }
  }

  return lines.join("\n");
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/env.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/env.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-circular evaluator - Environment operations

import type {
  Omega0Val,
  Omega0Env,
  Omega0Frame,
} from "./types";
import { makeFrame, emptyEnv } from "./types";

// Re-export emptyEnv for convenience
export { emptyEnv } from "./types";

// ─────────────────────────────────────────────────────────────────
// Environment Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Look up a variable in the environment.
 *
 * Searches from innermost to outermost frame.
 * Throws if variable is not found.
 */
export function lookup(env: Omega0Env, name: string): Omega0Val {
  for (const frame of env) {
    if (frame.has(name)) {
      return frame.get(name)!;
    }
  }
  throw new Error(`Unbound variable: ${name}`);
}

/**
 * Try to look up a variable, returning undefined if not found.
 */
export function tryLookup(env: Omega0Env, name: string): Omega0Val | undefined {
  for (const frame of env) {
    if (frame.has(name)) {
      return frame.get(name);
    }
  }
  return undefined;
}

/**
 * Check if a variable is bound in the environment.
 */
export function isBound(env: Omega0Env, name: string): boolean {
  for (const frame of env) {
    if (frame.has(name)) {
      return true;
    }
  }
  return false;
}

/**
 * Extend the environment with a new frame containing the given bindings.
 *
 * @param vars - Variable names
 * @param vals - Corresponding values
 * @param baseEnv - Environment to extend
 */
export function extendEnv(
  vars: string[],
  vals: Omega0Val[],
  baseEnv: Omega0Env
): Omega0Env {
  const frame = makeFrame();

  // Pair up variables with values
  for (let i = 0; i < vars.length; i++) {
    frame.set(vars[i], vals[i] ?? null);
  }

  // Return new environment with this frame at the front
  return [frame, ...baseEnv];
}

/**
 * Define a variable in the topmost frame of the environment.
 *
 * If the variable already exists in the top frame, it's updated.
 * If the environment is empty, a new frame is created.
 */
export function defineVar(
  env: Omega0Env,
  name: string,
  value: Omega0Val
): Omega0Env {
  if (env.length === 0) {
    // Create a new frame
    const frame = makeFrame();
    frame.set(name, value);
    return [frame];
  }

  // Define in the topmost frame (mutating)
  env[0].set(name, value);
  return env;
}

/**
 * Set a variable's value in the environment.
 *
 * The variable must already exist somewhere in the environment.
 * Throws if the variable is not found.
 */
export function setVar(
  env: Omega0Env,
  name: string,
  value: Omega0Val
): void {
  for (const frame of env) {
    if (frame.has(name)) {
      frame.set(name, value);
      return;
    }
  }
  throw new Error(`Cannot set! unbound variable: ${name}`);
}

/**
 * Create a copy of the environment (shallow copy of frames).
 *
 * This creates new frame objects but shares the values.
 */
export function copyEnv(env: Omega0Env): Omega0Env {
  return env.map(frame => new Map(frame));
}

/**
 * Get all variable names bound in the environment.
 */
export function envNames(env: Omega0Env): string[] {
  const names = new Set<string>();
  for (const frame of env) {
    for (const name of frame.keys()) {
      names.add(name);
    }
  }
  return Array.from(names);
}

/**
 * Get the bindings in the topmost frame.
 */
export function topFrameBindings(env: Omega0Env): Map<string, Omega0Val> {
  if (env.length === 0) {
    return new Map();
  }
  return new Map(env[0]);
}

/**
 * Create an environment snapshot for debugging/REPL.
 */
export function envSnapshot(env: Omega0Env): object {
  return {
    frameCount: env.length,
    bindings: env.map((frame, i) => ({
      frame: i,
      vars: Array.from(frame.keys()),
    })),
  };
}

// ─────────────────────────────────────────────────────────────────
// Environment Reference (for oracle protocol)
// ─────────────────────────────────────────────────────────────────

/** Global store for environment references */
const envStore = new Map<string, Omega0Env>();
let envCounter = 0;

/**
 * Store an environment and return a reference ID.
 */
export function storeEnv(env: Omega0Env): string {
  const id = `env-${envCounter++}`;
  envStore.set(id, env);
  return id;
}

/**
 * Retrieve an environment by reference ID.
 */
export function getEnv(id: string): Omega0Env | undefined {
  return envStore.get(id);
}

/**
 * Clear the environment store (for testing).
 */
export function clearEnvStore(): void {
  envStore.clear();
  envCounter = 0;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/eval0.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/eval0.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-circular evaluator - eval0 and apply0

import type {
  Omega0Expr,
  Omega0Val,
  Omega0Env,
  Omega0Closure,
  Omega0Prim,
  Omega0LLMProc,
  Omega0Symbol,
  EvalContext,
} from "./types";
import {
  isSymbol,
  symbolName,
  isSelfEvaluating,
  isVariable,
  isTaggedList,
  isQuoted,
  isIf,
  isLambda,
  isBegin,
  isDefine,
  isSet,
  isApplication,
  makeClosure,
  isClosure,
  isPrim,
  isLLMProc,
  isPair,
  omega0ToString,
  createEvalContext,
} from "./types";
import {
  lookup,
  extendEnv,
  defineVar,
  setVar,
} from "./env";

// ─────────────────────────────────────────────────────────────────
// Truthiness
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a value is truthy in Ω₀.
 * Only #f (false) and null are falsy.
 */
export function isTruthy(v: Omega0Val): boolean {
  if (v === false) return false;
  if (v === null) return false;
  return true;
}

// ─────────────────────────────────────────────────────────────────
// Expression Accessors
// ─────────────────────────────────────────────────────────────────

/**
 * Get the quoted datum from a quote expression.
 */
function quotedDatum(e: Omega0Expr): Omega0Val {
  if (Array.isArray(e) && e.length >= 2) {
    return exprToVal(e[1]);
  }
  throw new Error("Invalid quote expression");
}

/**
 * Convert an expression to a value (for quote).
 */
function exprToVal(e: Omega0Expr): Omega0Val {
  if (e === null) return null;
  if (typeof e === "number") return e;
  if (typeof e === "string") return e;
  if (typeof e === "boolean") return e;
  if (isSymbol(e)) return e;
  if (Array.isArray(e)) {
    // Convert to proper list
    if (e.length === 0) return null;
    let result: Omega0Val = null;
    for (let i = e.length - 1; i >= 0; i--) {
      result = { tag: "Pair", car: exprToVal(e[i]), cdr: result };
    }
    return result;
  }
  return null;
}

/**
 * Get if-test from an if expression.
 */
function ifTest(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 2) {
    return e[1];
  }
  throw new Error("Invalid if expression");
}

/**
 * Get if-consequent from an if expression.
 */
function ifConseq(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 3) {
    return e[2];
  }
  throw new Error("Invalid if expression");
}

/**
 * Get if-alternative from an if expression.
 */
function ifAlt(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 4) {
    return e[3];
  }
  return null; // default to null if no alt
}

/**
 * Get lambda parameters from a lambda expression.
 */
function lambdaParams(e: Omega0Expr): string[] {
  if (Array.isArray(e) && e.length >= 2 && Array.isArray(e[1])) {
    return e[1].map(p => {
      if (isSymbol(p)) return p.name;
      throw new Error(`Invalid parameter: ${omega0ToString(p as Omega0Val)}`);
    });
  }
  throw new Error("Invalid lambda expression");
}

/**
 * Get lambda body from a lambda expression.
 */
function lambdaBody(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 3) {
    // If multiple body expressions, wrap in begin
    if (e.length > 3) {
      return [{ tag: "Symbol", name: "begin" } as Omega0Symbol, ...e.slice(2)];
    }
    return e[2];
  }
  throw new Error("Invalid lambda expression");
}

/**
 * Get begin expressions.
 */
function beginExprs(e: Omega0Expr): Omega0Expr[] {
  if (Array.isArray(e)) {
    return e.slice(1);
  }
  throw new Error("Invalid begin expression");
}

/**
 * Get define name and value expression.
 */
function defineNameAndRhs(e: Omega0Expr): { name: string; rhs: Omega0Expr } {
  if (Array.isArray(e) && e.length >= 3) {
    const nameOrFn = e[1];

    // Simple define: (define x rhs)
    if (isSymbol(nameOrFn)) {
      return { name: nameOrFn.name, rhs: e[2] };
    }

    // Function define: (define (f x y) body) -> (define f (lambda (x y) body))
    if (Array.isArray(nameOrFn) && nameOrFn.length > 0 && isSymbol(nameOrFn[0])) {
      const fnName = nameOrFn[0].name;
      const params = nameOrFn.slice(1);
      const body = e.slice(2);
      const lambdaExpr: Omega0Expr = [
        { tag: "Symbol", name: "lambda" } as Omega0Symbol,
        params,
        ...body,
      ];
      return { name: fnName, rhs: lambdaExpr };
    }
  }
  throw new Error("Invalid define expression");
}

/**
 * Get set! name and value expression.
 */
function setNameAndRhs(e: Omega0Expr): { name: string; rhs: Omega0Expr } {
  if (Array.isArray(e) && e.length >= 3 && isSymbol(e[1])) {
    return { name: e[1].name, rhs: e[2] };
  }
  throw new Error("Invalid set! expression");
}

/**
 * Get application operator.
 */
function appOperator(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length > 0) {
    return e[0];
  }
  throw new Error("Invalid application");
}

/**
 * Get application operands.
 */
function appOperands(e: Omega0Expr): Omega0Expr[] {
  if (Array.isArray(e)) {
    return e.slice(1);
  }
  throw new Error("Invalid application");
}

// ─────────────────────────────────────────────────────────────────
// eval0 - The Meta-Circular Evaluator
// ─────────────────────────────────────────────────────────────────

/**
 * eval0 - Evaluate an Ω₀ expression in the given environment.
 *
 * This is the heart of the meta-circular evaluator.
 */
export function eval0(
  e: Omega0Expr,
  env: Omega0Env,
  ctx: EvalContext = createEvalContext()
): Omega0Val {
  // Check depth limit
  if (ctx.depth > ctx.maxDepth) {
    throw new Error(`Maximum evaluation depth exceeded (${ctx.maxDepth})`);
  }

  ctx.depth++;

  try {
    // Trace if enabled
    if (ctx.tracing) {
      ctx.trace.push({
        kind: "eval",
        subject: omega0ToString(e as Omega0Val),
        depth: ctx.depth,
      });
    }

    // Self-evaluating: numbers, strings, booleans
    if (isSelfEvaluating(e)) {
      return e as Omega0Val;
    }

    // Variable reference
    if (isVariable(e)) {
      const result = lookup(env, symbolName(e));
      if (ctx.tracing) {
        ctx.trace.push({
          kind: "lookup",
          subject: symbolName(e),
          result: omega0ToString(result),
          depth: ctx.depth,
        });
      }
      return result;
    }

    // Null
    if (e === null) {
      return null;
    }

    // Must be a list from here
    if (!Array.isArray(e)) {
      throw new Error(`Unknown expression type: ${typeof e}`);
    }

    // Empty list evaluates to null
    if (e.length === 0) {
      return null;
    }

    // Quote
    if (isQuoted(e)) {
      return quotedDatum(e);
    }

    // If
    if (isIf(e)) {
      const testVal = eval0(ifTest(e), env, ctx);
      if (isTruthy(testVal)) {
        return eval0(ifConseq(e), env, ctx);
      } else {
        return eval0(ifAlt(e), env, ctx);
      }
    }

    // Lambda
    if (isLambda(e)) {
      const params = lambdaParams(e);
      const body = lambdaBody(e);
      return makeClosure(params, body, env);
    }

    // Begin
    if (isBegin(e)) {
      return evalSequence(beginExprs(e), env, ctx);
    }

    // Define
    if (isDefine(e)) {
      const { name, rhs } = defineNameAndRhs(e);
      const value = eval0(rhs, env, ctx);
      defineVar(env, name, value);
      if (ctx.tracing) {
        ctx.trace.push({
          kind: "define",
          subject: name,
          result: omega0ToString(value),
          depth: ctx.depth,
        });
      }
      return value;
    }

    // Set!
    if (isSet(e)) {
      const { name, rhs } = setNameAndRhs(e);
      const value = eval0(rhs, env, ctx);
      setVar(env, name, value);
      return value;
    }

    // Application
    if (isApplication(e)) {
      const proc = eval0(appOperator(e), env, ctx);
      const args = appOperands(e).map(arg => eval0(arg, env, ctx));
      return apply0(proc, args, ctx);
    }

    throw new Error(`Unknown expression: ${omega0ToString(e as Omega0Val)}`);
  } finally {
    ctx.depth--;
  }
}

/**
 * Evaluate a sequence of expressions, returning the last value.
 */
function evalSequence(
  exprs: Omega0Expr[],
  env: Omega0Env,
  ctx: EvalContext
): Omega0Val {
  if (exprs.length === 0) {
    return null;
  }

  let result: Omega0Val = null;
  for (const expr of exprs) {
    result = eval0(expr, env, ctx);
  }
  return result;
}

// ─────────────────────────────────────────────────────────────────
// apply0 - Procedure Application
// ─────────────────────────────────────────────────────────────────

/**
 * apply0 - Apply a procedure to arguments.
 *
 * This handles closures, primitives, and LLM procedures.
 */
export function apply0(
  proc: Omega0Val,
  args: Omega0Val[],
  ctx: EvalContext = createEvalContext()
): Omega0Val {
  // Trace if enabled
  if (ctx.tracing) {
    ctx.trace.push({
      kind: "apply",
      subject: omega0ToString(proc),
      depth: ctx.depth,
    });
  }

  // Closure application
  if (isClosure(proc)) {
    const closure = proc as Omega0Closure;

    // Check arity
    if (args.length !== closure.params.length) {
      throw new Error(
        `Arity mismatch: expected ${closure.params.length} args, got ${args.length}`
      );
    }

    // Extend environment with parameter bindings
    const newEnv = extendEnv(closure.params, args, closure.env);

    // Evaluate body in extended environment
    return eval0(closure.body, newEnv, ctx);
  }

  // Primitive application
  if (isPrim(proc)) {
    const prim = proc as Omega0Prim;
    return prim.fn(args);
  }

  // LLM procedure application
  if (isLLMProc(proc)) {
    const llmProc = proc as Omega0LLMProc;

    // Check oracle call limit
    if (ctx.oracleCallCount >= ctx.maxOracleCalls) {
      throw new Error(`Maximum oracle calls exceeded (${ctx.maxOracleCalls})`);
    }

    ctx.oracleCallCount++;

    // Trace
    if (ctx.tracing) {
      ctx.trace.push({
        kind: "infer",
        subject: llmProc.name,
        depth: ctx.depth,
      });
    }

    // Call the inference handler
    return llmProc.infer(args);
  }

  throw new Error(`Cannot apply non-procedure: ${omega0ToString(proc)}`);
}

// ─────────────────────────────────────────────────────────────────
// Top-Level Driver
// ─────────────────────────────────────────────────────────────────

/**
 * Evaluate a program (sequence of expressions) in a fresh environment.
 */
export function evalProgram(
  program: Omega0Expr[],
  baseEnv: Omega0Env,
  ctx: EvalContext = createEvalContext()
): Omega0Val {
  let result: Omega0Val = null;

  for (const expr of program) {
    result = eval0(expr, baseEnv, ctx);
  }

  return result;
}

/**
 * Parse and evaluate an Ω₀ expression from a simple S-expression representation.
 */
export function evalString(
  source: string,
  env: Omega0Env,
  ctx: EvalContext = createEvalContext()
): Omega0Val {
  // Simple S-expression parser (for testing)
  const expr = parseSimpleSExpr(source);
  return eval0(expr, env, ctx);
}

/**
 * Simple S-expression parser.
 */
export function parseSimpleSExpr(source: string): Omega0Expr {
  const tokens = tokenize(source);
  let pos = 0;

  function peek(): string | null {
    return pos < tokens.length ? tokens[pos] : null;
  }

  function consume(): string {
    return tokens[pos++];
  }

  function parseExpr(): Omega0Expr {
    const tok = peek();

    if (tok === null) {
      throw new Error("Unexpected end of input");
    }

    if (tok === "(") {
      consume();
      const items: Omega0Expr[] = [];
      while (peek() !== ")" && peek() !== null) {
        items.push(parseExpr());
      }
      if (peek() !== ")") {
        throw new Error("Expected )");
      }
      consume();
      return items;
    }

    if (tok === "'") {
      consume();
      const quoted = parseExpr();
      return [{ tag: "Symbol", name: "quote" } as Omega0Symbol, quoted];
    }

    consume();

    // Number
    if (/^-?\d+(\.\d+)?$/.test(tok)) {
      return parseFloat(tok);
    }

    // Boolean
    if (tok === "#t" || tok === "true") return true;
    if (tok === "#f" || tok === "false") return false;

    // String
    if (tok.startsWith('"') && tok.endsWith('"')) {
      return tok.slice(1, -1);
    }

    // Symbol
    return { tag: "Symbol", name: tok } as Omega0Symbol;
  }

  return parseExpr();
}

/**
 * Tokenize S-expression source.
 */
function tokenize(source: string): string[] {
  const tokens: string[] = [];
  let i = 0;

  while (i < source.length) {
    const c = source[i];

    // Skip whitespace
    if (/\s/.test(c)) {
      i++;
      continue;
    }

    // Skip comments
    if (c === ";") {
      while (i < source.length && source[i] !== "\n") {
        i++;
      }
      continue;
    }

    // Parentheses
    if (c === "(" || c === ")") {
      tokens.push(c);
      i++;
      continue;
    }

    // Quote
    if (c === "'") {
      tokens.push(c);
      i++;
      continue;
    }

    // String
    if (c === '"') {
      let str = '"';
      i++;
      while (i < source.length && source[i] !== '"') {
        if (source[i] === "\\") {
          str += source[i++];
        }
        str += source[i++];
      }
      str += '"';
      i++;
      tokens.push(str);
      continue;
    }

    // Atom (symbol or number)
    let atom = "";
    while (i < source.length && !/[\s()'";]/.test(source[i])) {
      atom += source[i++];
    }
    if (atom) {
      tokens.push(atom);
    }
  }

  return tokens;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-circular Ω evaluator - Module exports

// ─────────────────────────────────────────────────────────────────
// Types
// ─────────────────────────────────────────────────────────────────

export type {
  // Expression types
  Omega0Expr,
  Omega0List,
  Omega0Symbol,
  // Value types
  Omega0Val,
  Omega0Pair,
  Omega0Closure,
  Omega0Prim,
  Omega0LLMProc,
  Omega0Meaning,
  // Environment types
  Omega0Frame,
  Omega0Env,
  // Evaluation types
  EvalTraceEntry,
  EvalContext,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Type Constructors and Predicates
// ─────────────────────────────────────────────────────────────────

export {
  // Symbol operations
  sym,
  isSymbol,
  symbolName,
  // Pair operations
  cons,
  isPair,
  car,
  cdr,
  isNull,
  isList,
  arrayToList,
  listToArray,
  listLength,
  // Closure operations
  makeClosure,
  isClosure,
  // Primitive operations
  makePrim,
  isPrim,
  // LLM procedure operations
  makeLLMProc,
  isLLMProc,
  // Meaning operations
  makeMeaning,
  isMeaning,
  // Environment operations
  emptyEnv,
  makeFrame,
  // Expression predicates
  isSelfEvaluating,
  isVariable,
  isTaggedList,
  isQuoted,
  isIf,
  isLambda,
  isBegin,
  isDefine,
  isSet,
  isApplication,
  // Context
  createEvalContext,
  // Display
  omega0ToString,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Environment Operations
// ─────────────────────────────────────────────────────────────────

export {
  lookup,
  tryLookup,
  isBound,
  extendEnv,
  defineVar,
  setVar,
  copyEnv,
  envNames,
  topFrameBindings,
  envSnapshot,
  storeEnv,
  getEnv,
  clearEnvStore,
} from "./env";

// ─────────────────────────────────────────────────────────────────
// Meta-Circular Evaluator (eval0/apply0)
// ─────────────────────────────────────────────────────────────────

export {
  isTruthy,
  eval0,
  apply0,
  evalProgram,
  evalString,
  parseSimpleSExpr,
} from "./eval0";

// ─────────────────────────────────────────────────────────────────
// Primitives and LLM Procedures
// ─────────────────────────────────────────────────────────────────

export type { LLMInferHandler } from "./primitives";

export {
  createBaseEnv,
  createLLMProc,
  createScriptedLLMProc,
  addLLMProcToEnv,
  createMakeLLMProcPrim,
} from "./primitives";

// ─────────────────────────────────────────────────────────────────
// Meta-Intensional Evaluator (int0)
// ─────────────────────────────────────────────────────────────────

export type {
  OracleReqEval,
  OracleReqApply,
  OracleRequest,
  OracleResponse,
  OracleHandler,
  IntContext,
} from "./int0";

export {
  createIntContext,
  int0,
  createFallbackOracle,
  createScriptedOracle,
  commitMeaning,
  isValidated,
  addObligation,
  obligationsSatisfied,
} from "./int0";

// ─────────────────────────────────────────────────────────────────
// DSL Definition and Interpretation
// ─────────────────────────────────────────────────────────────────

export type {
  SyntaxRule,
  SemanticRule,
  DSLDefinition,
  DSLInstance,
  SyntaxMatch,
  DSLAnalysis,
} from "./dsl";

export {
  defineDSL,
  addSyntax,
  addSemantics,
  addBinding,
  addPrimitive,
  instantiateDSL,
  createCalculatorDSL,
  createQueryDSL,
  createStateMachineDSL,
  composeDSLs,
  analyzeDSL,
  serializeDSL,
  documentDSL,
} from "./dsl";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/int0.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/int0.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-intensional evaluator - int0

import type {
  Omega0Expr,
  Omega0Val,
  Omega0Env,
  Omega0Meaning,
  Omega0Closure,
  Omega0LLMProc,
  EvalContext,
} from "./types";
import {
  isSymbol,
  symbolName,
  isSelfEvaluating,
  isVariable,
  isQuoted,
  isIf,
  isLambda,
  isBegin,
  isDefine,
  isSet,
  isApplication,
  makeMeaning,
  makeClosure,
  isClosure,
  isPrim,
  isLLMProc,
  isMeaning,
  omega0ToString,
  createEvalContext,
} from "./types";
import { lookup, extendEnv, defineVar, storeEnv, getEnv } from "./env";
import { eval0, apply0 } from "./eval0";

// ─────────────────────────────────────────────────────────────────
// Oracle Protocol Types
// ─────────────────────────────────────────────────────────────────

/**
 * Oracle request for evaluation.
 */
export type OracleReqEval = {
  kind: "ReqEval";
  expr: Omega0Expr;
  envRef: string;
};

/**
 * Oracle request for application.
 */
export type OracleReqApply = {
  kind: "ReqApply";
  proc: Omega0Val;
  args: Omega0Val[];
};

/**
 * Oracle request union.
 */
export type OracleRequest = OracleReqEval | OracleReqApply;

/**
 * Oracle response with meaning.
 */
export type OracleResponse = {
  denotation: Omega0Val;
  confidence: number;
  evidence?: string;
  /** Optional requests for the meta-evaluator */
  requests?: OracleRequest[];
};

/**
 * Oracle handler type.
 */
export type OracleHandler = (
  expr: Omega0Expr,
  envRef: string,
  ctx: IntContext
) => OracleResponse;

// ─────────────────────────────────────────────────────────────────
// Intensional Evaluation Context
// ─────────────────────────────────────────────────────────────────

/**
 * Context for intensional evaluation.
 */
export type IntContext = {
  /** Oracle handler for inference */
  oracle: OracleHandler;
  /** Evaluation context for extensional fallback */
  evalCtx: EvalContext;
  /** Cache of computed meanings */
  meaningCache: Map<string, Omega0Meaning>;
  /** Maximum oracle calls */
  maxOracleCalls: number;
  /** Current oracle call count */
  oracleCallCount: number;
  /** Depth limit */
  maxDepth: number;
  /** Current depth */
  depth: number;
  /** Whether to validate meanings against eval0 */
  validate: boolean;
  /** Confidence threshold for accepting predictions */
  confidenceThreshold: number;
};

/**
 * Create a default intensional context.
 */
export function createIntContext(
  oracle: OracleHandler,
  options: Partial<IntContext> = {}
): IntContext {
  return {
    oracle,
    evalCtx: createEvalContext({
      maxDepth: options.maxDepth ?? 100,
      maxOracleCalls: options.maxOracleCalls ?? 10,
    }),
    meaningCache: new Map(),
    maxOracleCalls: options.maxOracleCalls ?? 10,
    oracleCallCount: 0,
    maxDepth: options.maxDepth ?? 100,
    depth: 0,
    validate: options.validate ?? true,
    confidenceThreshold: options.confidenceThreshold ?? 0.5,
  };
}

// ─────────────────────────────────────────────────────────────────
// Expression Accessors (mirrored from eval0)
// ─────────────────────────────────────────────────────────────────

function quotedDatum(e: Omega0Expr): Omega0Val {
  if (Array.isArray(e) && e.length >= 2) {
    return exprToVal(e[1]);
  }
  throw new Error("Invalid quote expression");
}

function exprToVal(e: Omega0Expr): Omega0Val {
  if (e === null) return null;
  if (typeof e === "number") return e;
  if (typeof e === "string") return e;
  if (typeof e === "boolean") return e;
  if (isSymbol(e)) return e;
  if (Array.isArray(e)) {
    if (e.length === 0) return null;
    let result: Omega0Val = null;
    for (let i = e.length - 1; i >= 0; i--) {
      result = { tag: "Pair", car: exprToVal(e[i]), cdr: result };
    }
    return result;
  }
  return null;
}

function ifTest(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 2) return e[1];
  throw new Error("Invalid if expression");
}

function ifConseq(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 3) return e[2];
  throw new Error("Invalid if expression");
}

function ifAlt(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 4) return e[3];
  return null;
}

function lambdaParams(e: Omega0Expr): string[] {
  if (Array.isArray(e) && e.length >= 2 && Array.isArray(e[1])) {
    return e[1].map(p => {
      if (isSymbol(p)) return p.name;
      throw new Error(`Invalid parameter: ${omega0ToString(p as Omega0Val)}`);
    });
  }
  throw new Error("Invalid lambda expression");
}

function lambdaBody(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length >= 3) {
    if (e.length > 3) {
      return [{ tag: "Symbol", name: "begin" }, ...e.slice(2)];
    }
    return e[2];
  }
  throw new Error("Invalid lambda expression");
}

function beginExprs(e: Omega0Expr): Omega0Expr[] {
  if (Array.isArray(e)) return e.slice(1);
  throw new Error("Invalid begin expression");
}

function defineNameAndRhs(e: Omega0Expr): { name: string; rhs: Omega0Expr } {
  if (Array.isArray(e) && e.length >= 3) {
    const nameOrFn = e[1];
    if (isSymbol(nameOrFn)) {
      return { name: nameOrFn.name, rhs: e[2] };
    }
    if (Array.isArray(nameOrFn) && nameOrFn.length > 0 && isSymbol(nameOrFn[0])) {
      const fnName = nameOrFn[0].name;
      const params = nameOrFn.slice(1);
      const body = e.slice(2);
      return {
        name: fnName,
        rhs: [{ tag: "Symbol", name: "lambda" }, params, ...body],
      };
    }
  }
  throw new Error("Invalid define expression");
}

function setNameAndRhs(e: Omega0Expr): { name: string; rhs: Omega0Expr } {
  if (Array.isArray(e) && e.length >= 3 && isSymbol(e[1])) {
    return { name: e[1].name, rhs: e[2] };
  }
  throw new Error("Invalid set! expression");
}

function appOperator(e: Omega0Expr): Omega0Expr {
  if (Array.isArray(e) && e.length > 0) return e[0];
  throw new Error("Invalid application");
}

function appOperands(e: Omega0Expr): Omega0Expr[] {
  if (Array.isArray(e)) return e.slice(1);
  throw new Error("Invalid application");
}

// ─────────────────────────────────────────────────────────────────
// int0 - Meta-Intensional Evaluator
// ─────────────────────────────────────────────────────────────────

/**
 * int0 - Intensional evaluation of Ω₀ expressions.
 *
 * Returns a Meaning with predicted denotation and confidence.
 * May consult the oracle for semantic inference.
 */
export function int0(
  e: Omega0Expr,
  env: Omega0Env,
  ctx: IntContext
): Omega0Meaning {
  // Check depth limit
  if (ctx.depth > ctx.maxDepth) {
    return makeMeaning(null, 0, "Maximum depth exceeded", false);
  }

  ctx.depth++;

  try {
    // Check cache first
    const cacheKey = makeCacheKey(e, env);
    if (ctx.meaningCache.has(cacheKey)) {
      return ctx.meaningCache.get(cacheKey)!;
    }

    // Self-evaluating: high confidence, no oracle needed
    if (isSelfEvaluating(e)) {
      const meaning = makeMeaning(e as Omega0Val, 1.0, "self-evaluating", true);
      ctx.meaningCache.set(cacheKey, meaning);
      return meaning;
    }

    // Variable reference
    if (isVariable(e)) {
      try {
        const value = lookup(env, symbolName(e));
        const meaning = makeMeaning(value, 1.0, "variable lookup", true);
        ctx.meaningCache.set(cacheKey, meaning);
        return meaning;
      } catch {
        return makeMeaning(null, 0, `Unbound variable: ${symbolName(e)}`, false);
      }
    }

    // Null
    if (e === null) {
      return makeMeaning(null, 1.0, "null literal", true);
    }

    // Must be a list
    if (!Array.isArray(e)) {
      return makeMeaning(null, 0, `Unknown expression type: ${typeof e}`, false);
    }

    if (e.length === 0) {
      return makeMeaning(null, 1.0, "empty list", true);
    }

    // Quote: high confidence
    if (isQuoted(e)) {
      const meaning = makeMeaning(quotedDatum(e), 1.0, "quote", true);
      ctx.meaningCache.set(cacheKey, meaning);
      return meaning;
    }

    // If: consult oracle for branch prediction or evaluate both
    if (isIf(e)) {
      return intIf(e, env, ctx);
    }

    // Lambda: high confidence (just creates closure)
    if (isLambda(e)) {
      const params = lambdaParams(e);
      const body = lambdaBody(e);
      const closure = makeClosure(params, body, env);
      const meaning = makeMeaning(closure, 1.0, "lambda", true);
      ctx.meaningCache.set(cacheKey, meaning);
      return meaning;
    }

    // Begin: sequence of meanings
    if (isBegin(e)) {
      return intSequence(beginExprs(e), env, ctx);
    }

    // Define
    if (isDefine(e)) {
      const { name, rhs } = defineNameAndRhs(e);
      const rhsMeaning = int0(rhs, env, ctx);
      if (rhsMeaning.confidence >= ctx.confidenceThreshold) {
        defineVar(env, name, rhsMeaning.denotation);
      }
      return rhsMeaning;
    }

    // Set!
    if (isSet(e)) {
      const { name, rhs } = setNameAndRhs(e);
      const rhsMeaning = int0(rhs, env, ctx);
      // set! is side-effectful, confidence depends on rhs
      return makeMeaning(
        rhsMeaning.denotation,
        rhsMeaning.confidence * 0.9, // slight confidence reduction for mutation
        `set! ${name}`,
        rhsMeaning.validated
      );
    }

    // Application: may consult oracle
    if (isApplication(e)) {
      return intApplication(e, env, ctx);
    }

    return makeMeaning(null, 0, `Unknown expression: ${omega0ToString(e as Omega0Val)}`, false);
  } finally {
    ctx.depth--;
  }
}

/**
 * Intensional evaluation of if expressions.
 */
function intIf(e: Omega0Expr, env: Omega0Env, ctx: IntContext): Omega0Meaning {
  const testMeaning = int0(ifTest(e), env, ctx);

  // If test has high confidence, evaluate appropriate branch
  if (testMeaning.confidence >= ctx.confidenceThreshold) {
    const testValue = testMeaning.denotation;
    if (testValue !== false && testValue !== null) {
      const conseqMeaning = int0(ifConseq(e), env, ctx);
      return makeMeaning(
        conseqMeaning.denotation,
        testMeaning.confidence * conseqMeaning.confidence,
        `if-then: ${conseqMeaning.evidence}`,
        testMeaning.validated && conseqMeaning.validated
      );
    } else {
      const altMeaning = int0(ifAlt(e), env, ctx);
      return makeMeaning(
        altMeaning.denotation,
        testMeaning.confidence * altMeaning.confidence,
        `if-else: ${altMeaning.evidence}`,
        testMeaning.validated && altMeaning.validated
      );
    }
  }

  // Low confidence: consult oracle or evaluate both branches
  const conseqMeaning = int0(ifConseq(e), env, ctx);
  const altMeaning = int0(ifAlt(e), env, ctx);

  // Return the branch with higher confidence, reduced overall
  if (conseqMeaning.confidence >= altMeaning.confidence) {
    return makeMeaning(
      conseqMeaning.denotation,
      testMeaning.confidence * conseqMeaning.confidence * 0.5,
      `if-uncertain: conseq branch`,
      false
    );
  } else {
    return makeMeaning(
      altMeaning.denotation,
      testMeaning.confidence * altMeaning.confidence * 0.5,
      `if-uncertain: alt branch`,
      false
    );
  }
}

/**
 * Intensional evaluation of a sequence.
 */
function intSequence(
  exprs: Omega0Expr[],
  env: Omega0Env,
  ctx: IntContext
): Omega0Meaning {
  if (exprs.length === 0) {
    return makeMeaning(null, 1.0, "empty sequence", true);
  }

  let result: Omega0Meaning = makeMeaning(null, 1.0, "sequence start", true);
  for (const expr of exprs) {
    result = int0(expr, env, ctx);
    // If confidence drops too low, stop early
    if (result.confidence < ctx.confidenceThreshold * 0.5) {
      break;
    }
  }
  return result;
}

/**
 * Intensional evaluation of applications.
 */
function intApplication(
  e: Omega0Expr,
  env: Omega0Env,
  ctx: IntContext
): Omega0Meaning {
  const procMeaning = int0(appOperator(e), env, ctx);

  if (procMeaning.confidence < ctx.confidenceThreshold) {
    return makeMeaning(
      null,
      procMeaning.confidence,
      "low confidence in procedure",
      false
    );
  }

  const proc = procMeaning.denotation;

  // Evaluate arguments intensionally
  const argMeanings = appOperands(e).map(arg => int0(arg, env, ctx));
  const minArgConfidence = Math.min(1, ...argMeanings.map(m => m.confidence));

  if (minArgConfidence < ctx.confidenceThreshold) {
    return makeMeaning(
      null,
      minArgConfidence,
      "low confidence in arguments",
      false
    );
  }

  const args = argMeanings.map(m => m.denotation);

  // LLM procedure: consult oracle
  if (isLLMProc(proc)) {
    return intLLMProc(proc as Omega0LLMProc, args, ctx);
  }

  // Closure: intensional application
  if (isClosure(proc)) {
    return intClosure(proc as Omega0Closure, args, ctx);
  }

  // Primitive: high confidence, apply directly
  if (isPrim(proc)) {
    try {
      const result = proc.fn(args);
      return makeMeaning(
        result,
        procMeaning.confidence * minArgConfidence,
        `prim ${proc.name}`,
        true
      );
    } catch (err) {
      return makeMeaning(
        null,
        0,
        `prim error: ${err instanceof Error ? err.message : String(err)}`,
        false
      );
    }
  }

  return makeMeaning(null, 0, `Cannot apply: ${omega0ToString(proc)}`, false);
}

/**
 * Intensional application of LLM procedure.
 */
function intLLMProc(
  proc: Omega0LLMProc,
  args: Omega0Val[],
  ctx: IntContext
): Omega0Meaning {
  // Check oracle call limit
  if (ctx.oracleCallCount >= ctx.maxOracleCalls) {
    return makeMeaning(null, 0, "oracle call limit exceeded", false);
  }

  ctx.oracleCallCount++;

  // Construct oracle request
  const envRef = storeEnv([]);

  try {
    // Consult oracle
    const response = ctx.oracle(
      [{ tag: "Symbol", name: "apply" }, proc, ...args] as Omega0Expr,
      envRef,
      ctx
    );

    // Handle any oracle requests for meta-evaluator
    if (response.requests) {
      for (const req of response.requests) {
        handleOracleRequest(req, ctx);
      }
    }

    const meaning = makeMeaning(
      response.denotation,
      response.confidence,
      response.evidence ?? `llm-proc ${proc.name}`,
      false // Not validated until checked against eval0
    );

    // Optionally validate against extensional evaluation
    if (ctx.validate && response.confidence >= ctx.confidenceThreshold) {
      try {
        const actualResult = proc.infer(args);
        if (deepEqual(response.denotation, actualResult)) {
          meaning.validated = true;
          meaning.evidence = (meaning.evidence ?? "") + " [validated]";
        } else {
          meaning.confidence *= 0.5;
          meaning.evidence = (meaning.evidence ?? "") + " [validation failed]";
        }
      } catch {
        // Validation failed, keep original confidence
      }
    }

    return meaning;
  } catch (err) {
    return makeMeaning(
      null,
      0,
      `oracle error: ${err instanceof Error ? err.message : String(err)}`,
      false
    );
  }
}

/**
 * Intensional application of closure.
 */
function intClosure(
  closure: Omega0Closure,
  args: Omega0Val[],
  ctx: IntContext
): Omega0Meaning {
  // Check arity
  if (args.length !== closure.params.length) {
    return makeMeaning(
      null,
      0,
      `Arity mismatch: expected ${closure.params.length}, got ${args.length}`,
      false
    );
  }

  // Extend environment
  const newEnv = extendEnv(closure.params, args, closure.env);

  // Evaluate body intensionally
  return int0(closure.body, newEnv, ctx);
}

/**
 * Handle oracle request for meta-evaluator.
 */
function handleOracleRequest(req: OracleRequest, ctx: IntContext): Omega0Val {
  if (req.kind === "ReqEval") {
    const env = getEnv(req.envRef);
    if (!env) {
      throw new Error(`Invalid environment reference: ${req.envRef}`);
    }
    return eval0(req.expr, env, ctx.evalCtx);
  }

  if (req.kind === "ReqApply") {
    return apply0(req.proc, req.args, ctx.evalCtx);
  }

  throw new Error(`Unknown oracle request kind: ${(req as any).kind}`);
}

/**
 * Deep equality check for values.
 */
function deepEqual(a: Omega0Val, b: Omega0Val): boolean {
  if (a === b) return true;
  if (typeof a !== typeof b) return false;
  if (a === null || b === null) return a === b;

  if (typeof a === "object" && typeof b === "object") {
    if ((a as any).tag !== (b as any).tag) return false;

    if ((a as any).tag === "Pair") {
      return deepEqual((a as any).car, (b as any).car) &&
             deepEqual((a as any).cdr, (b as any).cdr);
    }

    if ((a as any).tag === "Symbol") {
      return (a as any).name === (b as any).name;
    }
  }

  return false;
}

/**
 * Create cache key for expression + environment.
 */
function makeCacheKey(e: Omega0Expr, env: Omega0Env): string {
  // Simple cache key based on expression string
  // In production, would use more sophisticated hashing
  return omega0ToString(e as Omega0Val) + ":" + env.length;
}

// ─────────────────────────────────────────────────────────────────
// Default Oracle Implementation
// ─────────────────────────────────────────────────────────────────

/**
 * Create a simple oracle that falls back to eval0.
 */
export function createFallbackOracle(): OracleHandler {
  return (expr, envRef, ctx) => {
    const env = getEnv(envRef) ?? [];
    try {
      const result = eval0(expr, env, ctx.evalCtx);
      return {
        denotation: result,
        confidence: 1.0,
        evidence: "eval0 fallback",
      };
    } catch (err) {
      return {
        denotation: null,
        confidence: 0,
        evidence: `eval0 error: ${err instanceof Error ? err.message : String(err)}`,
      };
    }
  };
}

/**
 * Create a scripted oracle for testing.
 */
export function createScriptedOracle(
  script: Map<string, OracleResponse> | ((expr: Omega0Expr) => OracleResponse)
): OracleHandler {
  return (expr, _envRef, _ctx) => {
    if (typeof script === "function") {
      return script(expr);
    }

    const key = omega0ToString(expr as Omega0Val);
    if (script.has(key)) {
      return script.get(key)!;
    }

    // Default: low confidence
    return {
      denotation: null,
      confidence: 0.1,
      evidence: "no scripted response",
    };
  };
}

// ─────────────────────────────────────────────────────────────────
// Utility Functions
// ─────────────────────────────────────────────────────────────────

/**
 * Extract the denotation from a meaning, throwing if low confidence.
 */
export function commitMeaning(meaning: Omega0Meaning, threshold: number = 0.5): Omega0Val {
  if (meaning.confidence < threshold) {
    throw new Error(
      `Cannot commit meaning with confidence ${meaning.confidence.toFixed(2)} ` +
      `(threshold: ${threshold}): ${meaning.evidence}`
    );
  }
  return meaning.denotation;
}

/**
 * Check if a meaning is validated.
 */
export function isValidated(meaning: Omega0Meaning): boolean {
  return meaning.validated;
}

/**
 * Add an obligation to a meaning.
 */
export function addObligation(meaning: Omega0Meaning, obligation: string): Omega0Meaning {
  return {
    ...meaning,
    obligations: [...(meaning.obligations ?? []), obligation],
  };
}

/**
 * Check if all obligations are satisfied.
 */
export function obligationsSatisfied(meaning: Omega0Meaning): boolean {
  return !meaning.obligations || meaning.obligations.length === 0;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/primitives.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/primitives.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-circular evaluator - Primitives and LLM procedures

import type {
  Omega0Val,
  Omega0Env,
  Omega0Prim,
  Omega0LLMProc,
  Omega0Pair,
} from "./types";
import {
  makePrim,
  makeLLMProc,
  cons,
  car,
  cdr,
  isPair,
  isNull,
  isSymbol,
  isClosure,
  isPrim,
  isLLMProc,
  isMeaning,
  arrayToList,
  listToArray,
  listLength,
  omega0ToString,
  sym,
} from "./types";
import { defineVar, emptyEnv } from "./env";

// ─────────────────────────────────────────────────────────────────
// Arithmetic Primitives
// ─────────────────────────────────────────────────────────────────

const primPlus = makePrim("+", (args) => {
  return args.reduce((sum, x) => {
    if (typeof sum === "number" && typeof x === "number") {
      return sum + x;
    }
    return sum;
  }, 0) as Omega0Val;
});

const primMinus = makePrim("-", (args) => {
  if (args.length === 0) return 0;
  if (args.length === 1 && typeof args[0] === "number") return -args[0];
  const first = typeof args[0] === "number" ? args[0] : 0;
  return args.slice(1).reduce((diff, x) => {
    if (typeof diff === "number" && typeof x === "number") {
      return diff - x;
    }
    return diff;
  }, first) as Omega0Val;
});

const primMult = makePrim("*", (args) => {
  return args.reduce((prod, x) => {
    if (typeof prod === "number" && typeof x === "number") {
      return prod * x;
    }
    return prod;
  }, 1) as Omega0Val;
});

const primDiv = makePrim("/", (args) => {
  if (args.length < 2) return 0;
  const first = typeof args[0] === "number" ? args[0] : 0;
  return args.slice(1).reduce((quot, x) => {
    if (typeof quot === "number" && typeof x === "number" && x !== 0) {
      return quot / x;
    }
    return quot;
  }, first) as Omega0Val;
});

const primMod = makePrim("modulo", (args) => {
  if (args.length >= 2 && typeof args[0] === "number" && typeof args[1] === "number") {
    return args[0] % args[1];
  }
  return 0;
});

// ─────────────────────────────────────────────────────────────────
// Comparison Primitives
// ─────────────────────────────────────────────────────────────────

const primEq = makePrim("=", (args) => {
  if (args.length < 2) return true;
  const first = args[0];
  return args.slice(1).every(x => x === first);
});

const primLt = makePrim("<", (args) => {
  if (args.length < 2) return true;
  for (let i = 0; i < args.length - 1; i++) {
    if (typeof args[i] !== "number" || typeof args[i + 1] !== "number") return false;
    if (args[i] as number >= (args[i + 1] as number)) return false;
  }
  return true;
});

const primGt = makePrim(">", (args) => {
  if (args.length < 2) return true;
  for (let i = 0; i < args.length - 1; i++) {
    if (typeof args[i] !== "number" || typeof args[i + 1] !== "number") return false;
    if (args[i] as number <= (args[i + 1] as number)) return false;
  }
  return true;
});

const primLe = makePrim("<=", (args) => {
  if (args.length < 2) return true;
  for (let i = 0; i < args.length - 1; i++) {
    if (typeof args[i] !== "number" || typeof args[i + 1] !== "number") return false;
    if (args[i] as number > (args[i + 1] as number)) return false;
  }
  return true;
});

const primGe = makePrim(">=", (args) => {
  if (args.length < 2) return true;
  for (let i = 0; i < args.length - 1; i++) {
    if (typeof args[i] !== "number" || typeof args[i + 1] !== "number") return false;
    if (args[i] as number < (args[i + 1] as number)) return false;
  }
  return true;
});

const primEqQuestion = makePrim("eq?", (args) => {
  if (args.length < 2) return true;
  return args[0] === args[1];
});

const primEqualQuestion = makePrim("equal?", (args) => {
  if (args.length < 2) return true;
  return deepEqual(args[0], args[1]);
});

function deepEqual(a: Omega0Val, b: Omega0Val): boolean {
  if (a === b) return true;
  if (typeof a !== typeof b) return false;
  if (isPair(a) && isPair(b)) {
    return deepEqual(a.car, b.car) && deepEqual(a.cdr, b.cdr);
  }
  if (isSymbol(a) && isSymbol(b)) {
    return a.name === b.name;
  }
  return false;
}

// ─────────────────────────────────────────────────────────────────
// Boolean Primitives
// ─────────────────────────────────────────────────────────────────

const primNot = makePrim("not", (args) => {
  if (args.length === 0) return true;
  return args[0] === false || args[0] === null;
});

const primAnd = makePrim("and", (args) => {
  for (const arg of args) {
    if (arg === false || arg === null) return false;
  }
  return args.length > 0 ? args[args.length - 1] : true;
});

const primOr = makePrim("or", (args) => {
  for (const arg of args) {
    if (arg !== false && arg !== null) return arg;
  }
  return false;
});

// ─────────────────────────────────────────────────────────────────
// List Primitives
// ─────────────────────────────────────────────────────────────────

const primCons = makePrim("cons", (args) => {
  if (args.length < 2) return null;
  return cons(args[0], args[1]);
});

const primCar = makePrim("car", (args) => {
  if (args.length === 0 || !isPair(args[0])) {
    throw new Error("car expects a pair");
  }
  return car(args[0] as Omega0Pair);
});

const primCdr = makePrim("cdr", (args) => {
  if (args.length === 0 || !isPair(args[0])) {
    throw new Error("cdr expects a pair");
  }
  return cdr(args[0] as Omega0Pair);
});

const primList = makePrim("list", (args) => {
  return arrayToList(args);
});

const primLength = makePrim("length", (args) => {
  if (args.length === 0) return 0;
  return listLength(args[0]);
});

const primAppend = makePrim("append", (args) => {
  if (args.length === 0) return null;
  if (args.length === 1) return args[0];

  const result: Omega0Val[] = [];
  for (const arg of args) {
    if (arg !== null) {
      result.push(...listToArray(arg));
    }
  }
  return arrayToList(result);
});

const primReverse = makePrim("reverse", (args) => {
  if (args.length === 0) return null;
  const arr = listToArray(args[0]);
  return arrayToList(arr.reverse());
});

const primMap = makePrim("map", (args) => {
  if (args.length < 2) return null;
  const fn = args[0];
  const list = args[1];

  if (!isClosure(fn) && !isPrim(fn) && !isLLMProc(fn)) {
    throw new Error("map expects a procedure");
  }

  const arr = listToArray(list);
  // Note: map needs to call the function, but we can't do that here without eval0
  // This is a simplified version that just returns the list
  // In a full implementation, map would be a special form or use continuation passing
  return list;
});

// ─────────────────────────────────────────────────────────────────
// Type Predicates
// ─────────────────────────────────────────────────────────────────

const primNullQuestion = makePrim("null?", (args) => {
  return args.length > 0 && isNull(args[0]);
});

const primPairQuestion = makePrim("pair?", (args) => {
  return args.length > 0 && isPair(args[0]);
});

const primListQuestion = makePrim("list?", (args) => {
  if (args.length === 0) return false;
  let current = args[0];
  while (current !== null) {
    if (!isPair(current)) return false;
    current = (current as Omega0Pair).cdr;
  }
  return true;
});

const primSymbolQuestion = makePrim("symbol?", (args) => {
  return args.length > 0 && isSymbol(args[0]);
});

const primNumberQuestion = makePrim("number?", (args) => {
  return args.length > 0 && typeof args[0] === "number";
});

const primStringQuestion = makePrim("string?", (args) => {
  return args.length > 0 && typeof args[0] === "string";
});

const primBooleanQuestion = makePrim("boolean?", (args) => {
  return args.length > 0 && typeof args[0] === "boolean";
});

const primProcedureQuestion = makePrim("procedure?", (args) => {
  return args.length > 0 && (isClosure(args[0]) || isPrim(args[0]) || isLLMProc(args[0]));
});

// ─────────────────────────────────────────────────────────────────
// String Primitives
// ─────────────────────────────────────────────────────────────────

const primStringAppend = makePrim("string-append", (args) => {
  return args.map(a => typeof a === "string" ? a : omega0ToString(a)).join("");
});

const primStringLength = makePrim("string-length", (args) => {
  if (args.length === 0 || typeof args[0] !== "string") return 0;
  return args[0].length;
});

const primSubstring = makePrim("substring", (args) => {
  if (args.length < 2 || typeof args[0] !== "string") return "";
  const str = args[0] as string;
  const start = typeof args[1] === "number" ? args[1] : 0;
  const end = args.length > 2 && typeof args[2] === "number" ? args[2] : str.length;
  return str.substring(start, end);
});

const primStringToList = makePrim("string->list", (args) => {
  if (args.length === 0 || typeof args[0] !== "string") return null;
  const chars = (args[0] as string).split("").map(c => c);
  return arrayToList(chars);
});

const primListToString = makePrim("list->string", (args) => {
  if (args.length === 0) return "";
  const arr = listToArray(args[0]);
  return arr.map(c => typeof c === "string" ? c : "").join("");
});

// ─────────────────────────────────────────────────────────────────
// I/O Primitives (simplified)
// ─────────────────────────────────────────────────────────────────

const primDisplay = makePrim("display", (args) => {
  if (args.length > 0) {
    // In a real implementation, this would output to a port
    // For now, just return the value
  }
  return null;
});

const primNewline = makePrim("newline", (_args) => {
  return null;
});

// ─────────────────────────────────────────────────────────────────
// Error Handling
// ─────────────────────────────────────────────────────────────────

const primError = makePrim("error", (args) => {
  const msg = args.map(a => omega0ToString(a)).join(" ");
  throw new Error(msg);
});

// ─────────────────────────────────────────────────────────────────
// Base Environment
// ─────────────────────────────────────────────────────────────────

/**
 * Create the base environment with all primitives.
 */
export function createBaseEnv(): Omega0Env {
  let env = emptyEnv();

  // Arithmetic
  env = defineVar(env, "+", primPlus);
  env = defineVar(env, "-", primMinus);
  env = defineVar(env, "*", primMult);
  env = defineVar(env, "/", primDiv);
  env = defineVar(env, "modulo", primMod);

  // Comparison
  env = defineVar(env, "=", primEq);
  env = defineVar(env, "<", primLt);
  env = defineVar(env, ">", primGt);
  env = defineVar(env, "<=", primLe);
  env = defineVar(env, ">=", primGe);
  env = defineVar(env, "eq?", primEqQuestion);
  env = defineVar(env, "equal?", primEqualQuestion);

  // Boolean
  env = defineVar(env, "not", primNot);
  env = defineVar(env, "and", primAnd);
  env = defineVar(env, "or", primOr);

  // List
  env = defineVar(env, "cons", primCons);
  env = defineVar(env, "car", primCar);
  env = defineVar(env, "cdr", primCdr);
  env = defineVar(env, "list", primList);
  env = defineVar(env, "length", primLength);
  env = defineVar(env, "append", primAppend);
  env = defineVar(env, "reverse", primReverse);

  // Type predicates
  env = defineVar(env, "null?", primNullQuestion);
  env = defineVar(env, "pair?", primPairQuestion);
  env = defineVar(env, "list?", primListQuestion);
  env = defineVar(env, "symbol?", primSymbolQuestion);
  env = defineVar(env, "number?", primNumberQuestion);
  env = defineVar(env, "string?", primStringQuestion);
  env = defineVar(env, "boolean?", primBooleanQuestion);
  env = defineVar(env, "procedure?", primProcedureQuestion);

  // String
  env = defineVar(env, "string-append", primStringAppend);
  env = defineVar(env, "string-length", primStringLength);
  env = defineVar(env, "substring", primSubstring);
  env = defineVar(env, "string->list", primStringToList);
  env = defineVar(env, "list->string", primListToString);

  // I/O
  env = defineVar(env, "display", primDisplay);
  env = defineVar(env, "newline", primNewline);

  // Error
  env = defineVar(env, "error", primError);

  return env;
}

// ─────────────────────────────────────────────────────────────────
// LLM Procedure Factory
// ─────────────────────────────────────────────────────────────────

/**
 * LLM inference handler type.
 */
export type LLMInferHandler = (
  prompt: string,
  args: Omega0Val[]
) => Omega0Val;

/**
 * Create an LLM procedure with a custom inference handler.
 */
export function createLLMProc(
  name: string,
  prompt: string,
  handler: LLMInferHandler
): Omega0LLMProc {
  return makeLLMProc(
    name,
    prompt,
    (args) => handler(prompt, args)
  );
}

/**
 * Create a scripted LLM procedure (for testing).
 *
 * The script maps input patterns to outputs.
 */
export function createScriptedLLMProc(
  name: string,
  prompt: string,
  script: Map<string, Omega0Val> | ((args: Omega0Val[]) => Omega0Val)
): Omega0LLMProc {
  const handler: LLMInferHandler = (_prompt, args) => {
    if (typeof script === "function") {
      return script(args);
    }

    // Try to match args against script keys
    const key = args.map(omega0ToString).join(",");
    if (script.has(key)) {
      return script.get(key)!;
    }

    // Default: return first arg or null
    return args.length > 0 ? args[0] : null;
  };

  return createLLMProc(name, prompt, handler);
}

/**
 * Add an LLM procedure to an environment.
 */
export function addLLMProcToEnv(
  env: Omega0Env,
  name: string,
  proc: Omega0LLMProc
): Omega0Env {
  return defineVar(env, name, proc);
}

/**
 * Primitive for creating LLM procedures at runtime.
 */
export function createMakeLLMProcPrim(
  defaultHandler: LLMInferHandler
): Omega0Prim {
  return makePrim("make-llm-proc", (args) => {
    if (args.length < 1 || typeof args[0] !== "string") {
      throw new Error("make-llm-proc expects a string prompt");
    }
    const prompt = args[0] as string;
    const name = args.length > 1 && typeof args[1] === "string"
      ? args[1] as string
      : "anonymous-llm-proc";

    return createLLMProc(name, prompt, defaultHandler);
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/meta/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/meta/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Prompt 18: Meta-circular evaluator - Type definitions for Ω₀

import type { Val } from "../eval/values";

// ─────────────────────────────────────────────────────────────────
// Ω₀ Expression Types (S-expression representation)
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ is a deliberately small object language subset:
 * - literals: numbers/strings/bools
 * - variables: symbols
 * - (quote datum)
 * - (if test conseq alt)
 * - (lambda (x ...) body)
 * - (begin e1 e2 ... en)
 * - (define x rhs)
 * - (set! x rhs)
 * - application: (f a1 ... an)
 *
 * No macros, no handle/effect, no infer, no amb.
 * Those exist at the host Ω level.
 */

/**
 * Ω₀ expression - S-expression style datum.
 */
export type Omega0Expr =
  | number
  | string
  | boolean
  | symbol
  | null
  | Omega0Symbol
  | Omega0List;

/**
 * Ω₀ list - a proper list of expressions.
 */
export type Omega0List = Omega0Expr[];

/**
 * Symbol representation for Ω₀ (using string with marker).
 */
export type Omega0Symbol = {
  tag: "Symbol";
  name: string;
};

/**
 * Create an Ω₀ symbol.
 */
export function sym(name: string): Omega0Symbol {
  return { tag: "Symbol", name };
}

/**
 * Check if value is an Ω₀ symbol.
 */
export function isSymbol(x: unknown): x is Omega0Symbol {
  return typeof x === "object" && x !== null && (x as any).tag === "Symbol";
}

/**
 * Get symbol name.
 */
export function symbolName(s: Omega0Symbol): string {
  return s.name;
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ Values (evaluation results)
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ value - result of evaluation.
 */
export type Omega0Val =
  | number
  | string
  | boolean
  | null
  | Omega0Symbol
  | Omega0List
  | Omega0Pair
  | Omega0Closure
  | Omega0Prim
  | Omega0LLMProc
  | Omega0Meaning;

/**
 * Ω₀ pair (cons cell).
 */
export type Omega0Pair = {
  tag: "Pair";
  car: Omega0Val;
  cdr: Omega0Val;
};

/**
 * Create a pair.
 */
export function cons(car: Omega0Val, cdr: Omega0Val): Omega0Pair {
  return { tag: "Pair", car, cdr };
}

/**
 * Check if value is a pair.
 */
export function isPair(x: unknown): x is Omega0Pair {
  return typeof x === "object" && x !== null && (x as any).tag === "Pair";
}

/**
 * Get car of pair.
 */
export function car(p: Omega0Pair): Omega0Val {
  return p.car;
}

/**
 * Get cdr of pair.
 */
export function cdr(p: Omega0Pair): Omega0Val {
  return p.cdr;
}

/**
 * Check if value is null (empty list).
 */
export function isNull(x: unknown): x is null {
  return x === null;
}

/**
 * Check if value is a list (null or pair with list cdr).
 */
export function isList(x: unknown): boolean {
  if (x === null) return true;
  if (isPair(x)) return isList(x.cdr);
  return false;
}

/**
 * Convert array to proper list.
 */
export function arrayToList(arr: Omega0Val[]): Omega0Val {
  if (arr.length === 0) return null;
  return cons(arr[0], arrayToList(arr.slice(1)));
}

/**
 * Convert proper list to array.
 */
export function listToArray(list: Omega0Val): Omega0Val[] {
  const result: Omega0Val[] = [];
  let current = list;
  while (isPair(current)) {
    result.push(current.car);
    current = current.cdr;
  }
  return result;
}

/**
 * Get length of a list.
 */
export function listLength(list: Omega0Val): number {
  let count = 0;
  let current = list;
  while (isPair(current)) {
    count++;
    current = current.cdr;
  }
  return count;
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ Closures
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ closure - a lambda with captured environment.
 */
export type Omega0Closure = {
  tag: "Closure";
  params: string[];
  body: Omega0Expr;
  env: Omega0Env;
  label?: string;
};

/**
 * Create a closure.
 */
export function makeClosure(
  params: string[],
  body: Omega0Expr,
  env: Omega0Env,
  label?: string
): Omega0Closure {
  return { tag: "Closure", params, body, env, label };
}

/**
 * Check if value is a closure.
 */
export function isClosure(x: unknown): x is Omega0Closure {
  return typeof x === "object" && x !== null && (x as any).tag === "Closure";
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ Primitives
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ primitive - a built-in operation.
 */
export type Omega0Prim = {
  tag: "Prim";
  name: string;
  fn: (args: Omega0Val[]) => Omega0Val;
};

/**
 * Create a primitive.
 */
export function makePrim(
  name: string,
  fn: (args: Omega0Val[]) => Omega0Val
): Omega0Prim {
  return { tag: "Prim", name, fn };
}

/**
 * Check if value is a primitive.
 */
export function isPrim(x: unknown): x is Omega0Prim {
  return typeof x === "object" && x !== null && (x as any).tag === "Prim";
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ LLM Procedures (Semantic Functions)
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ LLM procedure - a semantic function backed by inference.
 */
export type Omega0LLMProc = {
  tag: "LLMProc";
  name: string;
  prompt: string;
  schema?: unknown;
  /** Handler that performs inference */
  infer: (args: Omega0Val[]) => Omega0Val;
};

/**
 * Create an LLM procedure.
 */
export function makeLLMProc(
  name: string,
  prompt: string,
  infer: (args: Omega0Val[]) => Omega0Val,
  schema?: unknown
): Omega0LLMProc {
  return { tag: "LLMProc", name, prompt, infer, schema };
}

/**
 * Check if value is an LLM procedure.
 */
export function isLLMProc(x: unknown): x is Omega0LLMProc {
  return typeof x === "object" && x !== null && (x as any).tag === "LLMProc";
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ Meaning (Intensional Results)
// ─────────────────────────────────────────────────────────────────

/**
 * Ω₀ meaning - result of intensional evaluation (int0).
 */
export type Omega0Meaning = {
  tag: "Meaning";
  /** The predicted/computed denotation */
  denotation: Omega0Val;
  /** Confidence level (0-1) */
  confidence: number;
  /** Evidence/justification */
  evidence?: string;
  /** Whether validated against extensional eval */
  validated: boolean;
  /** Obligations for commit */
  obligations?: string[];
};

/**
 * Create a meaning.
 */
export function makeMeaning(
  denotation: Omega0Val,
  confidence: number,
  evidence?: string,
  validated: boolean = false
): Omega0Meaning {
  return { tag: "Meaning", denotation, confidence, evidence, validated };
}

/**
 * Check if value is a meaning.
 */
export function isMeaning(x: unknown): x is Omega0Meaning {
  return typeof x === "object" && x !== null && (x as any).tag === "Meaning";
}

// ─────────────────────────────────────────────────────────────────
// Ω₀ Environment
// ─────────────────────────────────────────────────────────────────

/**
 * Environment frame - association list of (name, value) pairs.
 */
export type Omega0Frame = Map<string, Omega0Val>;

/**
 * Environment - list of frames (most recent first).
 */
export type Omega0Env = Omega0Frame[];

/**
 * Create an empty environment.
 */
export function emptyEnv(): Omega0Env {
  return [];
}

/**
 * Create a new frame.
 */
export function makeFrame(): Omega0Frame {
  return new Map();
}

// ─────────────────────────────────────────────────────────────────
// Expression Predicates
// ─────────────────────────────────────────────────────────────────

/**
 * Check if expression is self-evaluating (number, string, boolean).
 */
export function isSelfEvaluating(e: Omega0Expr): boolean {
  return typeof e === "number" || typeof e === "string" || typeof e === "boolean";
}

/**
 * Check if expression is a variable (symbol).
 */
export function isVariable(e: Omega0Expr): e is Omega0Symbol {
  return isSymbol(e);
}

/**
 * Check if expression is a tagged list (e.g., (quote ...), (if ...), etc.).
 */
export function isTaggedList(e: Omega0Expr, tag: string): boolean {
  if (!Array.isArray(e) || e.length === 0) return false;
  const head = e[0];
  return isSymbol(head) && head.name === tag;
}

/**
 * Check if expression is a quote form.
 */
export function isQuoted(e: Omega0Expr): boolean {
  return isTaggedList(e, "quote");
}

/**
 * Check if expression is an if form.
 */
export function isIf(e: Omega0Expr): boolean {
  return isTaggedList(e, "if");
}

/**
 * Check if expression is a lambda form.
 */
export function isLambda(e: Omega0Expr): boolean {
  return isTaggedList(e, "lambda");
}

/**
 * Check if expression is a begin form.
 */
export function isBegin(e: Omega0Expr): boolean {
  return isTaggedList(e, "begin");
}

/**
 * Check if expression is a define form.
 */
export function isDefine(e: Omega0Expr): boolean {
  return isTaggedList(e, "define");
}

/**
 * Check if expression is a set! form.
 */
export function isSet(e: Omega0Expr): boolean {
  return isTaggedList(e, "set!");
}

/**
 * Check if expression is an application (any list that's not a special form).
 */
export function isApplication(e: Omega0Expr): boolean {
  return Array.isArray(e) && e.length > 0;
}

// ─────────────────────────────────────────────────────────────────
// Evaluation Trace (for differential testing)
// ─────────────────────────────────────────────────────────────────

/**
 * Trace entry for evaluation.
 */
export type EvalTraceEntry = {
  /** Kind of operation */
  kind: "eval" | "apply" | "lookup" | "define" | "infer";
  /** Expression or procedure being processed */
  subject: string;
  /** Result (stringified) */
  result?: string;
  /** Depth in call stack */
  depth: number;
};

/**
 * Evaluation context for tracing and governance.
 */
export type EvalContext = {
  /** Trace of evaluation steps */
  trace: EvalTraceEntry[];
  /** Current call depth */
  depth: number;
  /** Maximum depth allowed */
  maxDepth: number;
  /** Oracle call count */
  oracleCallCount: number;
  /** Maximum oracle calls allowed */
  maxOracleCalls: number;
  /** Whether tracing is enabled */
  tracing: boolean;
};

/**
 * Create a default evaluation context.
 */
export function createEvalContext(options: Partial<EvalContext> = {}): EvalContext {
  return {
    trace: [],
    depth: 0,
    maxDepth: options.maxDepth ?? 100,
    oracleCallCount: 0,
    maxOracleCalls: options.maxOracleCalls ?? 10,
    tracing: options.tracing ?? false,
  };
}

// ─────────────────────────────────────────────────────────────────
// Value Display
// ─────────────────────────────────────────────────────────────────

/**
 * Convert Ω₀ value to string for display.
 */
export function omega0ToString(v: Omega0Val): string {
  if (v === null) return "()";
  if (typeof v === "number") return String(v);
  if (typeof v === "string") return JSON.stringify(v);
  if (typeof v === "boolean") return v ? "#t" : "#f";
  if (isSymbol(v)) return v.name;
  if (isPair(v)) {
    const items: string[] = [];
    let current: Omega0Val = v;
    while (isPair(current)) {
      items.push(omega0ToString(current.car));
      current = current.cdr;
    }
    if (current !== null) {
      return `(${items.join(" ")} . ${omega0ToString(current)})`;
    }
    return `(${items.join(" ")})`;
  }
  if (isClosure(v)) return `#<closure${v.label ? ` ${v.label}` : ""}>`;
  if (isPrim(v)) return `#<prim ${v.name}>`;
  if (isLLMProc(v)) return `#<llm-proc ${v.name}>`;
  if (isMeaning(v)) return `#<meaning conf=${v.confidence.toFixed(2)}>`;
  if (Array.isArray(v)) {
    return `(${(v as Omega0Expr[]).map(x => omega0ToString(x as Omega0Val)).join(" ")})`;
  }
  return String(v);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/modules/artifact.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-7.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Binding } from "../syntax/binding";
import type { Expr } from "../ast";
import type { SRTransformer } from "../expand/syntaxRules";

export type ExportEntry0 = { name: string; bid: string; internal: string };
export type ExportEntry1 = { name: string; bid: string; transformer: SRTransformer };

export type ModuleArtifact = {
  moduleName: string;
  moduleId: string;                 // stable, used for prefixing bids/scopes
  scopeM0: string;
  scopeM1: string;

  // Full binding table closure for def-site resolution of imported macros
  bindings: Binding[];

  // The runtime init expression (phase 0)
  init: Expr;

  exports0: ExportEntry0[];
  exports1: ExportEntry1[];

  deps: string[];                   // module names or module ids (depends on loader)
  sourceHash: string;
  expandedHash: string;
  coreHash: string;

  // Hermetic inference receipts produced during compilation (Part 19 §178)
  receipts: unknown[];
};
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/modules/compileModule.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-7.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import { tokenize } from "../reader/tokenize";
import { parseAll } from "../reader/parse";
import type { Datum } from "../reader/datum";
import { isSym } from "../reader/datum";
import { datumToSyntax } from "../reader/toSyntax";
import { addScope } from "../syntax/syntax";
import type { Syntax, SIdent, SList } from "../syntax/syntax";
import { isIdent, isList } from "../syntax/syntax";
import type { Env, Binding } from "../syntax/binding";
import { resolveIdent } from "../syntax/binding";
import { lowerSyntax } from "../pipeline/lower";
import { compileSyntaxRules, type SRTransformer } from "../expand/syntaxRules";

// loader provides module source by name
export interface ModuleLoader {
  loadSource(moduleName: string): string;
  // optional: loadArtifact by hash
}

// compilation context to memoize compiled artifacts
export type CompileCtx = {
  compiled: Map<string, ModuleArtifact>;
  // moduleName -> artifact
};

export type ModuleArtifact = import("./artifact").ModuleArtifact;

// deterministic hashes (stub; use crypto hash in real code)
function hashText(s: string): string { return `H(${s.length}:${s.slice(0,64)})`; }

function expectList(stx: Syntax, msg: string): SList {
  if (!isList(stx)) throw new Error(msg);
  return stx;
}
function expectIdent(stx: Syntax, msg: string): SIdent {
  if (!isIdent(stx)) throw new Error(msg);
  return stx;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/modules/graph.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-8.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

export type DepGraph = Map<string, string[]>; // module -> deps

export function topoOrScc(graph: DepGraph): { tag: "Topo"; order: string[] } | { tag: "Cycle"; scc: string[] } {
  const index = new Map<string, number>();
  const lowlink = new Map<string, number>();
  const onStack = new Set<string>();
  const stack: string[] = [];
  let idx = 0;
  const sccs: string[][] = [];

  function strongconnect(v: string) {
    index.set(v, idx);
    lowlink.set(v, idx);
    idx++;
    stack.push(v);
    onStack.add(v);

    for (const w of graph.get(v) ?? []) {
      if (!index.has(w)) {
        strongconnect(w);
        lowlink.set(v, Math.min(lowlink.get(v)!, lowlink.get(w)!));
      } else if (onStack.has(w)) {
        lowlink.set(v, Math.min(lowlink.get(v)!, index.get(w)!));
      }
    }

    if (lowlink.get(v) === index.get(v)) {
      const scc: string[] = [];
      while (true) {
        const w = stack.pop()!;
        onStack.delete(w);
        scc.push(w);
        if (w === v) break;
      }
      sccs.push(scc);
    }
  }

  for (const v of graph.keys()) {
    if (!index.has(v)) strongconnect(v);
  }

  // if any SCC has size > 1 (or self-loop), it's a cycle
  for (const scc of sccs) {
    if (scc.length > 1) return { tag: "Cycle", scc };
    const v = scc[0];
    if ((graph.get(v) ?? []).includes(v)) return { tag: "Cycle", scc };
  }

  // If no cycles, a topo order can be obtained by reverse postorder via SCC list; simplest:
  // Here sccs is already in reverse topo of SCC DAG in Tarjan; flatten reversed:
  const order = sccs.flat().reverse();
  return { tag: "Topo", order };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/modules/instance.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-8.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Env as RTEnv } from "../eval/env";
import type { Store } from "../eval/store";

export type PhaseInstance = {
  env: RTEnv;     // runtime environment (internalName -> addr)
  store: Store;   // runtime store
};

export type InstanceCache = Map<string, Map<number, PhaseInstance>>; // moduleName -> phase -> instance
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/adapters/anthropic.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Anthropic OPR Adapter
 *
 * Makes real calls to Anthropic API
 */

import type { OprLLMRequest, AnthropicAdapterConfig } from './types';
import { BaseOprAdapter } from './types';

export class AnthropicOprAdapter extends BaseOprAdapter {
  private config: AnthropicAdapterConfig;

  constructor(config: AnthropicAdapterConfig) {
    super();
    this.config = config;
  }

  async complete(request: OprLLMRequest): Promise<string> {
    const { apiKey, baseURL, model, maxTokens, temperature, timeout } = this.config;

    // Extract system message from prompt (supports PSystem from FrameIR)
    let system = '';
    if (request.prompt && request.prompt.parts) {
      for (const part of request.prompt.parts) {
        if ((part as any).tag === 'PSystem') {
          system += (part as any).text + '\n';
        } else if ((part as any).tag === 'System') {
          system += (part as any).content + '\n';
        }
      }
    }

    const body: Record<string, unknown> = {
      model,
      max_tokens: request.maxTokens ?? maxTokens ?? 2000,
      messages: [{ role: 'user', content: request.userContent }],
    };

    if (system) {
      body.system = system.trim();
    }

    if ((request.temperature ?? temperature) !== undefined) {
      body.temperature = request.temperature ?? temperature;
    }

    const url = `${baseURL ?? 'https://api.anthropic.com'}/v1/messages`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout ?? 60000);

    try {
      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': apiKey,
          'anthropic-version': '2023-06-01',
        },
        body: JSON.stringify(body),
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`Anthropic API error ${response.status}: ${error}`);
      }

      const data = await response.json();

      // Track usage
      if (data.usage) {
        this.lastUsage = {
          promptTokens: data.usage.input_tokens,
          completionTokens: data.usage.output_tokens,
          totalTokens: data.usage.input_tokens + data.usage.output_tokens,
          estimatedCost: this.estimateCost(
            {
              promptTokens: data.usage.input_tokens,
              completionTokens: data.usage.output_tokens,
            },
            model
          ),
        };
      }

      // Extract text from content blocks
      const content = data.content ?? [];
      const text = content
        .filter((c: any) => c.type === 'text')
        .map((c: any) => c.text)
        .join('');

      return text;
    } catch (e) {
      clearTimeout(timeoutId);
      if ((e as Error).name === 'AbortError') {
        throw new Error('Anthropic request timed out');
      }
      throw e;
    }
  }

  getModel(): string {
    return this.config.model;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/adapters/index.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Adapters
 */

export * from './types';
export { ScriptedOprAdapter } from './scripted';
export { OpenAIOprAdapter } from './openai';
export { AnthropicOprAdapter } from './anthropic';

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/adapters/openai.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OpenAI OPR Adapter
 *
 * Makes real calls to OpenAI API
 */

import type { OprLLMRequest, OpenAIAdapterConfig } from './types';
import { BaseOprAdapter } from './types';

export class OpenAIOprAdapter extends BaseOprAdapter {
  private config: OpenAIAdapterConfig;

  constructor(config: OpenAIAdapterConfig) {
    super();
    this.config = config;
  }

  async complete(request: OprLLMRequest): Promise<string> {
    const { apiKey, baseURL, organization, model, maxTokens, temperature, timeout } = this.config;

    // Build messages from prompt
    const messages: Array<{ role: string; content: string }> = [];

    // Extract system message from prompt (supports PSystem from FrameIR)
    if (request.prompt && request.prompt.parts) {
      for (const part of request.prompt.parts) {
        if ((part as any).tag === 'PSystem') {
          messages.push({ role: 'system', content: (part as any).text });
        } else if ((part as any).tag === 'System') {
          messages.push({ role: 'system', content: (part as any).content });
        }
      }
    }

    // Add user content
    messages.push({ role: 'user', content: request.userContent });

    const body = {
      model,
      messages,
      max_tokens: request.maxTokens ?? maxTokens ?? 2000,
      temperature: request.temperature ?? temperature ?? 0,
    };

    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    };

    if (organization) {
      headers['OpenAI-Organization'] = organization;
    }

    const url = `${baseURL ?? 'https://api.openai.com/v1'}/chat/completions`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout ?? 60000);

    try {
      const response = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body),
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`OpenAI API error ${response.status}: ${error}`);
      }

      const data = await response.json();

      // Track usage
      if (data.usage) {
        this.lastUsage = {
          promptTokens: data.usage.prompt_tokens,
          completionTokens: data.usage.completion_tokens,
          totalTokens: data.usage.total_tokens,
          estimatedCost: this.estimateCost(
            {
              promptTokens: data.usage.prompt_tokens,
              completionTokens: data.usage.completion_tokens,
            },
            model
          ),
        };
      }

      return data.choices[0]?.message?.content ?? '';
    } catch (e) {
      clearTimeout(timeoutId);
      if ((e as Error).name === 'AbortError') {
        throw new Error('OpenAI request timed out');
      }
      throw e;
    }
  }

  getModel(): string {
    return this.config.model;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/adapters/scripted.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Scripted OPR Adapter
 *
 * Returns pre-defined responses in sequence. Used for testing.
 */

import type { OprLLMRequest, ScriptedAdapterConfig } from './types';
import { BaseOprAdapter } from './types';

/**
 * Adapter that returns scripted responses for testing
 */
export class ScriptedOprAdapter extends BaseOprAdapter {
  private responses: Array<string | { response: string; delay?: number }>;
  private loop: boolean;
  private index = 0;

  constructor(config: ScriptedAdapterConfig) {
    super();
    this.responses = config.responses;
    this.loop = config.loop ?? false;
  }

  async complete(request: OprLLMRequest): Promise<string> {
    if (this.index >= this.responses.length) {
      if (this.loop) {
        this.index = 0;
      } else {
        throw new Error('ScriptedOprAdapter: No more responses available');
      }
    }

    const item = this.responses[this.index++];
    const response = typeof item === 'string' ? item : item.response;
    const delay = typeof item === 'string' ? 0 : item.delay ?? 0;

    if (delay > 0) {
      await new Promise((resolve) => setTimeout(resolve, delay));
    }

    // Estimate token counts based on content length
    const promptTokens = Math.ceil(request.userContent.length / 4);
    const completionTokens = Math.ceil(response.length / 4);

    this.lastUsage = {
      promptTokens,
      completionTokens,
      totalTokens: promptTokens + completionTokens,
      estimatedCost: this.estimateCost({ promptTokens, completionTokens }, 'scripted'),
    };

    return response;
  }

  getModel(): string {
    return 'scripted';
  }

  /**
   * Reset the response index
   */
  reset(): void {
    this.index = 0;
  }

  /**
   * Get remaining response count
   */
  remainingResponses(): number {
    return Math.max(0, this.responses.length - this.index);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/adapters/types.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Adapter Interface
 *
 * Common interface for LLM adapters used by OprRuntime.
 * Adapters handle the actual LLM API calls.
 */

import type { PromptDoc } from '../../../frameir/prompt';

/**
 * Usage information from an LLM call
 */
export interface LLMUsage {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  estimatedCost: number; // in USD
}

/**
 * Request to send to LLM
 */
export interface OprLLMRequest {
  /** Kernel ID for context */
  kernelId: string;

  /** Compiled prompt (system + few-shot examples) */
  prompt: PromptDoc;

  /** User content (program, state, etc.) */
  userContent: string;

  /** Optional repair context from previous failed attempt */
  repairContext?: string;

  /** Max tokens for response */
  maxTokens?: number;

  /** Temperature (0-1) */
  temperature?: number;
}

/**
 * Interface for LLM adapters
 */
export interface OprLLMAdapter {
  /**
   * Send a completion request to the LLM
   * @returns The raw text response from the LLM
   */
  complete(request: OprLLMRequest): Promise<string>;

  /**
   * Get usage information from the last call (optional)
   */
  getLastUsage?(): LLMUsage;

  /**
   * Get the model identifier
   */
  getModel(): string;

  /**
   * Check if the adapter supports streaming
   */
  supportsStreaming(): boolean;
}

/**
 * Base configuration for all adapters
 */
export interface OprAdapterConfig {
  /** Model to use */
  model: string;

  /** Max tokens for response (default: 2000) */
  maxTokens?: number;

  /** Temperature (default: 0) */
  temperature?: number;

  /** Request timeout in ms (default: 60000) */
  timeout?: number;
}

/**
 * OpenAI-specific configuration
 */
export interface OpenAIAdapterConfig extends OprAdapterConfig {
  apiKey: string;
  baseURL?: string;
  organization?: string;
}

/**
 * Anthropic-specific configuration
 */
export interface AnthropicAdapterConfig extends OprAdapterConfig {
  apiKey: string;
  baseURL?: string;
}

/**
 * Scripted adapter configuration (for testing)
 */
export interface ScriptedAdapterConfig {
  /** Responses to return in sequence */
  responses: Array<string | { response: string; delay?: number }>;

  /** Whether to loop responses or throw on exhaustion */
  loop?: boolean;
}

/**
 * Abstract base class for LLM adapters
 * Provides common functionality like prompt compilation
 */
export abstract class BaseOprAdapter implements OprLLMAdapter {
  protected lastUsage: LLMUsage | null = null;

  abstract complete(request: OprLLMRequest): Promise<string>;
  abstract getModel(): string;

  getLastUsage(): LLMUsage {
    if (!this.lastUsage) {
      return {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
        estimatedCost: 0,
      };
    }
    return this.lastUsage;
  }

  supportsStreaming(): boolean {
    return false;
  }

  /**
   * Format the user message content
   */
  protected formatUserContent(request: OprLLMRequest): string {
    let content = request.userContent;

    if (request.repairContext) {
      content = `${request.repairContext}\n\n---\n\nORIGINAL REQUEST:\n${content}`;
    }

    return content;
  }

  /**
   * Estimate cost based on token usage and model
   */
  protected estimateCost(
    usage: { promptTokens: number; completionTokens: number },
    model: string
  ): number {
    // Rough estimates per 1M tokens
    const pricing: Record<string, { prompt: number; completion: number }> = {
      'gpt-4o': { prompt: 2.5, completion: 10.0 },
      'gpt-4o-mini': { prompt: 0.15, completion: 0.6 },
      'gpt-4-turbo': { prompt: 10.0, completion: 30.0 },
      'claude-3-opus': { prompt: 15.0, completion: 75.0 },
      'claude-3-sonnet': { prompt: 3.0, completion: 15.0 },
      'claude-3-haiku': { prompt: 0.25, completion: 1.25 },
    };

    const prices = pricing[model] ?? { prompt: 1.0, completion: 3.0 };

    return (
      (usage.promptTokens / 1_000_000) * prices.prompt +
      (usage.completionTokens / 1_000_000) * prices.completion
    );
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/hash.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Hash Utilities
 *
 * Deterministic hashing for content-addressed receipts and audit trail integrity.
 */

import { createHash, randomBytes } from 'crypto';
import type { Hash } from './types';

/**
 * Compute SHA-256 hash of content
 * Returns branded Hash type: `sha256:${hex}`
 */
export function sha256Of(content: unknown): Hash {
  const canonical = canonicalJson(content);
  const hash = createHash('sha256').update(canonical).digest('hex');
  return `sha256:${hash}` as Hash;
}

/**
 * Generate a new unique ID (for receipt IDs, etc.)
 */
export function newId(): string {
  return randomBytes(16).toString('hex');
}

/**
 * Canonical JSON serialization for deterministic hashing
 * - Sorts object keys alphabetically
 * - No extra whitespace
 * - Handles undefined by omitting keys
 */
export function canonicalJson(value: unknown): string {
  return JSON.stringify(value, (_, v) => {
    if (v && typeof v === 'object' && !Array.isArray(v)) {
      // Sort object keys
      const sorted: Record<string, unknown> = {};
      for (const key of Object.keys(v).sort()) {
        if (v[key] !== undefined) {
          sorted[key] = v[key];
        }
      }
      return sorted;
    }
    return v;
  });
}

/**
 * Verify a hash matches content
 */
export function verifyHash(content: unknown, expectedHash: Hash): boolean {
  const computed = sha256Of(content);
  return computed === expectedHash;
}

/**
 * Extract the hex portion from a Hash
 */
export function hashToHex(hash: Hash): string {
  return hash.slice(7); // Remove "sha256:" prefix
}

/**
 * Create a Hash from a hex string
 */
export function hexToHash(hex: string): Hash {
  return `sha256:${hex}` as Hash;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from './types';
export * from './validate';
export * from './retry';
export * from './hash';
export * from './receipts';
export * from './runtime';
export * from './adapters';

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/analyze.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Code Analysis Kernel (opr.analyze.v1)
 *
 * Analyzes Lisp/Scheme expressions for structure, complexity, effects.
 * Input: Lisp expression as string
 * Output: Analysis results
 */

import type { KernelPromptConfig } from '../runtime';

export const ANALYZE_KERNEL: KernelPromptConfig = {
  id: 'opr.analyze.v1',
  op: 'analyze',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a CODE ANALYSIS kernel for Lisp/Scheme expressions.

INPUT FORMAT:
{
  "expr": "(define (factorial n) (if (= n 0) 1 (* n (factorial (- n 1)))))",
  "focus": ["complexity", "purity", "tail-recursion"]  // optional
}

ANALYSIS DIMENSIONS:
- complexity: time/space complexity estimate
- purity: pure functional or has effects
- tail-recursion: is it tail-recursive
- bindings: what names are bound/free
- calls: what functions are called
- patterns: recognized idioms (map, fold, recursion, etc.)

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.analyze.v1",
  "op": "analyze",
  "ok": true,
  "result": {
    "complexity": { "time": "O(n)", "space": "O(n)" },
    "purity": { "pure": false, "effects": ["mutation", "io"] },
    "tail_recursive": false,
    "bindings": { "bound": ["n"], "free": ["=", "*", "-"] },
    "calls": ["=", "*", "-", "factorial"],
    "patterns": ["recursion", "conditional"]
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {}
}

Always analyze thoroughly. If an aspect doesn't apply, include it with null.`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/classify.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Classification Kernel (opr.classify.v1)
 *
 * Classifies input into predefined categories.
 * Input: item + categories
 * Output: classification with confidence
 */

import type { KernelPromptConfig } from '../runtime';

export const CLASSIFY_KERNEL: KernelPromptConfig = {
  id: 'opr.classify.v1',
  op: 'classify',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a CLASSIFICATION kernel.

INPUT FORMAT:
{
  "item": "text or data to classify",
  "categories": ["bug", "feature", "question", "docs"],
  "multi_label": false,  // true allows multiple categories
  "context": "optional domain context"
}

CLASSIFICATION RULES:
- Choose from ONLY the provided categories
- If multi_label=false, pick the BEST single category
- Always provide confidence scores
- Explain reasoning for ambiguous cases

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.classify.v1",
  "op": "classify",
  "ok": true,
  "result": {
    "classification": "bug",  // or ["bug", "feature"] if multi_label
    "confidence": 0.87,
    "scores": {
      "bug": 0.87,
      "feature": 0.45,
      "question": 0.12,
      "docs": 0.05
    },
    "reasoning": "Contains stack trace and 'error' keyword"
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "close_call": true,
    "alternative": "feature"
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/codeReview.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Code Review Kernel (opr.review.v1)
 *
 * Reviews code for bugs, style, security, performance.
 * Input: code snippet with language
 * Output: review findings
 */

import type { KernelPromptConfig } from '../runtime';

export const CODE_REVIEW_KERNEL: KernelPromptConfig = {
  id: 'opr.review.v1',
  op: 'review',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a CODE REVIEW kernel.

INPUT FORMAT:
{
  "code": "function foo() { ... }",
  "language": "typescript",
  "focus": ["bugs", "security", "performance", "style"]  // optional
}

REVIEW CATEGORIES:
- bugs: logic errors, null derefs, off-by-one, race conditions
- security: injection, XSS, auth issues, secrets exposure
- performance: N+1, unnecessary allocations, blocking IO
- style: naming, complexity, duplication, readability
- correctness: does it do what it claims

SEVERITY: critical > high > medium > low > info

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.review.v1",
  "op": "review",
  "ok": true,
  "result": {
    "findings": [
      {
        "category": "security",
        "severity": "high",
        "line": 42,
        "code": "eval(userInput)",
        "message": "Code injection vulnerability",
        "suggestion": "Use JSON.parse or a safe parser"
      }
    ],
    "summary": {
      "critical": 0,
      "high": 1,
      "medium": 2,
      "low": 3
    },
    "recommendation": "NEEDS_CHANGES" | "APPROVED" | "DISCUSS"
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {}
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/extract.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Data Extraction Kernel (opr.extract.v1)
 *
 * Extracts structured data from unstructured text.
 * Input: text + schema
 * Output: extracted data matching schema
 */

import type { KernelPromptConfig } from '../runtime';

export const EXTRACT_KERNEL: KernelPromptConfig = {
  id: 'opr.extract.v1',
  op: 'extract',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a DATA EXTRACTION kernel.

INPUT FORMAT:
{
  "text": "unstructured text to extract from",
  "schema": {
    "type": "object",
    "properties": {
      "name": { "type": "string" },
      "date": { "type": "string", "format": "date" },
      "amount": { "type": "number" }
    },
    "required": ["name"]
  }
}

EXTRACTION RULES:
- Extract ALL matching data, not just first occurrence
- Normalize dates, numbers, names consistently
- Mark confidence for each extracted field
- Handle missing data with null, not guesses

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.extract.v1",
  "op": "extract",
  "ok": true,
  "result": {
    "data": {
      "name": "John Smith",
      "date": "2024-01-15",
      "amount": 1500.00
    },
    "confidence": {
      "name": 0.98,
      "date": 0.85,
      "amount": 0.92
    },
    "sources": {
      "name": "line 3: 'From: John Smith'",
      "date": "line 7: 'dated January 15th'",
      "amount": "line 12: '$1,500'"
    }
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "unmatched_fields": ["phone"],
    "ambiguous": ["date could be 2024 or 2023"]
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/index.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Kernel Registry
 *
 * Kernels are prompts that define how an LLM processes structured input.
 * Each kernel specifies:
 *   - Input format (what the "program" looks like)
 *   - Processing rules
 *   - Output schema (the JSON contract)
 */

import type { KernelPromptConfig } from '../runtime';

// Re-export all kernels
export { LOGIC_KERNEL } from './logic';
export { ANALYZE_KERNEL } from './analyze';
export { SEMANTIC_KERNEL } from './semantic';
export { CODE_REVIEW_KERNEL } from './codeReview';
export { TRANSFORM_KERNEL } from './transform';
export { EXTRACT_KERNEL } from './extract';
export { CLASSIFY_KERNEL } from './classify';
export { SYNTHESIZE_KERNEL } from './synthesize';
export { VALIDATE_KERNEL } from './validate';
export { PLAN_KERNEL } from './plan';

// Kernel registry
const kernels = new Map<string, KernelPromptConfig>();

export function registerKernel(config: KernelPromptConfig): void {
  kernels.set(config.id, config);
}

export function getKernel(id: string): KernelPromptConfig | undefined {
  return kernels.get(id);
}

export function listKernels(): string[] {
  return Array.from(kernels.keys());
}

// Auto-register all kernels on import
import { LOGIC_KERNEL } from './logic';
import { ANALYZE_KERNEL } from './analyze';
import { SEMANTIC_KERNEL } from './semantic';
import { CODE_REVIEW_KERNEL } from './codeReview';
import { TRANSFORM_KERNEL } from './transform';
import { EXTRACT_KERNEL } from './extract';
import { CLASSIFY_KERNEL } from './classify';
import { SYNTHESIZE_KERNEL } from './synthesize';
import { VALIDATE_KERNEL } from './validate';
import { PLAN_KERNEL } from './plan';

[
  LOGIC_KERNEL,
  ANALYZE_KERNEL,
  SEMANTIC_KERNEL,
  CODE_REVIEW_KERNEL,
  TRANSFORM_KERNEL,
  EXTRACT_KERNEL,
  CLASSIFY_KERNEL,
  SYNTHESIZE_KERNEL,
  VALIDATE_KERNEL,
  PLAN_KERNEL,
].forEach(registerKernel);

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/logic.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Logic Inference Kernel (opr.logic.v1)
 *
 * Performs forward-chaining inference over horn clauses.
 * Input: rules (horn clauses) + facts
 * Output: newly derived facts
 */

import type { KernelPromptConfig } from '../runtime';

export const LOGIC_KERNEL: KernelPromptConfig = {
  id: 'opr.logic.v1',
  op: 'infer',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a LOGIC INFERENCE kernel implementing forward-chaining deduction.

INPUT FORMAT:
{
  "rules": ["head :- body1, body2", ...],  // Horn clauses
  "facts": ["predicate(args)", ...]         // Ground facts
}

SEMANTICS:
- Rules are horn clauses: "conclusion :- premise1, premise2"
- Variables are UPPERCASE: X, Y, Person
- Constants are lowercase: socrates, 42, true
- Apply all rules whose premises are satisfied by current facts
- Derive new facts by unifying variables with constants

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.logic.v1",
  "op": "infer",
  "ok": true,
  "result": {
    "delta": ["newly derived facts this iteration"]
  },
  "next_state": {
    "iteration": <int>,
    "derived": ["all derived facts so far"],
    "done": <true if delta is empty, false otherwise>
  },
  "effects": [],
  "diagnostics": {
    "rules_applied": ["which rules fired"],
    "bindings": [{"rule": "...", "unifier": {...}}]
  }
}

TERMINATION: Set done=true when no new facts can be derived (fixpoint).`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/plan.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Planning Kernel (opr.plan.v1)
 *
 * Creates execution plans for goals.
 * Input: goal + available actions + constraints
 * Output: step-by-step plan
 */

import type { KernelPromptConfig } from '../runtime';

export const PLAN_KERNEL: KernelPromptConfig = {
  id: 'opr.plan.v1',
  op: 'plan',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a PLANNING kernel implementing goal-directed planning.

INPUT FORMAT:
{
  "goal": "deploy new feature to production",
  "initial_state": {
    "branch": "feature-x",
    "tests": "not_run",
    "reviewed": false
  },
  "actions": [
    { "name": "run_tests", "precond": [], "effect": {"tests": "passed"} },
    { "name": "request_review", "precond": ["tests=passed"], "effect": {"reviewed": true} },
    { "name": "merge", "precond": ["reviewed=true"], "effect": {"branch": "main"} },
    { "name": "deploy", "precond": ["branch=main"], "effect": {"deployed": true} }
  ],
  "constraints": {
    "max_steps": 10,
    "required_actions": ["run_tests"],
    "forbidden_actions": []
  }
}

PLANNING ALGORITHM:
- Work backwards from goal or forwards from initial state
- Ensure all preconditions are met
- Minimize total steps
- Respect all constraints

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.plan.v1",
  "op": "plan",
  "ok": true,
  "result": {
    "plan": [
      { "step": 1, "action": "run_tests", "state_after": {"tests": "passed"} },
      { "step": 2, "action": "request_review", "state_after": {"tests": "passed", "reviewed": true} },
      { "step": 3, "action": "merge", "state_after": {"branch": "main", "reviewed": true} },
      { "step": 4, "action": "deploy", "state_after": {"deployed": true} }
    ],
    "achieves_goal": true,
    "total_steps": 4,
    "critical_path": ["run_tests", "request_review", "merge", "deploy"]
  },
  "next_state": {
    "iteration": 1,
    "plan_complete": true,
    "done": true
  },
  "effects": [],
  "diagnostics": {
    "alternatives_explored": 3,
    "dead_ends": 1
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/semantic.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Semantic Understanding Kernel (opr.semantic.v1)
 *
 * Extracts meaning, intent, and semantics from natural language or code.
 * Input: text or expression
 * Output: semantic representation
 */

import type { KernelPromptConfig } from '../runtime';

export const SEMANTIC_KERNEL: KernelPromptConfig = {
  id: 'opr.semantic.v1',
  op: 'understand',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a SEMANTIC UNDERSTANDING kernel.

INPUT FORMAT:
{
  "text": "string to understand",
  "context": { "domain": "...", "prior": [...] },  // optional
  "mode": "intent" | "entities" | "relations" | "full"
}

SEMANTIC EXTRACTION:
- intent: what action/goal is expressed
- entities: named things (people, places, concepts)
- relations: how entities relate
- presuppositions: what is assumed true
- implications: what follows logically

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.semantic.v1",
  "op": "understand",
  "ok": true,
  "result": {
    "intent": { "action": "query", "target": "weather" },
    "entities": [
      { "text": "tomorrow", "type": "time", "normalized": "2024-01-27" }
    ],
    "relations": [
      { "subject": "weather", "predicate": "at_time", "object": "tomorrow" }
    ],
    "presuppositions": ["speaker wants information"],
    "confidence": 0.92
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "ambiguities": ["word X could mean Y or Z"]
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/synthesize.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Code Synthesis Kernel (opr.synthesize.v1)
 *
 * Generates code from specification/description.
 * Input: specification + constraints
 * Output: generated code
 */

import type { KernelPromptConfig } from '../runtime';

export const SYNTHESIZE_KERNEL: KernelPromptConfig = {
  id: 'opr.synthesize.v1',
  op: 'synthesize',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a CODE SYNTHESIS kernel.

INPUT FORMAT:
{
  "spec": "natural language description of desired code",
  "language": "typescript",
  "signature": "function sortBy<T>(arr: T[], key: keyof T): T[]",  // optional
  "examples": [
    { "input": "[{a:2},{a:1}], 'a'", "output": "[{a:1},{a:2}]" }
  ],
  "constraints": {
    "pure": true,
    "no_mutation": true,
    "max_complexity": "O(n log n)"
  }
}

SYNTHESIS RULES:
- Generate WORKING code that satisfies all examples
- Respect all constraints
- Include type annotations
- Handle edge cases (empty input, null, etc.)

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.synthesize.v1",
  "op": "synthesize",
  "ok": true,
  "result": {
    "code": "function sortBy<T>(arr: T[], key: keyof T): T[] {\\n  return [...arr].sort((a, b) => a[key] > b[key] ? 1 : -1);\\n}",
    "tests_passed": true,
    "complexity": { "time": "O(n log n)", "space": "O(n)" },
    "edge_cases_handled": ["empty array", "single element"]
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "alternatives_considered": ["using localeCompare for strings"],
    "assumptions": ["key values are comparable with >"]
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/transform.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Code Transform Kernel (opr.transform.v1)
 *
 * Transforms code from one form to another.
 * Input: code + transformation spec
 * Output: transformed code
 */

import type { KernelPromptConfig } from '../runtime';

export const TRANSFORM_KERNEL: KernelPromptConfig = {
  id: 'opr.transform.v1',
  op: 'transform',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a CODE TRANSFORM kernel.

INPUT FORMAT:
{
  "code": "source code",
  "from": "javascript",
  "to": "typescript",  // or transformation name
  "options": {
    "strict": true,
    "preserve_comments": true
  }
}

TRANSFORMATIONS:
- Language translation: JS->TS, Python->Rust, etc.
- Refactoring: extract function, inline, rename
- Style: callback->async/await, class->functional
- Optimization: loop unrolling, memoization
- Desugar: macros, syntax sugar

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.transform.v1",
  "op": "transform",
  "ok": true,
  "result": {
    "code": "transformed source code",
    "changes": [
      { "type": "add_type", "line": 1, "description": "Added return type" },
      { "type": "rename", "from": "foo", "to": "processData" }
    ],
    "warnings": ["Possible semantic change at line 42"]
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "confidence": 0.95,
    "manual_review_needed": ["line 42: ambiguous conversion"]
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/kernels/validate.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Validation Kernel (opr.validate.v1)
 *
 * Validates data against rules/schema/constraints.
 * Input: data + validation rules
 * Output: validation results
 */

import type { KernelPromptConfig } from '../runtime';

export const VALIDATE_KERNEL: KernelPromptConfig = {
  id: 'opr.validate.v1',
  op: 'validate',
  prompt: {
    tag: 'PromptDoc',
    v: 'frameir@1',
    parts: [{
      tag: 'PSystem',
      v: 'frameir@1',
      text: `You are a VALIDATION kernel.

INPUT FORMAT:
{
  "data": { ... },  // data to validate
  "rules": [
    { "field": "email", "rule": "email_format" },
    { "field": "age", "rule": "range", "min": 0, "max": 150 },
    { "expr": "start_date < end_date" }
  ],
  "schema": { ... },  // optional JSON schema
  "mode": "strict" | "lenient"
}

VALIDATION TYPES:
- format: email, url, phone, date, uuid
- range: numeric bounds
- pattern: regex match
- required: must exist and not null
- type: string, number, boolean, array, object
- custom: arbitrary expressions

OUTPUT CONTRACT (strict JSON, no markdown):
{
  "kernel": "opr.validate.v1",
  "op": "validate",
  "ok": true,
  "result": {
    "valid": false,
    "errors": [
      {
        "field": "email",
        "rule": "email_format",
        "value": "not-an-email",
        "message": "Invalid email format"
      }
    ],
    "warnings": [
      {
        "field": "phone",
        "message": "Phone number missing country code"
      }
    ],
    "passed": ["age", "name", "start_date"]
  },
  "next_state": null,
  "effects": [],
  "diagnostics": {
    "rules_checked": 5,
    "time_ms": 12
  }
}`
    }]
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/receipts.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Receipt Chain
 *
 * Hash-linked receipt chain for audit trail of all LLM attempts.
 * Each receipt links to the previous, forming a verifiable chain.
 */

import type { OprReceipt, Hash, HashRef, ReceiptId, ReceiptStatus, Diagnostics } from './types';
import { sha256Of, newId } from './hash';

/**
 * Parameters for creating a receipt
 */
export interface CreateReceiptParams {
  prevReceiptHash: HashRef;
  requestHash: Hash;
  responseHash: HashRef;
  kernelId: string;
  op: string;
  attempt: number;
  status: ReceiptStatus;
  errors: string[];
  diagnostics?: Diagnostics;
}

/**
 * Result of chain verification
 */
export interface ChainVerificationResult {
  valid: boolean;
  brokenAt?: number;
  error?: string;
}

/**
 * Interface for receipt storage
 */
export interface ReceiptStore {
  /** Add a receipt to the store */
  add(receipt: OprReceipt): void;

  /** Get all receipts for a kernel */
  getByKernel(kernelId: string): OprReceipt[];

  /** Get all receipts */
  getAll(): OprReceipt[];

  /** Get the last receipt (for chaining) */
  getLast(): OprReceipt | null;

  /** Clear all receipts */
  clear(): void;

  /** Get count */
  count(): number;
}

/**
 * Create a receipt with computed self-hash
 */
export function createReceipt(params: CreateReceiptParams): OprReceipt {
  const receiptWithoutHash: Omit<OprReceipt, 'receipt_hash'> = {
    receipt_version: 1,
    receipt_id: `rct_${newId()}` as ReceiptId,
    created_at: new Date().toISOString(),
    prev_receipt_hash: params.prevReceiptHash,
    request_hash: params.requestHash,
    response_hash: params.responseHash,
    kernel_id: params.kernelId,
    op: params.op,
    attempt: params.attempt,
    status: params.status,
    errors: params.errors,
    diagnostics: params.diagnostics,
  };

  // Compute self-hash
  const receipt_hash = computeReceiptHash(receiptWithoutHash);

  return { ...receiptWithoutHash, receipt_hash };
}

/**
 * Compute hash of a receipt (excluding the receipt_hash field)
 */
function computeReceiptHash(receipt: Omit<OprReceipt, 'receipt_hash'>): Hash {
  return sha256Of(receipt);
}

/**
 * Verify the integrity of a receipt chain
 */
export function verifyReceiptChain(receipts: OprReceipt[]): ChainVerificationResult {
  if (receipts.length === 0) {
    return { valid: true };
  }

  for (let i = 0; i < receipts.length; i++) {
    const receipt = receipts[i];

    // Verify self-hash
    const { receipt_hash: _, ...hashableFields } = receipt;
    const computedHash = sha256Of(hashableFields);
    if (computedHash !== receipt.receipt_hash) {
      return {
        valid: false,
        brokenAt: i,
        error: `Receipt ${i} self-hash mismatch: expected ${receipt.receipt_hash}, computed ${computedHash}`,
      };
    }

    // Verify chain link (except first)
    if (i > 0) {
      const prevReceipt = receipts[i - 1];
      if (receipt.prev_receipt_hash !== prevReceipt.receipt_hash) {
        return {
          valid: false,
          brokenAt: i,
          error: `Receipt ${i} chain link broken: prev_receipt_hash doesn't match previous receipt`,
        };
      }
    } else {
      // First receipt should have null prev_receipt_hash
      if (receipt.prev_receipt_hash !== null) {
        return {
          valid: false,
          brokenAt: 0,
          error: `First receipt should have null prev_receipt_hash`,
        };
      }
    }
  }

  return { valid: true };
}

/**
 * In-memory implementation of ReceiptStore
 */
export class InMemoryReceiptStore implements ReceiptStore {
  private receipts: OprReceipt[] = [];
  private byKernel = new Map<string, OprReceipt[]>();

  add(receipt: OprReceipt): void {
    this.receipts.push(receipt);

    const kernelReceipts = this.byKernel.get(receipt.kernel_id) ?? [];
    kernelReceipts.push(receipt);
    this.byKernel.set(receipt.kernel_id, kernelReceipts);
  }

  getByKernel(kernelId: string): OprReceipt[] {
    return this.byKernel.get(kernelId) ?? [];
  }

  getAll(): OprReceipt[] {
    return [...this.receipts];
  }

  getLast(): OprReceipt | null {
    return this.receipts.length > 0 ? this.receipts[this.receipts.length - 1] : null;
  }

  clear(): void {
    this.receipts = [];
    this.byKernel.clear();
  }

  count(): number {
    return this.receipts.length;
  }
}

/**
 * Fluent builder for creating receipts
 */
export class ReceiptBuilder {
  private store: ReceiptStore;
  private kernelId: string;
  private op: string;

  constructor(store: ReceiptStore, kernelId: string, op: string) {
    this.store = store;
    this.kernelId = kernelId;
    this.op = op;
  }

  /** Create and add a receipt for a successful attempt */
  success(
    attempt: number,
    requestHash: Hash,
    responseHash: Hash,
    diagnostics?: Diagnostics
  ): OprReceipt {
    const receipt = createReceipt({
      prevReceiptHash: this.store.getLast()?.receipt_hash ?? null,
      requestHash,
      responseHash,
      kernelId: this.kernelId,
      op: this.op,
      attempt,
      status: 'OK',
      errors: [],
      diagnostics,
    });
    this.store.add(receipt);
    return receipt;
  }

  /** Create and add a receipt for a failed attempt */
  error(
    attempt: number,
    requestHash: Hash,
    responseHash: HashRef,
    errors: string[]
  ): OprReceipt {
    const receipt = createReceipt({
      prevReceiptHash: this.store.getLast()?.receipt_hash ?? null,
      requestHash,
      responseHash,
      kernelId: this.kernelId,
      op: this.op,
      attempt,
      status: 'ERROR',
      errors,
    });
    this.store.add(receipt);
    return receipt;
  }

  /** Create and add a receipt for a timeout */
  timeout(attempt: number, requestHash: Hash): OprReceipt {
    const receipt = createReceipt({
      prevReceiptHash: this.store.getLast()?.receipt_hash ?? null,
      requestHash,
      responseHash: null,
      kernelId: this.kernelId,
      op: this.op,
      attempt,
      status: 'TIMEOUT',
      errors: ['Request timed out'],
    });
    this.store.add(receipt);
    return receipt;
  }

  /** Create and add a receipt for a callback error */
  callbackError(
    attempt: number,
    requestHash: Hash,
    responseHash: HashRef,
    errors: string[]
  ): OprReceipt {
    const receipt = createReceipt({
      prevReceiptHash: this.store.getLast()?.receipt_hash ?? null,
      requestHash,
      responseHash,
      kernelId: this.kernelId,
      op: this.op,
      attempt,
      status: 'CALLBACK_ERROR',
      errors,
    });
    this.store.add(receipt);
    return receipt;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/retry.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ValidationViolation } from './types';

/**
 * Build a repair prompt from validation violations
 * This becomes the "counterexample" that guides the LLM to fix its output
 */
export function buildRepairPrompt(violations: ValidationViolation[]): string {
  const lines: string[] = [
    'YOUR PREVIOUS RESPONSE HAD VALIDATION ERRORS.',
    '',
    'VIOLATIONS:',
  ];

  for (const v of violations) {
    lines.push(`  - Path: ${v.path}`);
    lines.push(`    Code: ${v.code}`);
    lines.push(`    Error: ${v.message}`);
    if (v.expected) {
      lines.push(`    Expected: ${v.expected}`);
    }
    if (v.actual) {
      lines.push(`    Got: ${v.actual}`);
    }
    lines.push('');
  }

  lines.push('INSTRUCTIONS:');
  lines.push('1. Fix ALL violations listed above');
  lines.push('2. Return ONLY valid JSON matching the OUTPUT CONTRACT');
  lines.push('3. Do NOT include markdown code blocks');
  lines.push('4. Do NOT include any explanation or preamble');
  lines.push('');
  lines.push('Return the corrected JSON response now:');

  return lines.join('\n');
}

/**
 * Decide whether to retry based on violation type
 */
export function shouldRetry(violations: ValidationViolation[]): boolean {
  // Don't retry on kernel/op mismatch - indicates fundamental confusion
  const hasCriticalViolation = violations.some(v =>
    v.code === 'KERNEL_MISMATCH' || v.code === 'OP_MISMATCH'
  );

  if (hasCriticalViolation) {
    return false;
  }

  // Retry on fixable violations
  const fixableCodes: Set<string> = new Set([
    'NOT_JSON',
    'NOT_OBJECT',
    'MISSING_FIELD',
    'WRONG_TYPE',
    'INVALID_VALUE',
  ]);

  return violations.every(v => fixableCodes.has(v.code));
}

/**
 * Format violations for human-readable display
 */
export function formatViolationsForDisplay(violations: ValidationViolation[]): string {
  return violations.map(v => {
    let line = `[${v.code}] ${v.path}: ${v.message}`;
    if (v.expected && v.actual) {
      line += ` (expected ${v.expected}, got ${v.actual})`;
    }
    return line;
  }).join('\n');
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/runtime.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR Runtime
 *
 * The main execution engine for OPR kernel operations.
 * Handles validation, retry with counterexample feedback, and receipt generation.
 */

import type {
  OprStepResult,
  OprStepResultOk,
  OprStepResultBudgetExhausted,
  KernelOutput,
  KernelState,
  OprBudgetConfig,
  ProgressInvariants,
  ValidationViolation,
  Hash,
  OprReceipt,
} from './types';
import { OprBudgetExhaustedError } from './types';
import type { OprLLMAdapter, OprLLMRequest } from './adapters/types';
import type { ReceiptStore } from './receipts';
import { ReceiptBuilder } from './receipts';
import { validateKernelOutput, checkProgressInvariants } from './validate';
import { buildRepairPrompt } from './retry';
import { sha256Of } from './hash';
import type { PromptDoc } from '../../frameir/prompt';

/**
 * Kernel prompt configuration
 */
export interface KernelPromptConfig {
  /** Unique kernel identifier */
  id: string;

  /** Compiled prompt document */
  prompt: PromptDoc;

  /** Operation name (default: 'step') */
  op?: string;
}

/**
 * Session budget interface (optional)
 */
export interface SessionBudget {
  hasRemaining(type: 'tokens' | 'cost'): boolean;
  consumeTokens(tokens: number): void;
  consumeCost(cost: number): void;
}

/**
 * OPR Runtime configuration
 */
export interface OprRuntimeConfig {
  /** Kernel configuration with prompt and capabilities */
  kernel: KernelPromptConfig;

  /** LLM adapter for making calls */
  adapter: OprLLMAdapter;

  /** Receipt storage */
  receipts: ReceiptStore;

  /** Budget configuration */
  budget: OprBudgetConfig;

  /** Progress invariants to enforce (optional) */
  invariants?: ProgressInvariants;

  /** Session budget (optional) */
  sessionBudget?: SessionBudget;
}

/**
 * Parameters for executing a step
 */
export interface OprExecuteParams {
  /** Program/data to pass to kernel */
  program: unknown;

  /** Current state (null for first step, memento from previous step) */
  state: unknown | null;
}

/**
 * Internal request type
 */
export interface OprRequest {
  kernelId: string;
  prompt: PromptDoc;
  program: unknown;
  state: unknown | null;
  repairContext: string | null;
}

/**
 * Run result types
 */
export interface OprRunResultOk {
  tag: 'ok';
  results: OprStepResultOk[];
  finalState: KernelState | null;
  iterations: number;
  receipts: OprReceipt[];
}

export interface OprRunResultError {
  tag: 'error';
  error: OprStepResult;
  iterations: number;
  receipts: OprReceipt[];
}

export interface OprRunResultMaxIterations {
  tag: 'max-iterations';
  results: OprStepResultOk[];
  iterations: number;
  receipts: OprReceipt[];
}

export type OprRunResult = OprRunResultOk | OprRunResultError | OprRunResultMaxIterations;

interface ExtractOk {
  ok: true;
  json: unknown;
}

interface ExtractError {
  ok: false;
  error: string;
}

type ExtractResult = ExtractOk | ExtractError;

/**
 * Extract JSON object from LLM response
 * Handles markdown code blocks and extra text
 */
function extractJsonObject(response: string): ExtractResult {
  // Try to find JSON in code blocks first
  const codeBlockMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/);
  const content = codeBlockMatch ? codeBlockMatch[1].trim() : response.trim();

  // Find the first { and matching }
  const start = content.indexOf('{');
  if (start === -1) {
    return { ok: false, error: 'No JSON object found in response' } as ExtractError;
  }

  let depth = 0;
  let end = -1;
  for (let i = start; i < content.length; i++) {
    if (content[i] === '{') depth++;
    else if (content[i] === '}') {
      depth--;
      if (depth === 0) {
        end = i;
        break;
      }
    }
  }

  if (end === -1) {
    return { ok: false, error: 'Unbalanced braces in JSON' } as ExtractError;
  }

  const jsonStr = content.slice(start, end + 1);
  try {
    const json = JSON.parse(jsonStr);
    return { ok: true, json } as ExtractOk;
  } catch (e) {
    return { ok: false, error: `Invalid JSON: ${(e as Error).message}` } as ExtractError;
  }
}

/**
 * OPR Runtime - the main execution engine
 */
export class OprRuntime {
  private config: OprRuntimeConfig;
  private receiptBuilder: ReceiptBuilder;

  constructor(config: OprRuntimeConfig) {
    this.config = config;
    this.receiptBuilder = new ReceiptBuilder(
      config.receipts,
      config.kernel.id,
      config.kernel.op ?? 'step'
    );
  }

  /**
   * Execute a single kernel step with validation and retry
   */
  async step(params: OprExecuteParams): Promise<OprStepResult> {
    const { kernel, adapter, budget, invariants, sessionBudget } = this.config;
    const { maxAttempts } = budget;

    let lastViolations: ValidationViolation[] = [];
    let repairContext: string | null = null;

    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
      // Check session budget (if provided)
      if (sessionBudget) {
        if (!sessionBudget.hasRemaining('tokens')) {
          return this.makeBudgetExhaustedResult('session-tokens', attempt, lastViolations);
        }
        if (!sessionBudget.hasRemaining('cost')) {
          return this.makeBudgetExhaustedResult('session-cost', attempt, lastViolations);
        }
      }

      // Build request
      const userContent = this.formatUserContent(params, repairContext);
      const request: OprLLMRequest = {
        kernelId: kernel.id,
        prompt: kernel.prompt,
        userContent,
        repairContext: repairContext ?? undefined,
      };
      const requestHash = sha256Of(request);

      // Call LLM
      let response: string;
      try {
        response = await adapter.complete(request);
      } catch (e) {
        // Record timeout/error receipt
        this.receiptBuilder.timeout(attempt, requestHash);
        continue;
      }

      const responseHash = sha256Of(response);

      // Consume session budget (if provided)
      if (sessionBudget && adapter.getLastUsage) {
        const usage = adapter.getLastUsage();
        sessionBudget.consumeTokens(usage.totalTokens);
        sessionBudget.consumeCost(usage.estimatedCost);
      }

      // Extract JSON from response (handles markdown code blocks, etc.)
      const extracted = extractJsonObject(response);
      if (extracted.ok === false) {
        const errorMsg = (extracted as ExtractError).error;
        lastViolations = [
          {
            path: '$',
            code: 'NOT_JSON',
            message: errorMsg,
          },
        ];
        this.receiptBuilder.error(attempt, requestHash, responseHash, [errorMsg]);
        repairContext = buildRepairPrompt(lastViolations);
        continue;
      }

      // Validate response
      const validation = validateKernelOutput(JSON.stringify(extracted.json), {
        kernelId: kernel.id,
        op: kernel.op ?? 'step',
      });

      if (!validation.ok) {
        lastViolations = validation.violations;
        this.receiptBuilder.error(
          attempt,
          requestHash,
          responseHash,
          validation.violations.map((v) => v.message)
        );
        repairContext = buildRepairPrompt(validation.violations);
        continue;
      }

      const output = validation.parsed as KernelOutput;

      // Check progress invariants (if configured and we have previous state)
      if (invariants && params.state !== null && output.next_state !== null) {
        const invariantViolations = checkProgressInvariants(
          params.state as KernelState,
          output.next_state,
          invariants
        );
        if (invariantViolations.length > 0) {
          lastViolations = invariantViolations;
          this.receiptBuilder.error(
            attempt,
            requestHash,
            responseHash,
            invariantViolations.map((v) => v.message)
          );
          repairContext = buildRepairPrompt(invariantViolations);
          continue;
        }
      }

      // Success!
      this.receiptBuilder.success(attempt, requestHash, responseHash, output.diagnostics);

      return {
        tag: 'ok',
        ok: true,
        output,
        attempts: attempt,
        receipts: this.config.receipts.getAll(),
      };
    }

    // Exhausted local budget
    return this.makeBudgetExhaustedResult('attempts', maxAttempts, lastViolations);
  }

  /**
   * Run kernel to fixpoint (until next_state.done = true or null)
   */
  async runToFixpoint(params: OprExecuteParams): Promise<OprRunResult> {
    const results: OprStepResultOk[] = [];
    let currentState = params.state;
    let iterations = 0;
    const maxIterations = 100; // Safety limit

    while (iterations < maxIterations) {
      const result = await this.step({ program: params.program, state: currentState });

      if (result.tag !== 'ok') {
        return {
          tag: 'error',
          error: result,
          iterations,
          receipts: this.config.receipts.getAll(),
        };
      }

      results.push(result);
      iterations++;

      // Check termination
      const nextState = result.output.next_state;
      if (nextState === null || nextState.done === true) {
        return {
          tag: 'ok',
          results,
          finalState: nextState,
          iterations,
          receipts: this.config.receipts.getAll(),
        };
      }

      currentState = nextState;
    }

    // Max iterations reached
    return {
      tag: 'max-iterations',
      results,
      iterations,
      receipts: this.config.receipts.getAll(),
    };
  }

  /**
   * Format user content for the LLM request
   */
  private formatUserContent(params: OprExecuteParams, repairContext: string | null): string {
    const parts: string[] = [];

    if (repairContext) {
      parts.push(repairContext);
      parts.push('\n---\n');
    }

    parts.push('PROGRAM:');
    parts.push(JSON.stringify(params.program, null, 2));

    if (params.state !== null) {
      parts.push('\nCURRENT STATE:');
      parts.push(JSON.stringify(params.state, null, 2));
    }

    return parts.join('\n');
  }

  private makeBudgetExhaustedResult(
    budgetType: 'attempts' | 'session-tokens' | 'session-cost',
    attempts: number,
    lastViolations: ValidationViolation[]
  ): OprStepResultBudgetExhausted {
    return {
      tag: 'budget-exhausted',
      ok: false,
      error: new OprBudgetExhaustedError(`Budget exhausted: ${budgetType}`, budgetType),
      attempts,
      receipts: this.config.receipts.getAll(),
    };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/types.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * ΩPR Type System
 */

// Kernel Output Contract
export interface KernelState {
  iteration?: number;
  facts?: string[];
  derived?: string[];
  done?: boolean;
  [key: string]: unknown;
}

export interface Diagnostics {
  invariants_checked?: string[];
  notes?: string[];
  errors?: string[];
}

export interface KernelOutput {
  kernel: string;
  op: string;
  ok: boolean;
  result: unknown;
  next_state: KernelState | null;
  effects: Effect[];
  diagnostics: Diagnostics;
}

// Effect Types
export type EffectType =
  | 'callback.eval_lisp'
  | 'callback.artifact.get'
  | 'callback.facts.query'
  | 'callback.hash';

export interface Precondition {
  type: 'fact_exists' | 'artifact_exists' | 'capability_held';
  value: unknown;
}

export interface Effect {
  type: EffectType;
  idempotency_key: string;
  correlation_id?: string;
  payload: unknown;
  preconditions?: Precondition[];
}

// Validation Types
export type ViolationCode =
  | 'NOT_JSON'
  | 'NOT_OBJECT'
  | 'MISSING_FIELD'
  | 'WRONG_TYPE'
  | 'INVALID_VALUE'
  | 'KERNEL_MISMATCH'
  | 'OP_MISMATCH';

export interface ValidationViolation {
  path: string;
  code: ViolationCode;
  message: string;
  expected?: string;
  actual?: string;
}

export interface ValidationResult {
  ok: boolean;
  parsed?: unknown;
  violations: ValidationViolation[];
}

// Receipt Types
export type Hash = `sha256:${string}`;
export type ReceiptId = `rct_${string}`;
export type EffectReceiptId = `effr_${string}`;
export type HashRef = Hash | null;
export type ReceiptStatus = 'OK' | 'ERROR' | 'TIMEOUT' | 'CALLBACK_ERROR';

export interface OprReceipt {
  receipt_version: 1;
  receipt_id: ReceiptId;
  created_at: string;
  prev_receipt_hash: HashRef;
  request_hash: Hash;
  response_hash: HashRef;
  kernel_id: string;
  op: string;
  attempt: number;
  status: ReceiptStatus;
  errors: string[];
  diagnostics?: Diagnostics;
  receipt_hash: Hash;
}

// Callback and Capabilities Types
export interface CallbackResult {
  correlation_id: string;
  ok: boolean;
  value?: unknown;
  error?: {
    code: string;
    message: string;
  };
}

export interface OprCapabilities {
  allowedCallbacks: Set<EffectType>;
  maxCallbacksPerStep: number;
  callbackTimeout: number;
}

// Budget Types
export interface OprBudgetConfig {
  maxAttempts: number;
  sessionBudget?: unknown;
}

// Progress Invariants
export interface ProgressInvariants {
  iterationMonotonic: boolean;
  derivedMonotonic: boolean;
  deltaTermination: boolean;
}

// Error Classes
export class OprError extends Error {
  constructor(message: string, public readonly code: string) {
    super(message);
    this.name = 'OprError';
  }
}

export class OprValidationError extends OprError {
  constructor(
    message: string,
    public readonly violations: ValidationViolation[]
  ) {
    super(message, 'VALIDATION_FAILED');
    this.name = 'OprValidationError';
  }
}

export class OprBudgetExhaustedError extends OprError {
  constructor(
    message: string,
    public readonly budgetType: 'attempts' | 'session-tokens' | 'session-cost'
  ) {
    super(message, 'BUDGET_EXHAUSTED');
    this.name = 'OprBudgetExhaustedError';
  }
}

export class OprCapabilityError extends OprError {
  constructor(
    message: string,
    public readonly requestedCapability: string
  ) {
    super(message, 'CAPABILITY_VIOLATION');
    this.name = 'OprCapabilityError';
  }
}

// Step Result - Discriminated Union
export interface OprStepResultBase {
  attempts: number;
  receipts: OprReceipt[];
}

export interface OprStepResultOk extends OprStepResultBase {
  tag: 'ok';
  ok: true;
  output: KernelOutput;
}

export interface OprStepResultBudgetExhausted extends OprStepResultBase {
  tag: 'budget-exhausted';
  ok: false;
  error: OprBudgetExhaustedError;
  lastOutput?: KernelOutput;
}

export interface OprStepResultValidationFailed extends OprStepResultBase {
  tag: 'validation-failed';
  ok: false;
  error: OprValidationError;
  violations: ValidationViolation[];
}

export interface OprStepResultCapabilityViolation extends OprStepResultBase {
  tag: 'capability-violation';
  ok: false;
  error: OprCapabilityError;
  requestedCapability: string;
}

export type OprStepResult =
  | OprStepResultOk
  | OprStepResultBudgetExhausted
  | OprStepResultValidationFailed
  | OprStepResultCapabilityViolation;

// Type Guards
export function isOprStepResultOk(r: OprStepResult): r is OprStepResultOk {
  return r.tag === 'ok';
}

export function isOprStepResultBudgetExhausted(
  r: OprStepResult
): r is OprStepResultBudgetExhausted {
  return r.tag === 'budget-exhausted';
}

export function isOprStepResultValidationFailed(
  r: OprStepResult
): r is OprStepResultValidationFailed {
  return r.tag === 'validation-failed';
}

export function isOprStepResultCapabilityViolation(
  r: OprStepResult
): r is OprStepResultCapabilityViolation {
  return r.tag === 'capability-violation';
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/opr/validate.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * ΩPR Validation Pipeline
 *
 * Single-parse validation that returns structured violations usable for
 * counterexample-guided retry.
 */

import type {
  ValidationResult,
  ValidationViolation,
  KernelState,
  ProgressInvariants,
} from './types';

/**
 * Validates kernel output JSON response.
 *
 * Performs single-parse validation, reusing the parsed result for repair prompts.
 *
 * @param raw - Raw JSON string from kernel
 * @param expected - Expected kernel ID and operation for security validation
 * @returns ValidationResult with structured violations
 */
export function validateKernelOutput(
  raw: string,
  expected: { kernelId: string; op: string }
): ValidationResult {
  const violations: ValidationViolation[] = [];

  // 1. Parse JSON (single parse, reuse result)
  let parsed: unknown;
  try {
    parsed = JSON.parse(raw);
  } catch (e) {
    return {
      ok: false,
      violations: [
        {
          path: '$',
          code: 'NOT_JSON',
          message: `Invalid JSON: ${(e as Error).message}`,
        },
      ],
    };
  }

  // 2. Must be object
  if (typeof parsed !== 'object' || parsed === null || Array.isArray(parsed)) {
    return {
      ok: false,
      parsed,
      violations: [
        {
          path: '$',
          code: 'NOT_OBJECT',
          message: 'Response must be a JSON object',
          expected: 'object',
          actual: Array.isArray(parsed) ? 'array' : typeof parsed,
        },
      ],
    };
  }

  const obj = parsed as Record<string, unknown>;

  // 3. Required fields
  const required = ['kernel', 'op', 'ok', 'result', 'next_state', 'effects', 'diagnostics'];
  for (const field of required) {
    if (!(field in obj)) {
      violations.push({
        path: `$.${field}`,
        code: 'MISSING_FIELD',
        message: `Missing required field: ${field}`,
      });
    }
  }

  // Continue validation only if we have the basic structure
  if (violations.length > 0) {
    return { ok: false, parsed, violations };
  }

  // 4. Type checks
  validateFieldType(obj, 'kernel', 'string', violations);
  validateFieldType(obj, 'op', 'string', violations);
  validateFieldType(obj, 'ok', 'boolean', violations);

  // 5. Kernel/op match (critical for security)
  if (obj.kernel !== expected.kernelId) {
    violations.push({
      path: '$.kernel',
      code: 'KERNEL_MISMATCH',
      message: `Expected kernel "${expected.kernelId}", got "${obj.kernel}"`,
      expected: expected.kernelId,
      actual: String(obj.kernel),
    });
  }

  if (obj.op !== expected.op) {
    violations.push({
      path: '$.op',
      code: 'OP_MISMATCH',
      message: `Expected op "${expected.op}", got "${obj.op}"`,
      expected: expected.op,
      actual: String(obj.op),
    });
  }

  // 6. Effects array validation
  if ('effects' in obj) {
    if (!Array.isArray(obj.effects)) {
      violations.push({
        path: '$.effects',
        code: 'WRONG_TYPE',
        message: 'effects must be an array',
        expected: 'array',
        actual: typeof obj.effects,
      });
    } else {
      validateEffectsArray(obj.effects, violations);
    }
  }

  // 7. next_state must be object or null
  if ('next_state' in obj && obj.next_state !== null && typeof obj.next_state !== 'object') {
    violations.push({
      path: '$.next_state',
      code: 'WRONG_TYPE',
      message: 'next_state must be object or null',
      expected: 'object | null',
      actual: typeof obj.next_state,
    });
  }

  return {
    ok: violations.length === 0,
    parsed,
    violations,
  };
}

/**
 * Validates a field type within an object.
 *
 * @param obj - Object to validate
 * @param field - Field name
 * @param expectedType - Expected typeof result
 * @param violations - Array to accumulate violations
 */
export function validateFieldType(
  obj: Record<string, unknown>,
  field: string,
  expectedType: string,
  violations: ValidationViolation[]
): void {
  if (field in obj && typeof obj[field] !== expectedType) {
    violations.push({
      path: `$.${field}`,
      code: 'WRONG_TYPE',
      message: `${field} must be a ${expectedType}`,
      expected: expectedType,
      actual: typeof obj[field],
    });
  }
}

/**
 * Validates an array of effects.
 *
 * Each effect must have:
 * - type: string (effect type)
 * - idempotency_key: string (for deduplication)
 *
 * @param effects - Array of effects to validate
 * @param violations - Array to accumulate violations
 */
export function validateEffectsArray(
  effects: unknown[],
  violations: ValidationViolation[]
): void {
  for (let i = 0; i < effects.length; i++) {
    const effect = effects[i];
    if (typeof effect !== 'object' || effect === null) {
      violations.push({
        path: `$.effects[${i}]`,
        code: 'WRONG_TYPE',
        message: `Effect at index ${i} must be an object`,
        expected: 'object',
        actual: typeof effect,
      });
      continue;
    }

    const e = effect as Record<string, unknown>;

    // Required effect fields
    if (!('type' in e) || typeof e.type !== 'string') {
      violations.push({
        path: `$.effects[${i}].type`,
        code: 'MISSING_FIELD',
        message: `Effect at index ${i} missing required field: type`,
      });
    }

    if (!('idempotency_key' in e) || typeof e.idempotency_key !== 'string') {
      violations.push({
        path: `$.effects[${i}].idempotency_key`,
        code: 'MISSING_FIELD',
        message: `Effect at index ${i} missing required field: idempotency_key`,
      });
    }
  }
}

/**
 * Checks progress invariants between state transitions.
 *
 * Enforces monotonicity properties when enabled:
 * - iterationMonotonic: iteration number must increase
 * - derivedMonotonic: derived facts can only grow
 *
 * @param prevState - Previous kernel state (null if initial)
 * @param nextState - Next kernel state
 * @param invariants - Progress invariant configuration
 * @returns Array of violations
 */
export function checkProgressInvariants(
  prevState: KernelState | null,
  nextState: KernelState,
  invariants: ProgressInvariants
): ValidationViolation[] {
  const violations: ValidationViolation[] = [];

  if (prevState === null) return violations;

  if (invariants.iterationMonotonic) {
    const prevIter = prevState.iteration ?? 0;
    const nextIter = nextState.iteration ?? 0;
    if (nextIter <= prevIter) {
      violations.push({
        path: '$.next_state.iteration',
        code: 'INVALID_VALUE',
        message: `Iteration must increase: ${prevIter} -> ${nextIter}`,
      });
    }
  }

  if (invariants.derivedMonotonic) {
    const prevCount = prevState.derived?.length ?? 0;
    const nextCount = nextState.derived?.length ?? 0;
    if (nextCount < prevCount) {
      violations.push({
        path: '$.next_state.derived',
        code: 'INVALID_VALUE',
        message: `Derived facts must grow monotonically: ${prevCount} -> ${nextCount}`,
      });
    }
  }

  return violations;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapter.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapter.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md

import type { Val } from "../eval/values";
import type { EnvRef, StateRef, OracleSession } from "./protocol";

export type OracleInit =
  | { tag: "Infer"; payload: Val; envRef: EnvRef; stateRef: StateRef; policyDigest?: string }
  | { tag: "Apply"; proc: Val; args: Val[]; envRef: EnvRef; stateRef: StateRef; policyDigest?: string };

export type InferInit = Extract<OracleInit, { tag: "Infer" }>;
export type ApplyInit = Extract<OracleInit, { tag: "Apply" }>;

export interface OracleAdapter {
  startSession(init: OracleInit): OracleSession;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapters/anthropicAdapter.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapters/anthropicAdapter.ts
// Anthropic Claude adapter with native tool calling
// Supports both streaming and blocking modes

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, Meaning, QExpr, ObserveSpec } from "../protocol";
import type { Val } from "../../eval/values";
import type { LLMConfig, AdapterCaps, OracleAdapterWithCaps, ToolDef } from "./types";
import { meaning } from "../meaning";

// ═══════════════════════════════════════════════════════════════════════════
// TOOL DEFINITIONS
// ═══════════════════════════════════════════════════════════════════════════

const ORACLE_TOOLS: ToolDef[] = [
  {
    name: "eval",
    description: "Evaluate a Lisp expression in the current environment. Returns the result value.",
    parameters: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Lisp expression to evaluate (e.g., '(+ 1 2)')" },
      },
      required: ["expr"],
    },
  },
  {
    name: "apply",
    description: "Apply a function to arguments",
    parameters: {
      type: "object",
      properties: {
        fn: { type: "string", description: "Function name or expression" },
        args: { type: "array", items: { type: "string" }, description: "Arguments" },
      },
      required: ["fn", "args"],
    },
  },
  {
    name: "observe",
    description: "Observe runtime state (stack, control, handlers, store)",
    parameters: {
      type: "object",
      properties: {
        what: {
          type: "string",
          enum: ["stack", "control", "handlers", "store", "env", "defs"],
          description: "What to observe",
        },
      },
      required: ["what"],
    },
  },
  {
    name: "match",
    description: "Match an expression against a pattern with ?x binders",
    parameters: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Expression to match" },
        pattern: { type: "string", description: "Pattern with ?x binders" },
      },
      required: ["expr", "pattern"],
    },
  },
  {
    name: "assert",
    description: "Assert a condition - useful for validation",
    parameters: {
      type: "object",
      properties: {
        predicate: { type: "string", description: "Predicate expression" },
        msg: { type: "string", description: "Error message if false" },
      },
      required: ["predicate", "msg"],
    },
  },
  {
    name: "return",
    description: "Return a final result and end the session. Call this when you have computed the answer.",
    parameters: {
      type: "object",
      properties: {
        value: { type: "string", description: "Value to return (as Lisp literal)" },
        confidence: { type: "number", description: "Confidence 0-1" },
      },
      required: ["value"],
    },
  },
];

// Convert to Anthropic tool format
function toAnthropicTools(): any[] {
  return ORACLE_TOOLS.map(t => ({
    name: t.name,
    description: t.description,
    input_schema: t.parameters,
  }));
}

// ═══════════════════════════════════════════════════════════════════════════
// HELPERS
// ═══════════════════════════════════════════════════════════════════════════

function parseValLiteral(s: string): Val {
  s = s.trim();
  if (s === "#t" || s === "true") return { tag: "Bool", b: true };
  if (s === "#f" || s === "false") return { tag: "Bool", b: false };
  if (s === "()" || s === "unit" || s === "null") return { tag: "Unit" };
  if (/^-?\d+(\.\d+)?$/.test(s)) return { tag: "Num", n: parseFloat(s) };
  if (s.startsWith('"') && s.endsWith('"')) return { tag: "Str", s: s.slice(1, -1) };
  if (s.startsWith("'")) return { tag: "Sym", name: s.slice(1) };
  return { tag: "Str", s };
}

function formatVal(v: Val): string {
  switch (v.tag) {
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Str": return v.s;
    case "Sym": return v.name;
    case "Unit": return "()";
    case "Vector": return `[${v.items.map(formatVal).join(" ")}]`;
    case "Closure": return `<closure>`;
    case "Native": return `<native ${v.name}>`;
    default: return JSON.stringify(v);
  }
}

function parseObserveSpec(what: string): ObserveSpec {
  switch (what.toLowerCase()) {
    case "stack": return { tag: "Stack", limit: 10 };
    case "control": return { tag: "Control" };
    case "handlers": return { tag: "Handlers" };
    case "store": return { tag: "StoreSummary", maxCells: 50 };
    case "env": return { tag: "Env" };
    case "defs": return { tag: "Defs" };
    default: return { tag: "Control" };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// STREAMING HELPERS
// ═══════════════════════════════════════════════════════════════════════════

type StreamingToolUse = {
  id: string;
  name: string;
  input: string;  // JSON string accumulated from deltas
};

type StreamingState = {
  textContent: string;
  toolUses: Map<number, StreamingToolUse>;
  currentToolIndex: number;
};

/**
 * Parse SSE stream from Anthropic API
 */
async function* parseAnthropicSSE(response: Response): AsyncGenerator<any> {
  const reader = response.body!.getReader();
  const decoder = new TextDecoder();
  let buffer = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split("\n");
    buffer = lines.pop() || "";

    for (const line of lines) {
      const trimmed = line.trim();
      if (!trimmed.startsWith("data: ")) continue;
      const data = trimmed.slice(6);
      if (data === "[DONE]") return;

      try {
        yield JSON.parse(data);
      } catch {
        // Skip malformed JSON
      }
    }
  }
}

/**
 * Process Anthropic streaming event
 */
function processStreamEvent(state: StreamingState, event: any): void {
  switch (event.type) {
    case "content_block_start":
      if (event.content_block?.type === "tool_use") {
        state.currentToolIndex = event.index;
        state.toolUses.set(event.index, {
          id: event.content_block.id,
          name: event.content_block.name,
          input: "",
        });
      }
      break;

    case "content_block_delta":
      if (event.delta?.type === "text_delta") {
        state.textContent += event.delta.text || "";
      } else if (event.delta?.type === "input_json_delta") {
        const tool = state.toolUses.get(event.index);
        if (tool) {
          tool.input += event.delta.partial_json || "";
        }
      }
      break;

    case "message_stop":
      // Message complete
      break;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// TOOL CALL PROCESSING
// ═══════════════════════════════════════════════════════════════════════════

type ToolCallResult =
  | { done: false; toolResults: any[] }
  | { done: true; meaning: Meaning };

async function* processToolCalls(
  toolUses: { id: string; name: string; input: any }[],
  init: OracleInit,
  model: string,
  turn: number
): AsyncGenerator<OracleReq, ToolCallResult, OracleResp> {
  const toolResults: any[] = [];

  for (const tc of toolUses) {
    const toolArgs = tc.input;
    let req: OracleReq;
    let resp: OracleResp;
    let resultContent: string;

    switch (tc.name) {
      case "eval":
        req = {
          tag: "ReqEval",
          qexpr: toolArgs.expr as string as unknown as QExpr,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespVal") {
          resultContent = formatVal(resp.value);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "apply":
        const fnVal = parseValLiteral(toolArgs.fn);
        const argsVals = (toolArgs.args as string[]).map(parseValLiteral);
        req = {
          tag: "ReqApply",
          fn: fnVal,
          args: argsVals,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespVal") {
          resultContent = formatVal(resp.value);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "observe":
        req = {
          tag: "ReqObserve",
          what: parseObserveSpec(toolArgs.what),
          stateRef: init.stateRef,
        };
        resp = yield req;
        if (resp.tag === "RespObs") {
          resultContent = JSON.stringify(resp.data, null, 2);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "match":
        req = {
          tag: "ReqMatch",
          qexpr: toolArgs.expr as string as unknown as QExpr,
          pattern: toolArgs.pattern as string as unknown as QExpr,
          envRef: init.envRef,
        };
        resp = yield req;
        resultContent = JSON.stringify(resp);
        break;

      case "assert":
        req = {
          tag: "ReqAssert",
          predicate: toolArgs.predicate as string as unknown as QExpr,
          msg: toolArgs.msg,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespAck") {
          resultContent = "Assertion passed";
        } else if (resp.tag === "RespError") {
          resultContent = `Assertion failed: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "return":
        const retVal = parseValLiteral(toolArgs.value);
        const confidence = toolArgs.confidence ?? 0.9;
        return {
          done: true,
          meaning: meaning({
            denotation: retVal,
            confidence,
            trace: { tag: "Str", s: `adapter=anthropic model=${model} turns=${turn + 1}` },
          }),
        };

      default:
        resultContent = `Unknown tool: ${tc.name}`;
    }

    toolResults.push({
      type: "tool_result",
      tool_use_id: tc.id,
      content: resultContent!,
    });
  }

  return { done: false, toolResults };
}

// ═══════════════════════════════════════════════════════════════════════════
// ANTHROPIC ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Anthropic Claude adapter with native tool calling
 * Supports both streaming and blocking modes via config.streaming
 */
export class AnthropicAdapter implements OracleAdapterWithCaps {
  constructor(private config: LLMConfig) {}

  capabilities(): AdapterCaps {
    return {
      multiTurn: true,
      toolCalling: true,
      mcp: false,
      streaming: true,
      vision: true,
      maxContext: 200_000,  // Claude 3.5 Sonnet / Claude 4
    };
  }

  startSession(init: OracleInit): OracleSession {
    if (this.config.streaming) {
      return this.startStreamingSession(init);
    } else {
      return this.startBlockingSession(init);
    }
  }

  // ─────────────────────────────────────────────────────────────────────────
  // STREAMING MODE
  // ─────────────────────────────────────────────────────────────────────────

  private startStreamingSession(init: OracleInit): OracleSession {
    const config = this.config;
    const tools = toAnthropicTools();

    return (async function* (): OracleSession {
      const systemPrompt = config.systemPrompt ?? `You are an Oracle for a Lisp runtime.

CRITICAL: You MUST use the 'return' tool to provide your final answer. Do NOT write text answers directly.

For simple questions (yes/no, factual answers):
- Call the 'return' tool immediately with your answer

For computation requiring Lisp:
- Use 'eval' tool first, then 'return' tool with the result

You have these tools:
- return(value): Provide your final answer (REQUIRED)
- eval(expr): Run Lisp code only if needed`;

      const userPrompt = init.tag === "Infer"
        ? formatVal(init.payload)
        : `Apply procedure ${formatVal(init.proc)} to args: ${init.args.map(formatVal).join(", ")}`;

      const messages: any[] = [
        { role: "user", content: userPrompt },
      ];

      const apiKey = config.apiKey ?? process.env.ANTHROPIC_API_KEY;
      if (!apiKey) {
        return meaning({
          denotation: { tag: "Unit" },
          confidence: 0,
          trace: { tag: "Str", s: "error: ANTHROPIC_API_KEY not set" },
        });
      }

      const baseUrl = config.baseUrl ?? "https://api.anthropic.com";
      const model = config.model ?? "claude-sonnet-4-20250514";
      const maxTurns = 20;

      for (let turn = 0; turn < maxTurns; turn++) {
        const response = await fetch(`${baseUrl}/v1/messages`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01",
          },
          body: JSON.stringify({
            model,
            max_tokens: config.maxTokens ?? 4096,
            system: systemPrompt,
            tools,
            messages,
            stream: true,  // ← STREAMING ENABLED
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `Anthropic API error: ${err}` },
          });
        }

        // Accumulate streaming events
        const state: StreamingState = {
          textContent: "",
          toolUses: new Map(),
          currentToolIndex: -1,
        };

        for await (const event of parseAnthropicSSE(response)) {
          processStreamEvent(state, event);
        }

        // Convert accumulated tool uses to array
        const completedToolUses = Array.from(state.toolUses.values())
          .filter(tc => tc.name)
          .map(tc => ({
            id: tc.id,
            name: tc.name,
            input: tc.input ? JSON.parse(tc.input) : {},
          }));

        if (completedToolUses.length === 0) {
          if (state.textContent) {
            return meaning({
              denotation: { tag: "Str", s: state.textContent },
              confidence: 0.5,
              trace: { tag: "Str", s: `adapter=anthropic model=${model} streaming=true (text response)` },
            });
          }
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "Empty streaming response from Anthropic" },
          });
        }

        // Build assistant message for history
        const assistantContent: any[] = [];
        if (state.textContent) {
          assistantContent.push({ type: "text", text: state.textContent });
        }
        for (const tc of completedToolUses) {
          assistantContent.push({
            type: "tool_use",
            id: tc.id,
            name: tc.name,
            input: tc.input,
          });
        }
        messages.push({ role: "assistant", content: assistantContent });

        // Process tool calls
        const processor = processToolCalls(completedToolUses, init, model, turn);
        let procResp: OracleResp = { tag: "RespAck" };

        while (true) {
          const step = await processor.next(procResp);
          if (step.done) {
            const result = step.value;
            if (result.done === true) {
              return result.meaning;
            } else {
              // Add tool results as user message
              messages.push({ role: "user", content: result.toolResults });
              break;
            }
          }
          procResp = yield step.value as OracleReq;
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `Max turns (${maxTurns}) exceeded (streaming)` },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // BLOCKING MODE
  // ─────────────────────────────────────────────────────────────────────────

  private startBlockingSession(init: OracleInit): OracleSession {
    const config = this.config;
    const tools = toAnthropicTools();

    return (async function* (): OracleSession {
      const systemPrompt = config.systemPrompt ?? `You are an Oracle for a Lisp runtime.

CRITICAL: You MUST use the 'return' tool to provide your final answer. Do NOT write text answers directly.

For simple questions (yes/no, factual answers):
- Call the 'return' tool immediately with your answer

For computation requiring Lisp:
- Use 'eval' tool first, then 'return' tool with the result

You have these tools:
- return(value): Provide your final answer (REQUIRED)
- eval(expr): Run Lisp code only if needed`;

      const userPrompt = init.tag === "Infer"
        ? formatVal(init.payload)
        : `Apply procedure ${formatVal(init.proc)} to args: ${init.args.map(formatVal).join(", ")}`;

      const messages: any[] = [
        { role: "user", content: userPrompt },
      ];

      const apiKey = config.apiKey ?? process.env.ANTHROPIC_API_KEY;
      if (!apiKey) {
        return meaning({
          denotation: { tag: "Unit" },
          confidence: 0,
          trace: { tag: "Str", s: "error: ANTHROPIC_API_KEY not set" },
        });
      }

      const baseUrl = config.baseUrl ?? "https://api.anthropic.com";
      const model = config.model ?? "claude-sonnet-4-20250514";
      const maxTurns = 20;

      for (let turn = 0; turn < maxTurns; turn++) {
        const response = await fetch(`${baseUrl}/v1/messages`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01",
          },
          body: JSON.stringify({
            model,
            max_tokens: config.maxTokens ?? 4096,
            system: systemPrompt,
            tools,
            messages,
            // stream: false (default)
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `Anthropic API error: ${err}` },
          });
        }

        const data = await response.json() as any;

        // Extract text and tool_use blocks from content
        const content = data.content || [];
        let textContent = "";
        const toolUses: { id: string; name: string; input: any }[] = [];

        for (const block of content) {
          if (block.type === "text") {
            textContent += block.text;
          } else if (block.type === "tool_use") {
            toolUses.push({
              id: block.id,
              name: block.name,
              input: block.input,
            });
          }
        }

        if (toolUses.length === 0) {
          if (textContent) {
            return meaning({
              denotation: { tag: "Str", s: textContent },
              confidence: 0.5,
              trace: { tag: "Str", s: `adapter=anthropic model=${model} (text response)` },
            });
          }
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "Empty response from Anthropic" },
          });
        }

        // Add assistant message to history
        messages.push({ role: "assistant", content });

        // Process tool calls
        const processor = processToolCalls(toolUses, init, model, turn);
        let procResp: OracleResp = { tag: "RespAck" };

        while (true) {
          const step = await processor.next(procResp);
          if (step.done) {
            const result = step.value;
            if (result.done === true) {
              return result.meaning;
            } else {
              // Add tool results as user message
              messages.push({ role: "user", content: result.toolResults });
              break;
            }
          }
          procResp = yield step.value as OracleReq;
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `Max turns (${maxTurns}) exceeded` },
      });
    })();
  }
}

/**
 * Factory function for creating Anthropic adapter with env vars
 */
export function createAnthropicAdapter(overrides?: Partial<LLMConfig>): AnthropicAdapter {
  return new AnthropicAdapter({
    model: overrides?.model ?? "claude-sonnet-4-20250514",
    apiKey: overrides?.apiKey ?? process.env.ANTHROPIC_API_KEY,
    maxTokens: overrides?.maxTokens ?? 4096,
    temperature: overrides?.temperature ?? 0.7,
    ...overrides,
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapters/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapters/index.ts
// Oracle adapter plugins

export * from "./types";
export { AnthropicAdapter, createAnthropicAdapter } from "./anthropicAdapter";
export { OpenAIAdapter, createOpenAIAdapter } from "./openaiAdapter";
export { MCPClientAdapter, OmegaMCPServer, BidirectionalMCPAdapter } from "./mcpAdapter";

/**
 * Adapter Selection Guide:
 *
 * ┌─────────────────────────────────────────────────────────────────────┐
 * │ Adapter                │ Use Case                                   │
 * ├─────────────────────────────────────────────────────────────────────┤
 * │ ScriptedOracleAdapter  │ Tests, deterministic replay                │
 * │ OpenAIAdapter          │ GPT-4o with native tool calling            │
 * │ AnthropicAdapter       │ Claude with native tool calling            │
 * │ MCPClientAdapter       │ Connect to any MCP-compatible LLM server   │
 * │ OmegaMCPServer         │ Expose Omega runtime to external LLMs      │
 * │ BidirectionalMCPAdapter│ Full orchestration with tool composition   │
 * │ DepthTrackingAdapter   │ Wrapper to prevent infinite recursion      │
 * │ TracingAdapter         │ Wrapper for debugging/logging              │
 * └─────────────────────────────────────────────────────────────────────┘
 *
 * Composition Pattern:
 *
 *   const adapter = new DepthTrackingAdapter(
 *     new TracingAdapter(
 *       createAnthropicAdapter({ model: "claude-sonnet-4-20250514" })
 *     ),
 *     maxDepth: 4
 *   );
 *
 * MCP Pattern (Omega as server):
 *
 *   // In your MCP server setup
 *   const mcpServer = new OmegaMCPServer(portal, envRef, stateRef);
 *   // Expose mcpServer.listTools(), mcpServer.callTool() to MCP protocol
 *
 * MCP Pattern (Omega as client):
 *
 *   const adapter = new MCPClientAdapter("http://localhost:3000/mcp");
 *   // Adapter calls out to MCP server for inference
 */

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapters/mcpAdapter.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapters/mcpAdapter.ts
// MCP (Model Context Protocol) adapter
//
// MCP allows the LLM to access external tools/resources through a standardized protocol.
// This adapter exposes the Omega runtime as an MCP server that LLMs can call into.

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, Meaning, QExpr } from "../protocol";
import type { AdapterCaps, OracleAdapterWithCaps } from "./types";
import { meaning } from "../meaning";

/**
 * MCP Tool definition (subset of MCP spec)
 */
export type MCPTool = {
  name: string;
  description: string;
  inputSchema: {
    type: "object";
    properties: Record<string, { type: string; description?: string }>;
    required?: string[];
  };
};

/**
 * MCP Resource definition
 */
export type MCPResource = {
  uri: string;
  name: string;
  description?: string;
  mimeType?: string;
};

/**
 * MCP Server interface - what we expose TO the LLM
 */
export interface MCPServer {
  /** List available tools */
  listTools(): MCPTool[];

  /** Execute a tool */
  callTool(name: string, args: Record<string, unknown>): Promise<unknown>;

  /** List available resources */
  listResources(): MCPResource[];

  /** Read a resource */
  readResource(uri: string): Promise<{ contents: unknown; mimeType: string }>;
}

/**
 * Omega runtime as MCP server
 * Exposes eval/apply/observe as MCP tools
 */
export class OmegaMCPServer implements MCPServer {
  constructor(
    private portal: { perform(req: OracleReq): Promise<OracleResp> },
    private envRef: string,
    private stateRef: string
  ) {}

  listTools(): MCPTool[] {
    return [
      {
        name: "omega_eval",
        description: "Evaluate a Lisp expression in the Omega runtime",
        inputSchema: {
          type: "object",
          properties: {
            expr: { type: "string", description: "Lisp expression" },
          },
          required: ["expr"],
        },
      },
      {
        name: "omega_observe",
        description: "Observe runtime state",
        inputSchema: {
          type: "object",
          properties: {
            what: { type: "string", description: "stack|control|handlers|store" },
          },
          required: ["what"],
        },
      },
      {
        name: "omega_match",
        description: "Pattern match on AST",
        inputSchema: {
          type: "object",
          properties: {
            expr: { type: "string", description: "Expression to match" },
            pattern: { type: "string", description: "Pattern with ?binders" },
          },
          required: ["expr", "pattern"],
        },
      },
    ];
  }

  async callTool(name: string, args: Record<string, unknown>): Promise<unknown> {
    switch (name) {
      case "omega_eval": {
        const resp = await this.portal.perform({
          tag: "ReqEval",
          qexpr: args.expr as string,
          envRef: this.envRef,
        });
        if (resp.tag === "RespVal") return resp.value;
        if (resp.tag === "RespError") throw new Error(resp.message);
        return resp;
      }

      case "omega_observe": {
        const whatMap: Record<string, any> = {
          stack: { tag: "Stack", limit: 20 },
          control: { tag: "Control" },
          handlers: { tag: "Handlers" },
          store: { tag: "StoreSummary" },
        };
        const resp = await this.portal.perform({
          tag: "ReqObserve",
          what: whatMap[args.what as string] ?? { tag: "Control" },
          stateRef: this.stateRef,
        });
        if (resp.tag === "RespObs") return resp.data;
        return resp;
      }

      case "omega_match": {
        const resp = await this.portal.perform({
          tag: "ReqMatch",
          qexpr: args.expr as string,
          pattern: args.pattern as string,
          envRef: this.envRef,
        });
        if (resp.tag === "RespObs") return resp.data;
        return resp;
      }

      default:
        throw new Error(`Unknown tool: ${name}`);
    }
  }

  listResources(): MCPResource[] {
    return [
      {
        uri: "omega://env",
        name: "Current Environment",
        description: "The current variable bindings",
        mimeType: "application/json",
      },
      {
        uri: "omega://state",
        name: "Machine State",
        description: "The current CEKS machine state",
        mimeType: "application/json",
      },
    ];
  }

  async readResource(uri: string): Promise<{ contents: unknown; mimeType: string }> {
    if (uri === "omega://env") {
      // Would need to serialize env properly
      return { contents: { envRef: this.envRef }, mimeType: "application/json" };
    }
    if (uri === "omega://state") {
      return { contents: { stateRef: this.stateRef }, mimeType: "application/json" };
    }
    throw new Error(`Unknown resource: ${uri}`);
  }
}

/**
 * MCP Client adapter - calls an external MCP server
 * This is for when the Oracle IS an MCP client talking to some service
 */
export class MCPClientAdapter implements OracleAdapterWithCaps {
  constructor(
    private serverUrl: string,
    private authToken?: string
  ) {}

  capabilities(): AdapterCaps {
    return {
      multiTurn: true,
      toolCalling: true,
      mcp: true,
      streaming: false,    // MCP doesn't stream by default
      vision: false,
      maxContext: Infinity, // MCP doesn't have context limits
    };
  }

  startSession(init: OracleInit): OracleSession {
    const serverUrl = this.serverUrl;

    return (async function* (): OracleSession {
      // STUB: In production, this would:
      // 1. Connect to MCP server at serverUrl
      // 2. List available tools
      // 3. Decide which tools to call based on init.payload
      // 4. Call tools and process results
      // 5. Return final Meaning

      // For now, just return a placeholder
      return meaning({
        denotation: { tag: "Str", s: "MCP adapter stub" },
        confidence: 0,
        trace: { tag: "Str", s: `adapter=mcp serverUrl=${serverUrl}` },
      });
    })();
  }
}

/**
 * Bidirectional MCP adapter - Omega acts as BOTH client and server
 *
 * This is the powerful pattern:
 * - LLM calls Omega tools via MCP
 * - Omega can call LLM tools via MCP
 * - Enables tool composition and orchestration
 */
export class BidirectionalMCPAdapter implements OracleAdapterWithCaps {
  constructor(
    private mcpServerUrl: string,  // Where to call OUT
    private listenPort: number,     // Where we listen for calls IN
  ) {}

  capabilities(): AdapterCaps {
    return {
      multiTurn: true,
      toolCalling: true,
      mcp: true,
      streaming: true,
      vision: false,
      maxContext: Infinity,
    };
  }

  startSession(init: OracleInit): OracleSession {
    // STUB: Would set up bidirectional MCP connection
    return (async function* (): OracleSession {
      return meaning({
        denotation: { tag: "Str", s: "bidirectional MCP stub" },
        confidence: 0,
      });
    })();
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapters/openaiAdapter.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapters/openaiAdapter.ts
// Real OpenAI Oracle adapter with native tool calling

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, Meaning, QExpr, ObserveSpec } from "../protocol";
import type { Val } from "../../eval/values";
import type { LLMConfig, AdapterCaps, OracleAdapterWithCaps, ToolDef } from "./types";
import { meaning } from "../meaning";

// Tool definitions that map to Oracle protocol requests
const ORACLE_TOOLS: ToolDef[] = [
  {
    name: "eval",
    description: "Evaluate a Lisp expression in the current environment. Returns the result value.",
    parameters: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Lisp expression to evaluate (e.g., '(+ 1 2)' or '(define (f x) (* x x))')" },
      },
      required: ["expr"],
    },
  },
  {
    name: "apply",
    description: "Apply a function to arguments",
    parameters: {
      type: "object",
      properties: {
        fn: { type: "string", description: "Function name or expression" },
        args: { type: "array", items: { type: "string" }, description: "Arguments as Lisp expressions" },
      },
      required: ["fn", "args"],
    },
  },
  {
    name: "observe",
    description: "Observe runtime state - useful for introspection",
    parameters: {
      type: "object",
      properties: {
        what: {
          type: "string",
          enum: ["stack", "control", "handlers", "store", "env", "defs"],
          description: "What to observe: stack (call stack), control (current expression), handlers (effect handlers), store (memory), env (environment bindings), defs (top-level definitions)",
        },
      },
      required: ["what"],
    },
  },
  {
    name: "match",
    description: "Match an expression against a pattern with ?x binders",
    parameters: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Expression to match" },
        pattern: { type: "string", description: "Pattern with ?x binders (e.g., '(?op ?a ?b)')" },
      },
      required: ["expr", "pattern"],
    },
  },
  {
    name: "assert",
    description: "Assert a condition - useful for validation",
    parameters: {
      type: "object",
      properties: {
        predicate: { type: "string", description: "Predicate expression that should evaluate to true" },
        msg: { type: "string", description: "Error message if assertion fails" },
      },
      required: ["predicate", "msg"],
    },
  },
  {
    name: "return",
    description: "Return a final result and end the session. Call this when you have computed the answer.",
    parameters: {
      type: "object",
      properties: {
        value: { type: "string", description: "Value to return as a Lisp literal (e.g., '42', '#t', '(list 1 2 3)')" },
        confidence: { type: "number", description: "Confidence in result from 0 to 1 (default: 0.9)" },
      },
      required: ["value"],
    },
  },
];

// Convert to OpenAI function format
function toOpenAITools(): any[] {
  return ORACLE_TOOLS.map(t => ({
    type: "function",
    function: {
      name: t.name,
      description: t.description,
      parameters: t.parameters,
    },
  }));
}

// Parse a Lisp literal string into a Val (simplified)
function parseValLiteral(s: string): Val {
  s = s.trim();
  if (s === "#t" || s === "true") return { tag: "Bool", b: true };
  if (s === "#f" || s === "false") return { tag: "Bool", b: false };
  if (s === "()" || s === "unit" || s === "null") return { tag: "Unit" };
  if (/^-?\d+(\.\d+)?$/.test(s)) return { tag: "Num", n: parseFloat(s) };
  if (s.startsWith('"') && s.endsWith('"')) return { tag: "Str", s: s.slice(1, -1) };
  if (s.startsWith("'")) return { tag: "Sym", name: s.slice(1) };
  // For complex expressions, just wrap as string - let eval handle it
  return { tag: "Str", s };
}

// Check if a Val is a proper list (cons cells ending in Unit/null)
function isProperList(v: Val): boolean {
  let current = v;
  while (current.tag === "Vector" && current.items.length === 2) {
    current = current.items[1];
  }
  return current.tag === "Unit";
}

// Extract elements from a proper list
function listToArray(v: Val): Val[] {
  const result: Val[] = [];
  let current = v;
  while (current.tag === "Vector" && current.items.length === 2) {
    result.push(current.items[0]);
    current = current.items[1];
  }
  return result;
}

// Check if a list is all strings
function isStringList(v: Val): boolean {
  if (!isProperList(v)) return false;
  return listToArray(v).every(item => item.tag === "Str");
}

// Concatenate a list of strings into a single string
function concatStringList(v: Val): string {
  return listToArray(v).map(item => (item as { tag: "Str"; s: string }).s).join("");
}

// Format Val for display (used in prompts to LLM)
function formatVal(v: Val): string {
  switch (v.tag) {
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Str": return v.s;  // Return raw string without quotes for prompt
    case "Sym": return v.name;
    case "Unit": return "()";
    case "Vector": {
      // Check if it's a list of strings - concatenate them for cleaner prompt
      if (isStringList(v)) {
        return concatStringList(v);
      }
      // Otherwise format as list
      if (isProperList(v)) {
        return `(${listToArray(v).map(formatVal).join(" ")})`;
      }
      return `[${v.items.map(formatVal).join(" ")}]`;
    }
    case "Closure": return `<closure ${v.params.join(" ")}>`;
    case "Native": return `<native ${v.name}>`;
    case "Meaning": return `<meaning conf=${v.confidence}>`;
    default: return JSON.stringify(v);
  }
}

// Format ObserveSpec
function parseObserveSpec(what: string): ObserveSpec {
  switch (what.toLowerCase()) {
    case "stack": return { tag: "Stack", limit: 10 };
    case "control": return { tag: "Control" };
    case "handlers": return { tag: "Handlers" };
    case "store": return { tag: "StoreSummary", maxCells: 50 };
    case "env": return { tag: "Env" };
    case "defs": return { tag: "Defs" };
    default: return { tag: "Control" };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// STREAMING HELPERS
// ═══════════════════════════════════════════════════════════════════════════

type StreamingToolCall = {
  id: string;
  name: string;
  arguments: string;
};

/**
 * Parse SSE stream chunks from OpenAI streaming response
 */
async function* parseSSEStream(response: Response): AsyncGenerator<any> {
  const reader = response.body!.getReader();
  const decoder = new TextDecoder();
  let buffer = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split("\n");
    buffer = lines.pop() || "";  // Keep incomplete line in buffer

    for (const line of lines) {
      const trimmed = line.trim();
      if (!trimmed || !trimmed.startsWith("data: ")) continue;
      const data = trimmed.slice(6);
      if (data === "[DONE]") return;

      try {
        yield JSON.parse(data);
      } catch {
        // Skip malformed JSON
      }
    }
  }
}

/**
 * Accumulate streaming chunks into complete tool calls
 */
function accumulateStreamChunk(
  toolCalls: Map<number, StreamingToolCall>,
  contentBuffer: { content: string },
  chunk: any
): void {
  const delta = chunk.choices?.[0]?.delta;
  if (!delta) return;

  // Accumulate content
  if (delta.content) {
    contentBuffer.content += delta.content;
  }

  // Accumulate tool calls
  if (delta.tool_calls) {
    for (const tc of delta.tool_calls) {
      const idx = tc.index;
      const existing = toolCalls.get(idx) ?? { id: "", name: "", arguments: "" };

      if (tc.id) existing.id = tc.id;
      if (tc.function?.name) existing.name = tc.function.name;
      if (tc.function?.arguments) existing.arguments += tc.function.arguments;

      toolCalls.set(idx, existing);
    }
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// TOOL CALL PROCESSING (shared between streaming and blocking)
// ═══════════════════════════════════════════════════════════════════════════

type ToolCallResult =
  | { done: false; toolResults: any[] }
  | { done: true; meaning: Meaning };

/**
 * Process tool calls and yield to runtime - used by both modes
 */
async function* processToolCalls(
  toolCalls: { id: string; name: string; arguments: string }[],
  init: OracleInit,
  model: string,
  turn: number
): AsyncGenerator<OracleReq, ToolCallResult, OracleResp> {
  const toolResults: any[] = [];

  for (const tc of toolCalls) {
    const toolName = tc.name;
    let toolArgs: any;
    try {
      toolArgs = JSON.parse(tc.arguments || "{}");
    } catch {
      toolArgs = {};
    }

    let req: OracleReq;
    let resp: OracleResp;
    let resultContent: string;

    switch (toolName) {
      case "eval":
        req = {
          tag: "ReqEval",
          qexpr: toolArgs.expr as string as unknown as QExpr,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespVal") {
          resultContent = formatVal(resp.value);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "apply":
        const fnVal = parseValLiteral(toolArgs.fn);
        const argsVals = (toolArgs.args as string[]).map(parseValLiteral);
        req = {
          tag: "ReqApply",
          fn: fnVal,
          args: argsVals,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespVal") {
          resultContent = formatVal(resp.value);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "observe":
        req = {
          tag: "ReqObserve",
          what: parseObserveSpec(toolArgs.what),
          stateRef: init.stateRef,
        };
        resp = yield req;
        if (resp.tag === "RespObs") {
          resultContent = JSON.stringify(resp.data, null, 2);
        } else if (resp.tag === "RespError") {
          resultContent = `Error: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "match":
        req = {
          tag: "ReqMatch",
          qexpr: toolArgs.expr as string as unknown as QExpr,
          pattern: toolArgs.pattern as string as unknown as QExpr,
          envRef: init.envRef,
        };
        resp = yield req;
        resultContent = JSON.stringify(resp);
        break;

      case "assert":
        req = {
          tag: "ReqAssert",
          predicate: toolArgs.predicate as string as unknown as QExpr,
          msg: toolArgs.msg,
          envRef: init.envRef,
        };
        resp = yield req;
        if (resp.tag === "RespAck") {
          resultContent = "Assertion passed";
        } else if (resp.tag === "RespError") {
          resultContent = `Assertion failed: ${resp.message}`;
        } else {
          resultContent = JSON.stringify(resp);
        }
        break;

      case "return":
        const retVal = parseValLiteral(toolArgs.value);
        const confidence = toolArgs.confidence ?? 0.9;
        return {
          done: true,
          meaning: meaning({
            denotation: retVal,
            confidence,
            trace: { tag: "Str", s: `adapter=openai model=${model} turns=${turn + 1}` },
          }),
        };

      default:
        resultContent = `Unknown tool: ${toolName}`;
    }

    toolResults.push({
      role: "tool",
      tool_call_id: tc.id,
      content: resultContent!,
    });
  }

  return { done: false, toolResults };
}

// ═══════════════════════════════════════════════════════════════════════════
// OPENAI ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Real OpenAI Oracle adapter with tool calling
 * Supports both streaming and blocking modes via config.streaming
 */
export class OpenAIAdapter implements OracleAdapterWithCaps {
  constructor(private config: LLMConfig) {}

  capabilities(): AdapterCaps {
    return {
      multiTurn: true,
      toolCalling: true,
      mcp: false,
      streaming: true,
      vision: true,
      maxContext: 128_000,  // GPT-4
    };
  }

  startSession(init: OracleInit): OracleSession {
    if (this.config.streaming) {
      return this.startStreamingSession(init);
    } else {
      return this.startBlockingSession(init);
    }
  }

  // ─────────────────────────────────────────────────────────────────────────
  // STREAMING MODE - accumulates tool calls from SSE chunks
  // ─────────────────────────────────────────────────────────────────────────

  private startStreamingSession(init: OracleInit): OracleSession {
    const config = this.config;
    const tools = toOpenAITools();

    return (async function* (): OracleSession {
      const systemPrompt = config.systemPrompt ?? `You are an Oracle that answers questions using tool calls.

CRITICAL: You MUST use the 'return' tool to provide your answer. Do NOT write text answers directly.

For simple questions (yes/no, factual answers):
- Call the 'return' tool immediately with your answer

For computation requiring Lisp:
- Use 'eval' tool first, then 'return' tool with the result

You have these tools:
- return(value): Provide your final answer (REQUIRED for all responses)
- eval(expr): Run Lisp code only if needed`;

      const userPrompt = init.tag === "Infer"
        ? formatVal(init.payload)
        : `Apply procedure ${formatVal(init.proc)} to args: ${init.args.map(formatVal).join(", ")}`;

      const messages: any[] = [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ];

      const apiKey = config.apiKey ?? process.env.OPENAI_API_KEY;
      if (!apiKey) {
        return meaning({
          denotation: { tag: "Unit" },
          confidence: 0,
          trace: { tag: "Str", s: "error: OPENAI_API_KEY not set" },
        });
      }

      const baseUrl = config.baseUrl ?? "https://api.openai.com/v1";
      const model = config.model ?? "gpt-4o";
      const maxTurns = 20;

      for (let turn = 0; turn < maxTurns; turn++) {
        // Call OpenAI with streaming enabled
        const response = await fetch(`${baseUrl}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`,
          },
          body: JSON.stringify({
            model,
            messages,
            tools,
            tool_choice: "auto",
            max_tokens: config.maxTokens ?? 4096,
            temperature: config.temperature ?? 0.7,
            stream: true,  // ← STREAMING ENABLED
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `OpenAI API error: ${err}` },
          });
        }

        // Accumulate streaming chunks
        const toolCalls = new Map<number, StreamingToolCall>();
        const contentBuffer = { content: "" };

        for await (const chunk of parseSSEStream(response)) {
          accumulateStreamChunk(toolCalls, contentBuffer, chunk);
        }

        // Convert accumulated tool calls to array
        const completedToolCalls = Array.from(toolCalls.values()).filter(tc => tc.name);

        if (completedToolCalls.length === 0) {
          // No tool calls - check if we have content
          if (contentBuffer.content) {
            return meaning({
              denotation: { tag: "Str", s: contentBuffer.content },
              confidence: 0.5,
              trace: { tag: "Str", s: `adapter=openai model=${model} streaming=true (text response)` },
            });
          }
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "Empty streaming response from OpenAI" },
          });
        }

        // Build assistant message for history
        const assistantMsg: any = {
          role: "assistant",
          content: contentBuffer.content || null,
          tool_calls: completedToolCalls.map((tc, idx) => ({
            id: tc.id,
            type: "function",
            function: { name: tc.name, arguments: tc.arguments },
          })),
        };
        messages.push(assistantMsg);

        // Process tool calls using shared logic
        const processor = processToolCalls(completedToolCalls, init, model, turn);
        let procResp: OracleResp = { tag: "RespAck" };

        while (true) {
          const step = await processor.next(procResp);
          if (step.done) {
            const result = step.value;
            if (result.done === true) {
              return result.meaning;
            } else {
              // Add tool results to messages and continue
              messages.push(...result.toolResults);
              break;
            }
          }
          // Yield request to runtime
          procResp = yield step.value as OracleReq;
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `Max turns (${maxTurns}) exceeded (streaming)` },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // BLOCKING MODE - original implementation (waits for full response)
  // ─────────────────────────────────────────────────────────────────────────

  private startBlockingSession(init: OracleInit): OracleSession {
    const config = this.config;
    const tools = toOpenAITools();

    return (async function* (): OracleSession {
      const systemPrompt = config.systemPrompt ?? `You are an Oracle that answers questions using tool calls.

CRITICAL: You MUST use the 'return' tool to provide your answer. Do NOT write text answers directly.

For simple questions (yes/no, factual answers):
- Call the 'return' tool immediately with your answer

For computation requiring Lisp:
- Use 'eval' tool first, then 'return' tool with the result

You have these tools:
- return(value): Provide your final answer (REQUIRED for all responses)
- eval(expr): Run Lisp code only if needed`;

      const userPrompt = init.tag === "Infer"
        ? formatVal(init.payload)
        : `Apply procedure ${formatVal(init.proc)} to args: ${init.args.map(formatVal).join(", ")}`;

      const messages: any[] = [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ];

      const apiKey = config.apiKey ?? process.env.OPENAI_API_KEY;
      if (!apiKey) {
        return meaning({
          denotation: { tag: "Unit" },
          confidence: 0,
          trace: { tag: "Str", s: "error: OPENAI_API_KEY not set" },
        });
      }

      const baseUrl = config.baseUrl ?? "https://api.openai.com/v1";
      const model = config.model ?? "gpt-4o";
      const maxTurns = 20;

      for (let turn = 0; turn < maxTurns; turn++) {
        // Call OpenAI (blocking)
        const response = await fetch(`${baseUrl}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`,
          },
          body: JSON.stringify({
            model,
            messages,
            tools,
            tool_choice: "auto",
            max_tokens: config.maxTokens ?? 4096,
            temperature: config.temperature ?? 0.7,
            // stream: false (default)
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `OpenAI API error: ${err}` },
          });
        }

        const data = await response.json() as any;
        const choice = data.choices?.[0];
        const assistantMsg = choice?.message;

        if (!assistantMsg) {
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "No response from OpenAI" },
          });
        }

        messages.push(assistantMsg);

        const toolCalls = assistantMsg.tool_calls;
        if (!toolCalls || toolCalls.length === 0) {
          if (assistantMsg.content) {
            return meaning({
              denotation: { tag: "Str", s: assistantMsg.content },
              confidence: 0.5,
              trace: { tag: "Str", s: `adapter=openai model=${model} (text response, no return tool)` },
            });
          }
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "Empty response from OpenAI" },
          });
        }

        // Convert to common format and process
        const normalizedCalls = toolCalls.map((tc: any) => ({
          id: tc.id,
          name: tc.function?.name || "",
          arguments: tc.function?.arguments || "{}",
        }));

        const processor = processToolCalls(normalizedCalls, init, model, turn);
        let procResp: OracleResp = { tag: "RespAck" };

        while (true) {
          const step = await processor.next(procResp);
          if (step.done) {
            const result = step.value;
            if (result.done === true) {
              return result.meaning;
            } else {
              messages.push(...result.toolResults);
              break;
            }
          }
          procResp = yield step.value as OracleReq;
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `Max turns (${maxTurns}) exceeded` },
      });
    })();
  }
}

/**
 * Factory function for creating OpenAI adapter with env vars
 */
export function createOpenAIAdapter(overrides?: Partial<LLMConfig>): OpenAIAdapter {
  return new OpenAIAdapter({
    model: overrides?.model ?? "gpt-4o",
    apiKey: overrides?.apiKey ?? process.env.OPENAI_API_KEY,
    maxTokens: overrides?.maxTokens ?? 4096,
    temperature: overrides?.temperature ?? 0.7,
    ...overrides,
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/adapters/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/adapters/types.ts
// Plugin interface for Oracle backends

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, Meaning } from "../protocol";
import { meaning } from "../meaning";

/**
 * Configuration for LLM-based Oracle adapters
 */
export type LLMConfig = {
  model: string;
  apiKey?: string;
  baseUrl?: string;
  maxTokens?: number;
  temperature?: number;
  systemPrompt?: string;
  /** Enable streaming mode - accumulates tool calls from stream chunks */
  streaming?: boolean;
};

/**
 * Tool definition for tool-calling LLMs (OpenAI/Anthropic style)
 */
export type ToolDef = {
  name: string;
  description: string;
  parameters: Record<string, unknown>; // JSON Schema
};

/**
 * Extended adapter interface with capabilities discovery
 */
export interface OracleAdapterWithCaps extends OracleAdapter {
  /** What this adapter supports */
  capabilities(): AdapterCaps;
}

export type AdapterCaps = {
  /** Can do multi-turn conversations */
  multiTurn: boolean;
  /** Supports native tool calling (not prompt-based) */
  toolCalling: boolean;
  /** Supports MCP (Model Context Protocol) */
  mcp: boolean;
  /** Can stream responses */
  streaming: boolean;
  /** Supports vision/images */
  vision: boolean;
  /** Max context window */
  maxContext: number;
};

/**
 * Depth-tracking wrapper - prevents infinite recursion
 */
export class DepthTrackingAdapter implements OracleAdapter {
  private currentDepth = 0;

  constructor(
    private inner: OracleAdapter,
    private maxDepth: number = 8
  ) {}

  startSession(init: OracleInit): OracleSession {
    const maxDepth = this.maxDepth;
    if (this.currentDepth >= maxDepth) {
      // Return a session that immediately fails with proper Meaning
      return (async function* (): OracleSession {
        return meaning({
          denotation: { tag: "Unit" },
          confidence: 0,
          trace: { tag: "Str", s: `max nested depth ${maxDepth} exceeded` },
        });
      })();
    }

    this.currentDepth++;
    const innerSession = this.inner.startSession(init);

    // Wrap to decrement depth on completion
    const self = this;
    return (async function* (): OracleSession {
      try {
        let resp: OracleResp = { tag: "RespAck" };
        while (true) {
          const step = await innerSession.next(resp);
          if (step.done) {
            return step.value;
          }
          resp = yield step.value as OracleReq;
        }
      } finally {
        self.currentDepth--;
      }
    })();
  }
}

/**
 * Logging/tracing wrapper for debugging
 */
export class TracingAdapter implements OracleAdapter {
  constructor(
    private inner: OracleAdapter,
    private log: (msg: string, data?: unknown) => void = console.log
  ) {}

  startSession(init: OracleInit): OracleSession {
    this.log("Oracle session started", { tag: init.tag, envRef: init.envRef });
    const innerSession = this.inner.startSession(init);
    const log = this.log;

    return (async function* (): OracleSession {
      let resp: OracleResp = { tag: "RespAck" };
      let turn = 0;
      while (true) {
        const step = await innerSession.next(resp);
        if (step.done) {
          log("Oracle session completed", { result: step.value });
          return step.value;
        }
        turn++;
        log(`Oracle turn ${turn}`, { req: step.value });
        resp = yield step.value as OracleReq;
        log(`Oracle turn ${turn} response`, { resp });
      }
    })();
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/ctxReceipts.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/ctxReceipts.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set C3: Context economics gateway (snapshot/compress/hydrate)

import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type { EnvRef, StateRef } from "./protocol";

export type CtxReceipt = {
  tag: "CtxReceipt";
  rid: Hash;
  kind: "snapshot" | "compress";
  envRef: EnvRef;
  stateRef?: StateRef;
  meta?: unknown;
  timeMs: number;
};

export type CtxReceiptRepoOptions = {
  /**
   * Deterministic mode for testing.
   * If true, uses counter instead of timestamp in ID generation.
   */
  deterministic?: boolean;
  /** Optional prefix for IDs (useful for test isolation). */
  prefix?: string;
};

export class CtxReceiptRepo {
  private m = new Map<Hash, CtxReceipt>();
  private counter = 0;
  private deterministic: boolean;
  private prefix: string;

  constructor(opts: CtxReceiptRepoOptions = {}) {
    this.deterministic = opts.deterministic ?? false;
    this.prefix = opts.prefix ?? "";
  }

  private generateId(kind: string, data: unknown): { rid: Hash; t0: number } {
    const t0 = Date.now();
    if (this.deterministic) {
      const rid = sha256JSON({ kind, data, seq: ++this.counter });
      return { rid: this.prefix + rid, t0 };
    } else {
      const rid = sha256JSON({ kind, data, t0 });
      return { rid, t0 };
    }
  }

  snapshot(envRef: EnvRef, stateRef: StateRef | undefined, meta: unknown): CtxReceipt {
    const { rid, t0 } = this.generateId("snapshot", { envRef, stateRef, meta });
    const r: CtxReceipt = { tag: "CtxReceipt", rid, kind: "snapshot", envRef, stateRef, meta, timeMs: 0 };
    r.timeMs = this.deterministic ? 0 : Date.now() - t0;
    this.m.set(rid, r);
    return r;
  }

  compress(envRef: EnvRef, meta: unknown): CtxReceipt {
    const { rid, t0 } = this.generateId("compress", { envRef, meta });
    const r: CtxReceipt = { tag: "CtxReceipt", rid, kind: "compress", envRef, meta, timeMs: 0 };
    r.timeMs = this.deterministic ? 0 : Date.now() - t0;
    this.m.set(rid, r);
    return r;
  }

  get(rid: Hash): CtxReceipt | undefined {
    return this.m.get(rid);
  }

  has(rid: Hash): boolean {
    return this.m.has(rid);
  }

  clear(): void {
    this.m.clear();
    this.counter = 0;
  }

  /** Reset to initial state with new options. */
  reset(opts: CtxReceiptRepoOptions = {}): void {
    this.clear();
    this.deterministic = opts.deterministic ?? this.deterministic;
    this.prefix = opts.prefix ?? this.prefix;
  }

  /** Get all stored receipts (for debugging/testing). */
  all(): CtxReceipt[] {
    return Array.from(this.m.values());
  }

  /** Get the number of stored receipts. */
  size(): number {
    return this.m.size;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/driver.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/driver.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md

import type { OraclePortal } from "./portal";
import type { OracleSession, OracleReq, OracleResp, OracleReturn } from "./protocol";

export type OracleDriverOptions = {
  maxTurns: number;
};

const DEFAULT_OPTS: OracleDriverOptions = { maxTurns: 10_000 };

export async function runOracleSession(
  session: OracleSession,
  portal: OraclePortal,
  opts: OracleDriverOptions = DEFAULT_OPTS
): Promise<OracleReturn> {
  let resp: OracleResp = { tag: "RespAck" };

  for (let turns = 0; turns < opts.maxTurns; turns++) {
    const step = await session.next(resp);

    if (step.done) return step.value;

    // TypeScript doesn't narrow generator yields properly, so assert the type
    const req = step.value as OracleReq;

    // Spec: ReqReturn/ReqFail are "terminal requests"
    if (req.tag === "ReqReturn") return req.result;
    if (req.tag === "ReqFail") throw new Error(`Oracle failed: ${req.reason}`);

    resp = await portal.perform(req);
  }

  throw new Error(`Oracle session exceeded maxTurns=${opts.maxTurns}`);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/legacyAdapter.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/legacyAdapter.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md
// Compatibility wrapper to convert old-style simple oracle to new session-based oracle

import type { OracleAdapter, OracleInit } from "./adapter";
import type { OracleSession, OracleResp, Meaning } from "./protocol";
import type { Val } from "../eval/values";

/**
 * Interface for the old-style simple oracle (just infer).
 * Used for backward compatibility with existing tests and LLM adapters.
 */
export interface LegacyOracleAdapter {
  infer(payload: Val, ctxDigest: string): Promise<Val>;
}

/**
 * Wraps a legacy (simple) oracle to work with the new session-based protocol.
 * The session just calls infer() once and returns a Meaning with the result.
 */
export class LegacyOracleWrapper implements OracleAdapter {
  constructor(private readonly legacy: LegacyOracleAdapter, private readonly ctxDigest = "legacy") {}

  startSession(init: OracleInit): OracleSession {
    const legacy = this.legacy;
    const ctxDigest = this.ctxDigest;

    return (async function* (): OracleSession {
      // For infer: just call the legacy infer and return
      if (init.tag === "Infer") {
        const result = await legacy.infer(init.payload, ctxDigest);
        const meaning: Meaning = {
          tag: "Meaning",
          denotation: result,
          confidence: 1.0,
        };
        yield { tag: "ReqReturn", result: meaning };
        return meaning;
      }

      // For apply: call infer with the args (basic compatibility)
      if (init.tag === "Apply") {
        const payload: Val = { tag: "Vector", items: init.args };
        const result = await legacy.infer(payload, ctxDigest);
        const meaning: Meaning = {
          tag: "Meaning",
          denotation: result,
          confidence: 1.0,
        };
        yield { tag: "ReqReturn", result: meaning };
        return meaning;
      }

      // Fallback
      const meaning: Meaning = { tag: "Meaning", confidence: 0 };
      yield { tag: "ReqReturn", result: meaning };
      return meaning;
    })();
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/match.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/match.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set C2: Structural AST matcher with ?x binders and _ wildcard

export type Bindings = Record<string, unknown>;

function isObj(x: unknown): x is Record<string, unknown> {
  return !!x && typeof x === "object" && !Array.isArray(x);
}

function isVarBinder(node: unknown): string | null {
  // Supports either:
  //   {tag:"Var", name:"?x"}    OR   {tag:"Sym", name:"?x"}   OR plain string "?x"
  if (typeof node === "string" && node.startsWith("?")) return node.slice(1);
  if (isObj(node) && typeof node.name === "string" && node.name.startsWith("?")) return node.name.slice(1);
  return null;
}

function isWildcard(node: unknown): boolean {
  if (node === "_" || node === "*") return true;
  if (isObj(node) && (node.name === "_" || node.name === "*")) return true;
  return false;
}

export function matchAST(pattern: unknown, node: unknown): { ok: boolean; bindings: Bindings } {
  const bindings: Bindings = {};
  const ok = go(pattern, node, bindings);
  return { ok, bindings };
}

function go(p: unknown, n: unknown, b: Bindings): boolean {
  if (isWildcard(p)) return true;

  const binder = isVarBinder(p);
  if (binder) {
    if (binder in b) {
      return deepEqual(b[binder], n);
    }
    b[binder] = n;
    return true;
  }

  // primitives
  if (p === null || typeof p !== "object") return p === n;

  // arrays
  if (Array.isArray(p)) {
    if (!Array.isArray(n)) return false;
    if (p.length !== n.length) return false;
    for (let i = 0; i < p.length; i++) {
      if (!go(p[i], n[i], b)) return false;
    }
    return true;
  }

  // objects
  if (!isObj(n)) return false;
  const pObj = p as Record<string, unknown>;
  if (pObj.tag && n.tag && pObj.tag !== n.tag) return false;

  for (const k of Object.keys(pObj)) {
    if (k === "loc" || k === "span") continue; // ignore source locations
    if (!(k in n)) return false;
    if (!go(pObj[k], (n as Record<string, unknown>)[k], b)) return false;
  }
  return true;
}

function deepEqual(a: unknown, c: unknown): boolean {
  if (a === c) return true;
  if (typeof a !== typeof c) return false;
  if (a === null || c === null) return a === c;
  if (Array.isArray(a)) {
    if (!Array.isArray(c) || a.length !== c.length) return false;
    for (let i = 0; i < a.length; i++) if (!deepEqual(a[i], c[i])) return false;
    return true;
  }
  if (typeof a === "object") {
    const aObj = a as Record<string, unknown>;
    const cObj = c as Record<string, unknown>;
    const ak = Object.keys(aObj).filter(k => k !== "loc" && k !== "span").sort();
    const ck = Object.keys(cObj).filter(k => k !== "loc" && k !== "span").sort();
    if (ak.length !== ck.length) return false;
    for (let i = 0; i < ak.length; i++) if (ak[i] !== ck[i]) return false;
    for (const k of ak) if (!deepEqual(aObj[k], cObj[k])) return false;
    return true;
  }
  return false;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/meaning.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/meaning.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set A2: Meaning as structured first-class value
// Patch Set 6: Enhanced obligations for term rewriting

import type { Val } from "../eval/values";
import type { DistVal } from "../eval/dist";
import type { Expr } from "../ast";
import type { Evidence } from "../provenance/evidence";
import { evidenceToVal } from "../provenance/evidence";

export type { Evidence, OracleEvidence, TransformEvidence, DerivedEvidence } from "../provenance/evidence";

/**
 * Obligation types for governing program transformations.
 * These must be discharged before a commit can succeed.
 */
export type Obligation =
  | { tag: "OblTests"; tests: Expr[]; envRef: string }
  | { tag: "OblIdempotent"; f: Expr; domain?: Val }              // f(f(x)) = f(x)
  | { tag: "OblNoMatch"; pattern: Expr; scope: "output" | "all" } // pattern must not appear
  | { tag: "OblEqExt"; original: Expr; candidate: Expr; tests: Expr[]; envRef: string }; // extensional equivalence

/**
 * Rewrite trace step for debugging and audit.
 */
export type RewriteStep = {
  rule: string;         // rule name
  before: Val;          // AST before
  after: Val;           // AST after
  position?: string;    // path in AST where rewrite occurred
};

/**
 * Meaning is a VALUE in Omega.
 * We store "residual/rewrite" as Val so you can represent them as Syntax values (tag:"Syntax") or as quoted AST data.
 */
export type MeaningVal = {
  tag: "Meaning";

  // Denotation plane
  denotation?: Val | DistVal;

  // Program plane
  residual?: Val;   // typically {tag:"Syntax", stx: ...} or quoted AST (partially evaluated)
  rewrite?: Val;    // candidate transformed program

  // Analysis plane (optional for now; but the fields EXIST)
  invariants?: Val;
  effects?: Val;
  cost?: Val;
  paths?: Val;
  deps?: Val;
  memo?: Val;

  // Governance plane (Prompt 6 enhanced)
  obligation?: Val;        // legacy single obligation (backward compat)
  obligations?: Obligation[];  // structured obligations array
  evidence?: Evidence[];   // discharge evidence
  confidence?: number;     // 0..1
  trace?: Val | RewriteStep[];  // rewrite trace

  // Runtime surgery hook (optional but extremely powerful)
  adoptEnvRef?: string;
  adoptStateRef?: string;
};

export function meaning(partial: Omit<MeaningVal, "tag">): MeaningVal {
  return { tag: "Meaning", ...partial };
}

export function isMeaning(v: Val): v is MeaningVal {
  return typeof v === "object" && v !== null && (v as any).tag === "Meaning";
}

// Helper to convert old-style protocol Meaning to MeaningVal
function vStr(s: string): Val {
  return { tag: "Str", s };
}
function vNum(n: number): Val {
  return { tag: "Num", n };
}

/**
 * Convert MeaningVal to Map representation for backward compatibility.
 * Prefer using MeaningVal directly as it's now a first-class value.
 */
export function meaningToVal(m: MeaningVal): Val {
  const entries: Array<[Val, Val]> = [];
  entries.push([vStr("tag"), vStr("Meaning")]);

  if (m.denotation) entries.push([vStr("denotation"), m.denotation as Val]);
  if (m.confidence !== undefined) entries.push([vStr("confidence"), vNum(m.confidence)]);
  if (m.adoptEnvRef) entries.push([vStr("adoptEnvRef"), vStr(m.adoptEnvRef)]);
  if (m.residual) entries.push([vStr("residual"), m.residual]);
  if (m.rewrite) entries.push([vStr("rewrite"), m.rewrite]);
  if (m.obligation) entries.push([vStr("obligation"), m.obligation]);
  // Convert Evidence[] to Val (vector of maps) if present
  if (m.evidence) {
    const evidenceItems: Val[] = m.evidence.map(e => evidenceToVal(e));
    entries.push([vStr("evidence"), { tag: "Vector", items: evidenceItems }]);
  }
  if (m.trace) entries.push([vStr("trace"), m.trace as Val]);

  return { tag: "Map", entries };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/anthropic.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/anthropic.ts
// Anthropic Claude Plugin - Real implementation with native tool calling

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, QExpr } from "../protocol";
import type { Val } from "../../eval/values";
import { meaning } from "../meaning";
import {
  registry,
  type OraclePlugin,
  type PluginCapabilities,
  type BasePluginConfig,
  type ConfigValidation,
  type HealthCheckResult,
} from "./registry";

// ═══════════════════════════════════════════════════════════════════════════
// ANTHROPIC API TYPES
// ═══════════════════════════════════════════════════════════════════════════

type AnthropicMessage = {
  role: "user" | "assistant";
  content: AnthropicContent[];
};

type AnthropicContent =
  | { type: "text"; text: string }
  | { type: "tool_use"; id: string; name: string; input: Record<string, unknown> }
  | { type: "tool_result"; tool_use_id: string; content: string };

type AnthropicTool = {
  name: string;
  description: string;
  input_schema: {
    type: "object";
    properties: Record<string, { type: string; description?: string; enum?: string[] }>;
    required?: string[];
  };
};

type AnthropicRequest = {
  model: string;
  max_tokens: number;
  system?: string;
  tools?: AnthropicTool[];
  messages: AnthropicMessage[];
};

type AnthropicResponse = {
  id: string;
  type: "message";
  role: "assistant";
  content: AnthropicContent[];
  model: string;
  stop_reason: "end_turn" | "tool_use" | "max_tokens" | "stop_sequence";
  usage: { input_tokens: number; output_tokens: number };
};

// ═══════════════════════════════════════════════════════════════════════════
// ORACLE TOOLS
// ═══════════════════════════════════════════════════════════════════════════

const ORACLE_TOOLS: AnthropicTool[] = [
  {
    name: "omega_eval",
    description: "Evaluate a Lisp expression in the Omega runtime. Returns the result value.",
    input_schema: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Lisp expression to evaluate, e.g. '(+ 1 2)' or '(define x 42)'" },
      },
      required: ["expr"],
    },
  },
  {
    name: "omega_apply",
    description: "Apply a function to arguments in the runtime.",
    input_schema: {
      type: "object",
      properties: {
        fn: { type: "string", description: "Function name or lambda expression" },
        args: { type: "string", description: "Arguments as a Lisp list, e.g. '(1 2 3)'" },
      },
      required: ["fn", "args"],
    },
  },
  {
    name: "omega_observe",
    description: "Observe runtime state for debugging or analysis.",
    input_schema: {
      type: "object",
      properties: {
        what: {
          type: "string",
          enum: ["stack", "control", "handlers", "store", "env", "env_lookup", "defs"],
          description: "What to observe: stack (call stack), control (current expression), handlers (effect handlers), store (memory), env (list all bindings), env_lookup (lookup specific binding by name), defs (list user definitions)",
        },
        name: {
          type: "string",
          description: "For env_lookup: the name of the binding to look up",
        },
      },
      required: ["what"],
    },
  },
  {
    name: "omega_match",
    description: "Pattern match an expression against a pattern with ?x binders.",
    input_schema: {
      type: "object",
      properties: {
        expr: { type: "string", description: "Expression to match" },
        pattern: { type: "string", description: "Pattern with ?x binders, e.g. '(cons ?head ?tail)'" },
      },
      required: ["expr", "pattern"],
    },
  },
  {
    name: "omega_return",
    description: "Return a final result and end the Oracle session. Call this when you have computed your answer.",
    input_schema: {
      type: "object",
      properties: {
        value: { type: "string", description: "The result value as a Lisp literal, e.g. '42' or '(list \"a\" \"b\")'" },
        confidence: { type: "string", description: "Confidence 0-1 as a decimal string, e.g. '0.95'" },
        explanation: { type: "string", description: "Brief explanation of the result (for trace)" },
      },
      required: ["value"],
    },
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// VAL CONVERSION HELPERS
// ═══════════════════════════════════════════════════════════════════════════

function valToString(v: Val): string {
  switch (v.tag) {
    case "Str": return JSON.stringify(v.s);
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Unit": return "()";
    case "Sym": return v.name;
    case "Vector": return `[${v.items.map(valToString).join(" ")}]`;
    case "Map": {
      const pairs = v.entries.map(([k, val]) => `${valToString(k)} ${valToString(val)}`);
      return `{${pairs.join(" ")}}`;
    }
    case "Pair": return `(${valToString(v.car)} . ${valToString(v.cdr)})`;
    case "Meaning": return `(meaning ${valToString(v.denotation ?? { tag: "Unit" })} :confidence ${v.confidence ?? 0})`;
    default:
      return JSON.stringify(v);
  }
}

function valToJSON(v: Val): unknown {
  switch (v.tag) {
    case "Str": return v.s;
    case "Num": return v.n;
    case "Bool": return v.b;
    case "Unit": return null;
    case "Sym": return v.name;
    case "Vector": return v.items.map(valToJSON);
    case "Map": {
      const obj: Record<string, unknown> = {};
      for (const [k, val] of v.entries) {
        const key = k.tag === "Str" ? k.s : k.tag === "Sym" ? k.name : JSON.stringify(k);
        obj[key] = valToJSON(val);
      }
      return obj;
    }
    default:
      return valToString(v);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// ANTHROPIC ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

class AnthropicOracleAdapter implements OracleAdapter {
  private apiKey: string;
  private model: string;
  private maxTokens: number;
  private systemPrompt: string;

  constructor(config: BasePluginConfig) {
    this.apiKey = config.apiKey || process.env.ANTHROPIC_API_KEY || "";
    this.model = config.model || "claude-sonnet-4-20250514";
    this.maxTokens = config.maxTokens || 4096;
    this.systemPrompt = config.systemPrompt || DEFAULT_SYSTEM_PROMPT;
  }

  startSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;
    const stateRef = init.stateRef;

    return (async function* (): OracleSession {
      // Build initial user message
      const userContent = init.tag === "Infer"
        ? `Please compute a result for the following request:\n\n${valToString(init.payload)}\n\nUse the omega_* tools to interact with the runtime, then call omega_return when done.`
        : `Apply the procedure ${valToString(init.proc)} to arguments ${init.args.map(valToString).join(" ")}.\n\nUse the omega_* tools, then call omega_return when done.`;

      const messages: AnthropicMessage[] = [
        { role: "user", content: [{ type: "text", text: userContent }] },
      ];

      // Conversation loop
      let turnCount = 0;
      const maxTurns = 20; // Safety limit

      while (turnCount < maxTurns) {
        turnCount++;

        // Call Anthropic API
        const response = await adapter.callAPI(messages);

        // Process response content
        const assistantContent = response.content;
        messages.push({ role: "assistant", content: assistantContent });

        // Check for tool use
        const toolUses = assistantContent.filter(c => c.type === "tool_use");

        if (toolUses.length === 0) {
          // No tool use - check if there's text to interpret as final answer
          const textContent = assistantContent.find(c => c.type === "text");
          if (textContent && textContent.type === "text") {
            return meaning({
              denotation: { tag: "Str", s: textContent.text },
              confidence: 0.5,
              trace: { tag: "Str", s: `anthropic:${adapter.model}:no-tool-return` },
            });
          }
          // Empty response
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "empty response from LLM" },
          });
        }

        // Process each tool use
        const toolResults: AnthropicContent[] = [];

        for (const toolUse of toolUses) {
          if (toolUse.type !== "tool_use") continue;

          const { id, name, input } = toolUse;

          // Handle omega_return specially - it ends the session
          if (name === "omega_return") {
            const valueStr = String(input.value || "()");
            const confidenceStr = String(input.confidence || "0.8");
            const explanation = String(input.explanation || "");

            return meaning({
              denotation: { tag: "Str", s: valueStr }, // Will be parsed by caller
              confidence: parseFloat(confidenceStr) || 0.8,
              trace: { tag: "Str", s: explanation || `anthropic:${adapter.model}` },
            });
          }

          // Handle other tools by yielding OracleReq
          let req: OracleReq;
          switch (name) {
            case "omega_eval":
              req = {
                tag: "ReqEval",
                qexpr: String(input.expr) as unknown as QExpr,
                envRef,
              };
              break;

            case "omega_apply":
              // Parse fn and args - simplified for now
              req = {
                tag: "ReqEval",
                qexpr: `(${input.fn} ${input.args || ""})` as unknown as QExpr,
                envRef,
              };
              break;

            case "omega_observe":
              const whatStr = String(input.what);
              let observeSpec: import("../protocol").ObserveSpec;
              switch (whatStr) {
                case "stack": observeSpec = { tag: "Stack", limit: 20 }; break;
                case "handlers": observeSpec = { tag: "Handlers" }; break;
                case "store": observeSpec = { tag: "StoreSummary" }; break;
                case "env": observeSpec = { tag: "Env" }; break;
                case "env_lookup": observeSpec = { tag: "EnvLookup", name: String(input.name || "") }; break;
                case "defs": observeSpec = { tag: "Defs" }; break;
                default: observeSpec = { tag: "Control" };
              }
              req = {
                tag: "ReqObserve",
                what: observeSpec,
                stateRef,
              };
              break;

            case "omega_match":
              req = {
                tag: "ReqMatch",
                qexpr: String(input.expr) as unknown as QExpr,
                pattern: String(input.pattern),
                envRef,
              };
              break;

            default:
              // Unknown tool - return error
              toolResults.push({
                type: "tool_result",
                tool_use_id: id,
                content: `Error: Unknown tool '${name}'`,
              });
              continue;
          }

          // Yield the request and get response
          const resp: OracleResp = yield req;

          // Convert response to tool result
          let resultContent: string;
          switch (resp.tag) {
            case "RespVal":
              resultContent = JSON.stringify(valToJSON(resp.value));
              break;
            case "RespObs":
              resultContent = JSON.stringify(resp.data);
              break;
            case "RespError":
              resultContent = `Error: ${resp.message}`;
              break;
            case "RespAck":
              resultContent = "OK";
              break;
            default:
              resultContent = JSON.stringify(resp);
          }

          toolResults.push({
            type: "tool_result",
            tool_use_id: id,
            content: resultContent,
          });
        }

        // Add tool results to conversation
        messages.push({ role: "user", content: toolResults });
      }

      // Max turns exceeded
      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `max turns (${maxTurns}) exceeded` },
      });
    })();
  }

  private async callAPI(messages: AnthropicMessage[]): Promise<AnthropicResponse> {
    const request: AnthropicRequest = {
      model: this.model,
      max_tokens: this.maxTokens,
      system: this.systemPrompt,
      tools: ORACLE_TOOLS,
      messages,
    };

    const response = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-api-key": this.apiKey,
        "anthropic-version": "2023-06-01",
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Anthropic API error: ${response.status} ${errorText}`);
    }

    return await response.json() as AnthropicResponse;
  }
}

const DEFAULT_SYSTEM_PROMPT = `You are an Oracle for the Omega Lisp runtime. Your job is to compute results for inference requests.

You have access to the Omega runtime through tools:
- omega_eval: Evaluate Lisp expressions
- omega_apply: Apply functions to arguments
- omega_observe: Observe runtime state (stack, control, handlers, store)
- omega_match: Pattern match expressions
- omega_return: Return your final answer (MUST call this when done)

When given a task:
1. Think about what computations or lookups you need
2. Use omega_eval to run Lisp code as needed
3. Use omega_observe if you need to understand the current state
4. When you have your answer, call omega_return with the result

You can use your world knowledge for factual questions, but express your confidence level.
For computations, always verify with omega_eval when possible.

IMPORTANT: You MUST call omega_return when you have your final answer.`;

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN DEFINITION
// ═══════════════════════════════════════════════════════════════════════════

const anthropicPlugin: OraclePlugin = {
  id: "anthropic",
  name: "Anthropic Claude",

  capabilities: {
    oracleProtocol: {
      reqEval: true,
      reqApply: true,
      reqObserve: true,
      reqMatch: true,
      reqAssert: true,
    },
    tooling: {
      native: true,
      format: "anthropic",
      maxTools: 64,
    },
    mcp: {
      client: true,  // Claude can use MCP servers
      server: false,
    },
    session: {
      multiTurn: true,
      streaming: true,
      maxContext: 200_000,
    },
    io: {
      vision: true,
      audio: false,
      structuredOutput: true,
    },
  },

  supportedModels: [
    "claude-sonnet-4-20250514",
    "claude-opus-4-20250514",
    "claude-3-5-sonnet",
    "claude-3-5-haiku",
    "claude-3-opus",
    "claude-3-sonnet",
    "claude-3-haiku",
    "claude-*", // Wildcard for future models
  ],

  defaultModel: "claude-sonnet-4-20250514",

  validateConfig(config: BasePluginConfig): ConfigValidation {
    const apiKey = config.apiKey || process.env.ANTHROPIC_API_KEY;
    if (!apiKey) {
      return {
        valid: false,
        errors: ["Missing API key: set ANTHROPIC_API_KEY environment variable or pass apiKey in config"],
      };
    }
    return { valid: true };
  },

  createAdapter(config: BasePluginConfig): OracleAdapter {
    return new AnthropicOracleAdapter({
      ...config,
      model: config.model || this.defaultModel,
    });
  },

  async healthCheck(): Promise<HealthCheckResult> {
    const apiKey = process.env.ANTHROPIC_API_KEY;
    if (!apiKey) {
      return { ok: false, message: "ANTHROPIC_API_KEY not set" };
    }

    const start = Date.now();
    try {
      // Simple API call to check connectivity
      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "x-api-key": apiKey,
          "anthropic-version": "2023-06-01",
        },
        body: JSON.stringify({
          model: "claude-3-haiku-20240307",
          max_tokens: 10,
          messages: [{ role: "user", content: "ping" }],
        }),
      });

      const latencyMs = Date.now() - start;

      if (response.ok) {
        return { ok: true, message: "API reachable", latencyMs };
      } else if (response.status === 401) {
        return { ok: false, message: "Invalid API key" };
      } else {
        return { ok: false, message: `API error: ${response.status}` };
      }
    } catch (err) {
      return {
        ok: false,
        message: `Connection failed: ${err instanceof Error ? err.message : String(err)}`,
      };
    }
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// AUTO-REGISTER
// ═══════════════════════════════════════════════════════════════════════════

registry.register(anthropicPlugin);

export { anthropicPlugin, AnthropicOracleAdapter };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/index.ts
// Plugin System - exports and auto-registration

// Core registry (must be imported first)
export {
  registry,
  PluginRegistry,
  createAdapterFromModel,
  getDefaultAdapter,
  type OraclePlugin,
  type PluginCapabilities,
  type CapabilityFilter,
  type ProtocolCaps,
  type ToolingCaps,
  type MCPCaps,
  type SessionCaps,
  type IOCaps,
  type BasePluginConfig,
  type ConfigValidation,
  type HealthCheckResult,
  type PluginSummary,
} from "./registry";

// Import plugins to trigger auto-registration
import "./anthropic";
import "./openai";
import "./ollama";

// Re-export plugin classes for direct use
export { anthropicPlugin, AnthropicOracleAdapter } from "./anthropic";
export { openaiPlugin, OpenAIOracleAdapter } from "./openai";
export { ollamaPlugin, OllamaOracleAdapter, modelSupportsTools } from "./ollama";

// Model selection
export {
  ModelSelectorAdapter,
  createModelSelector,
  createPluginSelector,
  withModel,
  withPlugin,
  parseModelSpec,
  type ModelConfig,
} from "./modelSelector";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/modelSelector.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/modelSelector.ts
// Model Selection - Lisp-level model specification with default + per-call override

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp } from "../protocol";
import type { MeaningVal } from "../meaning";
import type { Val } from "../../eval/values";
import { registry as globalRegistry, type PluginRegistry, type BasePluginConfig } from "./registry";

// ═══════════════════════════════════════════════════════════════════════════
// MODEL CONFIGURATION
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Model configuration for the selector
 */
export type ModelConfig = {
  /** Default model to use when not specified */
  defaultModel: string;
  /** Default plugin to use when model doesn't specify */
  defaultPlugin?: string;
  /** Shared config for all adapters */
  sharedConfig?: Partial<BasePluginConfig>;
  /** Per-model config overrides */
  modelConfigs?: Record<string, Partial<BasePluginConfig>>;
  /** Custom registry (for testing), defaults to global registry */
  registry?: PluginRegistry;
};

/**
 * Parse model specification from Val payload
 *
 * Supports multiple formats:
 * - `(infer "question")` → use default model
 * - `(infer {:model "gpt-4o" :payload "question"})` → use specified model
 * - `(infer {:plugin "anthropic" :model "claude-3-opus" :payload "question"})` → explicit plugin
 * - `(infer {:model "anthropic:claude-3-opus" :payload "question"})` → plugin:model format
 */
function parseModelSpec(payload: Val): { model?: string; plugin?: string; actualPayload: Val } {
  if (payload.tag !== "Map") {
    // Simple payload - use default
    return { actualPayload: payload };
  }

  // Look for model/plugin keys in the map
  let model: string | undefined;
  let plugin: string | undefined;
  let actualPayload: Val = payload;

  for (const [k, v] of payload.entries) {
    const key = k.tag === "Str" ? k.s : k.tag === "Sym" ? k.name : null;

    if (key === "model" && v.tag === "Str") {
      model = v.s;
    } else if (key === "plugin" && v.tag === "Str") {
      plugin = v.s;
    } else if (key === "payload") {
      actualPayload = v;
    }
  }

  // If model contains ":", parse as plugin:model
  if (model && model.includes(":")) {
    const [p, m] = model.split(":", 2);
    plugin = plugin || p;
    model = m;
  }

  return { model, plugin, actualPayload };
}

// ═══════════════════════════════════════════════════════════════════════════
// MODEL SELECTOR ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

/**
 * ModelSelectorAdapter - Routes to appropriate adapter based on model specification
 *
 * Usage:
 * ```typescript
 * const selector = new ModelSelectorAdapter({
 *   defaultModel: "claude-sonnet-4-20250514",
 *   defaultPlugin: "anthropic",
 *   sharedConfig: { maxTokens: 4096 },
 * });
 *
 * const runtime = new RuntimeImpl(selector, snapshots, receipts, commit);
 *
 * // In Lisp:
 * (infer "question")                                    ; uses default
 * (infer {:model "gpt-4o" :payload "question"})         ; uses gpt-4o
 * (infer {:model "openai:gpt-4o" :payload "question"})  ; explicit plugin
 * ```
 */
export class ModelSelectorAdapter implements OracleAdapter {
  private config: ModelConfig;
  private adapterCache = new Map<string, OracleAdapter>();
  private registry: PluginRegistry;

  constructor(config: ModelConfig) {
    this.config = config;
    this.registry = config.registry || globalRegistry;
  }

  startSession(init: OracleInit): OracleSession {
    const selector = this;

    return (async function* (): OracleSession {
      // Extract model specification from payload
      const payload = init.tag === "Infer" ? init.payload : { tag: "Unit" as const };
      const { model, plugin, actualPayload } = parseModelSpec(payload);

      // Resolve which adapter to use
      const adapter = selector.getOrCreateAdapter(model, plugin);

      // Create modified init with actual payload
      const modifiedInit: OracleInit = init.tag === "Infer"
        ? { ...init, payload: actualPayload }
        : init;

      // Delegate to the resolved adapter
      const session = adapter.startSession(modifiedInit);

      // Passthrough the coroutine
      let resp: OracleResp = { tag: "RespAck" };
      while (true) {
        const step = await session.next(resp);
        if (step.done) {
          return step.value;
        }
        resp = yield step.value as OracleReq;
      }
    })();
  }

  /**
   * Get or create an adapter for the given model/plugin
   */
  private getOrCreateAdapter(model?: string, plugin?: string): OracleAdapter {
    // Use defaults if not specified
    const resolvedModel = model || this.config.defaultModel;
    const resolvedPlugin = plugin || this.config.defaultPlugin;

    // Build cache key
    const cacheKey = resolvedPlugin
      ? `${resolvedPlugin}:${resolvedModel}`
      : resolvedModel;

    // Check cache
    let adapter = this.adapterCache.get(cacheKey);
    if (adapter) return adapter;

    // Build config for this adapter
    const adapterConfig: BasePluginConfig = {
      ...this.config.sharedConfig,
      ...this.config.modelConfigs?.[resolvedModel],
      model: resolvedModel,
    };

    // Create adapter
    if (resolvedPlugin) {
      const pluginObj = this.registry.get(resolvedPlugin);
      if (!pluginObj) {
        throw new Error(`Unknown plugin: ${resolvedPlugin}`);
      }
      adapter = pluginObj.createAdapter(adapterConfig);
    } else {
      // Auto-detect plugin from model name
      const candidates = this.registry.findByModel(resolvedModel);
      if (candidates.length === 0) {
        throw new Error(`No plugin found for model: ${resolvedModel}`);
      }
      adapter = candidates[0].createAdapter(adapterConfig);
    }

    // Cache and return
    this.adapterCache.set(cacheKey, adapter);
    return adapter;
  }

  /**
   * Clear the adapter cache (useful for testing)
   */
  clearCache(): void {
    this.adapterCache.clear();
  }

  /**
   * Get the current config
   */
  getConfig(): ModelConfig {
    return { ...this.config };
  }

  /**
   * Update the default model
   */
  setDefaultModel(model: string): void {
    this.config.defaultModel = model;
  }

  /**
   * Update the default plugin
   */
  setDefaultPlugin(plugin: string): void {
    this.config.defaultPlugin = plugin;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// LISP PRIMITIVES FOR MODEL SELECTION
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Helper to build a model-specified inference payload
 *
 * In Lisp, you'd use:
 *   (infer (with-model "gpt-4o" "my question"))
 *
 * This helper builds the map structure for that.
 */
export function withModel(model: string, payload: Val): Val {
  return {
    tag: "Map",
    entries: [
      [{ tag: "Str", s: "model" }, { tag: "Str", s: model }],
      [{ tag: "Str", s: "payload" }, payload],
    ],
  };
}

/**
 * Helper to build a plugin-specified inference payload
 *
 * In Lisp:
 *   (infer (with-plugin "anthropic" "claude-3-opus" "my question"))
 */
export function withPlugin(plugin: string, model: string, payload: Val): Val {
  return {
    tag: "Map",
    entries: [
      [{ tag: "Str", s: "plugin" }, { tag: "Str", s: plugin }],
      [{ tag: "Str", s: "model" }, { tag: "Str", s: model }],
      [{ tag: "Str", s: "payload" }, payload],
    ],
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FACTORY FUNCTIONS
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Create a model selector with sensible defaults
 *
 * Tries to detect which plugins are available and picks a good default.
 */
export function createModelSelector(overrides?: Partial<ModelConfig>): ModelSelectorAdapter {
  // Try to find a working plugin
  const registry = overrides?.registry ?? globalRegistry;
  let defaultPlugin: string | undefined;
  let defaultModel: string;

  if (registry.has("anthropic") && process.env.ANTHROPIC_API_KEY) {
    defaultPlugin = "anthropic";
    defaultModel = "claude-sonnet-4-20250514";
  } else if (registry.has("openai") && process.env.OPENAI_API_KEY) {
    defaultPlugin = "openai";
    defaultModel = "gpt-4o";
  } else if (registry.has("ollama")) {
    defaultPlugin = "ollama";
    defaultModel = "llama3.1";
  } else {
    // Fallback - will error at runtime if no plugins available
    defaultModel = "claude-sonnet-4-20250514";
  }

  return new ModelSelectorAdapter({
    defaultModel: overrides?.defaultModel || defaultModel,
    defaultPlugin: overrides?.defaultPlugin || defaultPlugin,
    sharedConfig: overrides?.sharedConfig,
    modelConfigs: overrides?.modelConfigs,
    registry,
  });
}

/**
 * Create a model selector for a specific plugin
 */
export function createPluginSelector(
  pluginId: string,
  model?: string,
  config?: Partial<BasePluginConfig> & { registry?: PluginRegistry }
): ModelSelectorAdapter {
  const registry = config?.registry ?? globalRegistry;
  const plugin = registry.get(pluginId);
  if (!plugin) {
    throw new Error(`Unknown plugin: ${pluginId}`);
  }

  return new ModelSelectorAdapter({
    defaultModel: model || plugin.defaultModel,
    defaultPlugin: pluginId,
    sharedConfig: config,
  });
}

export { parseModelSpec };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/ollama.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/ollama.ts
// Ollama Plugin - Local models with optional tool calling

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, QExpr } from "../protocol";
import type { Val } from "../../eval/values";
import { meaning } from "../meaning";
import {
  registry,
  type OraclePlugin,
  type PluginCapabilities,
  type BasePluginConfig,
  type ConfigValidation,
  type HealthCheckResult,
} from "./registry";

// ═══════════════════════════════════════════════════════════════════════════
// OLLAMA API TYPES
// ═══════════════════════════════════════════════════════════════════════════

type OllamaMessage = {
  role: "system" | "user" | "assistant" | "tool";
  content: string;
  tool_calls?: OllamaToolCall[];
};

type OllamaToolCall = {
  function: {
    name: string;
    arguments: Record<string, unknown>;
  };
};

type OllamaTool = {
  type: "function";
  function: {
    name: string;
    description: string;
    parameters: {
      type: "object";
      properties: Record<string, { type: string; description?: string; enum?: string[] }>;
      required?: string[];
    };
  };
};

type OllamaRequest = {
  model: string;
  messages: OllamaMessage[];
  stream: false;
  tools?: OllamaTool[];
  options?: {
    temperature?: number;
    num_predict?: number;
  };
};

type OllamaResponse = {
  model: string;
  message: OllamaMessage;
  done: boolean;
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
  eval_count?: number;
};

// Models known to support tool calling
const TOOL_CAPABLE_MODELS = [
  "llama3.1",
  "llama3.2",
  "llama3.3",
  "mistral",
  "mixtral",
  "qwen2",
  "qwen2.5",
  "command-r",
  "firefunction",
];

function modelSupportsTools(model: string): boolean {
  return TOOL_CAPABLE_MODELS.some(m => model.toLowerCase().includes(m));
}

// ═══════════════════════════════════════════════════════════════════════════
// ORACLE TOOLS (Ollama format - same as OpenAI)
// ═══════════════════════════════════════════════════════════════════════════

const ORACLE_TOOLS: OllamaTool[] = [
  {
    type: "function",
    function: {
      name: "omega_eval",
      description: "Evaluate a Lisp expression in the Omega runtime. Returns the result value.",
      parameters: {
        type: "object",
        properties: {
          expr: { type: "string", description: "Lisp expression to evaluate" },
        },
        required: ["expr"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "omega_return",
      description: "Return a final result and end the session.",
      parameters: {
        type: "object",
        properties: {
          value: { type: "string", description: "The result value as a Lisp literal" },
          confidence: { type: "string", description: "Confidence 0-1" },
        },
        required: ["value"],
      },
    },
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// VAL CONVERSION HELPERS
// ═══════════════════════════════════════════════════════════════════════════

function valToString(v: Val): string {
  switch (v.tag) {
    case "Str": return JSON.stringify(v.s);
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Unit": return "()";
    case "Sym": return v.name;
    case "Vector": return `[${v.items.map(valToString).join(" ")}]`;
    case "Map": {
      const pairs = v.entries.map(([k, val]) => `${valToString(k)} ${valToString(val)}`);
      return `{${pairs.join(" ")}}`;
    }
    default:
      return JSON.stringify(v);
  }
}

function valToJSON(v: Val): unknown {
  switch (v.tag) {
    case "Str": return v.s;
    case "Num": return v.n;
    case "Bool": return v.b;
    case "Unit": return null;
    case "Sym": return v.name;
    case "Vector": return v.items.map(valToJSON);
    case "Map": {
      const obj: Record<string, unknown> = {};
      for (const [k, val] of v.entries) {
        const key = k.tag === "Str" ? k.s : k.tag === "Sym" ? k.name : JSON.stringify(k);
        obj[key] = valToJSON(val);
      }
      return obj;
    }
    default:
      return valToString(v);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// TEXT-BASED PROTOCOL (fallback for models without tool support)
// ═══════════════════════════════════════════════════════════════════════════

const TEXT_PROTOCOL_SYSTEM = `You are an Oracle for the Omega Lisp runtime.

When you need to evaluate Lisp code, use this format:
EVAL: (expression here)

When you have your final answer, use this format:
RETURN: value | confidence

Example:
User: What is 2 + 2?
Assistant: Let me evaluate that.
EVAL: (+ 2 2)
[System returns: 4]
RETURN: 4 | 0.99

Important:
- Use EVAL: to run Lisp code
- Use RETURN: to give your final answer with confidence (0-1)
- You can use multiple EVAL: calls before RETURN:`;

function parseTextProtocol(text: string): { type: "eval"; expr: string } | { type: "return"; value: string; confidence: number } | null {
  // Check for RETURN: pattern
  const returnMatch = text.match(/RETURN:\s*(.+?)\s*\|\s*([\d.]+)/);
  if (returnMatch) {
    return {
      type: "return",
      value: returnMatch[1].trim(),
      confidence: parseFloat(returnMatch[2]) || 0.5,
    };
  }

  // Check for EVAL: pattern
  const evalMatch = text.match(/EVAL:\s*(.+?)(?:\n|$)/);
  if (evalMatch) {
    return {
      type: "eval",
      expr: evalMatch[1].trim(),
    };
  }

  return null;
}

// ═══════════════════════════════════════════════════════════════════════════
// STREAMING HELPERS
// ═══════════════════════════════════════════════════════════════════════════

type OllamaStreamChunk = {
  model: string;
  message: {
    role: string;
    content: string;
    tool_calls?: OllamaToolCall[];
  };
  done: boolean;
};

/**
 * Parse NDJSON stream from Ollama API
 */
async function* parseOllamaStream(response: Response): AsyncGenerator<OllamaStreamChunk> {
  const reader = response.body!.getReader();
  const decoder = new TextDecoder();
  let buffer = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split("\n");
    buffer = lines.pop() || "";  // Keep incomplete line in buffer

    for (const line of lines) {
      const trimmed = line.trim();
      if (!trimmed) continue;

      try {
        yield JSON.parse(trimmed) as OllamaStreamChunk;
      } catch {
        // Skip malformed JSON
      }
    }
  }

  // Process any remaining buffer
  if (buffer.trim()) {
    try {
      yield JSON.parse(buffer.trim()) as OllamaStreamChunk;
    } catch {
      // Skip malformed JSON
    }
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// OLLAMA ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

class OllamaOracleAdapter implements OracleAdapter {
  private model: string;
  private baseUrl: string;
  private useTools: boolean;
  private maxTokens: number;
  private temperature: number;
  private streaming: boolean;

  constructor(config: BasePluginConfig) {
    this.model = config.model || "llama3.1";
    this.baseUrl = config.baseUrl || "http://localhost:11434";
    this.useTools = modelSupportsTools(this.model);
    this.maxTokens = config.maxTokens || 2048;
    this.temperature = config.temperature || 0.7;
    this.streaming = config.streaming || false;
  }

  startSession(init: OracleInit): OracleSession {
    if (this.streaming) {
      // Streaming mode
      if (this.useTools) {
        return this.startStreamingToolSession(init);
      } else {
        return this.startStreamingTextSession(init);
      }
    } else {
      // Blocking mode
      if (this.useTools) {
        return this.startToolSession(init);
      } else {
        return this.startTextSession(init);
      }
    }
  }

  // ─────────────────────────────────────────────────────────────────────────
  // STREAMING TOOL SESSION
  // ─────────────────────────────────────────────────────────────────────────

  private startStreamingToolSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;

    return (async function* (): OracleSession {
      const userContent = init.tag === "Infer"
        ? `Compute a result for: ${valToString(init.payload)}\n\nUse omega_eval to run Lisp code, then call omega_return with your answer.`
        : `Apply ${valToString(init.proc)} to ${init.args.map(valToString).join(" ")}`;

      const messages: OllamaMessage[] = [
        { role: "system", content: "You are an Oracle for a Lisp runtime. Use the tools to evaluate expressions and return results." },
        { role: "user", content: userContent },
      ];

      let turnCount = 0;
      const maxTurns = 15;

      while (turnCount < maxTurns) {
        turnCount++;

        const response = await fetch(`${adapter.baseUrl}/api/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            model: adapter.model,
            messages,
            stream: true,  // ← STREAMING ENABLED
            tools: ORACLE_TOOLS,
            options: {
              temperature: adapter.temperature,
              num_predict: adapter.maxTokens,
            },
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `Ollama API error: ${err}` },
          });
        }

        // Accumulate streaming chunks
        let contentBuffer = "";
        let toolCalls: OllamaToolCall[] = [];

        for await (const chunk of parseOllamaStream(response)) {
          if (chunk.message.content) {
            contentBuffer += chunk.message.content;
          }
          if (chunk.message.tool_calls) {
            toolCalls = chunk.message.tool_calls;  // Ollama sends complete tool calls
          }
        }

        // Build assistant message
        const msg: OllamaMessage = {
          role: "assistant",
          content: contentBuffer,
          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
        };
        messages.push(msg);

        if (toolCalls.length === 0) {
          return meaning({
            denotation: { tag: "Str", s: contentBuffer || "" },
            confidence: 0.5,
            trace: { tag: "Str", s: `ollama:${adapter.model}:streaming:text-only` },
          });
        }

        for (const toolCall of toolCalls) {
          const { name, arguments: args } = toolCall.function;

          if (name === "omega_return") {
            return meaning({
              denotation: { tag: "Str", s: String(args.value || "") },
              confidence: parseFloat(String(args.confidence || "0.7")) || 0.7,
              trace: { tag: "Str", s: `ollama:${adapter.model}:streaming` },
            });
          }

          if (name === "omega_eval") {
            const req: OracleReq = {
              tag: "ReqEval",
              qexpr: String(args.expr) as unknown as QExpr,
              envRef,
            };

            const resp: OracleResp = yield req;

            let result: string;
            if (resp.tag === "RespVal") {
              result = JSON.stringify(valToJSON(resp.value));
            } else if (resp.tag === "RespError") {
              result = `Error: ${resp.message}`;
            } else {
              result = JSON.stringify(resp);
            }

            messages.push({ role: "tool", content: result });
          }
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: "max turns exceeded (streaming)" },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // STREAMING TEXT SESSION (for models without tool support)
  // ─────────────────────────────────────────────────────────────────────────

  private startStreamingTextSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;

    return (async function* (): OracleSession {
      const userContent = init.tag === "Infer"
        ? `Compute a result for: ${valToString(init.payload)}`
        : `Apply ${valToString(init.proc)} to ${init.args.map(valToString).join(" ")}`;

      const messages: OllamaMessage[] = [
        { role: "system", content: TEXT_PROTOCOL_SYSTEM },
        { role: "user", content: userContent },
      ];

      let turnCount = 0;
      const maxTurns = 15;

      while (turnCount < maxTurns) {
        turnCount++;

        const response = await fetch(`${adapter.baseUrl}/api/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            model: adapter.model,
            messages,
            stream: true,  // ← STREAMING ENABLED
            options: {
              temperature: adapter.temperature,
              num_predict: adapter.maxTokens,
            },
          }),
        });

        if (!response.ok) {
          const err = await response.text();
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: `Ollama API error: ${err}` },
          });
        }

        // Accumulate streaming chunks
        let contentBuffer = "";
        for await (const chunk of parseOllamaStream(response)) {
          if (chunk.message.content) {
            contentBuffer += chunk.message.content;
          }
        }

        messages.push({ role: "assistant", content: contentBuffer });

        const parsed = parseTextProtocol(contentBuffer);

        if (!parsed) {
          return meaning({
            denotation: { tag: "Str", s: contentBuffer },
            confidence: 0.3,
            trace: { tag: "Str", s: `ollama:${adapter.model}:streaming:raw-text` },
          });
        }

        if (parsed.type === "return") {
          return meaning({
            denotation: { tag: "Str", s: parsed.value },
            confidence: parsed.confidence,
            trace: { tag: "Str", s: `ollama:${adapter.model}:streaming:text-protocol` },
          });
        }

        if (parsed.type === "eval") {
          const req: OracleReq = {
            tag: "ReqEval",
            qexpr: parsed.expr as unknown as QExpr,
            envRef,
          };

          const resp: OracleResp = yield req;

          let result: string;
          if (resp.tag === "RespVal") {
            result = JSON.stringify(valToJSON(resp.value));
          } else if (resp.tag === "RespError") {
            result = `Error: ${resp.message}`;
          } else {
            result = JSON.stringify(resp);
          }

          messages.push({ role: "user", content: `[Eval result: ${result}]` });
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: "max turns exceeded (streaming)" },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // BLOCKING TOOL SESSION (original implementation)
  // ─────────────────────────────────────────────────────────────────────────

  private startToolSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;

    return (async function* (): OracleSession {
      const userContent = init.tag === "Infer"
        ? `Compute a result for: ${valToString(init.payload)}\n\nUse omega_eval to run Lisp code, then call omega_return with your answer.`
        : `Apply ${valToString(init.proc)} to ${init.args.map(valToString).join(" ")}`;

      const messages: OllamaMessage[] = [
        { role: "system", content: "You are an Oracle for a Lisp runtime. Use the tools to evaluate expressions and return results." },
        { role: "user", content: userContent },
      ];

      let turnCount = 0;
      const maxTurns = 15;

      while (turnCount < maxTurns) {
        turnCount++;

        const response = await adapter.callAPI(messages, true);
        const msg = response.message;
        messages.push(msg);

        const toolCalls = msg.tool_calls || [];

        if (toolCalls.length === 0) {
          return meaning({
            denotation: { tag: "Str", s: msg.content || "" },
            confidence: 0.5,
            trace: { tag: "Str", s: `ollama:${adapter.model}:text-only` },
          });
        }

        for (const toolCall of toolCalls) {
          const { name, arguments: args } = toolCall.function;

          if (name === "omega_return") {
            return meaning({
              denotation: { tag: "Str", s: String(args.value || "") },
              confidence: parseFloat(String(args.confidence || "0.7")) || 0.7,
              trace: { tag: "Str", s: `ollama:${adapter.model}` },
            });
          }

          if (name === "omega_eval") {
            const req: OracleReq = {
              tag: "ReqEval",
              qexpr: String(args.expr) as unknown as QExpr,
              envRef,
            };

            const resp: OracleResp = yield req;

            let result: string;
            if (resp.tag === "RespVal") {
              result = JSON.stringify(valToJSON(resp.value));
            } else if (resp.tag === "RespError") {
              result = `Error: ${resp.message}`;
            } else {
              result = JSON.stringify(resp);
            }

            messages.push({ role: "tool", content: result });
          }
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: "max turns exceeded" },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // BLOCKING TEXT SESSION (for models without tool support)
  // ─────────────────────────────────────────────────────────────────────────

  private startTextSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;

    return (async function* (): OracleSession {
      const userContent = init.tag === "Infer"
        ? `Compute a result for: ${valToString(init.payload)}`
        : `Apply ${valToString(init.proc)} to ${init.args.map(valToString).join(" ")}`;

      const messages: OllamaMessage[] = [
        { role: "system", content: TEXT_PROTOCOL_SYSTEM },
        { role: "user", content: userContent },
      ];

      let turnCount = 0;
      const maxTurns = 15;

      while (turnCount < maxTurns) {
        turnCount++;

        const response = await adapter.callAPI(messages, false);
        const content = response.message.content;
        messages.push({ role: "assistant", content });

        const parsed = parseTextProtocol(content);

        if (!parsed) {
          return meaning({
            denotation: { tag: "Str", s: content },
            confidence: 0.3,
            trace: { tag: "Str", s: `ollama:${adapter.model}:raw-text` },
          });
        }

        if (parsed.type === "return") {
          return meaning({
            denotation: { tag: "Str", s: parsed.value },
            confidence: parsed.confidence,
            trace: { tag: "Str", s: `ollama:${adapter.model}:text-protocol` },
          });
        }

        if (parsed.type === "eval") {
          const req: OracleReq = {
            tag: "ReqEval",
            qexpr: parsed.expr as unknown as QExpr,
            envRef,
          };

          const resp: OracleResp = yield req;

          let result: string;
          if (resp.tag === "RespVal") {
            result = JSON.stringify(valToJSON(resp.value));
          } else if (resp.tag === "RespError") {
            result = `Error: ${resp.message}`;
          } else {
            result = JSON.stringify(resp);
          }

          messages.push({ role: "user", content: `[Eval result: ${result}]` });
        }
      }

      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: "max turns exceeded" },
      });
    })();
  }

  // ─────────────────────────────────────────────────────────────────────────
  // BLOCKING API CALL
  // ─────────────────────────────────────────────────────────────────────────

  private async callAPI(messages: OllamaMessage[], useTools: boolean): Promise<OllamaResponse> {
    const request: OllamaRequest = {
      model: this.model,
      messages,
      stream: false,
      options: {
        temperature: this.temperature,
        num_predict: this.maxTokens,
      },
    };

    if (useTools) {
      request.tools = ORACLE_TOOLS;
    }

    const response = await fetch(`${this.baseUrl}/api/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Ollama API error: ${response.status} ${errorText}`);
    }

    return await response.json() as OllamaResponse;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN DEFINITION
// ═══════════════════════════════════════════════════════════════════════════

const ollamaPlugin: OraclePlugin = {
  id: "ollama",
  name: "Ollama Local",

  capabilities: {
    oracleProtocol: {
      reqEval: true,
      reqApply: true,
      reqObserve: false, // Not reliable via text protocol
      reqMatch: false,
      reqAssert: false,
    },
    tooling: {
      native: false, // Model-dependent, conservative default
      format: "ollama",
    },
    mcp: {
      client: false,
      server: false,
    },
    session: {
      multiTurn: true,
      streaming: true,
      maxContext: 8192, // Conservative default, model-dependent
    },
    io: {
      vision: false, // Model-dependent
      audio: false,
      structuredOutput: false,
    },
  },

  supportedModels: [
    "llama3.1",
    "llama3.2",
    "llama3.3",
    "llama2",
    "mistral",
    "mixtral",
    "codellama",
    "phi",
    "phi3",
    "qwen",
    "qwen2",
    "gemma",
    "gemma2",
    "*", // Any model name
  ],

  defaultModel: "llama3.1",

  validateConfig(config: BasePluginConfig): ConfigValidation {
    // No API key needed for local Ollama
    return { valid: true };
  },

  createAdapter(config: BasePluginConfig): OracleAdapter {
    return new OllamaOracleAdapter({
      ...config,
      model: config.model || this.defaultModel,
    });
  },

  async healthCheck(): Promise<HealthCheckResult> {
    const baseUrl = process.env.OLLAMA_HOST || "http://localhost:11434";
    const start = Date.now();

    try {
      const response = await fetch(`${baseUrl}/api/tags`);
      const latencyMs = Date.now() - start;

      if (response.ok) {
        const data = await response.json() as { models?: unknown[] };
        const modelCount = data.models?.length || 0;
        return {
          ok: true,
          message: `Ollama running with ${modelCount} models`,
          latencyMs,
        };
      } else {
        return { ok: false, message: `Ollama error: ${response.status}` };
      }
    } catch (err) {
      return {
        ok: false,
        message: `Ollama not reachable at ${baseUrl}: ${err instanceof Error ? err.message : String(err)}`,
      };
    }
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// AUTO-REGISTER
// ═══════════════════════════════════════════════════════════════════════════

registry.register(ollamaPlugin);

export { ollamaPlugin, OllamaOracleAdapter, modelSupportsTools };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/openai.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/openai.ts
// OpenAI Plugin - Real implementation with function calling

import type { OracleAdapter, OracleInit } from "../adapter";
import type { OracleSession, OracleReq, OracleResp, QExpr } from "../protocol";
import type { Val } from "../../eval/values";
import { meaning } from "../meaning";
import {
  registry,
  type OraclePlugin,
  type PluginCapabilities,
  type BasePluginConfig,
  type ConfigValidation,
  type HealthCheckResult,
} from "./registry";

// ═══════════════════════════════════════════════════════════════════════════
// OPENAI API TYPES
// ═══════════════════════════════════════════════════════════════════════════

type OpenAIMessage = {
  role: "system" | "user" | "assistant" | "tool";
  content: string | null;
  tool_calls?: OpenAIToolCall[];
  tool_call_id?: string;
};

type OpenAIToolCall = {
  id: string;
  type: "function";
  function: {
    name: string;
    arguments: string; // JSON string
  };
};

type OpenAITool = {
  type: "function";
  function: {
    name: string;
    description: string;
    parameters: {
      type: "object";
      properties: Record<string, { type: string; description?: string; enum?: string[] }>;
      required?: string[];
    };
  };
};

type OpenAIRequest = {
  model: string;
  max_tokens?: number;
  messages: OpenAIMessage[];
  tools?: OpenAITool[];
  tool_choice?: "auto" | "none" | { type: "function"; function: { name: string } };
};

type OpenAIResponse = {
  id: string;
  object: "chat.completion";
  choices: Array<{
    index: number;
    message: OpenAIMessage;
    finish_reason: "stop" | "tool_calls" | "length" | "content_filter";
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
};

// ═══════════════════════════════════════════════════════════════════════════
// ORACLE TOOLS (OpenAI format)
// ═══════════════════════════════════════════════════════════════════════════

const ORACLE_TOOLS: OpenAITool[] = [
  {
    type: "function",
    function: {
      name: "omega_eval",
      description: "Evaluate a Lisp expression in the Omega runtime. Returns the result value.",
      parameters: {
        type: "object",
        properties: {
          expr: { type: "string", description: "Lisp expression to evaluate, e.g. '(+ 1 2)' or '(define x 42)'" },
        },
        required: ["expr"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "omega_apply",
      description: "Apply a function to arguments in the runtime.",
      parameters: {
        type: "object",
        properties: {
          fn: { type: "string", description: "Function name or lambda expression" },
          args: { type: "string", description: "Arguments as a Lisp list, e.g. '(1 2 3)'" },
        },
        required: ["fn", "args"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "omega_observe",
      description: "Observe runtime state for debugging or analysis.",
      parameters: {
        type: "object",
        properties: {
          what: {
            type: "string",
            enum: ["stack", "control", "handlers", "store", "env", "env_lookup", "defs"],
            description: "What to observe: stack (call stack), control (current expression), handlers (effect handlers), store (memory), env (list all bindings), env_lookup (lookup specific binding by name), defs (list user definitions)",
          },
          name: {
            type: "string",
            description: "For env_lookup: the name of the binding to look up",
          },
        },
        required: ["what"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "omega_match",
      description: "Pattern match an expression against a pattern with ?x binders.",
      parameters: {
        type: "object",
        properties: {
          expr: { type: "string", description: "Expression to match" },
          pattern: { type: "string", description: "Pattern with ?x binders, e.g. '(cons ?head ?tail)'" },
        },
        required: ["expr", "pattern"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "omega_return",
      description: "Return a final result and end the Oracle session. Call this when you have computed your answer.",
      parameters: {
        type: "object",
        properties: {
          value: { type: "string", description: "The result value as a Lisp literal, e.g. '42' or '(list \"a\" \"b\")'" },
          confidence: { type: "string", description: "Confidence 0-1 as a decimal string, e.g. '0.95'" },
          explanation: { type: "string", description: "Brief explanation of the result (for trace)" },
        },
        required: ["value"],
      },
    },
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// VAL CONVERSION HELPERS
// ═══════════════════════════════════════════════════════════════════════════

function valToString(v: Val): string {
  switch (v.tag) {
    case "Str": return JSON.stringify(v.s);
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Unit": return "()";
    case "Sym": return v.name;
    case "Vector": return `[${v.items.map(valToString).join(" ")}]`;
    case "Map": {
      const pairs = v.entries.map(([k, val]) => `${valToString(k)} ${valToString(val)}`);
      return `{${pairs.join(" ")}}`;
    }
    case "Pair": return `(${valToString(v.car)} . ${valToString(v.cdr)})`;
    case "Meaning": return `(meaning ${valToString(v.denotation ?? { tag: "Unit" })} :confidence ${v.confidence ?? 0})`;
    default:
      return JSON.stringify(v);
  }
}

function valToJSON(v: Val): unknown {
  switch (v.tag) {
    case "Str": return v.s;
    case "Num": return v.n;
    case "Bool": return v.b;
    case "Unit": return null;
    case "Sym": return v.name;
    case "Vector": return v.items.map(valToJSON);
    case "Map": {
      const obj: Record<string, unknown> = {};
      for (const [k, val] of v.entries) {
        const key = k.tag === "Str" ? k.s : k.tag === "Sym" ? k.name : JSON.stringify(k);
        obj[key] = valToJSON(val);
      }
      return obj;
    }
    default:
      return valToString(v);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// OPENAI ADAPTER
// ═══════════════════════════════════════════════════════════════════════════

class OpenAIOracleAdapter implements OracleAdapter {
  private apiKey: string;
  private model: string;
  private maxTokens: number;
  private systemPrompt: string;
  private baseUrl: string;

  constructor(config: BasePluginConfig) {
    this.apiKey = config.apiKey || process.env.OPENAI_API_KEY || "";
    this.model = config.model || "gpt-4o";
    this.maxTokens = config.maxTokens || 4096;
    this.systemPrompt = config.systemPrompt || DEFAULT_SYSTEM_PROMPT;
    this.baseUrl = config.baseUrl || "https://api.openai.com/v1";
  }

  startSession(init: OracleInit): OracleSession {
    const adapter = this;
    const envRef = init.envRef;
    const stateRef = init.stateRef;

    return (async function* (): OracleSession {
      // Build initial messages
      const userContent = init.tag === "Infer"
        ? `Please compute a result for the following request:\n\n${valToString(init.payload)}\n\nUse the omega_* tools to interact with the runtime, then call omega_return when done.`
        : `Apply the procedure ${valToString(init.proc)} to arguments ${init.args.map(valToString).join(" ")}.\n\nUse the omega_* tools, then call omega_return when done.`;

      const messages: OpenAIMessage[] = [
        { role: "system", content: adapter.systemPrompt },
        { role: "user", content: userContent },
      ];

      // Conversation loop
      let turnCount = 0;
      const maxTurns = 20;

      while (turnCount < maxTurns) {
        turnCount++;

        // Call OpenAI API
        const response = await adapter.callAPI(messages);
        const choice = response.choices[0];
        const assistantMessage = choice.message;

        // Add assistant response to history
        messages.push(assistantMessage);

        // Check for tool calls
        const toolCalls = assistantMessage.tool_calls || [];

        if (toolCalls.length === 0) {
          // No tool calls - check if there's content
          if (assistantMessage.content) {
            return meaning({
              denotation: { tag: "Str", s: assistantMessage.content },
              confidence: 0.5,
              trace: { tag: "Str", s: `openai:${adapter.model}:no-tool-return` },
            });
          }
          return meaning({
            denotation: { tag: "Unit" },
            confidence: 0,
            trace: { tag: "Str", s: "empty response from LLM" },
          });
        }

        // Process each tool call
        for (const toolCall of toolCalls) {
          const { id, function: fn } = toolCall;
          const name = fn.name;
          let input: Record<string, unknown>;

          try {
            input = JSON.parse(fn.arguments);
          } catch {
            messages.push({
              role: "tool",
              tool_call_id: id,
              content: "Error: Invalid JSON in tool arguments",
            });
            continue;
          }

          // Handle omega_return - ends session
          if (name === "omega_return") {
            const valueStr = String(input.value || "()");
            const confidenceStr = String(input.confidence || "0.8");
            const explanation = String(input.explanation || "");

            return meaning({
              denotation: { tag: "Str", s: valueStr },
              confidence: parseFloat(confidenceStr) || 0.8,
              trace: { tag: "Str", s: explanation || `openai:${adapter.model}` },
            });
          }

          // Build OracleReq
          let req: OracleReq;
          switch (name) {
            case "omega_eval":
              req = {
                tag: "ReqEval",
                qexpr: String(input.expr) as unknown as QExpr,
                envRef,
              };
              break;

            case "omega_apply":
              req = {
                tag: "ReqEval",
                qexpr: `(${input.fn} ${input.args || ""})` as unknown as QExpr,
                envRef,
              };
              break;

            case "omega_observe":
              const whatStr = String(input.what);
              let observeSpec: import("../protocol").ObserveSpec;
              switch (whatStr) {
                case "stack": observeSpec = { tag: "Stack", limit: 20 }; break;
                case "handlers": observeSpec = { tag: "Handlers" }; break;
                case "store": observeSpec = { tag: "StoreSummary" }; break;
                case "env": observeSpec = { tag: "Env" }; break;
                case "env_lookup": observeSpec = { tag: "EnvLookup", name: String(input.name || "") }; break;
                case "defs": observeSpec = { tag: "Defs" }; break;
                default: observeSpec = { tag: "Control" };
              }
              req = {
                tag: "ReqObserve",
                what: observeSpec,
                stateRef,
              };
              break;

            case "omega_match":
              req = {
                tag: "ReqMatch",
                qexpr: String(input.expr) as unknown as QExpr,
                pattern: String(input.pattern),
                envRef,
              };
              break;

            default:
              messages.push({
                role: "tool",
                tool_call_id: id,
                content: `Error: Unknown tool '${name}'`,
              });
              continue;
          }

          // Yield request and get response
          const resp: OracleResp = yield req;

          // Convert response to tool result
          let resultContent: string;
          switch (resp.tag) {
            case "RespVal":
              resultContent = JSON.stringify(valToJSON(resp.value));
              break;
            case "RespObs":
              resultContent = JSON.stringify(resp.data);
              break;
            case "RespError":
              resultContent = `Error: ${resp.message}`;
              break;
            case "RespAck":
              resultContent = "OK";
              break;
            default:
              resultContent = JSON.stringify(resp);
          }

          messages.push({
            role: "tool",
            tool_call_id: id,
            content: resultContent,
          });
        }
      }

      // Max turns exceeded
      return meaning({
        denotation: { tag: "Unit" },
        confidence: 0,
        trace: { tag: "Str", s: `max turns (${maxTurns}) exceeded` },
      });
    })();
  }

  private async callAPI(messages: OpenAIMessage[]): Promise<OpenAIResponse> {
    const request: OpenAIRequest = {
      model: this.model,
      max_tokens: this.maxTokens,
      messages,
      tools: ORACLE_TOOLS,
      tool_choice: "auto",
    };

    const response = await fetch(`${this.baseUrl}/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OpenAI API error: ${response.status} ${errorText}`);
    }

    return await response.json() as OpenAIResponse;
  }
}

const DEFAULT_SYSTEM_PROMPT = `You are an Oracle for the Omega Lisp runtime. Your job is to compute results for inference requests.

You have access to the Omega runtime through tools:
- omega_eval: Evaluate Lisp expressions
- omega_apply: Apply functions to arguments
- omega_observe: Observe runtime state (stack, control, handlers, store)
- omega_match: Pattern match expressions
- omega_return: Return your final answer (MUST call this when done)

When given a task:
1. Think about what computations or lookups you need
2. Use omega_eval to run Lisp code as needed
3. Use omega_observe if you need to understand the current state
4. When you have your answer, call omega_return with the result

You can use your world knowledge for factual questions, but express your confidence level.
For computations, always verify with omega_eval when possible.

IMPORTANT: You MUST call omega_return when you have your final answer.`;

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN DEFINITION
// ═══════════════════════════════════════════════════════════════════════════

const openaiPlugin: OraclePlugin = {
  id: "openai",
  name: "OpenAI GPT",

  capabilities: {
    oracleProtocol: {
      reqEval: true,
      reqApply: true,
      reqObserve: true,
      reqMatch: true,
      reqAssert: true,
    },
    tooling: {
      native: true,
      format: "openai",
      maxTools: 128,
    },
    mcp: {
      client: false,
      server: false,
    },
    session: {
      multiTurn: true,
      streaming: true,
      maxContext: 128_000, // GPT-4o context
    },
    io: {
      vision: true,
      audio: true, // GPT-4o supports audio
      structuredOutput: true,
    },
  },

  supportedModels: [
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-4-turbo",
    "gpt-4-turbo-preview",
    "gpt-4",
    "gpt-3.5-turbo",
    "o1-preview",
    "o1-mini",
    "gpt-*", // Wildcard
  ],

  defaultModel: "gpt-4o",

  validateConfig(config: BasePluginConfig): ConfigValidation {
    const apiKey = config.apiKey || process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return {
        valid: false,
        errors: ["Missing API key: set OPENAI_API_KEY environment variable or pass apiKey in config"],
      };
    }
    return { valid: true };
  },

  createAdapter(config: BasePluginConfig): OracleAdapter {
    return new OpenAIOracleAdapter({
      ...config,
      model: config.model || this.defaultModel,
    });
  },

  async healthCheck(): Promise<HealthCheckResult> {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return { ok: false, message: "OPENAI_API_KEY not set" };
    }

    const start = Date.now();
    try {
      const response = await fetch("https://api.openai.com/v1/models", {
        headers: {
          "Authorization": `Bearer ${apiKey}`,
        },
      });

      const latencyMs = Date.now() - start;

      if (response.ok) {
        return { ok: true, message: "API reachable", latencyMs };
      } else if (response.status === 401) {
        return { ok: false, message: "Invalid API key" };
      } else {
        return { ok: false, message: `API error: ${response.status}` };
      }
    } catch (err) {
      return {
        ok: false,
        message: `Connection failed: ${err instanceof Error ? err.message : String(err)}`,
      };
    }
  },
};

// ═══════════════════════════════════════════════════════════════════════════
// AUTO-REGISTER
// ═══════════════════════════════════════════════════════════════════════════

registry.register(openaiPlugin);

export { openaiPlugin, OpenAIOracleAdapter };

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/plugins/registry.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/plugins/registry.ts
// Plugin Registry - pluggable LLM adapter system with capability declarations

import type { OracleAdapter } from "../adapter";

// ═══════════════════════════════════════════════════════════════════════════
// CAPABILITY TYPES - What each plugin can do
// ═══════════════════════════════════════════════════════════════════════════

/** Oracle Protocol support */
export type ProtocolCaps = {
  reqEval: boolean;      // Can execute ReqEval
  reqApply: boolean;     // Can execute ReqApply
  reqObserve: boolean;   // Can execute ReqObserve
  reqMatch: boolean;     // Can execute ReqMatch
  reqAssert: boolean;    // Can execute ReqAssert
};

/** Tool calling capabilities */
export type ToolingCaps = {
  native: boolean;                                    // Has native tool calling
  format?: "anthropic" | "openai" | "ollama" | "mcp"; // Which format
  maxTools?: number;                                  // Tool limit per call
};

/** MCP protocol support */
export type MCPCaps = {
  client: boolean;   // Can call MCP servers
  server: boolean;   // Can expose as MCP server
};

/** Session behavior */
export type SessionCaps = {
  multiTurn: boolean;     // Can maintain conversation state
  streaming: boolean;     // Can stream partial responses
  maxContext: number;     // Token limit
};

/** I/O capabilities */
export type IOCaps = {
  vision: boolean;           // Can process images
  audio: boolean;            // Can process audio
  structuredOutput: boolean; // Can return JSON schema-constrained output
};

/** Full capability declaration */
export type PluginCapabilities = {
  oracleProtocol: ProtocolCaps;
  tooling: ToolingCaps;
  mcp: MCPCaps;
  session: SessionCaps;
  io: IOCaps;
};

/** Deep partial type for filtering */
type DeepPartial<T> = {
  [P in keyof T]?: T[P] extends object ? DeepPartial<T[P]> : T[P];
};

/** Capability filter (allows partial matching) */
export type CapabilityFilter = DeepPartial<PluginCapabilities>;

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN CONFIG TYPES
// ═══════════════════════════════════════════════════════════════════════════

/** Base config all plugins accept */
export type BasePluginConfig = {
  apiKey?: string;
  model?: string;
  maxTokens?: number;
  temperature?: number;
  systemPrompt?: string;
  baseUrl?: string;
  /** Enable streaming mode - accumulates responses from stream chunks */
  streaming?: boolean;
};

/** Config validation result */
export type ConfigValidation = {
  valid: boolean;
  errors?: string[];
};

/** Health check result */
export type HealthCheckResult = {
  ok: boolean;
  message?: string;
  latencyMs?: number;
};

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN INTERFACE
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OraclePlugin - Contract for all LLM adapter plugins
 *
 * Each plugin:
 * 1. Declares its capabilities honestly
 * 2. Can validate configuration before creation
 * 3. Creates OracleAdapter instances
 * 4. Optionally provides health checking
 */
export interface OraclePlugin {
  /** Unique identifier (e.g., "anthropic", "openai", "ollama") */
  readonly id: string;

  /** Human-readable name */
  readonly name: string;

  /** What this plugin supports */
  readonly capabilities: PluginCapabilities;

  /** Supported model identifiers for this plugin */
  readonly supportedModels: string[];

  /** Default model if none specified */
  readonly defaultModel: string;

  /** Validate config before creation */
  validateConfig(config: BasePluginConfig): ConfigValidation;

  /** Create an adapter instance */
  createAdapter(config: BasePluginConfig): OracleAdapter;

  /** Optional: Check if this plugin can work (API key set, service reachable) */
  healthCheck?(): Promise<HealthCheckResult>;
}

// ═══════════════════════════════════════════════════════════════════════════
// CAPABILITY QUERY HELPERS
// ═══════════════════════════════════════════════════════════════════════════

/** Check if capabilities match a filter */
function matchesCapabilities(
  caps: PluginCapabilities,
  filter: CapabilityFilter
): boolean {
  // Check oracleProtocol
  if (filter.oracleProtocol) {
    const p = filter.oracleProtocol;
    const c = caps.oracleProtocol;
    if (p.reqEval && !c.reqEval) return false;
    if (p.reqApply && !c.reqApply) return false;
    if (p.reqObserve && !c.reqObserve) return false;
    if (p.reqMatch && !c.reqMatch) return false;
    if (p.reqAssert && !c.reqAssert) return false;
  }

  // Check tooling
  if (filter.tooling) {
    const t = filter.tooling;
    const c = caps.tooling;
    if (t.native && !c.native) return false;
    if (t.format && c.format !== t.format) return false;
  }

  // Check mcp
  if (filter.mcp) {
    const m = filter.mcp;
    const c = caps.mcp;
    if (m.client && !c.client) return false;
    if (m.server && !c.server) return false;
  }

  // Check session
  if (filter.session) {
    const s = filter.session;
    const c = caps.session;
    if (s.multiTurn && !c.multiTurn) return false;
    if (s.streaming && !c.streaming) return false;
    if (s.maxContext && c.maxContext < s.maxContext) return false;
  }

  // Check io
  if (filter.io) {
    const i = filter.io;
    const c = caps.io;
    if (i.vision && !c.vision) return false;
    if (i.audio && !c.audio) return false;
    if (i.structuredOutput && !c.structuredOutput) return false;
  }

  return true;
}

/** Score a plugin's capabilities (higher = better for Oracle) */
function scoreCapabilities(caps: PluginCapabilities): number {
  let score = 0;

  // Protocol support (most important)
  if (caps.oracleProtocol.reqEval) score += 10;
  if (caps.oracleProtocol.reqApply) score += 10;
  if (caps.oracleProtocol.reqObserve) score += 5;
  if (caps.oracleProtocol.reqMatch) score += 3;
  if (caps.oracleProtocol.reqAssert) score += 2;

  // Native tools (very valuable)
  if (caps.tooling.native) score += 15;

  // MCP support
  if (caps.mcp.client) score += 5;
  if (caps.mcp.server) score += 3;

  // Session features
  if (caps.session.multiTurn) score += 5;
  if (caps.session.streaming) score += 2;

  // I/O
  if (caps.io.structuredOutput) score += 5;
  if (caps.io.vision) score += 2;

  return score;
}

// ═══════════════════════════════════════════════════════════════════════════
// PLUGIN REGISTRY
// ═══════════════════════════════════════════════════════════════════════════

/**
 * PluginRegistry - Central registry for Oracle plugins
 *
 * Usage:
 *   import { registry } from "./plugins/registry";
 *
 *   // List what's available
 *   console.log(registry.list().map(p => p.id));
 *
 *   // Query by capability
 *   const mcpPlugins = registry.query({ mcp: { client: true } });
 *
 *   // Find best for Oracle protocol
 *   const best = registry.findBestForOracle();
 *
 *   // Create adapter
 *   const adapter = best.createAdapter({ model: "claude-sonnet-4-20250514" });
 */
export class PluginRegistry {
  private plugins = new Map<string, OraclePlugin>();

  /** Register a new plugin */
  register(plugin: OraclePlugin): void {
    if (this.plugins.has(plugin.id)) {
      throw new Error(`Plugin '${plugin.id}' already registered`);
    }
    this.plugins.set(plugin.id, plugin);
  }

  /** Unregister a plugin */
  unregister(id: string): boolean {
    return this.plugins.delete(id);
  }

  /** Get a plugin by ID */
  get(id: string): OraclePlugin | undefined {
    return this.plugins.get(id);
  }

  /** Check if a plugin is registered */
  has(id: string): boolean {
    return this.plugins.has(id);
  }

  /** List all registered plugins */
  list(): OraclePlugin[] {
    return [...this.plugins.values()];
  }

  /** Query plugins by capability filter */
  query(filter: CapabilityFilter): OraclePlugin[] {
    return this.list().filter(p => matchesCapabilities(p.capabilities, filter));
  }

  /** Find plugins that support a specific model */
  findByModel(model: string): OraclePlugin[] {
    return this.list().filter(p =>
      p.supportedModels.some(m => {
        if (m === model) return true;
        if (m.includes("*") && model.startsWith(m.replace("*", ""))) return true;
        if (model.startsWith(m)) return true;
        return false;
      })
    );
  }

  /** Find the best plugin for Oracle protocol (scored by capabilities) */
  findBestForOracle(): OraclePlugin | undefined {
    const candidates = this.query({
      oracleProtocol: { reqEval: true, reqApply: true, reqObserve: true }
    });

    if (candidates.length === 0) {
      // Fallback: any plugin with reqEval
      const fallback = this.query({ oracleProtocol: { reqEval: true } });
      if (fallback.length === 0) return undefined;
      return fallback.sort((a, b) =>
        scoreCapabilities(b.capabilities) - scoreCapabilities(a.capabilities)
      )[0];
    }

    return candidates.sort((a, b) =>
      scoreCapabilities(b.capabilities) - scoreCapabilities(a.capabilities)
    )[0];
  }

  /** Check health of all plugins */
  async healthCheckAll(): Promise<Map<string, HealthCheckResult>> {
    const results = new Map<string, HealthCheckResult>();

    for (const plugin of this.plugins.values()) {
      if (plugin.healthCheck) {
        try {
          const result = await plugin.healthCheck();
          results.set(plugin.id, result);
        } catch (err) {
          results.set(plugin.id, {
            ok: false,
            message: err instanceof Error ? err.message : String(err)
          });
        }
      } else {
        results.set(plugin.id, { ok: true, message: "No health check defined" });
      }
    }

    return results;
  }

  /** Get a summary of all plugins and their capabilities */
  summary(): PluginSummary[] {
    return this.list().map(p => ({
      id: p.id,
      name: p.name,
      defaultModel: p.defaultModel,
      hasNativeTools: p.capabilities.tooling.native,
      hasMCP: p.capabilities.mcp.client || p.capabilities.mcp.server,
      hasVision: p.capabilities.io.vision,
      maxContext: p.capabilities.session.maxContext,
      score: scoreCapabilities(p.capabilities),
    }));
  }
}

export type PluginSummary = {
  id: string;
  name: string;
  defaultModel: string;
  hasNativeTools: boolean;
  hasMCP: boolean;
  hasVision: boolean;
  maxContext: number;
  score: number;
};

// ═══════════════════════════════════════════════════════════════════════════
// GLOBAL REGISTRY INSTANCE
// ═══════════════════════════════════════════════════════════════════════════

/** Global plugin registry - import and use directly */
export const registry = new PluginRegistry();

// ═══════════════════════════════════════════════════════════════════════════
// HELPER: Create adapter from model string
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Create an adapter from a model specification
 *
 * @param model Model name or "plugin:model" format
 * @param config Optional additional config
 * @returns OracleAdapter
 *
 * Examples:
 *   createAdapterFromModel("claude-sonnet-4-20250514")       // auto-detect plugin
 *   createAdapterFromModel("anthropic:claude-3-opus")  // explicit plugin
 *   createAdapterFromModel("openai:gpt-4o")            // explicit plugin
 *   createAdapterFromModel("ollama:llama3.1:70b")      // explicit plugin
 */
export function createAdapterFromModel(
  model: string,
  config: Partial<BasePluginConfig> = {}
): OracleAdapter {
  // Check for "plugin:model" format
  if (model.includes(":")) {
    const [pluginId, modelName] = model.split(":", 2);
    const plugin = registry.get(pluginId);
    if (!plugin) {
      throw new Error(`Unknown plugin: ${pluginId}`);
    }
    return plugin.createAdapter({ ...config, model: modelName });
  }

  // Auto-detect plugin from model name
  const candidates = registry.findByModel(model);
  if (candidates.length === 0) {
    throw new Error(`No plugin found for model: ${model}`);
  }

  // Use first match (could be smarter about this)
  return candidates[0].createAdapter({ ...config, model });
}

/**
 * Get or create the default Oracle adapter
 * Prefers: 1) anthropic if available, 2) openai, 3) any with reqEval
 */
export function getDefaultAdapter(config: Partial<BasePluginConfig> = {}): OracleAdapter {
  // Try anthropic first
  const anthropic = registry.get("anthropic");
  if (anthropic) {
    const validation = anthropic.validateConfig(config);
    if (validation.valid) {
      return anthropic.createAdapter(config);
    }
  }

  // Try openai
  const openai = registry.get("openai");
  if (openai) {
    const validation = openai.validateConfig(config);
    if (validation.valid) {
      return openai.createAdapter(config);
    }
  }

  // Fall back to best available
  const best = registry.findBestForOracle();
  if (!best) {
    throw new Error("No Oracle plugins registered. Install an adapter plugin first.");
  }

  return best.createAdapter(config);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/portal.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/portal.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md

import type { OracleReq, OracleResp } from "./protocol";

export interface OraclePortal {
  perform(req: OracleReq): Promise<OracleResp>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/portalImpl.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/portalImpl.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set C4: Extended portal with ReqMatch, ReqAssert, ReqSnapshot, ReqCompress, ReqHydrate

import type { OraclePortal } from "./portal";
import type { OracleReq, OracleResp, ObserveSpec, EnvRef, StateRef, QExpr, TestSpec } from "./protocol";
import type { SnapshotRepo } from "./snapshots";
import type { ReceiptStore } from "./receipts";
import { receiptKey } from "./receipts";

import type { Runtime } from "../eval/runtime";
import type { State } from "../eval/machine";
import type { Val } from "../eval/values";
import type { Env } from "../eval/env";
import type { Store } from "../eval/store";
import { envSet, envGet } from "../eval/env";
import { runToCompletionWithState } from "../eval/run";

// Patch Set C imports
import { matchAST } from "./match";
import { CtxReceiptRepo } from "./ctxReceipts";

// Tool registry import
import type { ToolRegistry } from "../tools/registry";

// Governance imports for capability checking
import { capRequire, capHas, type CapSet } from "../governance/caps";

type PortalOptions = {
  maxEvalSteps: number;
  parseText?: (src: string) => unknown;
  toolRegistry?: ToolRegistry;
  caps?: CapSet;  // Capabilities for governance checks
};

const DEFAULT_OPTS: PortalOptions = { maxEvalSteps: 500_000, caps: ["*"] };

export class PortalImpl implements OraclePortal {
  private adoptEnvRef?: EnvRef;
  private ctxReceipts = new CtxReceiptRepo();

  constructor(
    private runtime: Runtime,
    private snapshots: SnapshotRepo,
    private receipts: ReceiptStore,
    private opts: PortalOptions = DEFAULT_OPTS
  ) {}

  consumeAdoptEnvRef(): EnvRef | undefined {
    const x = this.adoptEnvRef;
    this.adoptEnvRef = undefined;
    return x;
  }

  async perform(req: OracleReq): Promise<OracleResp> {
    // Receipts gate: replay/record
    const key = receiptKey(req);
    if (this.receipts.mode === "replay") {
      const hit = this.receipts.get(key);
      if (!hit) return { tag: "RespError", message: `missing receipt for ${req.tag}`, details: { key } };
      return hit.resp;
    }

    const t0 = Date.now();
    const resp = await this.performUncached(req);
    const t1 = Date.now();

    if (this.receipts.mode === "record") {
      this.receipts.put({ key, req, resp, timeMs: t1 - t0 });
    }

    return resp;
  }

  private normalizeQExpr(q: QExpr): unknown {
    if (typeof q === "string") {
      // If we have a parser, use it
      if (this.opts.parseText) return this.opts.parseText(q);
      // Otherwise return as-is (string matching)
      return q;
    }
    if (q && typeof q === "object" && "tag" in q && q.tag === "Text" && "text" in q && typeof q.text === "string") {
      if (this.opts.parseText) return this.opts.parseText(q.text);
      return q.text;
    }
    return q;
  }

  private async performUncached(req: OracleReq): Promise<OracleResp> {
    switch (req.tag) {
      case "ReqEval": {
        const { env, store } = this.snapshots.getEnv(req.envRef);
        const expr = this.normalizeQExpr(req.qexpr);
        const { value, state } = await this.evalExpr(expr, env, store);
        const envRef2 = this.snapshots.putEnv({ env: state.env, store: state.store });
        const stateRef2 = this.snapshots.putState({ state });
        return { tag: "RespVal", value, envRef: envRef2, stateRef: stateRef2 };
      }

      case "ReqApply": {
        const { env, store } = this.snapshots.getEnv(req.envRef);
        const { value, env2, store2 } = await this.applyVal(req.fn, req.args, env, store);
        const envRef2 = this.snapshots.putEnv({ env: env2, store: store2 });
        return { tag: "RespVal", value, envRef: envRef2 };
      }

      case "ReqObserve": {
        const { state } = this.snapshots.getState(req.stateRef);
        const data = this.observe(state, req.what);
        return { tag: "RespObs", data };
      }

      case "ReqAdoptEnv": {
        this.adoptEnvRef = req.envRef;
        return { tag: "RespAck" };
      }

      // Patch Set C: ReqMatch - structural AST matching
      case "ReqMatch": {
        const q = this.normalizeQExpr(req.qexpr);
        const p = this.normalizeQExpr(req.pattern);
        const { ok, bindings } = matchAST(p, q);
        return { tag: "RespObs", data: { ok, bindings } };
      }

      // Patch Set C: ReqAssert - evaluate predicate or check value
      case "ReqAssert": {
        const sev = req.severity ?? "error";
        let truth = false;

        if (typeof req.predicate === "string" ||
            (req.predicate && typeof req.predicate === "object" && "tag" in req.predicate && req.predicate.tag === "Text")) {
          // evaluate predicate in the interpreter
          const expr = this.normalizeQExpr(req.predicate as QExpr);
          const { env, store } = this.snapshots.getEnv(req.envRef);
          try {
            const { value } = await this.evalExpr(expr, env, store);
            truth = value.tag === "Bool" ? value.b : !!value;
          } catch (e: any) {
            return { tag: "RespError", message: `assertion eval failed: ${e?.message ?? e}` };
          }
        } else {
          const v = req.predicate as Val;
          truth = v?.tag === "Bool" ? !!v.b : !!v;
        }

        if (!truth) {
          const msg = `assertion failed: ${req.msg}`;
          if (sev === "warn") return { tag: "RespObs", data: { warning: msg } };
          return { tag: "RespError", message: msg };
        }
        return { tag: "RespAck" };
      }

      // Patch Set C: ReqSnapshot - create context receipt
      case "ReqSnapshot": {
        const r = this.ctxReceipts.snapshot(req.envRef, req.stateRef, req.meta);
        return { tag: "RespObs", data: r };
      }

      // Patch Set C: ReqCompress - create compress receipt
      case "ReqCompress": {
        const r = this.ctxReceipts.compress(req.envRef, req.meta);
        return { tag: "RespObs", data: r };
      }

      // Patch Set C: ReqHydrate - retrieve stored receipt
      case "ReqHydrate": {
        const r = this.ctxReceipts.get(req.receiptId);
        if (!r) return { tag: "RespError", message: `missing receipt ${req.receiptId}` };
        return { tag: "RespObs", data: { envRef: r.envRef, stateRef: r.stateRef } };
      }

      case "ReqTest": {
        return this.runTest(req);
      }

      case "ReqTool": {
        const registry = this.opts.toolRegistry;
        if (!registry) {
          return { tag: "RespError", message: "tool registry not configured" };
        }
        const result = await registry.execute(req.call);
        return { tag: "RespTool", result };
      }

      case "ReqEmitExample": {
        // Hook to dataset store later; for now we just ack.
        return { tag: "RespAck" };
      }

      default: {
        return { tag: "RespError", message: `unsupported oracle req: ${(req as any).tag}` };
      }
    }
  }

  private async evalExpr(expr: unknown, env: Env, store: Store): Promise<{ value: Val; state: State }> {
    const st0: State = {
      control: { tag: "Expr", e: expr },
      env,
      store,
      kont: [],
      handlers: [],
    } as any;

    return runToCompletionWithState(this.runtime, st0, this.opts.maxEvalSteps);
  }

  /**
   * Apply a Val-procedure to args in a given snapshot.
   * This is "extensional apply" for the oracle plane.
   */
  private async applyVal(fn: Val, args: Val[], env: Env, store: Store): Promise<{ value: Val; env2: Env; store2: Store }> {
    // Closure application
    if (fn.tag === "Closure") {
      if (fn.params.length !== args.length) throw new Error(`apply: arity mismatch ${fn.params.length} vs ${args.length}`);

      let envCall = fn.env;
      let storeCall = store;

      for (let i = 0; i < fn.params.length; i++) {
        const [s2, addr] = storeCall.alloc(args[i]);
        storeCall = s2;
        envCall = envSet(envCall, fn.params[i], addr);
      }

      const { value, state } = await this.evalExpr(fn.body, envCall, storeCall);
      return { value, env2: state.env, store2: state.store };
    }

    // Native primitive application
    if (fn.tag === "Native") {
      const st0: State = {
        control: { tag: "Val", v: { tag: "Unit" } },
        env,
        store,
        kont: [],
        handlers: [],
      } as any;

      const st1 = fn.fn(args, st0);
      const { value, state } = await runToCompletionWithState(
        this.runtime,
        st1 as State,
        this.opts.maxEvalSteps
      );
      return { value, env2: state.env, store2: state.store };
    }

    // Continuation application (single-arg)
    if (fn.tag === "Cont") {
      const arg0 = args[0] ?? ({ tag: "Unit" } as Val);
      const st1 = fn.resumption.invoke(arg0);
      const { value, state } = await runToCompletionWithState(this.runtime, st1, this.opts.maxEvalSteps);
      return { value, env2: state.env, store2: state.store };
    }

    throw new Error(`apply: not a procedure: ${fn.tag}`);
  }

  private observe(st: State, spec: ObserveSpec): unknown {
    switch (spec.tag) {
      case "Control":
        return st.control;

      case "Handlers":
        return st.handlers?.map((h: any, i: number) => ({ i, tag: h.tag ?? "Handler" })) ?? [];

      case "StoreSummary":
        return {
          note: "store summary is backend-specific",
        };

      case "Stack": {
        const limit = spec.limit ?? 50;
        const frames = (st.kont ?? []).slice(0, limit).map((fr: any, i: number) => {
          const frameInfo: any = {
            index: i,
            tag: fr.tag ?? "Frame",
            hasEnv: fr.env !== undefined,
          };
          // Include envRef for frames that have environments
          if (fr.env !== undefined) {
            frameInfo.envRef = this.snapshots.putEnv({ env: fr.env, store: st.store });
          }
          // Include expression hint if available (for debugging)
          if (fr.e) {
            frameInfo.exprTag = fr.e.tag;
          }
          return frameInfo;
        });
        return { depth: (st.kont ?? []).length, frames };
      }

      case "FrameEnv": {
        const fr: any = (st.kont ?? [])[spec.frameIndex];
        if (!fr) return { error: `no such frame ${spec.frameIndex}` };
        if (!fr.env) return { error: `frame ${spec.frameIndex} has no env` };

        const envRef = this.snapshots.putEnv({ env: fr.env, store: st.store });
        return { envRef };
      }

      case "Env": {
        // List all bindings in the environment
        const { env, store } = spec.envRef
          ? this.snapshots.getEnv(spec.envRef)
          : { env: st.env, store: st.store };

        const bindings: Array<{ name: string; addr: number; value?: unknown }> = [];
        const seen = new Set<string>();

        // Walk the env chain collecting all bindings
        for (let cur: Env | undefined = env; cur && (cur as any).tag === "Ctx"; cur = (cur as any).parent) {
          const frame = (cur as any).frame as Map<string, number>;
          for (const [name, addr] of frame) {
            if (!seen.has(name)) {
              seen.add(name);
              try {
                const val = store.read(addr);
                bindings.push({
                  name,
                  addr,
                  value: val ? { tag: val.tag } : undefined
                });
              } catch {
                // addr not in store (stale reference)
                bindings.push({ name, addr, value: undefined });
              }
            }
          }
        }

        return { bindings, count: bindings.length };
      }

      case "EnvLookup": {
        // Lookup a specific binding by name
        const { env, store } = spec.envRef
          ? this.snapshots.getEnv(spec.envRef)
          : { env: st.env, store: st.store };

        const addr = envGet(env, spec.name);
        if (addr === undefined) {
          return { found: false, name: spec.name };
        }

        let value: Val | null = null;
        try {
          value = store.read(addr);
        } catch {
          // addr not in store
        }
        return {
          found: true,
          name: spec.name,
          addr,
          value
        };
      }

      case "Defs": {
        // List top-level definitions (user-defined, excluding primitives)
        const { env, store } = spec.envRef
          ? this.snapshots.getEnv(spec.envRef)
          : { env: st.env, store: st.store };

        const defs: Array<{ name: string; type: string }> = [];
        const seen = new Set<string>();

        // Walk the env chain, collect non-Native values (user definitions)
        for (let cur: Env | undefined = env; cur && (cur as any).tag === "Ctx"; cur = (cur as any).parent) {
          const frame = (cur as any).frame as Map<string, number>;
          for (const [name, addr] of frame) {
            if (!seen.has(name)) {
              seen.add(name);
              try {
                const val = store.read(addr);
                // Only include non-Native values (user-defined)
                if (val && val.tag !== "Native") {
                  defs.push({ name, type: val.tag });
                }
              } catch {
                // addr not in store (stale reference)
              }
            }
          }
        }

        return { defs, count: defs.length };
      }

      default:
        return { error: `unknown ObserveSpec ${(spec as any).tag}` };
    }
  }

  private async runTest(req: { tag: "ReqTest"; spec: TestSpec }): Promise<OracleResp> {
    const spec = req.spec;
    const caps = this.opts.caps ?? ["*"];

    // Capability check: require "test" capability for all test operations
    try {
      capRequire(caps, "test", "ReqTest");
    } catch (e: any) {
      return { tag: "RespError", message: e.message };
    }

    if (spec.tag === "Smoke") {
      try {
        const { env, store } = this.snapshots.getEnv(spec.envRef);
        await this.evalExpr(spec.qexpr, env, store);
        return { tag: "RespTest", passed: true, report: { tag: "SmokeOk" } };
      } catch (e: any) {
        return { tag: "RespTest", passed: false, report: { tag: "SmokeFail", message: String(e?.message ?? e) } };
      }
    }

    if (spec.tag === "ExprEquals") {
      try {
        const { env, store } = this.snapshots.getEnv(spec.envRef);
        const { value } = await this.evalExpr(spec.qexpr, env, store);
        const ok = JSON.stringify(value) === JSON.stringify(spec.expected);
        return { tag: "RespTest", passed: ok, report: { expected: spec.expected, got: value } };
      } catch (e: any) {
        return { tag: "RespTest", passed: false, report: { tag: "Error", message: String(e?.message ?? e) } };
      }
    }

    // Tests: batch test execution - each expr should return truthy
    if (spec.tag === "Tests") {
      const { env, store } = this.snapshots.getEnv(spec.envRef);
      const results: Array<{ index: number; passed: boolean; error?: string }> = [];
      let allPassed = true;

      for (let i = 0; i < spec.tests.length; i++) {
        const qexpr = spec.tests[i];
        try {
          const expr = this.normalizeQExpr(qexpr);
          const { value } = await this.evalExpr(expr, env, store);
          // Check if truthy (Bool true, or non-false/non-unit value)
          const passed = value.tag === "Bool" ? value.b : (value.tag !== "Unit");
          results.push({ index: i, passed });
          if (!passed) allPassed = false;
        } catch (e: any) {
          results.push({ index: i, passed: false, error: String(e?.message ?? e) });
          allPassed = false;
        }
      }

      return {
        tag: "RespTest",
        passed: allPassed,
        report: {
          tag: "BatchTests",
          total: spec.tests.length,
          passed: results.filter(r => r.passed).length,
          failed: results.filter(r => !r.passed).length,
          results
        }
      };
    }

    // TestSuite: named test suite with individual test names
    if (spec.tag === "TestSuite") {
      const { env, store } = this.snapshots.getEnv(spec.envRef);
      const results: Array<{ name: string; passed: boolean; error?: string }> = [];
      let allPassed = true;

      for (const test of spec.tests) {
        try {
          const expr = this.normalizeQExpr(test.qexpr);
          const { value } = await this.evalExpr(expr, env, store);
          const passed = value.tag === "Bool" ? value.b : (value.tag !== "Unit");
          results.push({ name: test.name, passed });
          if (!passed) allPassed = false;
        } catch (e: any) {
          results.push({ name: test.name, passed: false, error: String(e?.message ?? e) });
          allPassed = false;
        }
      }

      return {
        tag: "RespTest",
        passed: allPassed,
        report: {
          tag: "TestSuite",
          suiteName: spec.name,
          total: spec.tests.length,
          passed: results.filter(r => r.passed).length,
          failed: results.filter(r => !r.passed).length,
          results
        }
      };
    }

    return { tag: "RespError", message: "unknown TestSpec", details: spec };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/protocol.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/protocol.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set C: Extended Oracle protocol request algebra

import type { Expr } from "../ast";
import type { Val } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import type { MeaningVal } from "./meaning";

export type EnvRef = Hash;
export type StateRef = Hash;

// Re-export MeaningVal as the protocol's Meaning type
export type Meaning = MeaningVal;

export type QExpr = string | { tag: "Text"; text: string } | Expr;

export type ObserveSpec =
  | { tag: "Stack"; limit?: number }
  | { tag: "Control" }
  | { tag: "Handlers" }
  | { tag: "FrameEnv"; frameIndex: number }
  | { tag: "StoreSummary"; maxCells?: number }
  | { tag: "Env"; envRef?: EnvRef }                     // List all bindings in environment
  | { tag: "EnvLookup"; name: string; envRef?: EnvRef } // Lookup specific binding by name
  | { tag: "Defs"; envRef?: EnvRef };                   // List top-level definitions

export type ToolCall = {
  name: string;
  argv: string[];
  cwd?: string;
  stdin?: string;
  timeoutMs?: number;
};

export type TestSpec =
  | { tag: "ExprEquals"; qexpr: Expr; expected: Val; envRef: EnvRef }
  | { tag: "Smoke"; qexpr: Expr; envRef: EnvRef }
  | { tag: "Tests"; tests: QExpr[]; envRef: EnvRef }  // Batch tests: each expr should return truthy
  | { tag: "TestSuite"; name: string; tests: Array<{ name: string; qexpr: QExpr }>; envRef: EnvRef };  // Named suite

export type TrainingExample = {
  tag: "Example";
  payload: unknown;
};

export type OracleReq =
  // Core REPL re-entry
  | { tag: "ReqEval"; qexpr: QExpr; envRef: EnvRef }
  | { tag: "ReqApply"; fn: Val; args: Val[]; envRef: EnvRef }
  | { tag: "ReqObserve"; what: ObserveSpec; stateRef: StateRef }

  // Patch Set C: Extended request algebra
  | { tag: "ReqMatch"; qexpr: QExpr; pattern: QExpr; envRef: EnvRef }
  | { tag: "ReqAssert"; predicate: QExpr | Val; msg: string; severity?: "warn" | "error"; envRef: EnvRef }
  | { tag: "ReqSnapshot"; envRef: EnvRef; stateRef?: StateRef; meta?: unknown }
  | { tag: "ReqCompress"; envRef: EnvRef; meta?: unknown }
  | { tag: "ReqHydrate"; receiptId: Hash }

  // Tools and testing
  | { tag: "ReqTool"; call: ToolCall; envRef?: EnvRef }
  | { tag: "ReqTest"; spec: TestSpec }
  | { tag: "ReqEmitExample"; ex: TrainingExample }

  // Adoption and termination
  | { tag: "ReqAdoptEnv"; envRef: EnvRef }
  | { tag: "ReqReturn"; result: Meaning }
  | { tag: "ReqFail"; reason: string };

export type OracleResp =
  | { tag: "RespVal"; value: Val; envRef?: EnvRef; stateRef?: StateRef }
  | { tag: "RespObs"; data: unknown }
  | { tag: "RespTool"; result: unknown }
  | { tag: "RespTest"; passed: boolean; report: unknown }
  | { tag: "RespAck" }
  | { tag: "RespError"; message: string; details?: unknown };

export type OracleReturn = Meaning;

/**
 * Interactive oracle session:
 *   - yields OracleReq
 *   - receives OracleResp
 *   - returns OracleReturn (Meaning)
 */
export type OracleSession = AsyncGenerator<OracleReq, OracleReturn, OracleResp>;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/receipts.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/receipts.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md

import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type { OracleReq, OracleResp } from "./protocol";

export type ReceiptMode = "off" | "record" | "replay";

export type OracleReceipt = {
  key: Hash;
  req: OracleReq;
  resp: OracleResp;
  timeMs?: number;
};

export interface ReceiptStore {
  mode: ReceiptMode;
  get(key: Hash): OracleReceipt | undefined;
  put(r: OracleReceipt): void;
}

/** In-memory implementation for now (good enough to validate protocol). */
export class InMemoryReceiptStore implements ReceiptStore {
  mode: ReceiptMode;
  private m = new Map<Hash, OracleReceipt>();

  constructor(mode: ReceiptMode = "off") {
    this.mode = mode;
  }

  get(key: Hash): OracleReceipt | undefined {
    return this.m.get(key);
  }

  put(r: OracleReceipt): void {
    this.m.set(r.key, r);
  }

  /**
   * Reset the store to initial state.
   * Useful for testing to ensure clean state between tests.
   */
  reset(mode?: ReceiptMode): void {
    this.m.clear();
    if (mode !== undefined) {
      this.mode = mode;
    }
  }

  /** Get all stored receipts (for debugging/testing). */
  all(): OracleReceipt[] {
    return Array.from(this.m.values());
  }

  /** Get the number of stored receipts. */
  size(): number {
    return this.m.size;
  }

  /** Check if a receipt exists for the given key. */
  has(key: Hash): boolean {
    return this.m.has(key);
  }
}

/** Deterministic key for request (you can extend with policyDigest, envelope, ctxDigest, etc.). */
export function receiptKey(req: OracleReq): Hash {
  return sha256JSON(req);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/scriptedEngine.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/scriptedEngine.ts
// SOURCE: LambdaLLM/ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Scripted oracle engine for deterministic testing and replay

import type { OracleReq, OracleResp } from "./protocol";
import type { MeaningVal } from "./meaning";

/**
 * An OracleSession is an async generator that:
 * - Yields OracleReq (requests to the runtime)
 * - Receives OracleResp (responses from runtime)
 * - Returns a final value (typically MeaningVal)
 */
export type OracleSession = AsyncGenerator<OracleReq, { tag: "Return"; value: MeaningVal }, OracleResp>;

export type SessionFactory = () => OracleSession;

/**
 * ScriptedOracleEngine wraps a session factory.
 * This allows deterministic, replayable oracle sessions.
 */
export class ScriptedOracleEngine {
  constructor(private readonly mk: SessionFactory) {}

  session(): OracleSession {
    return this.mk();
  }
}

/**
 * Helper: create a scripted oracle from an async generator function.
 *
 * Usage:
 * ```ts
 * const oracle = scripted(async function* () {
 *   // Request evaluation
 *   const evalResp = yield { tag: "ReqEval", qexpr: "(+ 1 2)", envRef };
 *
 *   // Request tests
 *   const testResp = yield { tag: "ReqTest", spec: tests, envRef };
 *
 *   // Return final meaning
 *   return { tag: "Return", value: meaning };
 * });
 * ```
 */
export function scripted(fn: SessionFactory): ScriptedOracleEngine {
  return new ScriptedOracleEngine(fn);
}

/**
 * Run an oracle session to completion, dispatching requests through a handler.
 * Returns the final MeaningVal.
 */
export async function runSession(
  session: OracleSession,
  handler: (req: OracleReq) => Promise<OracleResp>
): Promise<MeaningVal> {
  let next = await session.next(undefined as any);

  while (!next.done) {
    const req = next.value as OracleReq;
    const resp = await handler(req);
    next = await session.next(resp);
  }

  return next.value.value;
}

/**
 * Record a session's request/response pairs for replay.
 */
export type SessionTranscript = Array<{ req: OracleReq; resp: OracleResp }>;

export async function recordSession(
  session: OracleSession,
  handler: (req: OracleReq) => Promise<OracleResp>
): Promise<{ result: MeaningVal; transcript: SessionTranscript }> {
  const transcript: SessionTranscript = [];
  let next = await session.next(undefined as any);

  while (!next.done) {
    const req = next.value as OracleReq;
    const resp = await handler(req);
    transcript.push({ req, resp });
    next = await session.next(resp);
  }

  return { result: next.value.value, transcript };
}

/**
 * Replay a session from a transcript (deterministic).
 */
export function replaySession(transcript: SessionTranscript): SessionFactory {
  return async function* () {
    let i = 0;
    for (const { req, resp } of transcript) {
      const actualResp = yield req;
      // In replay mode, we ignore the actual response and use the recorded one
      // But we could assert they match for validation
      i++;
    }
    // The transcript doesn't include the final return, so this is a limitation
    throw new Error("Replay session reached end without return");
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/scriptedOracle.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/scriptedOracle.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md
// This is the test oracle that proves your plane works without calling any model.

import type { OracleAdapter, OracleInit } from "./adapter";
import type { OracleSession, OracleResp, Meaning } from "./protocol";
import type { Expr } from "../ast";
import type { Val } from "../eval/values";

function exprPlus(a: number, b: number): Expr {
  return {
    tag: "App",
    fn: { tag: "Var", name: "+" },
    args: [{ tag: "Lit", value: a }, { tag: "Lit", value: b }],
  } as any;
}

/** Extract a string from a Val for dispatch purposes */
function getSpecKey(spec: Val): string {
  if (spec.tag === "Str") return spec.s;
  if (spec.tag === "Sym") return spec.name;
  if (spec.tag === "Vector" && spec.items.length > 0 && spec.items[0].tag === "Sym") {
    return spec.items[0].name;
  }
  return "default";
}

export class ScriptedOracleAdapter implements OracleAdapter {
  startSession(init: OracleInit): OracleSession {
    if (init.tag === "Infer") return this.inferSession(init.payload, init.envRef, init.stateRef);
    return this.applySession(init.proc, init.args, init.envRef, init.stateRef);
  }

  private inferSession(_payload: Val, envRef: string, stateRef: string): OracleSession {
    return (async function* (): OracleSession {
      // 1) Observe stack (prove we can introspect the paused state)
      let r: OracleResp = yield { tag: "ReqObserve", what: { tag: "Stack", limit: 8 }, stateRef };
      const stackDepth = r.tag === "RespObs" ? String((r.data as unknown[])?.length ?? 0) : "unknown";

      // 2) Ask runtime to evaluate (+ 20 22)
      r = yield { tag: "ReqEval", qexpr: exprPlus(20, 22), envRef };
      if (r.tag !== "RespVal") {
        return { tag: "Meaning", confidence: 0, trace: { tag: "Str", s: `error: eval failed, stackDepth=${stackDepth}` } };
      }

      const sum = r.value;

      // 3) Return a Meaning whose denotation is that value
      const meaning: Meaning = {
        tag: "Meaning",
        denotation: sum,
        confidence: 1.0,
        trace: { tag: "Str", s: `stackDepth=${stackDepth}` },
      };

      yield { tag: "ReqReturn", result: meaning };
      return meaning;
    })();
  }

  private applySession(proc: Val, args: Val[], envRef: string, stateRef: string): OracleSession {
    // Extract spec from OracleProc to dispatch behavior
    const spec = proc.tag === "OracleProc" ? proc.spec : { tag: "Str", s: "default" } as Val;
    const specKey = getSpecKey(spec);

    // Dispatch based on spec
    switch (specKey) {
      case "apply-add1":
        return this.applyAdd1Session(args);

      case "apply-add":
        return this.applyAddSession(args);

      case "must-reenter-eval":
        return this.reenterEvalSession(args, envRef);

      case "repair-loop":
        return this.repairLoopSession(args, envRef, stateRef);

      // B4: Return full Meaning value
      case "return-meaning":
        return this.returnMeaningSession(args);

      // B7: Attempt a commit (will fail in speculative regime)
      case "do-commit":
        return this.doCommitSession(args);

      // B8: Return Meaning with satisfied obligation
      case "return-certified-meaning":
        return this.returnCertifiedMeaningSession(args);

      // ─────────────────────────────────────────────────────────────────
      // Prompt 3: Semantic tests
      // ─────────────────────────────────────────────────────────────────

      // 3.1: Classify sentiment - returns 'positive or 'negative symbol
      case "classify-sentiment":
        return this.classifySentimentSession(args);

      // 3.2: Extract named entity - returns string with entity name
      case "extract-named-entity":
        return this.extractNamedEntitySession(args);

      // 3.3: Semantic rewrite - uses ReqEval to call string-replace-all
      case "semantic-rewrite":
        return this.semanticRewriteSession(args, envRef);

      // 3.4: Match AST shape - returns result of pattern matching
      case "match-ast-shape":
        return this.matchAstShapeSession(args);

      // 3.5: Get tree accessor - returns accessor for ADT
      case "get-tree-accessor":
        return this.getTreeAccessorSession(args, envRef);

      // 3.6: Suggest number - for Dist search, returns candidate number
      case "suggest-number":
        return this.suggestNumberSession(args);

      // 3.6: Check safety predicate
      case "check-safety":
        return this.checkSafetySession(args);

      // ─────────────────────────────────────────────────────────────────
      // Prompt 4: AMB and Streams semantic tests
      // ─────────────────────────────────────────────────────────────────

      // 4.1: find-sensitive - returns sensitivity level of data
      case "find-sensitive":
        return this.findSensitiveSession(args);

      // 4.1: safe? - checks if data is safe to process
      case "safe?":
        return this.safePredicateSession(args);

      // 4.1: semantic-redact - redacts sensitive info from text
      case "semantic-redact":
        return this.semanticRedactSession(args);

      // 4.2: classify-ticket - classifies support ticket to department
      case "classify-ticket":
        return this.classifyTicketSession(args);

      // 4.4: rank-strategy - returns priority ranking for a strategy
      case "rank-strategy":
        return this.rankStrategySession(args);

      // 4.5: classify-content - classifies content type
      case "classify-content":
        return this.classifyContentSession(args);

      // 4.6: expensive-compute - simulates expensive computation (tracks calls)
      case "expensive-compute":
        return this.expensiveComputeSession(args);

      // 4.7: safe-predicate - checks safety for stream filtering
      case "safe-predicate":
        return this.safePredicateSession(args);

      // ─────────────────────────────────────────────────────────────────
      // Prompt 5: Generic Operations semantic tests
      // ─────────────────────────────────────────────────────────────────

      // 5.3: synthesize-processor - synthesizes a processor type for unknown data
      case "synthesize-processor":
        return this.synthesizeProcessorSession(args);

      default:
        // Default: add args using runtime
        return this.defaultApplySession(args, envRef);
    }
  }

  /** C1 Test: Simple add1 - directly return x + 1 */
  private applyAdd1Session(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const x = args[0]?.tag === "Num" ? args[0].n : 0;
      const m: Meaning = { tag: "Meaning", denotation: { tag: "Num", n: x + 1 }, confidence: 1 };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** C3 Test: Simple add - directly return x + y */
  private applyAddSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const x = args[0]?.tag === "Num" ? args[0].n : 0;
      const y = args[1]?.tag === "Num" ? args[1].n : 0;
      const m: Meaning = { tag: "Meaning", denotation: { tag: "Num", n: x + y }, confidence: 1 };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** C4 Test: Re-entrant eval - use ReqEval and ReqApply */
  private reenterEvalSession(args: Val[], envRef: string): OracleSession {
    return (async function* (): OracleSession {
      // 1) ReqEval to get the '+' function
      let r: OracleResp = yield { tag: "ReqEval", qexpr: { tag: "Var", name: "+" } as Expr, envRef };
      if (r.tag !== "RespVal") {
        const m: Meaning = { tag: "Meaning", confidence: 0, trace: { tag: "Str", s: `error: eval failed` } };
        return m;
      }

      const plusFn = r.value;

      // 2) ReqApply to apply '+' to [x, 1]
      const x = args[0] ?? { tag: "Num", n: 0 };
      r = yield { tag: "ReqApply", fn: plusFn, args: [x, { tag: "Num", n: 1 }], envRef };
      if (r.tag !== "RespVal") {
        const m: Meaning = { tag: "Meaning", confidence: 0, trace: { tag: "Str", s: `error: apply failed` } };
        return m;
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: r.value,
        confidence: 1,
        trace: { tag: "Str", s: "used ReqEval + ReqApply" },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** C5 Test: Multi-shot rollback via ReqSnapshot/ReqHydrate */
  private repairLoopSession(args: Val[], envRef: string, stateRef: string): OracleSession {
    return (async function* (): OracleSession {
      // 1) Take a snapshot
      let r: OracleResp = yield { tag: "ReqSnapshot", envRef, stateRef };
      const receipt = r.tag === "RespObs" ? (r.data as { receipt?: string })?.receipt ?? "R0" : "R0";

      // 2) Try a wrong computation (would return wrong result)
      // In a real scenario, the oracle would detect an error and hydrate back
      // For testing, we simulate: first attempt wrong, then correct

      // 3) Hydrate back to the snapshot
      r = yield { tag: "ReqHydrate", receiptId: receipt };

      // 4) Now compute correctly: x + 1
      const x = args[0]?.tag === "Num" ? args[0].n : 0;
      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Num", n: x + 1 },
        confidence: 1,
        trace: { tag: "Str", s: `used snapshot/hydrate loop, receipt=${receipt}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** Default: use runtime to add args */
  private defaultApplySession(args: Val[], envRef: string): OracleSession {
    return (async function* (): OracleSession {
      // Demonstrate: oracle can get a function and apply it by asking runtime.
      // First, eval '+' to obtain the primitive.
      let r: OracleResp = yield { tag: "ReqEval", qexpr: { tag: "Var", name: "+" } as Expr, envRef };
      if (r.tag !== "RespVal") {
        const m: Meaning = { tag: "Meaning", confidence: 0, trace: { tag: "Str", s: `error: eval failed tag=${r.tag}` } };
        yield { tag: "ReqReturn", result: m };
        return m;
      }

      const plusFn = r.value;

      // Now request apply of '+' to args
      r = yield { tag: "ReqApply", fn: plusFn, args, envRef };
      if (r.tag !== "RespVal") {
        const m: Meaning = { tag: "Meaning", confidence: 0, trace: { tag: "Str", s: `error: apply failed tag=${r.tag}` } };
        yield { tag: "ReqReturn", result: m };
        return m;
      }

      const m: Meaning = { tag: "Meaning", denotation: r.value, confidence: 1 };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** B4 Test: Return full Meaning value */
  private returnMeaningSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const x = args[0]?.tag === "Num" ? args[0].n : 0;
      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Num", n: x + 1 },
        confidence: 1,
        trace: { tag: "Str", s: "return-meaning session" },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** B7 Test: Return a meaning without satisfied obligations (for commit rejection test) */
  private doCommitSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      // Returns a meaning WITHOUT satisfied obligation
      // When this is passed to commit.op in test-certified regime, it should fail
      const payload = args[0] ?? { tag: "Unit" };
      const m: Meaning = {
        tag: "Meaning",
        denotation: payload,
        confidence: 1,
        // No obligation field = not certified
        trace: { tag: "Str", s: "do-commit session without obligation" },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** B8 Test: Return Meaning with satisfied obligation */
  private returnCertifiedMeaningSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const x = args[0]?.tag === "Num" ? args[0].n : 0;
      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Num", n: x + 1 },
        confidence: 1,
        obligation: { tag: "Str", s: "satisfied" },
        trace: { tag: "Str", s: "certified meaning with satisfied obligation" },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  // ─────────────────────────────────────────────────────────────────
  // Prompt 3: Semantic test oracle methods
  // ─────────────────────────────────────────────────────────────────

  /** 3.1: Classify sentiment - simulates LLM sentiment classification
   * Input: string text
   * Output: 'positive or 'negative symbol
   */
  private classifySentimentSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const text = args[0]?.tag === "Str" ? args[0].s : "";

      // Simulate sentiment classification based on keywords
      const lowerText = text.toLowerCase();
      const positiveWords = ["good", "great", "excellent", "happy", "love", "wonderful", "amazing", "best"];
      const negativeWords = ["bad", "terrible", "awful", "sad", "hate", "horrible", "worst", "poor"];

      let positiveScore = 0;
      let negativeScore = 0;

      for (const word of positiveWords) {
        if (lowerText.includes(word)) positiveScore++;
      }
      for (const word of negativeWords) {
        if (lowerText.includes(word)) negativeScore++;
      }

      const sentiment = positiveScore >= negativeScore ? "positive" : "negative";
      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Sym", name: sentiment },
        confidence: 1,
        trace: { tag: "Str", s: `classified "${text.substring(0, 20)}..." as ${sentiment}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.2: Extract named entity - simulates NER extraction
   * Input: string text
   * Output: string with extracted entity name (or "UNKNOWN")
   */
  private extractNamedEntitySession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const text = args[0]?.tag === "Str" ? args[0].s : "";

      // Simple entity extraction: find capitalized words
      // In real LLM, this would be semantic understanding
      const words = text.split(/\s+/);
      let entity = "UNKNOWN";

      for (const word of words) {
        // Find capitalized word that's not at sentence start
        if (word.length > 1 && word[0] === word[0].toUpperCase() && word[0] !== word[0].toLowerCase()) {
          // Skip common sentence starters
          if (!["The", "A", "An", "This", "That", "It", "I"].includes(word)) {
            entity = word.replace(/[.,!?;:]/g, ""); // Remove punctuation
            break;
          }
        }
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Str", s: entity },
        confidence: entity === "UNKNOWN" ? 0.5 : 1.0,
        trace: { tag: "Str", s: `extracted entity "${entity}" from text` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.3: Semantic rewrite - uses ReqEval to call string-replace-all
   * Demonstrates hybrid approach: oracle decides WHAT to rewrite,
   * then uses REPL to do the mechanical rewrite
   * Input: (text entity replacement)
   * Output: rewritten text
   */
  private semanticRewriteSession(args: Val[], envRef: string): OracleSession {
    return (async function* (): OracleSession {
      const text = args[0]?.tag === "Str" ? args[0].s : "";
      const entity = args[1]?.tag === "Str" ? args[1].s : "";
      const replacement = args[2]?.tag === "Str" ? args[2].s : "";

      // Use ReqEval to call string-replace-all from the runtime
      // This demonstrates the oracle using mechanical tools
      const replaceExpr: Expr = {
        tag: "App",
        fn: { tag: "Var", name: "string-replace-all" },
        args: [
          { tag: "Lit", value: text },
          { tag: "Lit", value: entity },
          { tag: "Lit", value: replacement },
        ],
      } as any;

      const r: OracleResp = yield { tag: "ReqEval", qexpr: replaceExpr, envRef };

      if (r.tag !== "RespVal") {
        const m: Meaning = {
          tag: "Meaning",
          denotation: { tag: "Str", s: text }, // Fall back to original
          confidence: 0,
          trace: { tag: "Str", s: "semantic-rewrite: ReqEval failed" },
        };
        return m;
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: r.value,
        confidence: 1,
        trace: { tag: "Str", s: `rewrote "${entity}" to "${replacement}" using ReqEval` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.4: Match AST shape - simulates pattern matching on AST
   * Input: AST represented as quoted list structure (cons-cell or flat)
   * Output: matched pattern variables or #f
   */
  private matchAstShapeSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const ast = args[0];

      // Helper to convert cons-cell list to flat array
      function listToArray(v: Val): Val[] | null {
        if (v.tag !== "Vector") return null;
        const result: Val[] = [];
        let cur: Val = v;
        // Handle both flat vectors and cons-cell lists
        while (cur.tag === "Vector") {
          if (cur.items.length === 2) {
            // Cons cell: [head, tail]
            result.push(cur.items[0]);
            cur = cur.items[1];
          } else if (cur.items.length > 0) {
            // Flat vector: return all items
            return cur.items;
          } else {
            break;
          }
        }
        return result.length > 0 ? result : null;
      }

      // Check if AST matches pattern (if (eq? ?x 0) 1 ...)
      // For testing, we just check if it's a conditional
      function isConditional(v: Val): boolean {
        const arr = listToArray(v);
        if (!arr || arr.length < 2) return false;
        const head = arr[0];
        if (head.tag === "Sym" && head.name === "if") return true;
        return false;
      }

      function extractBindings(v: Val): Val {
        // Extract pattern variable bindings as a list
        // For (if (eq? x 0) 1 body), extract x and body
        const arr = listToArray(v);
        if (!arr || arr.length < 4) {
          return { tag: "Bool", b: false };
        }

        const condition = arr[1];
        const thenBranch = arr[2];
        const elseBranch = arr[3];

        // Build bindings list: ((condition . <cond>) (then . <then>) (else . <else>))
        const bindings: Val = {
          tag: "Vector",
          items: [
            {
              tag: "Vector",
              items: [{ tag: "Sym", name: "condition" }, condition]
            },
            {
              tag: "Vector",
              items: [
                {
                  tag: "Vector",
                  items: [{ tag: "Sym", name: "then" }, thenBranch]
                },
                {
                  tag: "Vector",
                  items: [
                    {
                      tag: "Vector",
                      items: [{ tag: "Sym", name: "else" }, elseBranch]
                    },
                    { tag: "Unit" }
                  ]
                }
              ]
            }
          ]
        };
        return bindings;
      }

      const matched = isConditional(ast);
      const result = matched ? extractBindings(ast) : { tag: "Bool", b: false } as Val;

      const m: Meaning = {
        tag: "Meaning",
        denotation: result,
        confidence: matched ? 1 : 0,
        trace: { tag: "Str", s: matched ? "matched conditional pattern" : "pattern did not match" },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.5: Get tree accessor - returns appropriate accessor for ADT representation
   * Input: representation tag ('list-tree or 'record-tree)
   * Output: accessor functions wrapped in a list
   */
  private getTreeAccessorSession(args: Val[], envRef: string): OracleSession {
    return (async function* (): OracleSession {
      const repTag = args[0]?.tag === "Sym" ? args[0].name : "list-tree";

      // Return accessor functions based on representation
      // For list-tree: (value left right) = (car car.cdr car.cdr.cdr)
      // For record-tree: use get-field accessors

      let accessors: Val;

      if (repTag === "list-tree") {
        // Use ReqEval to get the standard accessors
        let r: OracleResp = yield { tag: "ReqEval", qexpr: { tag: "Var", name: "car" } as Expr, envRef };
        const carFn = r.tag === "RespVal" ? r.value : { tag: "Unit" } as Val;

        r = yield { tag: "ReqEval", qexpr: { tag: "Var", name: "cadr" } as Expr, envRef };
        const cadrFn = r.tag === "RespVal" ? r.value : { tag: "Unit" } as Val;

        r = yield { tag: "ReqEval", qexpr: { tag: "Var", name: "caddr" } as Expr, envRef };
        const caddrFn = r.tag === "RespVal" ? r.value : { tag: "Unit" } as Val;

        // Return (list value-accessor left-accessor right-accessor)
        accessors = {
          tag: "Vector",
          items: [
            carFn,
            { tag: "Vector", items: [cadrFn, { tag: "Vector", items: [caddrFn, { tag: "Unit" }] }] }
          ]
        };
      } else {
        // For record-tree, return symbolic accessor names
        accessors = {
          tag: "Vector",
          items: [
            { tag: "Sym", name: "tree-value" },
            {
              tag: "Vector",
              items: [
                { tag: "Sym", name: "tree-left" },
                { tag: "Vector", items: [{ tag: "Sym", name: "tree-right" }, { tag: "Unit" }] }
              ]
            }
          ]
        };
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: accessors,
        confidence: 1,
        trace: { tag: "Str", s: `returned accessors for ${repTag}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.6: Suggest number - returns a candidate number for Dist search
   * Input: constraints (min, max)
   * Output: suggested number
   */
  private suggestNumberSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const min = args[0]?.tag === "Num" ? args[0].n : 0;
      const max = args[1]?.tag === "Num" ? args[1].n : 100;

      // Suggest a number in range (deterministic for testing)
      const suggested = Math.floor((min + max) / 2);

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Num", n: suggested },
        confidence: 1,
        trace: { tag: "Str", s: `suggested ${suggested} in range [${min}, ${max}]` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 3.6: Check safety predicate - determines if operation is "safe"
   * Input: operation description
   * Output: #t or #f
   */
  private checkSafetySession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const op = args[0];

      // Check if operation looks "safe"
      // For testing: numbers > 0 are safe, strings without "danger" are safe
      let isSafe = true;

      if (op.tag === "Num") {
        isSafe = op.n > 0;
      } else if (op.tag === "Str") {
        isSafe = !op.s.toLowerCase().includes("danger");
      } else if (op.tag === "Sym") {
        isSafe = !op.name.toLowerCase().includes("danger");
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Bool", b: isSafe },
        confidence: 1,
        trace: { tag: "Str", s: `safety check: ${isSafe ? "safe" : "unsafe"}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  // ─────────────────────────────────────────────────────────────────
  // Prompt 4: AMB and Streams semantic test oracle methods
  // ─────────────────────────────────────────────────────────────────

  /** 4.1: find-sensitive - returns sensitivity level of data
   * Input: string data
   * Output: 'high, 'medium, 'low, or 'none symbol
   */
  private findSensitiveSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const data = args[0]?.tag === "Str" ? args[0].s : "";
      const lowerData = data.toLowerCase();

      let level: string;
      if (lowerData.includes("ssn") || lowerData.includes("password") || lowerData.includes("credit card")) {
        level = "high";
      } else if (lowerData.includes("email") || lowerData.includes("phone") || lowerData.includes("address")) {
        level = "medium";
      } else if (lowerData.includes("name") || lowerData.includes("id")) {
        level = "low";
      } else {
        level = "none";
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Sym", name: level },
        confidence: 1,
        trace: { tag: "Str", s: `sensitivity level: ${level}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 4.1/4.7: safe? - checks if data is safe to process
   * Input: any value
   * Output: #t or #f
   */
  private safePredicateSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const data = args[0];
      let isSafe = true;

      if (data.tag === "Str") {
        const lowerData = data.s.toLowerCase();
        isSafe = !lowerData.includes("danger") && !lowerData.includes("unsafe") && !lowerData.includes("malicious");
      } else if (data.tag === "Num") {
        isSafe = data.n >= 0 && data.n < 1000; // Numbers in safe range
      } else if (data.tag === "Sym") {
        isSafe = !data.name.toLowerCase().includes("danger");
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Bool", b: isSafe },
        confidence: 1,
        trace: { tag: "Str", s: `safe? check: ${isSafe}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 4.1: semantic-redact - redacts sensitive info from text
   * Input: string text, symbol sensitivity-level
   * Output: redacted text string
   */
  private semanticRedactSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const text = args[0]?.tag === "Str" ? args[0].s : "";
      const level = args[1]?.tag === "Sym" ? args[1].name : "low";

      let redacted = text;

      // Redact based on sensitivity level
      if (level === "high" || level === "medium" || level === "low") {
        // Redact SSN-like patterns
        redacted = redacted.replace(/\d{3}-\d{2}-\d{4}/g, "[REDACTED-SSN]");
        // Redact email-like patterns
        redacted = redacted.replace(/[\w.-]+@[\w.-]+\.\w+/g, "[REDACTED-EMAIL]");
        // Redact phone-like patterns
        redacted = redacted.replace(/\d{3}[-.]?\d{3}[-.]?\d{4}/g, "[REDACTED-PHONE]");
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Str", s: redacted },
        confidence: 1,
        trace: { tag: "Str", s: `redacted at level ${level}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 4.2: classify-ticket - classifies support ticket to department
   * Input: ticket description string
   * Output: symbol ('billing, 'technical, 'sales, 'general)
   */
  private classifyTicketSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const ticket = args[0]?.tag === "Str" ? args[0].s : "";
      const lowerTicket = ticket.toLowerCase();

      let department: string;
      if (lowerTicket.includes("bill") || lowerTicket.includes("payment") || lowerTicket.includes("invoice") || lowerTicket.includes("charge")) {
        department = "billing";
      } else if (lowerTicket.includes("bug") || lowerTicket.includes("error") || lowerTicket.includes("crash") || lowerTicket.includes("not working")) {
        department = "technical";
      } else if (lowerTicket.includes("buy") || lowerTicket.includes("price") || lowerTicket.includes("discount") || lowerTicket.includes("purchase")) {
        department = "sales";
      } else {
        department = "general";
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Sym", name: department },
        confidence: 1,
        trace: { tag: "Str", s: `classified ticket to ${department}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 4.4: rank-strategy - returns priority ranking for a strategy
   * Input: strategy symbol
   * Output: number (lower is higher priority)
   */
  private rankStrategySession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const strategy = args[0]?.tag === "Sym" ? args[0].name : "unknown";

      // Priority ranking: cache > local > remote > fallback
      const rankings: Record<string, number> = {
        "cache": 1,
        "local": 2,
        "fast": 2,
        "remote": 3,
        "slow": 3,
        "fallback": 4,
        "default": 5,
      };

      const rank = rankings[strategy.toLowerCase()] ?? 10;

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Num", n: rank },
        confidence: 1,
        trace: { tag: "Str", s: `strategy ${strategy} ranked ${rank}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** 4.5: classify-content - classifies content type
   * Input: content string
   * Output: symbol ('code, 'text, 'data, 'mixed)
   */
  private classifyContentSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const content = args[0]?.tag === "Str" ? args[0].s : "";

      let contentType: string;
      // Check for code indicators
      if (content.includes("{") || content.includes("}") || content.includes("function") || content.includes("=>") || content.includes("def ")) {
        contentType = "code";
      } else if (content.includes("[") && content.includes("]") || content.includes(",") && /\d+/.test(content)) {
        contentType = "data";
      } else if (content.length > 50 && content.split(" ").length > 10) {
        contentType = "text";
      } else {
        contentType = "mixed";
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Sym", name: contentType },
        confidence: 1,
        trace: { tag: "Str", s: `classified content as ${contentType}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  // Call counter for expensive-compute (for memoization testing)
  private static expensiveComputeCallCount = 0;

  /** 4.6: expensive-compute - simulates expensive computation
   * Tracks call count to verify memoization works
   * Input: any value
   * Output: computed result + increments counter
   */
  private expensiveComputeSession(args: Val[]): OracleSession {
    const self = this.constructor as typeof ScriptedOracleAdapter;
    return (async function* (): OracleSession {
      self.expensiveComputeCallCount++;
      const input = args[0];

      // Return input * 2 for numbers, "COMPUTED:" prefix for strings
      let result: Val;
      if (input.tag === "Num") {
        result = { tag: "Num", n: input.n * 2 };
      } else if (input.tag === "Str") {
        result = { tag: "Str", s: `COMPUTED:${input.s}` };
      } else {
        result = { tag: "Str", s: "COMPUTED:unknown" };
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: result,
        confidence: 1,
        trace: { tag: "Str", s: `expensive-compute call #${self.expensiveComputeCallCount}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }

  /** Reset the expensive-compute call counter (for test setup) */
  static resetExpensiveComputeCounter(): void {
    ScriptedOracleAdapter.expensiveComputeCallCount = 0;
  }

  /** Get the expensive-compute call count (for test assertions) */
  static getExpensiveComputeCallCount(): number {
    return ScriptedOracleAdapter.expensiveComputeCallCount;
  }

  // ─────────────────────────────────────────────────────────────────
  // Prompt 5: Generic Operations
  // ─────────────────────────────────────────────────────────────────

  /** 5.3: synthesize-processor - synthesizes a processor for unknown data type
   * Input: type-tag symbol, data value
   * Output: symbol indicating the processor type to use
   */
  private synthesizeProcessorSession(args: Val[]): OracleSession {
    return (async function* (): OracleSession {
      const typeTag = args[0]?.tag === "Sym" ? args[0].name : "unknown";
      // const data = args[1]; // Could inspect data if needed

      // Synthesize a processor based on the type tag
      let processor: string;
      switch (typeTag) {
        case "markdown":
        case "html":
        case "text":
        case "document":
          processor = "text-processor";
          break;
        case "image":
        case "binary":
        case "media":
          processor = "binary-processor";
          break;
        case "json":
        case "xml":
        case "data":
          processor = "data-processor";
          break;
        default:
          processor = "generic-processor";
          break;
      }

      const m: Meaning = {
        tag: "Meaning",
        denotation: { tag: "Sym", name: processor },
        confidence: 0.8, // Lower confidence for synthesized processors
        trace: { tag: "Str", s: `synthesized ${processor} for type ${typeTag}` },
      };
      yield { tag: "ReqReturn", result: m };
      return m;
    })();
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/snapshots.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/snapshots.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-14.md

import type { Hash } from "../artifacts/hash";
import type { Env } from "../eval/env";
import type { Store } from "../eval/store";
import type { State } from "../eval/machine";

export type EnvSnapshot = { env: Env; store: Store };
export type StateSnapshot = { state: State };

export type SnapshotRepoOptions = {
  /** Optional prefix for IDs (useful for test isolation). */
  prefix?: string;
  /** Starting counter value (useful for deterministic testing). */
  startCounter?: number;
};

export class SnapshotRepo {
  private envSnaps = new Map<Hash, EnvSnapshot>();
  private stateSnaps = new Map<Hash, StateSnapshot>();

  // Use incrementing IDs since Env/Store are Maps which don't serialize with JSON.stringify
  private envCounter: number;
  private stateCounter: number;
  private prefix: string;

  constructor(opts: SnapshotRepoOptions = {}) {
    this.prefix = opts.prefix ?? "";
    this.envCounter = opts.startCounter ?? 0;
    this.stateCounter = opts.startCounter ?? 0;
  }

  /**
   * Reset the repository to initial state.
   * Useful for testing to ensure deterministic IDs.
   */
  reset(opts: SnapshotRepoOptions = {}): void {
    this.envSnaps.clear();
    this.stateSnaps.clear();
    this.prefix = opts.prefix ?? this.prefix;
    this.envCounter = opts.startCounter ?? 0;
    this.stateCounter = opts.startCounter ?? 0;
  }

  /** Get the current prefix. */
  getPrefix(): string {
    return this.prefix;
  }

  /** Set the prefix (useful for test isolation). */
  setPrefix(prefix: string): void {
    this.prefix = prefix;
  }

  putEnv(s: EnvSnapshot): Hash {
    const h = `${this.prefix}env:${++this.envCounter}`;
    this.envSnaps.set(h, s);
    return h;
  }
  getEnv(h: Hash): EnvSnapshot {
    const s = this.envSnaps.get(h);
    if (!s) throw new Error(`SnapshotRepo: missing EnvRef ${h}`);
    return s;
  }

  putState(s: StateSnapshot): Hash {
    const h = `${this.prefix}state:${++this.stateCounter}`;
    this.stateSnaps.set(h, s);
    return h;
  }
  getState(h: Hash): StateSnapshot {
    const s = this.stateSnaps.get(h);
    if (!s) throw new Error(`SnapshotRepo: missing StateRef ${h}`);
    return s;
  }

  /** Get current ID counters (for debugging/testing). */
  getCounters(): { envCounter: number; stateCounter: number } {
    return { envCounter: this.envCounter, stateCounter: this.stateCounter };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/oracle/trs.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/oracle/trs.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Patch Set 6-A2: Deterministic Term Rewriting System engine

import type { Val } from "../eval/values";
import { matchAST, type Bindings } from "./match";

/**
 * A rewrite rule: pattern → template, optionally guarded by a predicate.
 */
export type Rule = {
  name: string;
  pattern: Val;
  template: Val;
  /** Optional predicate over bindings. Returns true if rule is applicable. */
  where?: (bindings: Bindings) => boolean;
};

/**
 * Traversal strategy for applying rewrite rules.
 */
export type Strategy = "topdown" | "bottomup";

/**
 * Result of a single rewrite step.
 */
export type RewriteResult = {
  changed: boolean;
  result: Val;
  ruleName?: string;
  position?: string;
};

/**
 * Conflict report from confluence analysis.
 */
export type ConflictReport = {
  rule1: string;
  rule2: string;
  overlap: "same-head" | "embeds" | "similar-shape";
  description: string;
};

// -----------------------------------------------------------------------------
// Pattern substitution: apply bindings to a template
// -----------------------------------------------------------------------------

function isObj(x: unknown): x is Record<string, unknown> {
  return !!x && typeof x === "object" && !Array.isArray(x);
}

function isVarRef(node: Val): string | null {
  // Template variable: {tag:"Sym", name:"?x"} or {tag:"Var", name:"?x"}
  if (isObj(node) && typeof (node as any).name === "string") {
    const name = (node as any).name as string;
    if (name.startsWith("?")) return name.slice(1);
  }
  return null;
}

/**
 * Substitute bindings into a template, producing a new Val.
 */
export function substitute(template: Val, bindings: Bindings): Val {
  const ref = isVarRef(template);
  if (ref !== null) {
    if (ref in bindings) {
      return bindings[ref] as Val;
    }
    // Unbound variable stays as-is (for partial templates)
    return template;
  }

  if (template === null || typeof template !== "object") {
    return template;
  }

  if (Array.isArray(template)) {
    return template.map(item => substitute(item as Val, bindings)) as unknown as Val;
  }

  // Object (Val node)
  const obj = template as Record<string, unknown>;
  const result: Record<string, unknown> = {};
  for (const k of Object.keys(obj)) {
    if (k === "loc" || k === "span") {
      // Don't recurse into source locations
      result[k] = obj[k];
    } else {
      result[k] = substitute(obj[k] as Val, bindings);
    }
  }
  return result as Val;
}

// -----------------------------------------------------------------------------
// Tree traversal helpers
// -----------------------------------------------------------------------------

function getChildren(node: Val): { key: string; child: Val }[] {
  if (node === null || typeof node !== "object") return [];
  if (Array.isArray(node)) {
    return node.map((item, i) => ({ key: String(i), child: item as Val }));
  }

  const obj = node as Record<string, unknown>;
  const children: { key: string; child: Val }[] = [];

  // Recurse into known Val structural fields
  switch (obj.tag) {
    case "Pair":
      children.push({ key: "car", child: obj.car as Val });
      children.push({ key: "cdr", child: obj.cdr as Val });
      break;
    case "Vector":
      (obj.items as Val[]).forEach((item, i) => {
        children.push({ key: `items[${i}]`, child: item });
      });
      break;
    case "Map":
      (obj.entries as Array<[Val, Val]>).forEach(([k, v], i) => {
        children.push({ key: `entries[${i}][0]`, child: k });
        children.push({ key: `entries[${i}][1]`, child: v });
      });
      break;
    case "Syntax":
      children.push({ key: "stx", child: obj.stx as Val });
      break;
    // For quoted Exprs, recurse into their structure
    default:
      // Generic object: recurse into non-special fields
      for (const k of Object.keys(obj)) {
        if (k === "tag" || k === "loc" || k === "span") continue;
        const v = obj[k];
        if (v && typeof v === "object") {
          children.push({ key: k, child: v as Val });
        }
      }
  }
  return children;
}

function setChild(node: Val, key: string, newChild: Val): Val {
  if (Array.isArray(node)) {
    const idx = parseInt(key, 10);
    const copy = [...node];
    copy[idx] = newChild;
    return copy as unknown as Val;
  }

  const obj = node as Record<string, unknown>;
  const copy = { ...obj };

  // Handle indexed keys like "items[0]" or "entries[0][1]"
  const arrayMatch = key.match(/^(\w+)\[(\d+)\](?:\[(\d+)\])?$/);
  if (arrayMatch) {
    const [, field, idx1, idx2] = arrayMatch;
    const arr = [...(copy[field] as unknown[])];
    if (idx2 !== undefined) {
      // entries[i][j]
      const inner = [...(arr[parseInt(idx1, 10)] as unknown[])];
      inner[parseInt(idx2, 10)] = newChild;
      arr[parseInt(idx1, 10)] = inner;
    } else {
      arr[parseInt(idx1, 10)] = newChild;
    }
    copy[field] = arr;
  } else {
    copy[key] = newChild;
  }

  return copy as Val;
}

// -----------------------------------------------------------------------------
// Core rewrite engine
// -----------------------------------------------------------------------------

/**
 * Try to apply a single rule at the root of the node.
 * Returns the rewritten node if the rule matched, or null otherwise.
 */
function tryApplyRule(rule: Rule, node: Val): Val | null {
  const { ok, bindings } = matchAST(rule.pattern, node);
  if (!ok) return null;
  if (rule.where && !rule.where(bindings)) return null;
  return substitute(rule.template, bindings);
}

/**
 * Apply the first matching rule at the root.
 * Returns { changed: true, result, ruleName } if a rule matched,
 * or { changed: false, result: node } otherwise.
 */
function applyRulesAtRoot(rules: Rule[], node: Val): RewriteResult {
  for (const rule of rules) {
    const result = tryApplyRule(rule, node);
    if (result !== null) {
      return { changed: true, result, ruleName: rule.name };
    }
  }
  return { changed: false, result: node };
}

/**
 * Rewrite once using topdown strategy: try root first, then children.
 */
function rewriteOnceTopdown(rules: Rule[], node: Val, path: string = ""): RewriteResult {
  // Try root first
  const rootResult = applyRulesAtRoot(rules, node);
  if (rootResult.changed) {
    return { ...rootResult, position: path || "root" };
  }

  // Try children
  const children = getChildren(node);
  for (const { key, child } of children) {
    const childPath = path ? `${path}.${key}` : key;
    const childResult = rewriteOnceTopdown(rules, child, childPath);
    if (childResult.changed) {
      const newNode = setChild(node, key, childResult.result);
      return { changed: true, result: newNode, ruleName: childResult.ruleName, position: childResult.position };
    }
  }

  return { changed: false, result: node };
}

/**
 * Rewrite once using bottomup strategy: try children first, then root.
 */
function rewriteOnceBottomup(rules: Rule[], node: Val, path: string = ""): RewriteResult {
  // Try children first
  const children = getChildren(node);
  let currentNode = node;
  let anyChildChanged = false;

  for (const { key, child } of children) {
    const childPath = path ? `${path}.${key}` : key;
    const childResult = rewriteOnceBottomup(rules, child, childPath);
    if (childResult.changed) {
      currentNode = setChild(currentNode, key, childResult.result);
      anyChildChanged = true;
      // Return on first change (outermost bottomup)
      return { changed: true, result: currentNode, ruleName: childResult.ruleName, position: childResult.position };
    }
  }

  // Try root after children
  const rootResult = applyRulesAtRoot(rules, currentNode);
  if (rootResult.changed) {
    return { ...rootResult, position: path || "root" };
  }

  return { changed: anyChildChanged, result: currentNode };
}

/**
 * Apply rules once at the first matching position.
 */
export function rewriteOnce(rules: Rule[], expr: Val, strategy: Strategy = "topdown"): RewriteResult {
  if (strategy === "topdown") {
    return rewriteOnceTopdown(rules, expr);
  } else {
    return rewriteOnceBottomup(rules, expr);
  }
}

/**
 * Apply rules repeatedly until fixpoint or fuel exhausted.
 * @param fuel Maximum number of rewrite steps (default 100)
 */
export function rewriteFixpoint(
  rules: Rule[],
  expr: Val,
  strategy: Strategy = "topdown",
  fuel: number = 100
): { result: Val; steps: number; reachedFixpoint: boolean } {
  let current = expr;
  let steps = 0;

  while (steps < fuel) {
    const { changed, result } = rewriteOnce(rules, current, strategy);
    if (!changed) {
      return { result: current, steps, reachedFixpoint: true };
    }
    current = result;
    steps++;
  }

  return { result: current, steps, reachedFixpoint: false };
}

/**
 * Apply rules and return the full trace of intermediate results.
 */
export function rewriteTrace(
  rules: Rule[],
  expr: Val,
  strategy: Strategy = "topdown",
  fuel: number = 100
): { trace: Array<{ expr: Val; ruleName?: string; position?: string }>; reachedFixpoint: boolean } {
  const trace: Array<{ expr: Val; ruleName?: string; position?: string }> = [{ expr }];
  let current = expr;
  let steps = 0;

  while (steps < fuel) {
    const { changed, result, ruleName, position } = rewriteOnce(rules, current, strategy);
    if (!changed) {
      return { trace, reachedFixpoint: true };
    }
    current = result;
    trace.push({ expr: current, ruleName, position });
    steps++;
  }

  return { trace, reachedFixpoint: false };
}

// -----------------------------------------------------------------------------
// Confluence diagnostic: critical pair detection
// -----------------------------------------------------------------------------

/**
 * Extract the "head shape" of a pattern for overlap detection.
 * For Val nodes, this is the tag + direct structure.
 */
function getPatternHead(pattern: Val): string {
  if (pattern === null || typeof pattern !== "object") {
    return String(pattern);
  }
  if (Array.isArray(pattern)) {
    return `Array[${pattern.length}]`;
  }
  const obj = pattern as Record<string, unknown>;
  if (obj.tag) {
    return String(obj.tag);
  }
  return "Object";
}

/**
 * Check if two patterns have structural overlap that could cause non-confluence.
 */
function patternsOverlap(p1: Val, p2: Val): "same-head" | "embeds" | "similar-shape" | null {
  const head1 = getPatternHead(p1);
  const head2 = getPatternHead(p2);

  // Different head tags - no overlap
  if (head1 !== head2) return null;

  // Same head tag - need deeper analysis
  if (isObj(p1) && isObj(p2)) {
    const obj1 = p1 as Record<string, unknown>;
    const obj2 = p2 as Record<string, unknown>;

    // For App nodes, check if the function names differ
    if (obj1.tag === "App" && obj2.tag === "App") {
      const fn1 = obj1.fn as Record<string, unknown> | undefined;
      const fn2 = obj2.fn as Record<string, unknown> | undefined;

      // If both have concrete (non-variable) function names that differ, no overlap
      if (fn1 && fn2 &&
          fn1.tag === "Var" && fn2.tag === "Var" &&
          typeof fn1.name === "string" && typeof fn2.name === "string" &&
          !fn1.name.startsWith("?") && !fn2.name.startsWith("?") &&
          fn1.name !== fn2.name) {
        return null;
      }
    }

    // For Var nodes with different concrete names, no overlap
    if (obj1.tag === "Var" && obj2.tag === "Var") {
      const name1 = obj1.name as string | undefined;
      const name2 = obj2.name as string | undefined;
      if (name1 && name2 &&
          !name1.startsWith("?") && !name2.startsWith("?") &&
          name1 !== name2) {
        return null;
      }
    }

    // For Num nodes with different values, no overlap
    if (obj1.tag === "Num" && obj2.tag === "Num") {
      if (obj1.n !== obj2.n) {
        return null;
      }
    }

    // For Sym nodes with different concrete names, no overlap
    if (obj1.tag === "Sym" && obj2.tag === "Sym") {
      const name1 = obj1.name as string | undefined;
      const name2 = obj2.name as string | undefined;
      if (name1 && name2 &&
          !name1.startsWith("?") && !name2.startsWith("?") &&
          name1 !== name2) {
        return null;
      }
    }

    // Count pattern variables to check for embedding
    const vars1 = countPatternVars(p1);
    const vars2 = countPatternVars(p2);

    // If one has more concrete structure (fewer vars), it might embed
    if (Math.abs(vars1 - vars2) > 0) {
      return "embeds";
    }

    // Same structure - potential conflict
    return "same-head";
  }

  // Primitive types with same head
  if (head1 !== "Object") {
    return "same-head";
  }

  return null;
}

function countPatternVars(node: unknown): number {
  if (node === null) return 0;
  if (typeof node === "string") return node.startsWith("?") ? 1 : 0;
  if (typeof node !== "object") return 0;

  if (Array.isArray(node)) {
    return node.reduce((acc, item) => acc + countPatternVars(item), 0);
  }

  const obj = node as Record<string, unknown>;
  if (typeof obj.name === "string" && obj.name.startsWith("?")) return 1;

  let count = 0;
  for (const k of Object.keys(obj)) {
    if (k !== "tag" && k !== "loc" && k !== "span") {
      count += countPatternVars(obj[k]);
    }
  }
  return count;
}

/**
 * Detect potential non-confluence in a rule set.
 * Returns conflict reports for pairs of rules that might produce different results.
 */
export function detectConflicts(rules: Rule[]): ConflictReport[] {
  const conflicts: ConflictReport[] = [];

  for (let i = 0; i < rules.length; i++) {
    for (let j = i + 1; j < rules.length; j++) {
      const r1 = rules[i];
      const r2 = rules[j];
      const overlap = patternsOverlap(r1.pattern, r2.pattern);

      if (overlap) {
        conflicts.push({
          rule1: r1.name,
          rule2: r2.name,
          overlap,
          description: `Rules '${r1.name}' and '${r2.name}' have overlapping patterns (${overlap}). ` +
            `This may cause non-confluent rewriting depending on rule order.`
        });
      }
    }
  }

  return conflicts;
}

// -----------------------------------------------------------------------------
// Rule construction helpers
// -----------------------------------------------------------------------------

/**
 * Create a rewrite rule.
 */
export function rule(name: string, pattern: Val, template: Val, where?: (bindings: Bindings) => boolean): Rule {
  return { name, pattern, template, where };
}

/**
 * Create a rule from pattern/template Val objects.
 */
export function makeRule(
  name: string,
  pattern: Val,
  template: Val,
  wherePred?: Val
): Rule {
  // wherePred would need to be evaluated in context; for now, leave it as optional JS function
  return { name, pattern, template };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/outcome.ts
// ═══════════════════════════════════════════════════════════════════════════

// Structured Outcome/Failure/Diagnostic algebraic data types
// Provides simple Result-like helpers with diagnostics attached to failures.

export const FAILURE_CODES = [
  "invalid_input",
  "not_found",
  "conflict",
  "unauthorized",
  "forbidden",
  "timeout",
  "unavailable",
  "internal_error",
] as const;

export type FailureCode = (typeof FAILURE_CODES)[number];

export type DiagnosticSeverity = "error" | "warning" | "info";

export type DiagnosticPosition = {
  line: number;
  column: number;
  offset?: number;
};

export type DiagnosticSpan = {
  file?: string;
  start: DiagnosticPosition;
  end?: DiagnosticPosition;
};

export type Diagnostic = {
  message: string;
  severity: DiagnosticSeverity;
  span?: DiagnosticSpan;
  code?: string;
  source?: string;
  data?: Record<string, unknown>;
};

export type Failure = {
  code: FailureCode;
  message: string;
  diagnostics: Diagnostic[];
  cause?: unknown;
  data?: Record<string, unknown>;
};

export type Ok<T> = {
  tag: "Ok";
  value: T;
  diagnostics: Diagnostic[];
};

export type Err<F extends Failure = Failure> = {
  tag: "Err";
  failure: F;
};

export type Outcome<T> = Ok<T> | Err<Failure>;

type FailureOptions = {
  diagnostics?: Diagnostic[];
  cause?: unknown;
  data?: Record<string, unknown>;
};

type DiagnosticExtras = {
  code?: string;
  source?: string;
  data?: Record<string, unknown>;
};

const FAILURE_CODE_SET = new Set<string>(FAILURE_CODES as readonly string[]);

function assertFailureCode(code: FailureCode | string): asserts code is FailureCode {
  if (!FAILURE_CODE_SET.has(code)) {
    throw new Error(`Unknown failure code: ${code}`);
  }
}

export function failure(code: FailureCode, message: string, options: FailureOptions = {}): Failure {
  assertFailureCode(code);
  return {
    code,
    message,
    diagnostics: options.diagnostics ?? [],
    cause: options.cause,
    data: options.data,
  };
}

export function ok<T>(value: T, diagnostics: Diagnostic[] = []): Ok<T> {
  return { tag: "Ok", value, diagnostics };
}

export function err(codeOrFailure: Failure | FailureCode, message?: string, options: FailureOptions = {}): Err {
  if (typeof codeOrFailure === "string") {
    const failureMessage = message ?? codeOrFailure;
    return { tag: "Err", failure: failure(codeOrFailure, failureMessage, options) };
  }

  assertFailureCode(codeOrFailure.code);
  return { tag: "Err", failure: codeOrFailure };
}

export function isOk<T>(outcome: Outcome<T>): outcome is Ok<T> {
  return outcome.tag === "Ok";
}

export function isErr<T>(outcome: Outcome<T>): outcome is Err {
  return outcome.tag === "Err";
}

function diagnostic(
  severity: DiagnosticSeverity,
  message: string,
  span?: DiagnosticSpan,
  extras: DiagnosticExtras = {},
): Diagnostic {
  return {
    severity,
    message,
    span,
    ...extras,
  };
}

export function warn(message: string, span?: DiagnosticSpan, extras?: DiagnosticExtras): Diagnostic {
  return diagnostic("warning", message, span, extras);
}

export function info(message: string, span?: DiagnosticSpan, extras?: DiagnosticExtras): Diagnostic {
  return diagnostic("info", message, span, extras);
}

export function error(message: string, span?: DiagnosticSpan, extras?: DiagnosticExtras): Diagnostic {
  return diagnostic("error", message, span, extras);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/pipeline/anf.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/pipeline/anf.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION (Prompt 8)
// ANF Transform: Convert expressions to A-Normal Form
//
// In ANF:
// - All intermediate values are bound to names
// - Effect points are explicit (each effect is in tail position of a let)
// - Enables optimization passes (fusion, hoisting, memoization)

import type { Expr } from "../ast";

/**
 * Counter for generating fresh names
 */
let anfCounter = 0;
function freshVar(prefix: string = "t"): string {
  return `${prefix}$${++anfCounter}`;
}

/**
 * Reset the counter (for testing)
 */
export function resetAnfCounter(): void {
  anfCounter = 0;
}

/**
 * Check if an expression is atomic (doesn't need binding)
 * Atomic: Lit, Var, Lambda
 */
function isAtomic(e: Expr): boolean {
  return e.tag === "Lit" || e.tag === "Var" || e.tag === "Lambda";
}

/**
 * Convert an expression to ANF.
 * Returns a pair: [bindings, result]
 * where bindings is a list of (name, expr) pairs
 * and result is an atomic expression
 */
type Binding = { name: string; expr: Expr };

function anfExpr(e: Expr): { bindings: Binding[]; result: Expr } {
  switch (e.tag) {
    case "Lit":
    case "Var":
      return { bindings: [], result: e };

    case "Lambda": {
      // Transform body but keep lambda atomic
      const body = anfToExpr(anfExpr(e.body));
      return {
        bindings: [],
        result: { ...e, body },
      };
    }

    case "If": {
      // Transform test, but branches stay as expressions
      const testAnf = anfExpr(e.test);
      const conseq = anfToExpr(anfExpr(e.conseq));
      const alt = anfToExpr(anfExpr(e.alt));

      if (isAtomic(testAnf.result)) {
        return {
          bindings: testAnf.bindings,
          result: { ...e, test: testAnf.result, conseq, alt },
        };
      }

      // Bind test to a variable
      const testVar = freshVar("test");
      return {
        bindings: [
          ...testAnf.bindings,
          { name: testVar, expr: testAnf.result },
        ],
        result: { ...e, test: { tag: "Var", name: testVar }, conseq, alt },
      };
    }

    case "App": {
      // Transform fn and all args
      const fnAnf = anfExpr(e.fn);
      const argsAnf = e.args.map(anfExpr);

      const bindings: Binding[] = [...fnAnf.bindings];

      // Bind fn if not atomic
      let fnResult = fnAnf.result;
      if (!isAtomic(fnResult)) {
        const fnVar = freshVar("fn");
        bindings.push({ name: fnVar, expr: fnResult });
        fnResult = { tag: "Var", name: fnVar };
      }

      // Bind args if not atomic
      const argResults: Expr[] = [];
      for (const argAnf of argsAnf) {
        bindings.push(...argAnf.bindings);
        if (isAtomic(argAnf.result)) {
          argResults.push(argAnf.result);
        } else {
          const argVar = freshVar("arg");
          bindings.push({ name: argVar, expr: argAnf.result });
          argResults.push({ tag: "Var", name: argVar });
        }
      }

      // The application itself may need binding if used in complex context
      const appExpr: Expr = { tag: "App", fn: fnResult, args: argResults };
      return { bindings, result: appExpr };
    }

    case "Effect": {
      // Transform args
      const argsAnf = e.args.map(anfExpr);

      const bindings: Binding[] = [];
      const argResults: Expr[] = [];

      for (const argAnf of argsAnf) {
        bindings.push(...argAnf.bindings);
        if (isAtomic(argAnf.result)) {
          argResults.push(argAnf.result);
        } else {
          const argVar = freshVar("arg");
          bindings.push({ name: argVar, expr: argAnf.result });
          argResults.push({ tag: "Var", name: argVar });
        }
      }

      const effectExpr: Expr = { tag: "Effect", op: e.op, args: argResults };
      return { bindings, result: effectExpr };
    }

    case "Begin": {
      // Transform each expression in sequence
      const exprsAnf = e.exprs.map(anfExpr);

      const allBindings: Binding[] = [];
      const results: Expr[] = [];

      for (const exprAnf of exprsAnf) {
        allBindings.push(...exprAnf.bindings);
        results.push(exprAnf.result);
      }

      // Begin with transformed expressions
      return {
        bindings: allBindings,
        result: { tag: "Begin", exprs: results },
      };
    }

    case "Define": {
      // Transform RHS
      const rhsAnf = anfExpr(e.rhs);
      const rhs = anfToExpr(rhsAnf);
      return {
        bindings: [],
        result: { ...e, rhs },
      };
    }

    case "Set": {
      // Transform RHS
      const rhsAnf = anfExpr(e.rhs);
      const bindings = [...rhsAnf.bindings];
      let rhs = rhsAnf.result;

      if (!isAtomic(rhs)) {
        const rhsVar = freshVar("rhs");
        bindings.push({ name: rhsVar, expr: rhs });
        rhs = { tag: "Var", name: rhsVar };
      }

      return {
        bindings,
        result: { ...e, rhs },
      };
    }

    case "Handle": {
      // Transform body and clause bodies
      const body = anfToExpr(anfExpr(e.body));
      const handler = {
        ...e.handler,
        on: e.handler.on.map(clause => ({
          ...clause,
          body: anfToExpr(anfExpr(clause.body)),
        })),
        ret: e.handler.ret ? {
          ...e.handler.ret,
          body: anfToExpr(anfExpr(e.handler.ret.body)),
        } : undefined,
        fin: e.handler.fin ? {
          ...e.handler.fin,
          body: anfToExpr(anfExpr(e.handler.fin.body)),
        } : undefined,
      };

      return {
        bindings: [],
        result: { ...e, body, handler },
      };
    }

    case "Let": {
      // Transform bindings and body
      const bindingsAnf = e.bindings.map(b => ({
        name: b.name,
        init: anfToExpr(anfExpr(b.init)),
      }));
      const body = anfToExpr(anfExpr(e.body));

      return {
        bindings: [],
        result: { ...e, bindings: bindingsAnf, body },
      };
    }

    case "Letrec": {
      // Transform bindings and body
      const bindingsAnf = e.bindings.map(b => ({
        name: b.name,
        init: anfToExpr(anfExpr(b.init)),
      }));
      const body = anfToExpr(anfExpr(e.body));

      return {
        bindings: [],
        result: { ...e, bindings: bindingsAnf, body },
      };
    }

    case "Match": {
      // Transform scrutinee and clause bodies
      const scrutineeAnf = anfExpr(e.scrutinee);
      const bindings = [...scrutineeAnf.bindings];

      let scrutinee = scrutineeAnf.result;
      if (!isAtomic(scrutinee)) {
        const scrutVar = freshVar("scrut");
        bindings.push({ name: scrutVar, expr: scrutinee });
        scrutinee = { tag: "Var", name: scrutVar };
      }

      const clauses = e.clauses.map(c => ({
        ...c,
        body: anfToExpr(anfExpr(c.body)),
      }));

      return {
        bindings,
        result: { ...e, scrutinee, clauses },
      };
    }

    case "OracleLambda": {
      // Transform spec
      const spec = anfToExpr(anfExpr(e.spec));
      return {
        bindings: [],
        result: { ...e, spec },
      };
    }

    case "Quote":
    case "QuoteSyntax":
      return { bindings: [], result: e };

    default:
      // Unknown expression type - return as-is
      return { bindings: [], result: e };
  }
}

/**
 * Convert ANF result back to expression with let bindings
 */
function anfToExpr(anf: { bindings: Binding[]; result: Expr }): Expr {
  if (anf.bindings.length === 0) {
    return anf.result;
  }

  // Wrap in nested lets
  let result = anf.result;
  for (let i = anf.bindings.length - 1; i >= 0; i--) {
    const b = anf.bindings[i];
    result = {
      tag: "Let",
      bindings: [{ name: b.name, init: b.expr }],
      body: result,
    };
  }

  return result;
}

/**
 * Transform an expression to ANF
 */
export function toAnf(e: Expr): Expr {
  resetAnfCounter();
  return anfToExpr(anfExpr(e));
}

/**
 * Check if an expression is in ANF
 * (useful for testing)
 */
export function isAnf(e: Expr): boolean {
  switch (e.tag) {
    case "Lit":
    case "Var":
    case "Quote":
    case "QuoteSyntax":
      return true;

    case "Lambda":
      return isAnf(e.body);

    case "If":
      return isAtomic(e.test) && isAnf(e.conseq) && isAnf(e.alt);

    case "App":
      return isAtomic(e.fn) && e.args.every(isAtomic);

    case "Effect":
      return e.args.every(isAtomic);

    case "Begin":
      return e.exprs.every(isAnf);

    case "Define":
      return isAnf(e.rhs);

    case "Set":
      return isAtomic(e.rhs);

    case "Let":
      return e.bindings.every(b => isAnf(b.init)) && isAnf(e.body);

    case "Letrec":
      return e.bindings.every(b => isAnf(b.init)) && isAnf(e.body);

    case "Handle":
      return isAnf(e.body);

    case "Match":
      return isAtomic(e.scrutinee) && e.clauses.every(c => isAnf(c.body));

    case "OracleLambda":
      return isAnf(e.spec);

    default:
      return false;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/pipeline/compileText.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-5.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import { tokenize } from "../reader/tokenize";
import { parseAll } from "../reader/parse";
import { datumToSyntax } from "../reader/toSyntax";
import type { Syntax, SIdent, SList } from "../syntax/syntax";
import { isIdent, isList, addScope, freshScope } from "../syntax/syntax";
import type { Binding, Env } from "../syntax/binding";
import { resolveIdent } from "../syntax/binding";
import type { Expr, HandlerExpr } from "../ast";
import { compileSyntaxRules, applySyntaxRules, type SRRule, type SRTransformer } from "../expand/syntaxRules";
import { lowerSyntax } from "./lower";
import { sym, type Datum, isSym } from "../reader/datum";

/** Deterministic counters: no Math.random in the compiler core (reproducibility). */
type Counters = { scope: { n: number }, bid: { n: number } };

function freshBid(c: Counters): string {
  c.bid.n += 1;
  return `bid#${c.bid.n}`;
}

function internalName(name: string, bid: string): string {
  return `${name}$${bid}`;
}

/** Create a new value binding for an identifier syntax object. */
function bindValue(env: Env, id: SIdent, bid: string, internal: string): Env {
  const b: Binding = {
    bid,
    name: id.name,
    scopes: id.scopes.slice(),
    phase: 0,
    kind: "value",
    value: internal,
  };
  return env.concat([b]);
}

/** Create a new syntax binding (macro). */
function bindSyntax(env: Env, id: SIdent, bid: string, tr: SRTransformer): Env {
  const b: Binding = {
    bid,
    name: id.name,
    scopes: id.scopes.slice(),
    phase: 1,
    kind: "syntax",
    value: tr,
  };
  return env.concat([b]);
}

function headName(stx: Syntax): string | null {
  if (!isList(stx)) return null;
  const items = stx.items;
  if (items.length === 0) return null;
  const h = items[0];
  return isIdent(h) ? h.name : null;
}

function expectList(stx: Syntax, msg: string): SList {
  if (!isList(stx)) throw new Error(msg);
  return stx;
}

function expectIdent(stx: Syntax, msg: string): SIdent {
  if (!isIdent(stx)) throw new Error(msg);
  return stx;
}

/**
 * Initialize compile-time env with primitive bindings whose runtime internal names match.
 * This MUST align with installPrims() in src/core/prims.ts
 */
function initialEnv(moduleScope: string): Env {
  // All 117 primitives from src/core/prims.ts
  const prims = [
    // Arithmetic
    "+", "-", "*", "/", "modulo",
    // Comparison
    "=", "<", ">", "<=", ">=",
    // Logic
    "not", "even?",
    // Special values
    "unit", "mzero", "mplus", "bind", "*uninit*",
    // Continuations
    "call/cc", "call-with-prompt", "abort-to-prompt",
    // Conditions
    "signal", "error", "invoke-restart", "find-restart", "compute-restarts", "handler-bind", "restart-bind",
    // List operations
    "cons", "car", "cdr", "null?", "pair?", "list", "append", "length", "reverse", "list-ref",
    "cadr", "caddr",
    // Equality
    "eq?", "equal?",
    // Type predicates
    "symbol?", "string?", "number?", "boolean?", "procedure?",
    // String operations
    "string=?", "string-contains?", "string-replace-all", "string-split", "string-join",
    "string-trim", "string-downcase", "string-upcase", "string-length", "string-append", "substring",
    // Higher-order functions
    "map", "filter", "fold", "foldr", "andmap", "ormap",
    "apply", "compose", "partial", "pipe", "identity", "constantly",
    // Distribution operations
    "dist", "dist?", "dist-count", "dist-value-at", "dist-weight-at", "dist-normalize",
    "dist-sample", "dist-topk", "dist-from-list", "dist-to-list",
    // Stream operations
    "the-empty-stream", "stream-null?", "stream-car", "stream-cdr",
    "stream-map", "stream-filter", "stream-take", "stream->list", "list->stream",
    // Promise/delay operations
    "make-promise", "force", "promise?", "promise-forced?",
    // Generic dispatch / tagged data
    "attach-tag", "type-tag", "contents", "tagged?",
    "make-op-table", "op-table?", "op-table-get", "op-table-put",
    "apply-generic", "apply-generic-coerced",
    "make-coercion-table", "coercion-table?", "get-coercion", "put-coercion",
    "find-coercion-path", "find-all-coercion-paths", "coerce-value",
    // Pattern matching
    "match-pattern", "substitute-template",
    // Rule/rewriting
    "make-rule", "make-rule-where", "rule?",
    "rewrite-once", "rewrite-fixpoint", "rewrite-trace", "rewrite-conflicts",
    // Evidence
    "evidence-id", "verify-evidence", "evidence-stale?",
    // Machine introspection (debugging)
    "machine-new", "machine?", "machine-step", "machine-run", "machine-done?",
    "machine-value", "machine-control", "machine-stack", "machine-step-count",
    "machine-fork", "machine-resume", "machine-add-breakpoint", "machine-last-op",
  ];
  let env: Env = [];
  for (const p of prims) {
    env = env.concat([{
      bid: `prim:${p}`,
      name: p,
      scopes: [moduleScope],  // imported into module scope
      phase: 0,
      kind: "value",
      value: p,               // runtime internal name = symbol name
    } satisfies Binding]);
  }
  return env;
}

/**
 * Compile text to core Expr:
 *   read → syntax(with module scope) → expand (define/define-syntax) → lower to Expr
 */
export function compileTextToExpr(src: string): Expr {
  const toks = tokenize(src);
  const ds = parseAll(toks);

  // If multiple forms, wrap in (begin ...)
  const topDatum: Datum =
    ds.length === 1 ? ds[0] : [sym("begin"), ...ds];

  // Datum → Syntax
  let stx = datumToSyntax(topDatum);

  // Counters + module scope
  const c: Counters = { scope: { n: 0 }, bid: { n: 0 } };
  const M0 = freshScope(c.scope);
  stx = addScope(stx, M0);

  // Compile-time env Γ (phases included in one list, filtered by resolveIdent)
  let env: Env = initialEnv(M0);

  // Expand top-level expression (stateful over begin sequence)
  const expanded = expandTop(stx, env, c);
  env = expanded.env;

  // Lower to core Expr using global env table (scope sets disambiguate)
  return lowerSyntax(expanded.stx, env);
}

/** Result carrying updated env (monotonic binding table). */
type ExpandRes = { stx: Syntax; env: Env };

/** Expand top-level expression; begin processes definitions sequentially. */
function expandTop(stx: Syntax, env: Env, c: Counters): ExpandRes {
  if (isList(stx) && headName(stx) === "begin") {
    const items = stx.items.slice(1);
    const seq = expandSequence(items, env, c);
    // Rewrap into begin
    return { stx: { ...stx, items: [stx.items[0], ...seq.items] }, env: seq.env };
  }
  // Otherwise treat as expression (no define-syntax at top level in this minimal harness)
  const e = expandExpr(stx, env, c);
  return e;
}

function expandSequence(items: Syntax[], env: Env, c: Counters): { items: Syntax[]; env: Env } {
  const out: Syntax[] = [];
  let Γ = env;

  for (const form of items) {
    const hn = headName(form);
    if (hn === "define-syntax") {
      // compile and install macro; remove from runtime output
      // headName returning non-null implies form is a list
      const r = expandDefineSyntax(form as SList, Γ, c);
      Γ = r.env;
      continue;
    }

    if (hn === "define") {
      // headName returning non-null implies form is a list
      const r = expandDefine(form as SList, Γ, c);
      Γ = r.env;
      out.push(r.stx);
      continue;
    }

    // ordinary expression
    const r = expandExpr(form, Γ, c);
    Γ = r.env;
    out.push(r.stx);
  }

  return { items: out, env: Γ };
}

/**
 * Expand an expression, performing macro expansion and binder-scope insertion
 * for reserved binding forms (lambda, let).
 */
function expandExpr(stx: Syntax, env: Env, c: Counters): ExpandRes {
  if (!isList(stx)) return { stx, env };

  if (stx.items.length === 0) return { stx, env };

  const h = stx.items[0];
  if (!isIdent(h)) {
    // Expand children
    let Γ = env;
    const items2 = [];
    for (const it of stx.items) {
      const r = expandExpr(it, Γ, c);
      Γ = r.env;
      items2.push(r.stx);
    }
    return { stx: { ...stx, items: items2 }, env: Γ };
  }

  // Reserved forms (keywords)
  switch (h.name) {
    case "quote":
      // do not expand under quote
      return { stx, env };

    case "begin": {
      const seq = expandSequence(stx.items.slice(1), env, c);
      return { stx: { ...stx, items: [h, ...seq.items] }, env: seq.env };
    }

    case "if": {
      if (stx.items.length !== 4) throw new Error("if: expected (if test conseq alt)");
      const r1 = expandExpr(stx.items[1], env, c);
      const r2 = expandExpr(stx.items[2], r1.env, c);
      const r3 = expandExpr(stx.items[3], r2.env, c);
      return { stx: { ...stx, items: [h, r1.stx, r2.stx, r3.stx] }, env: r3.env };
    }

    case "lambda":
      return expandLambda(stx, env, c);

    case "oracle-lambda":
      return expandOracleLambda(stx, env, c);

    case "let":
      return expandLet(stx, env, c);

    case "letrec":
      return expandLetrec(stx, env, c);

    case "set!": {
      if (stx.items.length !== 3) throw new Error("set!: expected (set! x rhs)");
      const rhs = expandExpr(stx.items[2], env, c);
      return { stx: { ...stx, items: [h, stx.items[1], rhs.stx] }, env: rhs.env };
    }

    case "effect": {
      // (effect op arg...)
      let Γ = env;
      const items2: Syntax[] = [h, stx.items[1]];
      for (let i = 2; i < stx.items.length; i++) {
        const r = expandExpr(stx.items[i], Γ, c);
        Γ = r.env;
        items2.push(r.stx);
      }
      return { stx: { ...stx, items: items2 }, env: Γ };
    }

    case "handle": {
      // (handle body (on op (x k) ...) (return (v) ...) (finally ...))
      // Expand body and clause bodies. We treat clause syntax structurally; no macro expansion in op names.
      if (stx.items.length < 2) throw new Error("handle: expected (handle body ...clauses)");
      const bodyR = expandExpr(stx.items[1], env, c);

      let Γ = bodyR.env;
      const clauses2: Syntax[] = [h, bodyR.stx];

      for (let i = 2; i < stx.items.length; i++) {
        const cl = stx.items[i];
        // Expand clause body conservatively:
        // (on op (x k) body) etc. We'll expand the body expression position.
        if (isList(cl) && cl.items.length >= 2 && isIdent(cl.items[0])) {
          const tag = (cl.items[0] as SIdent).name;
          if (tag === "on") {
            const bodyIdx = cl.items.length - 1;
            const b = expandExpr(cl.items[bodyIdx], Γ, c);
            Γ = b.env;
            const cl2 = { ...cl, items: cl.items.slice(0, bodyIdx).concat([b.stx]) };
            clauses2.push(cl2);
            continue;
          }
          if (tag === "return") {
            const bodyIdx = cl.items.length - 1;
            const b = expandExpr(cl.items[bodyIdx], Γ, c);
            Γ = b.env;
            const cl2 = { ...cl, items: cl.items.slice(0, bodyIdx).concat([b.stx]) };
            clauses2.push(cl2);
            continue;
          }
          if (tag === "finally") {
            const bodyIdx = cl.items.length - 1;
            const b = expandExpr(cl.items[bodyIdx], Γ, c);
            Γ = b.env;
            const cl2 = { ...cl, items: cl.items.slice(0, bodyIdx).concat([b.stx]) };
            clauses2.push(cl2);
            continue;
          }
        }
        // unknown clause shape: expand it as ordinary expression
        const r = expandExpr(cl, Γ, c);
        Γ = r.env;
        clauses2.push(r.stx);
      }

      return { stx: { ...stx, items: clauses2 }, env: Γ };
    }

    case "handler-bind": {
      if (stx.items.length < 3) throw new Error("handler-bind: expected (handler-bind ((type handler) ...) body...)");
      const bindsList = expectList(stx.items[1], "handler-bind: bindings must be list");
      let envBind = env;
      const bindsOut: Syntax[] = [];
      for (const b of bindsList.items) {
        const pair = expectList(b, "handler-bind: binding must be list");
        if (pair.items.length !== 2) throw new Error("handler-bind: binding must be (type handler)");
        const handlerR = expandExpr(pair.items[1], envBind, c);
        envBind = handlerR.env;
        bindsOut.push({ ...pair, items: [pair.items[0], handlerR.stx] });
      }
      let envBody = envBind;
      const bodyOut: Syntax[] = [];
      for (let i = 2; i < stx.items.length; i++) {
        const r = expandExpr(stx.items[i], envBody, c);
        envBody = r.env;
        bodyOut.push(r.stx);
      }
      const bindsListOut: Syntax = { ...bindsList, items: bindsOut };
      return { stx: { ...stx, items: [stx.items[0], bindsListOut, ...bodyOut] }, env: envBody };
    }

    case "restart-bind": {
      if (stx.items.length < 3) throw new Error("restart-bind: expected (restart-bind ((name fn) ...) body...)");
      const bindsList = expectList(stx.items[1], "restart-bind: bindings must be list");
      let envBind = env;
      const bindsOut: Syntax[] = [];
      for (const b of bindsList.items) {
        const pair = expectList(b, "restart-bind: binding must be list");
        if (pair.items.length !== 2) throw new Error("restart-bind: binding must be (name fn)");
        const fnR = expandExpr(pair.items[1], envBind, c);
        envBind = fnR.env;
        bindsOut.push({ ...pair, items: [pair.items[0], fnR.stx] });
      }
      let envBody = envBind;
      const bodyOut: Syntax[] = [];
      for (let i = 2; i < stx.items.length; i++) {
        const r = expandExpr(stx.items[i], envBody, c);
        envBody = r.env;
        bodyOut.push(r.stx);
      }
      const bindsListOut: Syntax = { ...bindsList, items: bindsOut };
      return { stx: { ...stx, items: [stx.items[0], bindsListOut, ...bodyOut] }, env: envBody };
    }
  }

  // Macro application: resolve head at phase 1 in "syntax" binding space
  const macroBinding = resolveIdent(h, env, 1, "syntax");
  if (macroBinding) {
    const tr = macroBinding.value as SRTransformer;
    // IMPORTANT: we do NOT “add surrounding binder scopes” to the expansion output.
    // Hygiene is preserved because only substituted pieces carry call-site scopes.
    const out = applySyntaxRules(tr, stx, env, c.scope);
    return expandExpr(out, env, c); // macro chaining
  }

  // Not a macro: recursively expand children (function position and args)
  let Γ = env;
  const items2: Syntax[] = [];
  for (const it of stx.items) {
    const r = expandExpr(it, Γ, c);
    Γ = r.env;
    items2.push(r.stx);
  }
  return { stx: { ...stx, items: items2 }, env: Γ };
}

function expandLambda(stx: SList, env: Env, c: Counters): ExpandRes {
  // (lambda (x ...) body...)
  if (stx.items.length < 3) throw new Error("lambda: expected (lambda (params) body...)");
  const paramsList = expectList(stx.items[1], "lambda: params must be list");
  const bodyForms = stx.items.slice(2);

  const B = freshScope(c.scope);

  // Scope params with binder scope
  const paramsB: SIdent[] = paramsList.items.map(p => expectIdent(p, "lambda param must be ident"))
    .map(p => addScope(p, B) as SIdent);

  // Extend env with param bindings (monotonic table)
  let Γ = env;
  for (const p of paramsB) {
    const bid = freshBid(c);
    Γ = bindValue(Γ, p, bid, internalName(p.name, bid));
  }

  // Add binder scope to body BEFORE expanding
  const bodyScoped = bodyForms.map(b => addScope(b, B));
  const bodyExpanded: Syntax[] = [];
  let Γ2 = Γ;
  for (const b of bodyScoped) {
    const r = expandExpr(b, Γ2, c);
    Γ2 = r.env;
    bodyExpanded.push(r.stx);
  }

  const stx2: Syntax = {
    ...stx,
    items: [
      stx.items[0],
      { ...paramsList, items: paramsB },
      ...bodyExpanded,
    ],
  };

  return { stx: stx2, env: Γ2 };
}

function expandOracleLambda(stx: SList, env: Env, c: Counters): ExpandRes {
  // (oracle-lambda (x ...) spec)
  // Similar to lambda but params are scoped for use in spec (the prompt/goal)
  if (stx.items.length !== 3) throw new Error("oracle-lambda: expected (oracle-lambda (params) spec)");
  const paramsList = expectList(stx.items[1], "oracle-lambda: params must be list");
  const specForm = stx.items[2];

  const B = freshScope(c.scope);

  // Scope params with binder scope
  const paramsB: SIdent[] = paramsList.items.map(p => expectIdent(p, "oracle-lambda param must be ident"))
    .map(p => addScope(p, B) as SIdent);

  // Extend env with param bindings
  let Γ = env;
  for (const p of paramsB) {
    const bid = freshBid(c);
    Γ = bindValue(Γ, p, bid, internalName(p.name, bid));
  }

  // Add binder scope to spec and expand
  const specScoped = addScope(specForm, B);
  const specR = expandExpr(specScoped, Γ, c);

  const stx2: Syntax = {
    ...stx,
    items: [
      stx.items[0],
      { ...paramsList, items: paramsB },
      specR.stx,
    ],
  };

  return { stx: stx2, env: specR.env };
}

function expandLet(stx: SList, env: Env, c: Counters): ExpandRes {
  // (let ((x e) ...) body...)
  if (stx.items.length < 3) throw new Error("let: expected (let ((x e) ...) body...)");
  const bindsList = expectList(stx.items[1], "let: bindings must be list");
  const bodyForms = stx.items.slice(2);

  const B = freshScope(c.scope);

  // Expand initializers first (non-recursive let): do NOT add binder scope B
  let Γ = env;
  const bindPairs: Array<{ idB: SIdent; init: Syntax }> = [];

  for (const bp of bindsList.items) {
    const pair = expectList(bp, "let: binding must be list");
    if (pair.items.length !== 2) throw new Error("let: binding must be (x init)");
    const id = expectIdent(pair.items[0], "let: binder must be ident");
    const init0 = pair.items[1];

    const initR = expandExpr(init0, Γ, c);
    Γ = initR.env;

    const idB = addScope(id, B) as SIdent;
    bindPairs.push({ idB, init: initR.stx });
  }

  // Now install binder bindings into env
  for (const { idB } of bindPairs) {
    const bid = freshBid(c);
    Γ = bindValue(Γ, idB, bid, internalName(idB.name, bid));
  }

  // Add binder scope to body BEFORE expanding
  const bodyScoped = bodyForms.map(b => addScope(b, B));
  const bodyExpanded: Syntax[] = [];
  let Γ2 = Γ;

  for (const b of bodyScoped) {
    const r = expandExpr(b, Γ2, c);
    Γ2 = r.env;
    bodyExpanded.push(r.stx);
  }

  const bindsOut: Syntax = {
    ...bindsList,
    items: bindPairs.map(({ idB, init }) => ({
      tag: "List",
      scopes: [],
      items: [idB, init],
    })),
  };

  const stx2: Syntax = {
    ...stx,
    items: [stx.items[0], bindsOut, ...bodyExpanded],
  };

  return { stx: stx2, env: Γ2 };
}

function expandLetrec(stx: SList, env: Env, c: Counters): ExpandRes {
  // (letrec ((x e) ...) body...)
  // Unlike let, bindings ARE in scope for their own init expressions (recursive)
  if (stx.items.length < 3) throw new Error("letrec: expected (letrec ((x e) ...) body...)");
  const bindsList = expectList(stx.items[1], "letrec: bindings must be list");
  const bodyForms = stx.items.slice(2);

  const B = freshScope(c.scope);

  // For letrec, we need to add bindings BEFORE expanding init expressions
  // First, collect all the identifiers and add binder scope
  const bindersWithScope: SIdent[] = [];
  let Γ = env;

  for (const bp of bindsList.items) {
    const pair = expectList(bp, "letrec: binding must be list");
    if (pair.items.length !== 2) throw new Error("letrec: binding must be (x init)");
    const id = expectIdent(pair.items[0], "letrec: binder must be ident");
    const idB = addScope(id, B) as SIdent;
    bindersWithScope.push(idB);

    // Install binding NOW (before processing inits)
    const bid = freshBid(c);
    Γ = bindValue(Γ, idB, bid, internalName(idB.name, bid));
  }

  // Now expand init expressions WITH bindings in scope
  const bindPairs: Array<{ idB: SIdent; init: Syntax }> = [];

  for (let i = 0; i < bindsList.items.length; i++) {
    const pair = expectList(bindsList.items[i], "letrec: binding must be list");
    const init0 = pair.items[1];
    // Add binder scope to init expression (so refs can see the bindings)
    const initScoped = addScope(init0, B);
    const initR = expandExpr(initScoped, Γ, c);
    Γ = initR.env;
    bindPairs.push({ idB: bindersWithScope[i], init: initR.stx });
  }

  // Add binder scope to body BEFORE expanding
  const bodyScoped = bodyForms.map(b => addScope(b, B));
  const bodyExpanded: Syntax[] = [];
  let Γ2 = Γ;

  for (const b of bodyScoped) {
    const r = expandExpr(b, Γ2, c);
    Γ2 = r.env;
    bodyExpanded.push(r.stx);
  }

  const bindsOut: Syntax = {
    ...bindsList,
    items: bindPairs.map(({ idB, init }) => ({
      tag: "List",
      scopes: [],
      items: [idB, init],
    })),
  };

  const stx2: Syntax = {
    ...stx,
    items: [stx.items[0], bindsOut, ...bodyExpanded],
  };

  return { stx: stx2, env: Γ2 };
}

function expandDefine(stx: SList, env: Env, c: Counters): ExpandRes {
  // (define x rhs) or (define (f args...) body...)
  if (stx.items.length < 3) throw new Error("define: expected (define x rhs) or (define (f ...) ...)");
  const target = stx.items[1];

  // function definition sugar
  if (isList(target)) {
    const sig = target;
    if (sig.items.length < 1 || !isIdent(sig.items[0])) throw new Error("define: bad function signature");
    const f = sig.items[0] as SIdent;
    const args = sig.items.slice(1);
    const lambdaForm: Syntax = {
      tag: "List",
      scopes: [],
      items: [
        { tag: "Ident", name: "lambda", scopes: (stx.items[0] as any).scopes ?? [] },
        { tag: "List", scopes: [], items: args },
        ...stx.items.slice(2),
      ],
    };
    const rewritten: Syntax = {
      ...stx,
      items: [stx.items[0], f, lambdaForm],
    };
    return expandDefine(rewritten as SList, env, c);
  }

  const id = expectIdent(target, "define: name must be ident");
  // Install binding before expanding RHS (supports self recursion)
  let Γ = env;
  const bid = freshBid(c);
  Γ = bindValue(Γ, id, bid, internalName(id.name, bid));

  const rhs0 = stx.items[2];
  const rhsR = expandExpr(rhs0, Γ, c);
  Γ = rhsR.env;

  const stx2: Syntax = { ...stx, items: [stx.items[0], id, rhsR.stx] };
  return { stx: stx2, env: Γ };
}

function expandDefineSyntax(stx: SList, env: Env, c: Counters): ExpandRes {
  // (define-syntax m (syntax-rules (lits...) (pat tmpl) ...))
  if (stx.items.length !== 3) throw new Error("define-syntax: expected (define-syntax name transformer)");
  const id = expectIdent(stx.items[1], "define-syntax: name must be ident");
  const rhs = stx.items[2];

  const tr = compileTransformer(rhs, env);
  const bid = freshBid(c);
  const Γ = bindSyntax(env, id, bid, tr);
  // define-syntax disappears at runtime
  return { stx: { tag: "Atom", value: null, scopes: [] }, env: Γ };
}

function compileTransformer(rhs: Syntax, envDefOut: Env): SRTransformer {
  // only syntax-rules supported in this harness
  const r = expectList(rhs, "define-syntax: transformer must be list");
  if (r.items.length < 3) throw new Error("syntax-rules: expected (syntax-rules (lits) (pat tmpl)...)");

  const h = expectIdent(r.items[0], "syntax-rules: head must be ident");
  if (h.name !== "syntax-rules") throw new Error("define-syntax: only syntax-rules supported");

  const litsList = expectList(r.items[1], "syntax-rules: literal list must be list");
  const literals = litsList.items.map(x => expectIdent(x, "syntax-rules literal must be ident"));

  const rules: SRRule[] = [];
  for (let i = 2; i < r.items.length; i++) {
    const rr = expectList(r.items[i], "syntax-rules: rule must be list");
    if (rr.items.length !== 2) throw new Error("syntax-rules: each rule must be (pat tmpl)");
    rules.push({ pat: rr.items[0], tmpl: rr.items[1] });
  }

  // phaseOut = 0 for normal macros
  return compileSyntaxRules(0, envDefOut.slice(), literals, rules);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/pipeline/lower.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Syntax, SIdent, SList } from "../syntax/syntax";
import { isIdent, isList } from "../syntax/syntax";
import type { Env } from "../syntax/binding";
import { resolveIdent } from "../syntax/binding";
import type { Expr, HandlerExpr, Pattern } from "../ast";

function expectIdent(stx: Syntax, msg: string): SIdent {
  if (!isIdent(stx)) throw new Error(msg);
  return stx;
}
function expectList(stx: Syntax, msg: string): SList {
  if (!isList(stx)) throw new Error(msg);
  return stx;
}

function lowerVar(id: SIdent, env: Env, phase: number): Expr {
  const b = resolveIdent(id, env, phase);
  if (!b) return { tag: "Var", name: id.name };
  return { tag: "Var", name: b.value as string };
}

export function lowerSyntax(stx: Syntax, env: Env, phase = 0): Expr {
  if (stx.tag === "Atom") {
    const v = stx.value;
    if (typeof v === "number" || typeof v === "string" || typeof v === "boolean" || v === null) {
      return { tag: "Lit", value: v };
    }
    return { tag: "Lit", value: String(v) };
  }

  if (stx.tag === "Ident") return lowerVar(stx, env, phase);

  const items = stx.items;
  if (items.length === 0) return { tag: "Quote", datum: [] };

  const h = items[0];

  if (isIdent(h)) {
    switch (h.name) {
      case "quote": {
        if (items.length !== 2) throw new Error("quote: expected (quote datum)");
        return { tag: "Quote", datum: stripDatum(items[1]) };
      }

      case "begin": {
        return { tag: "Begin", exprs: items.slice(1).map(x => lowerSyntax(x, env, phase)) };
      }

      case "if": {
        if (items.length !== 4) throw new Error("if: expected (if t c a)");
        return {
          tag: "If",
          test: lowerSyntax(items[1], env, phase),
          conseq: lowerSyntax(items[2], env, phase),
          alt: lowerSyntax(items[3], env, phase),
        };
      }

      case "lambda": {
        if (items.length < 3) throw new Error("lambda: expected (lambda (params) body...)");
        const paramsList = expectList(items[1], "lambda: params must be list");
        const params = paramsList.items.map(p => {
          const id = expectIdent(p, "lambda param must be ident");
          const b = resolveIdent(id, env, phase);
          if (!b) throw new Error("lambda param did not resolve");
          return b.value as string;
        });
        const bodyForms = items.slice(2).map(x => lowerSyntax(x, env, phase));
        const body: Expr = bodyForms.length === 1 ? bodyForms[0] : { tag: "Begin", exprs: bodyForms };
        return { tag: "Lambda", params, body };
      }

      case "oracle-lambda": {
        // (oracle-lambda (params...) spec)
        // Creates an OracleProc - first-class inference procedure
        if (items.length !== 3) throw new Error("oracle-lambda: expected (oracle-lambda (params) spec)");
        const paramsList = expectList(items[1], "oracle-lambda: params must be list");
        const params = paramsList.items.map(p => {
          const id = expectIdent(p, "oracle-lambda param must be ident");
          const b = resolveIdent(id, env, phase);
          if (!b) throw new Error("oracle-lambda param did not resolve");
          return b.value as string;
        });
        const spec = lowerSyntax(items[2], env, phase);
        return { tag: "OracleLambda", params, spec };
      }

      case "let": {
        if (items.length < 3) throw new Error("let: expected (let ((x e) ...) body...)");
        const bindsList = expectList(items[1], "let: bindings must be list");
        const bindPairs = bindsList.items.map(bp0 => {
          const bp = expectList(bp0, "let: binding must be list");
          if (bp.items.length !== 2) throw new Error("let: binding must be (x init)");
          const id = expectIdent(bp.items[0], "let: binder must be ident");
          const b = resolveIdent(id, env, phase);
          if (!b) throw new Error("let binder did not resolve");
          return { internal: b.value as string, init: lowerSyntax(bp.items[1], env, phase) };
        });

        const params = bindPairs.map(p => p.internal);
        const args = bindPairs.map(p => p.init);

        const bodyForms = items.slice(2).map(x => lowerSyntax(x, env, phase));
        const body: Expr = bodyForms.length === 1 ? bodyForms[0] : { tag: "Begin", exprs: bodyForms };

        return { tag: "App", fn: { tag: "Lambda", params, body }, args };
      }

      case "letrec": {
        if (items.length < 3) throw new Error("letrec: expected (letrec ((x e) ...) body...)");
        const bindsList = expectList(items[1], "letrec: bindings must be list");

        const bindPairs = bindsList.items.map(bp0 => {
          const bp = expectList(bp0, "letrec: binding must be list");
          if (bp.items.length !== 2) throw new Error("letrec: binding must be (x init)");
          const id = expectIdent(bp.items[0], "letrec: binder must be ident");
          const b = resolveIdent(id, env, phase);
          if (!b) throw new Error("letrec binder did not resolve");
          return { internal: b.value as string, init: lowerSyntax(bp.items[1], env, phase) };
        });

        const params = bindPairs.map(p => p.internal);

        const placeholder: Expr = { tag: "App", fn: { tag: "Var", name: "*uninit*" }, args: [] };
        const args = bindPairs.map(_ => placeholder);

        const sets: Expr[] = bindPairs.map(p => ({ tag: "Set", name: p.internal, rhs: p.init }));
        const loweredBodyForms = items.slice(2).map(x => lowerSyntax(x, env, phase));
        const bodySeq = sets.concat(loweredBodyForms);
        const body: Expr = bodySeq.length === 1 ? bodySeq[0] : { tag: "Begin", exprs: bodySeq };

        return { tag: "App", fn: { tag: "Lambda", params, body }, args };
      }

      case "define": {
        if (items.length !== 3) throw new Error("define: expected (define x rhs)");
        const id = expectIdent(items[1], "define: name must be ident");
        const b = resolveIdent(id, env, phase);
        if (!b) throw new Error("define binder did not resolve");
        return { tag: "Define", name: b.value as string, rhs: lowerSyntax(items[2], env, phase) };
      }

      case "set!": {
        if (items.length !== 3) throw new Error("set!: expected (set! x rhs)");
        const id = expectIdent(items[1], "set!: target must be ident");
        const b = resolveIdent(id, env, phase);
        if (!b) throw new Error("set! target did not resolve");
        return { tag: "Set", name: b.value as string, rhs: lowerSyntax(items[2], env, phase) };
      }

      case "effect": {
        if (items.length < 2) throw new Error("effect: expected (effect op arg...)");
        const opStx = items[1];
        const op = opStx.tag === "Ident" ? opStx.name : String((opStx as any).value);
        return { tag: "Effect", op, args: items.slice(2).map(x => lowerSyntax(x, env, phase)) };
      }

      case "handle": {
        if (items.length < 2) throw new Error("handle: expected (handle body clauses...)");
        const body = lowerSyntax(items[1], env, phase);
      const handler = lowerHandler(items.slice(2), env, phase);
      return { tag: "Handle", body, handler };
    }

    case "handler-bind": {
      if (items.length < 3) throw new Error("handler-bind: expected (handler-bind ((type handler) ...) body...)");
      const bindsList = expectList(items[1], "handler-bind: bindings must be list");
      const handlers = bindsList.items.map(bp0 => {
        const bp = expectList(bp0, "handler-bind: binding must be list");
        if (bp.items.length !== 2) throw new Error("handler-bind: binding must be (type handler)");
        const typeId = expectIdent(bp.items[0], "handler-bind: type must be ident");
        const handlerExpr = lowerSyntax(bp.items[1], env, phase);
        return { type: typeId.name, handler: handlerExpr };
      });
      const bodyForms = items.slice(2).map(x => lowerSyntax(x, env, phase));
      const body: Expr = bodyForms.length === 1 ? bodyForms[0] : { tag: "Begin", exprs: bodyForms };
      const handlerPairs: Expr[] = handlers.map(h => ({
        tag: "App",
        fn: { tag: "Var", name: "cons" },
        args: [
          { tag: "Quote", datum: { sym: h.type } },
          h.handler,
        ],
      }));
      const handlerList: Expr = { tag: "App", fn: { tag: "Var", name: "list" }, args: handlerPairs };
      const thunk: Expr = { tag: "Lambda", params: [], body };
      return { tag: "App", fn: { tag: "Var", name: "handler-bind" }, args: [handlerList, thunk] };
    }

    case "restart-bind": {
      if (items.length < 3) throw new Error("restart-bind: expected (restart-bind ((name fn) ...) body...)");
      const bindsList = expectList(items[1], "restart-bind: bindings must be list");
      const restarts = bindsList.items.map(bp0 => {
        const bp = expectList(bp0, "restart-bind: binding must be list");
        if (bp.items.length !== 2) throw new Error("restart-bind: binding must be (name fn)");
        const nameId = expectIdent(bp.items[0], "restart-bind: name must be ident");
        const fnExpr = lowerSyntax(bp.items[1], env, phase);
        return { name: nameId.name, fn: fnExpr };
      });
      const bodyForms = items.slice(2).map(x => lowerSyntax(x, env, phase));
      const body: Expr = bodyForms.length === 1 ? bodyForms[0] : { tag: "Begin", exprs: bodyForms };
      const restartPairs: Expr[] = restarts.map(r => ({
        tag: "App",
        fn: { tag: "Var", name: "cons" },
        args: [
          { tag: "Quote", datum: { sym: r.name } },
          r.fn,
        ],
      }));
      const restartsList: Expr = { tag: "App", fn: { tag: "Var", name: "list" }, args: restartPairs };
      const thunk: Expr = { tag: "Lambda", params: [], body };
      return { tag: "App", fn: { tag: "Var", name: "restart-bind" }, args: [restartsList, thunk] };
    }

    case "match": {
      // (match scrutinee (pat1 body1) (pat2 body2) ...)
      if (items.length < 2) throw new Error("match: expected (match scrutinee clauses...)");
      const scrutinee = lowerSyntax(items[1], env, phase);
        const clauses = items.slice(2).map(cl => {
          const clauseList = expectList(cl, "match clause must be list");
          if (clauseList.items.length < 2) throw new Error("match clause must have pattern and body");
          const pat = lowerPattern(clauseList.items[0], env, phase);
          const bodyForms = clauseList.items.slice(1).map(x => lowerSyntax(x, env, phase));
          const body: Expr = bodyForms.length === 1 ? bodyForms[0] : { tag: "Begin", exprs: bodyForms };
          return { pat, body };
        });
        return { tag: "Match", scrutinee, clauses };
      }

      case "amb": {
        // (amb e1 e2 ... en) - nondeterministic choice
        // Desugar to: (effect amb.choose (list (lambda () e1) (lambda () e2) ...))
        // Each alternative is wrapped in a thunk to preserve laziness
        if (items.length < 2) throw new Error("amb: expected at least one alternative");
        const thunks: Expr[] = items.slice(1).map(alt => ({
          tag: "Lambda",
          params: [],
          body: lowerSyntax(alt, env, phase),
        }));
        // Build (list thunk1 thunk2 ...)
        const listExpr: Expr = {
          tag: "App",
          fn: { tag: "Var", name: "list" },
          args: thunks,
        };
        return { tag: "Effect", op: "amb.choose", args: [listExpr] };
      }

      case "mplus": {
        // (mplus e1 e2 ... en) - binary/variadic monadic choice (lazy)
        // Desugar to amb.choose over zero-arg thunks to avoid eager branch evaluation
        if (items.length === 1) {
          return { tag: "Effect", op: "amb.fail", args: [] };
        }
        const thunks: Expr[] = items.slice(1).map(alt => ({
          tag: "Lambda",
          params: [],
          body: lowerSyntax(alt, env, phase),
        }));
        const listExpr: Expr = { tag: "App", fn: { tag: "Var", name: "list" }, args: thunks };
        return { tag: "Effect", op: "amb.choose", args: [listExpr] };
      }

      case "require": {
        // (require pred) - fail if predicate is false
        // Desugar to: (if pred unit (effect amb.fail "require failed"))
        if (items.length !== 2) throw new Error("require: expected (require pred)");
        const pred = lowerSyntax(items[1], env, phase);
        return {
          tag: "If",
          test: pred,
          conseq: { tag: "Lit", value: null }, // unit
          alt: { tag: "Effect", op: "amb.fail", args: [{ tag: "Lit", value: "require failed" }] },
        };
      }

      case "delay": {
        // (delay expr) - create a memoizing thunk
        // Desugar to: (make-promise (lambda () expr))
        if (items.length !== 2) throw new Error("delay: expected (delay expr)");
        const body = lowerSyntax(items[1], env, phase);
        const thunk: Expr = { tag: "Lambda", params: [], body };
        return {
          tag: "App",
          fn: { tag: "Var", name: "make-promise" },
          args: [thunk],
        };
      }

      case "cons-stream": {
        // (cons-stream a b) - create stream pair with delayed tail
        // Desugar to: (cons a (delay b))
        if (items.length !== 3) throw new Error("cons-stream: expected (cons-stream head tail)");
        const head = lowerSyntax(items[1], env, phase);
        const tail = lowerSyntax(items[2], env, phase);
        const delayedTail: Expr = {
          tag: "App",
          fn: { tag: "Var", name: "make-promise" },
          args: [{ tag: "Lambda", params: [], body: tail }],
        };
        return {
          tag: "App",
          fn: { tag: "Var", name: "cons" },
          args: [head, delayedTail],
        };
      }
    }
  }

  return { tag: "App", fn: lowerSyntax(items[0], env, phase), args: items.slice(1).map(x => lowerSyntax(x, env, phase)) };
}

function stripDatum(stx: Syntax): unknown {
  if (stx.tag === "Atom") return stx.value;
  if (stx.tag === "Ident") return { sym: stx.name };
  return stx.items.map(stripDatum);
}

function lowerHandler(clauses: Syntax[], env: Env, phase: number): HandlerExpr {
  const on: HandlerExpr["on"] = [];
  let ret: HandlerExpr["ret"] | undefined;
  let fin: HandlerExpr["fin"] | undefined;

  for (const cl of clauses) {
    const lst = expectList(cl, "handle clause must be list");
    if (lst.items.length < 2) throw new Error("handle clause too short");
    const tag = expectIdent(lst.items[0], "handle clause tag must be ident").name;

    if (tag === "on") {
      if (lst.items.length !== 4) throw new Error("on: expected (on op (x k) body)");
      const op = expectIdent(lst.items[1], "on: op must be ident").name;
      const argsList = expectList(lst.items[2], "on: (x k) must be list");
      if (argsList.items.length !== 2) throw new Error("on: expected (x k)");
      const x = expectIdent(argsList.items[0], "on: x must be ident").name;
      const k = expectIdent(argsList.items[1], "on: k must be ident").name;
      const body = lowerSyntax(lst.items[3], env, phase);
      on.push({ op, params: [x], k, body });
      continue;
    }

    if (tag === "return") {
      if (lst.items.length !== 3) throw new Error("return: expected (return (v) body)");
      const vList = expectList(lst.items[1], "return: (v) must be list");
      if (vList.items.length !== 1) throw new Error("return: expected one var");
      const v = expectIdent(vList.items[0], "return var must be ident").name;
      const body = lowerSyntax(lst.items[2], env, phase);
      ret = { v, body };
      continue;
    }

    if (tag === "finally") {
      if (lst.items.length !== 2) throw new Error("finally: expected (finally body)");
      fin = { body: lowerSyntax(lst.items[1], env, phase) };
      continue;
    }

    throw new Error(`unknown handle clause: ${tag}`);
  }

  return { on, ret, fin };
}

/**
 * Lower a pattern syntax to a Pattern AST node.
 * Supports:
 * - _ (wildcard)
 * - ?x (pattern variable binding)
 * - literals (numbers, strings, booleans, null)
 * - symbols (quoted identifiers become literal symbols)
 * - (p1 p2 ...) or [p1 p2 ...] (list/vector patterns)
 * - else (wildcard, same as _)
 */
function lowerPattern(stx: Syntax, env: Env, phase: number): Pattern {
  // Atom: literal pattern (number, string, boolean, null)
  if (stx.tag === "Atom") {
    const v = stx.value;
    if (typeof v === "number" || typeof v === "string" || typeof v === "boolean" || v === null) {
      return { tag: "PLit", value: v };
    }
    return { tag: "PLit", value: String(v) };
  }

  // Identifier: check for special patterns
  if (stx.tag === "Ident") {
    const name = stx.name;

    // Wildcard patterns
    if (name === "_" || name === "else") {
      return { tag: "PWild" };
    }

    // Pattern variable: starts with ?
    if (name.startsWith("?")) {
      const varName = name.slice(1);
      // Resolve through binding env if possible, otherwise use as-is
      const b = resolveIdent({ ...stx, name: varName }, env, phase);
      return { tag: "PVar", name: b ? (b.value as string) : varName };
    }

    // Quoted symbol pattern: match a symbol with this name
    // For bare identifiers in patterns, treat as literal symbol match
    return { tag: "PLit", value: name };
  }

  // List: vector pattern
  if (stx.tag === "List") {
    // Check for special pattern forms
    if (stx.items.length > 0) {
      const head = stx.items[0];
      if (isIdent(head)) {
        // (quote x) in pattern means literal value
        if (head.name === "quote" && stx.items.length === 2) {
          const datum = stripPatternDatum(stx.items[1]);
          return datumToPattern(datum);
        }
      }
    }

    // Regular list/vector pattern
    const items = stx.items.map(item => lowerPattern(item, env, phase));
    return { tag: "PVector", items };
  }

  throw new Error(`Cannot lower pattern: ${JSON.stringify(stx)}`);
}

/** Convert a stripped datum to a pattern */
function datumToPattern(d: unknown): Pattern {
  if (d === null) return { tag: "PLit", value: null };
  if (typeof d === "number") return { tag: "PLit", value: d };
  if (typeof d === "boolean") return { tag: "PLit", value: d };
  if (typeof d === "string") return { tag: "PLit", value: d };
  if (typeof d === "object" && d !== null && "sym" in d) {
    // Symbol: match as literal symbol name
    return { tag: "PLit", value: (d as { sym: string }).sym };
  }
  if (Array.isArray(d)) {
    return { tag: "PVector", items: d.map(datumToPattern) };
  }
  return { tag: "PLit", value: JSON.stringify(d) };
}

function stripPatternDatum(stx: Syntax): unknown {
  if (stx.tag === "Atom") return stx.value;
  if (stx.tag === "Ident") return { sym: stx.name };
  return stx.items.map(stripPatternDatum);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/pipeline/optimizer.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/pipeline/optimizer.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION (Prompt 8)
// Optimizer passes for semantic computation
//
// Three main optimizations:
// 1. Fusion: Combine adjacent effect operations
// 2. Hoist: Move invariant expressions out of loops
// 3. Memo: Add memoization for repeated effect calls

import type { Expr } from "../ast";

/**
 * Optimization statistics for measurement
 */
export type OptStats = {
  fusedEffects: number;
  hoistedExprs: number;
  memoizedCalls: number;
  totalReductions: number;
};

function emptyStats(): OptStats {
  return { fusedEffects: 0, hoistedExprs: 0, memoizedCalls: 0, totalReductions: 0 };
}

// ─────────────────────────────────────────────────────────────────
// Pass 1: Fusion
// Combine adjacent infer.op calls when safe
// ─────────────────────────────────────────────────────────────────

/**
 * Check if two effect operations can be fused
 */
function canFuse(op1: string, op2: string): boolean {
  // For now, only fuse same-type infer operations
  if (op1 === "infer.op" && op2 === "infer.op") return true;
  return false;
}

/**
 * Fuse adjacent effects in a Begin block
 */
function fuseBegin(exprs: Expr[], stats: OptStats): Expr[] {
  const result: Expr[] = [];
  let i = 0;

  while (i < exprs.length) {
    const e = exprs[i];

    // Check if this and next are fusable effects
    if (i + 1 < exprs.length &&
        e.tag === "Effect" &&
        exprs[i + 1].tag === "Effect" &&
        canFuse(e.op, (exprs[i + 1] as any).op)) {

      const next = exprs[i + 1] as any;

      // Create a fused effect with combined args
      const fusedArgs = [...e.args, ...next.args];
      result.push({
        tag: "Effect",
        op: "infer.batch.op",  // Use batch operation
        args: [{
          tag: "Lit",
          value: [e.op, next.op],  // Track original ops
        }, ...fusedArgs],
      });

      stats.fusedEffects++;
      stats.totalReductions++;
      i += 2;  // Skip both
    } else {
      result.push(optimizeExpr(e, stats));
      i++;
    }
  }

  return result;
}

/**
 * Fusion pass: combine adjacent effect operations
 */
function fusion(e: Expr, stats: OptStats): Expr {
  switch (e.tag) {
    case "Begin": {
      const fused = fuseBegin(e.exprs, stats);
      return { ...e, exprs: fused };
    }

    case "Let": {
      // Check for sequential let bindings that can be fused
      return {
        ...e,
        bindings: e.bindings.map(b => ({
          ...b,
          init: fusion(b.init, stats),
        })),
        body: fusion(e.body, stats),
      };
    }

    default:
      return e;
  }
}

// ─────────────────────────────────────────────────────────────────
// Pass 2: Hoisting
// Move invariant expressions out of repeated contexts
// ─────────────────────────────────────────────────────────────────

/**
 * Check if an expression is pure (no effects)
 */
function isPure(e: Expr): boolean {
  switch (e.tag) {
    case "Lit":
    case "Var":
    case "Quote":
    case "QuoteSyntax":
      return true;

    case "Lambda":
      return true;  // Lambda itself is pure (body may not be)

    case "If":
      return isPure(e.test) && isPure(e.conseq) && isPure(e.alt);

    case "App":
      // Conservative: only pure if all parts are literals/vars
      return e.fn.tag === "Var" && e.args.every(a => a.tag === "Lit" || a.tag === "Var");

    case "Begin":
      return e.exprs.every(isPure);

    case "Let":
      return e.bindings.every(b => isPure(b.init)) && isPure(e.body);

    case "Effect":
      return false;  // Effects are not pure

    default:
      return false;
  }
}

/**
 * Collect free variables in an expression
 */
function freeVars(e: Expr): Set<string> {
  const free = new Set<string>();

  function collect(e: Expr, bound: Set<string>): void {
    switch (e.tag) {
      case "Lit":
      case "Quote":
      case "QuoteSyntax":
        break;

      case "Var":
        if (!bound.has(e.name)) free.add(e.name);
        break;

      case "Lambda": {
        const newBound = new Set(bound);
        e.params.forEach(p => newBound.add(p));
        collect(e.body, newBound);
        break;
      }

      case "If":
        collect(e.test, bound);
        collect(e.conseq, bound);
        collect(e.alt, bound);
        break;

      case "App":
        collect(e.fn, bound);
        e.args.forEach(a => collect(a, bound));
        break;

      case "Effect":
        e.args.forEach(a => collect(a, bound));
        break;

      case "Begin":
        e.exprs.forEach(x => collect(x, bound));
        break;

      case "Let": {
        const newBound = new Set(bound);
        e.bindings.forEach(b => {
          collect(b.init, bound);
          newBound.add(b.name);
        });
        collect(e.body, newBound);
        break;
      }

      case "Letrec": {
        const newBound = new Set(bound);
        e.bindings.forEach(b => newBound.add(b.name));
        e.bindings.forEach(b => collect(b.init, newBound));
        collect(e.body, newBound);
        break;
      }

      case "Handle":
        collect(e.body, bound);
        // Clause vars are bound in bodies
        e.handler.on.forEach(c => {
          const clauseBound = new Set(bound);
          c.params.forEach(p => clauseBound.add(p));
          clauseBound.add(c.k);
          collect(c.body, clauseBound);
        });
        break;

      case "Match":
        collect(e.scrutinee, bound);
        e.clauses.forEach(c => collect(c.body, bound));
        break;

      case "Define":
        collect(e.rhs, bound);
        break;

      case "Set":
        collect(e.rhs, bound);
        break;

      case "OracleLambda": {
        const newBound = new Set(bound);
        e.params.forEach(p => newBound.add(p));
        collect(e.spec, newBound);
        break;
      }
    }
  }

  collect(e, new Set());
  return free;
}

/**
 * Check if expression can be hoisted (invariant w.r.t. loop vars)
 */
function canHoist(e: Expr, loopVars: Set<string>): boolean {
  if (!isPure(e)) return false;
  const free = freeVars(e);
  for (const v of loopVars) {
    if (free.has(v)) return false;
  }
  return true;
}

/**
 * Hoisting pass: move invariant expressions out
 */
function hoist(e: Expr, stats: OptStats): Expr {
  // For now, just mark expressions that could be hoisted
  // A full implementation would collect and lift them
  return optimizeExpr(e, stats);
}

// ─────────────────────────────────────────────────────────────────
// Pass 3: Memoization
// Add caching for repeated effect calls with same args
// ─────────────────────────────────────────────────────────────────

/**
 * Generate a cache key for an effect call
 */
function effectKey(op: string, args: Expr[]): string {
  const argsStr = args.map(exprToKey).join(",");
  return `${op}(${argsStr})`;
}

function exprToKey(e: Expr): string {
  switch (e.tag) {
    case "Lit":
      return JSON.stringify(e.value);
    case "Var":
      return `var:${e.name}`;
    case "Quote":
      return `quote:${JSON.stringify(e.datum)}`;
    default:
      return `?:${e.tag}`;
  }
}

/**
 * Track seen effects for memoization
 */
type EffectCache = Map<string, { name: string; count: number }>;

/**
 * Memoization pass: wrap repeated effects in cache lookups
 */
function memo(e: Expr, cache: EffectCache, stats: OptStats): Expr {
  switch (e.tag) {
    case "Effect": {
      const key = effectKey(e.op, e.args);
      const cached = cache.get(key);

      if (cached && cached.count >= 1) {
        // Already seen - use cached variable
        stats.memoizedCalls++;
        stats.totalReductions++;
        return { tag: "Var", name: cached.name };
      }

      // First occurrence - track it
      const cacheVar = `cache$${cache.size}`;
      cache.set(key, { name: cacheVar, count: (cached?.count || 0) + 1 });

      // Return a let-bound version for later use
      return {
        tag: "Let",
        bindings: [{ name: cacheVar, init: e }],
        body: { tag: "Var", name: cacheVar },
      };
    }

    case "Begin":
      return { ...e, exprs: e.exprs.map(x => memo(x, cache, stats)) };

    case "Let":
      return {
        ...e,
        bindings: e.bindings.map(b => ({
          ...b,
          init: memo(b.init, cache, stats),
        })),
        body: memo(e.body, cache, stats),
      };

    case "If":
      return {
        ...e,
        test: memo(e.test, cache, stats),
        conseq: memo(e.conseq, cache, stats),
        alt: memo(e.alt, cache, stats),
      };

    case "Lambda":
      // New scope - new cache
      return {
        ...e,
        body: memo(e.body, new Map(), stats),
      };

    default:
      return e;
  }
}

// ─────────────────────────────────────────────────────────────────
// Main optimizer
// ─────────────────────────────────────────────────────────────────

/**
 * Apply a single optimization pass
 */
function optimizeExpr(e: Expr, stats: OptStats): Expr {
  switch (e.tag) {
    case "Lit":
    case "Var":
    case "Quote":
    case "QuoteSyntax":
      return e;

    case "Lambda":
      return { ...e, body: optimizeExpr(e.body, stats) };

    case "If":
      return {
        ...e,
        test: optimizeExpr(e.test, stats),
        conseq: optimizeExpr(e.conseq, stats),
        alt: optimizeExpr(e.alt, stats),
      };

    case "App":
      return {
        ...e,
        fn: optimizeExpr(e.fn, stats),
        args: e.args.map(a => optimizeExpr(a, stats)),
      };

    case "Effect":
      return { ...e, args: e.args.map(a => optimizeExpr(a, stats)) };

    case "Begin":
      return { ...e, exprs: e.exprs.map(x => optimizeExpr(x, stats)) };

    case "Define":
      return { ...e, rhs: optimizeExpr(e.rhs, stats) };

    case "Set":
      return { ...e, rhs: optimizeExpr(e.rhs, stats) };

    case "Let":
      return {
        ...e,
        bindings: e.bindings.map(b => ({
          ...b,
          init: optimizeExpr(b.init, stats),
        })),
        body: optimizeExpr(e.body, stats),
      };

    case "Letrec":
      return {
        ...e,
        bindings: e.bindings.map(b => ({
          ...b,
          init: optimizeExpr(b.init, stats),
        })),
        body: optimizeExpr(e.body, stats),
      };

    case "Handle":
      return {
        ...e,
        body: optimizeExpr(e.body, stats),
        handler: {
          ...e.handler,
          on: e.handler.on.map(c => ({
            ...c,
            body: optimizeExpr(c.body, stats),
          })),
          ret: e.handler.ret ? {
            ...e.handler.ret,
            body: optimizeExpr(e.handler.ret.body, stats),
          } : undefined,
          fin: e.handler.fin ? {
            ...e.handler.fin,
            body: optimizeExpr(e.handler.fin.body, stats),
          } : undefined,
        },
      };

    case "Match":
      return {
        ...e,
        scrutinee: optimizeExpr(e.scrutinee, stats),
        clauses: e.clauses.map(c => ({
          ...c,
          body: optimizeExpr(c.body, stats),
        })),
      };

    case "OracleLambda":
      return { ...e, spec: optimizeExpr(e.spec, stats) };

    default:
      return e;
  }
}

/**
 * Run all optimization passes
 */
export function optimize(e: Expr): { expr: Expr; stats: OptStats } {
  const stats = emptyStats();

  // Pass 1: Fusion
  let result = fusion(e, stats);

  // Pass 2: Hoisting
  result = hoist(result, stats);

  // Pass 3: Memoization
  result = memo(result, new Map(), stats);

  return { expr: result, stats };
}

/**
 * Run only fusion pass
 */
export function fusionOnly(e: Expr): { expr: Expr; stats: OptStats } {
  const stats = emptyStats();
  const result = fusion(e, stats);
  return { expr: result, stats };
}

/**
 * Run only memoization pass
 */
export function memoOnly(e: Expr): { expr: Expr; stats: OptStats } {
  const stats = emptyStats();
  const result = memo(e, new Map(), stats);
  return { expr: result, stats };
}

/**
 * Count effect operations in an expression
 */
export function countEffects(e: Expr): number {
  let count = 0;

  function walk(e: Expr): void {
    switch (e.tag) {
      case "Effect":
        count++;
        e.args.forEach(walk);
        break;

      case "Lambda":
        walk(e.body);
        break;

      case "If":
        walk(e.test);
        walk(e.conseq);
        walk(e.alt);
        break;

      case "App":
        walk(e.fn);
        e.args.forEach(walk);
        break;

      case "Begin":
        e.exprs.forEach(walk);
        break;

      case "Let":
        e.bindings.forEach(b => walk(b.init));
        walk(e.body);
        break;

      case "Letrec":
        e.bindings.forEach(b => walk(b.init));
        walk(e.body);
        break;

      case "Handle":
        walk(e.body);
        e.handler.on.forEach(c => walk(c.body));
        if (e.handler.ret) walk(e.handler.ret.body);
        if (e.handler.fin) walk(e.handler.fin.body);
        break;

      case "Match":
        walk(e.scrutinee);
        e.clauses.forEach(c => walk(c.body));
        break;

      case "Define":
        walk(e.rhs);
        break;

      case "Set":
        walk(e.rhs);
        break;

      case "OracleLambda":
        walk(e.spec);
        break;
    }
  }

  walk(e);
  return count;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/prims.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/prims.ts
// Production primitives for OmegaLLM CEKS machine
// Originally from test/helpers/prims.ts - moved to production

import type { Env } from "./eval/env";
import { envEmpty, envSet } from "./eval/env";
import type { Store } from "./eval/store";
import type { State, Frame, StepOutcome } from "./eval/machine";
import type { Val } from "./eval/values";
import { VUnit, VTrue, VFalse } from "./eval/values";
import type { Expr } from "./ast";
import { rule, rewriteOnce, rewriteFixpoint, rewriteTrace, detectConflicts, substitute, type Rule, type Strategy } from "./oracle/trs";
import { matchAST } from "./oracle/match";
import { isMeaning } from "./oracle/meaning";
import { evidenceId as computeEvidenceId, type Evidence } from "./provenance/evidence";
import { registerConditionPrims } from "./conditions/prims";
import { captureValueResumption } from "./effects/capture";
import { registerProvenancePrims } from "./provenance/prims";
import { registerSolverPrims } from "./solver/prims";
import { compileTextToExpr } from "./pipeline/compileText";

export function installPrims(store: Store): { env: Env; store: Store } {
  let env: Env = envEmpty();
  let st: Store = store;

  function def(name: string, v: Val) {
    const [st2, addr] = st.alloc(v);
    st = st2;
    env = envSet(env, name, addr);
  }

  function isCallable(proc: Val): proc is Val {
    return proc.tag === "Native" || proc.tag === "Closure";
  }

  function ensureArity(proc: Val, expected: number, name: string): void {
    if (proc.tag === "Native") {
      if (proc.arity !== "variadic" && proc.arity !== expected) {
        throw new Error(`${name}: expected procedure of arity ${expected}`);
      }
      return;
    }
    if (proc.tag === "Closure") {
      if (proc.params.length !== expected) {
        throw new Error(`${name}: expected procedure of arity ${expected}`);
      }
      return;
    }
    throw new Error(`${name}: expected a procedure`);
  }

  function applyProcedure(proc: Val, procArgs: Val[], state: State): State | StepOutcome {
    if (proc.tag === "Native") {
      return proc.fn(procArgs, state);
    }
    if (proc.tag === "Closure") {
      if (proc.params.length !== procArgs.length) {
        throw new Error(`procedure arity mismatch: expected ${proc.params.length}, got ${procArgs.length}`);
      }
      let store = state.store;
      let env2 = proc.env;
      for (let i = 0; i < proc.params.length; i++) {
        const [store2, addr] = store.alloc(procArgs[i]);
        store = store2;
        env2 = envSet(env2, proc.params[i], addr);
      }
      const kont = state.kont.concat([{ tag: "KCall", savedEnv: state.env } as Frame]);
      return { ...state, control: { tag: "Expr", e: proc.body }, env: env2, store, kont };
    }
    throw new Error("expected procedure");
  }

  // Condition system primitives
  registerConditionPrims(def, { applyProcedure, ensureArity, isCallable });

  function promptKey(v: Val): string {
    switch (v.tag) {
      case "Sym": return `sym:${v.name}`;
      case "Str": return `str:${v.s}`;
      case "Num": return `num:${v.n}`;
      case "Bool": return `bool:${v.b}`;
      default:
        try {
          return `${v.tag}:${JSON.stringify(v)}`;
        } catch {
          return v.tag;
        }
    }
  }

  let gensymCounter = 0;
  function gensym(prefix: string): string {
    gensymCounter += 1;
    return `${prefix}${gensymCounter}`;
  }

  // *uninit*: placeholder for letrec uninitialized bindings
  // Returns Unit as a placeholder value that will be overwritten by set!
  def("*uninit*", { tag: "Native", name: "*uninit*", arity: 0, fn: (_args, s) => {
    return { ...s, control: { tag: "Val", v: VUnit } };
  }});

  // arithmetic and predicates (reference-grade)
  def("+", { tag: "Native", name: "+", arity: "variadic", fn: (args, s) => ({ ...s, control: { tag: "Val", v: { tag: "Num", n: args.reduce((a, x) => a + (x as any).n, 0) } } }) });
  def("-", { tag: "Native", name: "-", arity: "variadic", fn: (args, s) => {
    const ns = args.map(a => (a as any).n as number);
    const n = ns.length === 1 ? -ns[0] : ns.slice(1).reduce((a, x) => a - x, ns[0]);
    return { ...s, control: { tag: "Val", v: { tag: "Num", n } } };
  }});

  def("*", { tag: "Native", name: "*", arity: "variadic", fn: (args, s) => {
    const n = args.reduce((a, x) => a * (x as any).n, 1);
    return { ...s, control: { tag: "Val", v: { tag: "Num", n } } };
  }});

  def("=", { tag: "Native", name: "=", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: a === b ? VTrue : VFalse } };
  }});

  def("<", { tag: "Native", name: "<", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: a < b ? VTrue : VFalse } };
  }});

  def(">", { tag: "Native", name: ">", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: a > b ? VTrue : VFalse } };
  }});

  def("<=", { tag: "Native", name: "<=", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: a <= b ? VTrue : VFalse } };
  }});

  def(">=", { tag: "Native", name: ">=", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: a >= b ? VTrue : VFalse } };
  }});

  def("/", { tag: "Native", name: "/", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: a / b } } };
  }});

  def("modulo", { tag: "Native", name: "modulo", arity: 2, fn: (args, s) => {
    const a = (args[0] as any).n, b = (args[1] as any).n;
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: a % b } } };
  }});

  def("even?", { tag: "Native", name: "even?", arity: 1, fn: (args, s) => {
    const n = (args[0] as any).n as number;
    return { ...s, control: { tag: "Val", v: n % 2 === 0 ? VTrue : VFalse } };
  }});

  def("not", { tag: "Native", name: "not", arity: 1, fn: (args, s) => {
    const b = (args[0] as any).b as boolean;
    return { ...s, control: { tag: "Val", v: (!b ? VTrue : VFalse) } };
  }});

  // Logical or (non-short-circuit in primitive form, returns first truthy value)
  def("or", { tag: "Native", name: "or", arity: "variadic", fn: (args, s) => {
    for (const arg of args) {
      const truthy = !(arg.tag === "Bool" && !arg.b) && arg.tag !== "Unit";
      if (truthy) {
        return { ...s, control: { tag: "Val", v: arg } };
      }
    }
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // Logical and (non-short-circuit, returns last argument when all truthy)
  def("and", { tag: "Native", name: "and", arity: "variadic", fn: (args, s) => {
    let last: Val = VTrue;
    for (const arg of args) {
      const truthy = !(arg.tag === "Bool" && !arg.b) && arg.tag !== "Unit";
      if (!truthy) {
        return { ...s, control: { tag: "Val", v: arg } };
      }
      last = arg;
    }
    return { ...s, control: { tag: "Val", v: last } };
  }});

  // Monadic primitives for nondeterminism
  function emitAmbChoose(thunks: Val[], s: State): StepOutcome {
    const suspended: State = { ...s, control: { tag: "Val", v: VUnit } };
    const resumption = captureValueResumption(suspended);
    const choices: Val = { tag: "Vector", items: thunks };
    const opcall = { op: "amb.choose", args: [choices], ctxDigest: s.env.cid, resumption };
    return { tag: "Op", opcall, state: suspended };
  }

  def("unit", { tag: "Native", name: "unit", arity: 1, fn: (args, s) => ({ ...s, control: { tag: "Val", v: args[0] } }) });

  def("mzero", { tag: "Native", name: "mzero", arity: 0, fn: (_args, s) => emitAmbChoose([], s) });

  def("mplus", { tag: "Native", name: "mplus", arity: 2, lazyArgs: [0, 1], fn: (args, s) => {
    return emitAmbChoose(args, s);
  }});

  def("bind", { tag: "Native", name: "bind", arity: 2, lazyArgs: [0], fn: (args, s) => {
    const [thunk, fn] = args;
    if (!isCallable(fn)) {
      throw new Error("bind expects a procedure as second argument");
    }
    ensureArity(fn, 1, "bind");

    if (!isCallable(thunk)) {
      throw new Error("bind expects a computation (thunk) as first argument");
    }
    ensureArity(thunk, 0, "bind");

    const kont = s.kont.concat([{ tag: "KBind", fn, env: s.env } as Frame]);
    const stWithKont: State = { ...s, kont };
    return applyProcedure(thunk, [], stWithKont);
  }});

  // ─────────────────────────────────────────────────────────────────
  // Continuations and prompts
  // ─────────────────────────────────────────────────────────────────
  def("call/cc", { tag: "Native", name: "call/cc", arity: 1, fn: (args, s: State) => {
    const proc = args[0];
    if (!isCallable(proc)) {
      throw new Error("call/cc expects a procedure");
    }
    ensureArity(proc, 1, "call/cc");

    const cont: Val = {
      tag: "Continuation",
      kont: s.kont.slice(),
      env: s.env,
      store: s.store,
      handlers: s.handlers.slice(),
    } as Val;

    return applyProcedure(proc, [cont], s);
  }});

  def("call-with-prompt", { tag: "Native", name: "call-with-prompt", arity: 3, fn: (args, s: State) => {
    const [tagVal, thunk, handler] = args;
    if (!isCallable(thunk)) throw new Error("call-with-prompt: expected thunk");
    if (!isCallable(handler)) throw new Error("call-with-prompt: expected handler");
    ensureArity(thunk, 0, "call-with-prompt");
    ensureArity(handler, 2, "call-with-prompt");

    const promptFrame: Frame = {
      tag: "KPrompt",
      promptTag: tagVal,
      handler,
      env: s.env,
      savedKont: s.kont.slice(),
      savedHandlersDepth: s.handlers.length,
    };

    const stWithPrompt: State = { ...s, kont: s.kont.concat([promptFrame]) };
    return applyProcedure(thunk, [], stWithPrompt);
  }});

  def("abort-to-prompt", { tag: "Native", name: "abort-to-prompt", arity: 2, fn: (args, s: State) => {
    const [tagVal, value] = args;
    const targetKey = promptKey(tagVal);

    let found = -1;
    for (let i = s.kont.length - 1; i >= 0; i--) {
      const fr = s.kont[i] as Frame;
      if (fr.tag === "KPrompt" && promptKey((fr as any).promptTag) === targetKey) {
        found = i;
        break;
      }
    }

    if (found < 0) {
      throw new Error(`abort-to-prompt: no prompt for tag ${targetKey}`);
    }

    const pf = s.kont[found] as any;
    const handlerState: State = {
      ...s,
      env: pf.env,
      kont: pf.savedKont,
      handlers: s.handlers.slice(0, pf.savedHandlersDepth),
    };

    const kVal: Val = {
      tag: "Continuation",
      kont: s.kont.slice(found),
      env: s.env,
      store: s.store,
      handlers: s.handlers.slice(0, pf.savedHandlersDepth),
    } as Val;

    return applyProcedure(pf.handler, [kVal, value], handlerState);
  }});

  // ─────────────────────────────────────────────────────────────────
  // Metacircular primitives (cons, car, cdr, null?, pair?)
  // With these you can build list, append, map, filter, etc.
  // ─────────────────────────────────────────────────────────────────

  // cons: construct a pair
  def("cons", { tag: "Native", name: "cons", arity: 2, fn: (args, s) => {
    const pair: Val = { tag: "Vector", items: [args[0], args[1]] };
    return { ...s, control: { tag: "Val", v: pair } };
  }});

  // car: first element of pair
  def("car", { tag: "Native", name: "car", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag === "Vector" && v.items.length >= 1) {
      return { ...s, control: { tag: "Val", v: v.items[0] } };
    }
    throw new Error("car: expected pair");
  }});

  // cdr: rest of pair
  def("cdr", { tag: "Native", name: "cdr", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag === "Vector" && v.items.length >= 2) {
      return { ...s, control: { tag: "Val", v: v.items[1] } };
    }
    throw new Error("cdr: expected pair");
  }});

  // null?: check if value is null/empty
  def("null?", { tag: "Native", name: "null?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    const isNull = v.tag === "Unit" || (v.tag === "Vector" && v.items.length === 0);
    return { ...s, control: { tag: "Val", v: isNull ? VTrue : VFalse } };
  }});

  // pair?: check if value is a pair
  def("pair?", { tag: "Native", name: "pair?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    const isPair = v.tag === "Vector" && v.items.length >= 2;
    return { ...s, control: { tag: "Val", v: isPair ? VTrue : VFalse } };
  }});

  // list: construct a list from arguments (variadic)
  def("list", { tag: "Native", name: "list", arity: "variadic", fn: (args, s) => {
    // Build proper list from args: (list 1 2 3) => (cons 1 (cons 2 (cons 3 null)))
    let result: Val = VUnit; // null terminator
    for (let i = args.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [args[i], result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // append: concatenate lists (variadic)
  def("append", { tag: "Native", name: "append", arity: "variadic", fn: (args, s) => {
    // Flatten all lists into one
    const items: Val[] = [];
    for (const arg of args) {
      let current = arg as any;
      while (current.tag === "Vector" && current.items.length >= 2) {
        items.push(current.items[0]);
        current = current.items[1];
      }
      // If it's a non-null atom at the end, include it (improper list)
      if (current.tag !== "Unit") {
        items.push(current);
      }
    }
    // Rebuild as proper list
    let result: Val = VUnit;
    for (let i = items.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [items[i], result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // eq?: identity/equality comparison
  def("eq?", { tag: "Native", name: "eq?", arity: 2, fn: (args, s) => {
    const a = args[0] as any, b = args[1] as any;
    let eq = false;
    if (a.tag === b.tag) {
      if (a.tag === "Num") eq = a.n === b.n;
      else if (a.tag === "Bool") eq = a.b === b.b;
      else if (a.tag === "Str") eq = a.s === b.s;
      else if (a.tag === "Sym") eq = a.name === b.name;
      else if (a.tag === "Unit") eq = true;
      else eq = a === b; // reference equality
    }
    return { ...s, control: { tag: "Val", v: eq ? VTrue : VFalse } };
  }});

  // NOTE: For nested LLM calls, use the built-in Oracle Protocol:
  //   (infer.op payload)  - invoke LLM with payload, returns Meaning
  //   (int.op payload)    - same as infer.op
  // The LLM can then use eval/apply/observe tools to interact with Lisp.

  // ─────────────────────────────────────────────────────────────────
  // Distribution primitives (Dist<Val>)
  // For working with nondeterministic distributions from oracle ops
  // ─────────────────────────────────────────────────────────────────

  // dist: create a point distribution from a single value
  def("dist", { tag: "Native", name: "dist", arity: 1, fn: (args, s) => {
    const v = args[0];
    const d: Val = { tag: "Dist", support: [{ v, w: 1 }], normalized: true };
    return { ...s, control: { tag: "Val", v: d } };
  }});

  // dist?: check if value is a distribution
  def("dist?", { tag: "Native", name: "dist?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    const isDist = v.tag === "Dist";
    return { ...s, control: { tag: "Val", v: isDist ? VTrue : VFalse } };
  }});

  // dist-count: number of support elements
  def("dist-count", { tag: "Native", name: "dist-count", arity: 1, fn: (args, s) => {
    const d = args[0] as any;
    if (d.tag !== "Dist") throw new Error("dist-count: expected Dist");
    const n = d.support.length;
    return { ...s, control: { tag: "Val", v: { tag: "Num", n } } };
  }});

  // dist-value-at: get the value at index i
  def("dist-value-at", { tag: "Native", name: "dist-value-at", arity: 2, fn: (args, s) => {
    const d = args[0] as any;
    const i = (args[1] as any).n;
    if (d.tag !== "Dist") throw new Error("dist-value-at: expected Dist");
    if (i < 0 || i >= d.support.length) throw new Error("dist-value-at: index out of bounds");
    return { ...s, control: { tag: "Val", v: d.support[i].v } };
  }});

  // dist-weight-at: get the weight at index i
  def("dist-weight-at", { tag: "Native", name: "dist-weight-at", arity: 2, fn: (args, s) => {
    const d = args[0] as any;
    const i = (args[1] as any).n;
    if (d.tag !== "Dist") throw new Error("dist-weight-at: expected Dist");
    if (i < 0 || i >= d.support.length) throw new Error("dist-weight-at: index out of bounds");
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: d.support[i].w } } };
  }});

  // dist-normalize: normalize distribution weights to sum to 1
  def("dist-normalize", { tag: "Native", name: "dist-normalize", arity: 1, fn: (args, s) => {
    const d = args[0] as any;
    if (d.tag !== "Dist") throw new Error("dist-normalize: expected Dist");
    const sum = d.support.reduce((a: number, it: any) => a + it.w, 0);
    if (sum <= 0) {
      const empty: Val = { tag: "Dist", support: [], normalized: true, meta: d.meta };
      return { ...s, control: { tag: "Val", v: empty } };
    }
    const support = d.support.map((it: any) => ({ v: it.v, w: it.w / sum }));
    const norm: Val = { tag: "Dist", support, normalized: true, meta: d.meta };
    return { ...s, control: { tag: "Val", v: norm } };
  }});

  // dist-sample: sample a value from distribution with seed
  def("dist-sample", { tag: "Native", name: "dist-sample", arity: 2, fn: (args, s) => {
    const d0 = args[0] as any;
    const seed = (args[1] as any).n;
    if (d0.tag !== "Dist") throw new Error("dist-sample: expected Dist");

    // Normalize if needed
    let d = d0;
    if (!d.normalized) {
      const sum = d.support.reduce((a: number, it: any) => a + it.w, 0);
      if (sum > 0) {
        d = { ...d, support: d.support.map((it: any) => ({ v: it.v, w: it.w / sum })), normalized: true };
      }
    }

    if (d.support.length === 0) throw new Error("dist-sample: empty support");

    // Mulberry32 PRNG
    let t = seed >>> 0;
    t += 0x6D2B79F5;
    let x = t;
    x = Math.imul(x ^ (x >>> 15), x | 1);
    x ^= x + Math.imul(x ^ (x >>> 7), x | 61);
    const r = ((x ^ (x >>> 14)) >>> 0) / 4294967296;

    let acc = 0;
    for (const it of d.support) {
      acc += it.w;
      if (r <= acc) return { ...s, control: { tag: "Val", v: it.v } };
    }
    return { ...s, control: { tag: "Val", v: d.support[d.support.length - 1].v } };
  }});

  // dist-topk: get top k elements by weight
  def("dist-topk", { tag: "Native", name: "dist-topk", arity: 2, fn: (args, s) => {
    const d0 = args[0] as any;
    const k = (args[1] as any).n;
    if (d0.tag !== "Dist") throw new Error("dist-topk: expected Dist");

    const sorted = d0.support.slice().sort((a: any, b: any) => b.w - a.w);
    const support = sorted.slice(0, Math.max(0, k));
    const topk: Val = { tag: "Dist", support, normalized: d0.normalized, meta: d0.meta };
    return { ...s, control: { tag: "Val", v: topk } };
  }});

  // dist-from-list: create distribution from list of (value weight) pairs
  def("dist-from-list", { tag: "Native", name: "dist-from-list", arity: 1, fn: (args, s) => {
    const lst = args[0] as any;
    const support: Array<{ v: Val; w: number }> = [];

    // Walk the list (list of pairs where each pair is (value . weight))
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const pair = cur.items[0] as any;
      if (pair.tag === "Vector" && pair.items.length >= 2) {
        const v = pair.items[0];
        const w = (pair.items[1] as any).n ?? 1;
        support.push({ v, w });
      }
      cur = cur.items[1];
    }

    const d: Val = { tag: "Dist", support, normalized: false };
    return { ...s, control: { tag: "Val", v: d } };
  }});

  // dist-to-list: convert distribution to list of (value weight) pairs
  def("dist-to-list", { tag: "Native", name: "dist-to-list", arity: 1, fn: (args, s) => {
    const d = args[0] as any;
    if (d.tag !== "Dist") throw new Error("dist-to-list: expected Dist");

    // Build list of pairs
    let result: Val = VUnit;
    for (let i = d.support.length - 1; i >= 0; i--) {
      const it = d.support[i];
      const pair: Val = { tag: "Vector", items: [it.v, { tag: "Num", n: it.w }] };
      result = { tag: "Vector", items: [pair, result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // String primitives (semantic text toolbox)
  // These allow mechanical/extensional string processing
  // ─────────────────────────────────────────────────────────────────

  // string=?: string equality
  def("string=?", { tag: "Native", name: "string=?", arity: 2, fn: (args, s) => {
    const a = args[0] as any, b = args[1] as any;
    if (a.tag !== "Str" || b.tag !== "Str") throw new Error("string=?: expected strings");
    return { ...s, control: { tag: "Val", v: a.s === b.s ? VTrue : VFalse } };
  }});

  // string-contains?: check if string contains substring
  def("string-contains?", { tag: "Native", name: "string-contains?", arity: 2, fn: (args, s) => {
    const str = args[0] as any, sub = args[1] as any;
    if (str.tag !== "Str" || sub.tag !== "Str") throw new Error("string-contains?: expected strings");
    return { ...s, control: { tag: "Val", v: str.s.includes(sub.s) ? VTrue : VFalse } };
  }});

  // string-replace-all: replace all occurrences of substr with replacement
  def("string-replace-all", { tag: "Native", name: "string-replace-all", arity: 3, fn: (args, s) => {
    const str = args[0] as any, sub = args[1] as any, repl = args[2] as any;
    if (str.tag !== "Str" || sub.tag !== "Str" || repl.tag !== "Str") {
      throw new Error("string-replace-all: expected strings");
    }
    // Use split/join for global replace without regex
    const result = str.s.split(sub.s).join(repl.s);
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: result } } };
  }});

  // string-split: split string by delimiter
  def("string-split", { tag: "Native", name: "string-split", arity: 2, fn: (args, s) => {
    const str = args[0] as any, delim = args[1] as any;
    if (str.tag !== "Str" || delim.tag !== "Str") throw new Error("string-split: expected strings");
    const parts = str.s.split(delim.s);
    // Build proper list
    let result: Val = VUnit;
    for (let i = parts.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [{ tag: "Str", s: parts[i] }, result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // string-join: join list of strings with delimiter
  def("string-join", { tag: "Native", name: "string-join", arity: 2, fn: (args, s) => {
    const lst = args[0] as any, delim = args[1] as any;
    if (delim.tag !== "Str") throw new Error("string-join: delimiter must be string");
    // Walk the list
    const parts: string[] = [];
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const elem = cur.items[0] as any;
      if (elem.tag === "Str") parts.push(elem.s);
      cur = cur.items[1];
    }
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: parts.join(delim.s) } } };
  }});

  // string-trim: remove leading/trailing whitespace
  def("string-trim", { tag: "Native", name: "string-trim", arity: 1, fn: (args, s) => {
    const str = args[0] as any;
    if (str.tag !== "Str") throw new Error("string-trim: expected string");
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: str.s.trim() } } };
  }});

  // string-downcase: convert to lowercase
  def("string-downcase", { tag: "Native", name: "string-downcase", arity: 1, fn: (args, s) => {
    const str = args[0] as any;
    if (str.tag !== "Str") throw new Error("string-downcase: expected string");
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: str.s.toLowerCase() } } };
  }});

  // string-upcase: convert to uppercase
  def("string-upcase", { tag: "Native", name: "string-upcase", arity: 1, fn: (args, s) => {
    const str = args[0] as any;
    if (str.tag !== "Str") throw new Error("string-upcase: expected string");
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: str.s.toUpperCase() } } };
  }});

  // string-length: get length of string
  def("string-length", { tag: "Native", name: "string-length", arity: 1, fn: (args, s) => {
    const str = args[0] as any;
    if (str.tag !== "Str") throw new Error("string-length: expected string");
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: str.s.length } } };
  }});

  // string-append: concatenate strings
  def("string-append", { tag: "Native", name: "string-append", arity: "variadic", fn: (args, s) => {
    let result = "";
    for (const arg of args) {
      if ((arg as any).tag !== "Str") throw new Error("string-append: expected strings");
      result += (arg as any).s;
    }
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: result } } };
  }});

  // substring: extract substring
  def("substring", { tag: "Native", name: "substring", arity: 3, fn: (args, s) => {
    const str = args[0] as any, start = args[1] as any, end = args[2] as any;
    if (str.tag !== "Str") throw new Error("substring: expected string");
    if (start.tag !== "Num" || end.tag !== "Num") throw new Error("substring: expected numbers for indices");
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: str.s.substring(start.n, end.n) } } };
  }});

  // string->number: convert string to number (canonical Lisp primitive)
  def("string->number", { tag: "Native", name: "string->number", arity: 1, fn: (args, s) => {
    const str = args[0] as any;
    if (str.tag !== "Str") throw new Error("string->number: expected string");
    const n = parseFloat(str.s);
    if (isNaN(n)) return { ...s, control: { tag: "Val", v: { tag: "Bool", b: false } } };
    return { ...s, control: { tag: "Val", v: { tag: "Num", n } } };
  }});

  // number->string: convert number to string (canonical Lisp primitive)
  def("number->string", { tag: "Native", name: "number->string", arity: 1, fn: (args, s) => {
    const num = args[0] as any;
    if (num.tag !== "Num") throw new Error("number->string: expected number");
    return { ...s, control: { tag: "Val", v: { tag: "Str", s: String(num.n) } } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // Symbol and type predicates
  // ─────────────────────────────────────────────────────────────────

  // symbol?: check if value is a symbol
  def("symbol?", { tag: "Native", name: "symbol?", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0].tag === "Sym" ? VTrue : VFalse } };
  }});

  // string?: check if value is a string
  def("string?", { tag: "Native", name: "string?", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0].tag === "Str" ? VTrue : VFalse } };
  }});

  // number?: check if value is a number
  def("number?", { tag: "Native", name: "number?", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0].tag === "Num" ? VTrue : VFalse } };
  }});

  // boolean?: check if value is a boolean
  def("boolean?", { tag: "Native", name: "boolean?", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0].tag === "Bool" ? VTrue : VFalse } };
  }});

  // procedure?: check if value is callable
  def("procedure?", { tag: "Native", name: "procedure?", arity: 1, fn: (args, s) => {
    const v = args[0];
    const isProc = v.tag === "Closure" || v.tag === "Native" || v.tag === "OracleProc" || v.tag === "Continuation" || v.tag === "Cont";
    return { ...s, control: { tag: "Val", v: isProc ? VTrue : VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // List utilities (additional helpers for SICP-style programming)
  // ─────────────────────────────────────────────────────────────────

  // length: get length of list
  def("length", { tag: "Native", name: "length", arity: 1, fn: (args, s) => {
    let count = 0;
    let cur = args[0] as any;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      count++;
      cur = cur.items[1];
    }
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: count } } };
  }});

  // list-ref: get nth element
  def("list-ref", { tag: "Native", name: "list-ref", arity: 2, fn: (args, s) => {
    const lst = args[0] as any;
    const n = (args[1] as any).n;
    let cur = lst;
    for (let i = 0; i < n; i++) {
      if (cur.tag !== "Vector" || cur.items.length < 2) throw new Error("list-ref: index out of bounds");
      cur = cur.items[1];
    }
    if (cur.tag !== "Vector" || cur.items.length < 1) throw new Error("list-ref: index out of bounds");
    return { ...s, control: { tag: "Val", v: cur.items[0] } };
  }});

  // reverse: reverse a list
  def("reverse", { tag: "Native", name: "reverse", arity: 1, fn: (args, s) => {
    const items: Val[] = [];
    let cur = args[0] as any;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      items.push(cur.items[0]);
      cur = cur.items[1];
    }
    // Build reversed list
    let result: Val = VUnit;
    for (const item of items) {
      result = { tag: "Vector", items: [item, result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // cadr, caddr, etc. (convenience accessors)
  def("cadr", { tag: "Native", name: "cadr", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag !== "Vector" || v.items.length < 2) throw new Error("cadr: expected pair");
    const cdr = v.items[1] as any;
    if (cdr.tag !== "Vector" || cdr.items.length < 1) throw new Error("cadr: expected pair in cdr");
    return { ...s, control: { tag: "Val", v: cdr.items[0] } };
  }});

  def("caddr", { tag: "Native", name: "caddr", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag !== "Vector" || v.items.length < 2) throw new Error("caddr: expected pair");
    const cdr = v.items[1] as any;
    if (cdr.tag !== "Vector" || cdr.items.length < 2) throw new Error("caddr: expected pair in cdr");
    const cddr = cdr.items[1] as any;
    if (cddr.tag !== "Vector" || cddr.items.length < 1) throw new Error("caddr: expected pair in cddr");
    return { ...s, control: { tag: "Val", v: cddr.items[0] } };
  }});

  // equal?: deep structural equality
  def("equal?", { tag: "Native", name: "equal?", arity: 2, fn: (args, s) => {
    function deepEq(a: Val, b: Val): boolean {
      if (a.tag !== b.tag) return false;
      switch (a.tag) {
        case "Unit": return true;
        case "Num": return (b as any).n === a.n;
        case "Bool": return (b as any).b === a.b;
        case "Str": return (b as any).s === a.s;
        case "Sym": return (b as any).name === a.name;
        case "Vector": {
          const bb = b as any;
          if (bb.items.length !== a.items.length) return false;
          for (let i = 0; i < a.items.length; i++) {
            if (!deepEq(a.items[i], bb.items[i])) return false;
          }
          return true;
        }
        default:
          return JSON.stringify(a) === JSON.stringify(b);
      }
    }
    return { ...s, control: { tag: "Val", v: deepEq(args[0], args[1]) ? VTrue : VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // Higher-Order Function combinators (HOF)
  // These accept Native | Closure | OracleProc as arguments
  // ─────────────────────────────────────────────────────────────────

  // Helper to apply a procedure (Native only for now, Closure/OracleProc need machine stepping)
  function applyNative(proc: Val, procArgs: Val[], state: any): Val | null {
    if (proc.tag === "Native") {
      const result = (proc as any).fn(procArgs, state);
      if (result.control?.tag === "Val") {
        return result.control.v;
      }
    }
    return null;
  }

  // map: apply f to each element of list
  def("map", { tag: "Native", name: "map", arity: 2, fn: (args, s) => {
    const f = args[0];
    const lst = args[1] as any;

    // Collect list elements
    const items: Val[] = [];
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      items.push(cur.items[0]);
      cur = cur.items[1];
    }

    // Apply f to each element
    const results: Val[] = [];
    for (const item of items) {
      const result = applyNative(f, [item], s);
      if (result === null) {
        // For Closure/OracleProc, we'd need proper machine stepping
        throw new Error("map: only Native functions supported in primitive; use recursive map for Closure/OracleProc");
      }
      results.push(result);
    }

    // Build result list
    let resultList: Val = VUnit;
    for (let i = results.length - 1; i >= 0; i--) {
      resultList = { tag: "Vector", items: [results[i], resultList] };
    }
    return { ...s, control: { tag: "Val", v: resultList } };
  }});

  // filter: keep elements where predicate returns true
  def("filter", { tag: "Native", name: "filter", arity: 2, fn: (args, s) => {
    const pred = args[0];
    const lst = args[1] as any;

    // Collect list elements
    const items: Val[] = [];
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      items.push(cur.items[0]);
      cur = cur.items[1];
    }

    // Filter elements
    const results: Val[] = [];
    for (const item of items) {
      const result = applyNative(pred, [item], s);
      if (result === null) {
        throw new Error("filter: only Native functions supported in primitive; use recursive filter for Closure/OracleProc");
      }
      // Check if truthy (Bool true, or non-false value)
      if (result.tag === "Bool" && result.b) {
        results.push(item);
      } else if (result.tag !== "Bool" && result.tag !== "Unit") {
        // Non-boolean, non-unit values are truthy
        results.push(item);
      }
    }

    // Build result list
    let resultList: Val = VUnit;
    for (let i = results.length - 1; i >= 0; i--) {
      resultList = { tag: "Vector", items: [results[i], resultList] };
    }
    return { ...s, control: { tag: "Val", v: resultList } };
  }});

  // fold (foldl): left fold - (fold f init xs) applies (f acc x) for each x
  def("fold", { tag: "Native", name: "fold", arity: 3, fn: (args, s) => {
    const f = args[0];
    let acc = args[1];
    const lst = args[2] as any;

    // Walk the list
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const item = cur.items[0];
      const result = applyNative(f, [acc, item], s);
      if (result === null) {
        throw new Error("fold: only Native functions supported in primitive; use recursive fold for Closure/OracleProc");
      }
      acc = result;
      cur = cur.items[1];
    }

    return { ...s, control: { tag: "Val", v: acc } };
  }});

  // foldr: right fold - (foldr f init xs) applies (f x acc) from right to left
  def("foldr", { tag: "Native", name: "foldr", arity: 3, fn: (args, s) => {
    const f = args[0];
    const init = args[1];
    const lst = args[2] as any;

    // Collect elements
    const items: Val[] = [];
    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      items.push(cur.items[0]);
      cur = cur.items[1];
    }

    // Fold from right
    let acc = init;
    for (let i = items.length - 1; i >= 0; i--) {
      const result = applyNative(f, [items[i], acc], s);
      if (result === null) {
        throw new Error("foldr: only Native functions supported in primitive; use recursive foldr for Closure/OracleProc");
      }
      acc = result;
    }

    return { ...s, control: { tag: "Val", v: acc } };
  }});

  // compose: (compose f g) => (lambda (x) (f (g x)))
  // Returns a new Native that composes f and g
  def("compose", { tag: "Native", name: "compose", arity: 2, fn: (args, s) => {
    const f = args[0];
    const g = args[1];

    const composed: Val = {
      tag: "Native",
      name: "composed",
      arity: 1,
      fn: (innerArgs: Val[], innerS: any) => {
        // Apply g first
        const gResult = applyNative(g, innerArgs, innerS);
        if (gResult === null) {
          throw new Error("compose: inner function (g) must be Native");
        }
        // Then apply f
        const fResult = applyNative(f, [gResult], innerS);
        if (fResult === null) {
          throw new Error("compose: outer function (f) must be Native");
        }
        return { ...innerS, control: { tag: "Val", v: fResult } };
      }
    };

    return { ...s, control: { tag: "Val", v: composed } };
  }});

  // pipe: (pipe f g) => (lambda (x) (g (f x)))
  // Opposite of compose - f first, then g
  def("pipe", { tag: "Native", name: "pipe", arity: 2, fn: (args, s) => {
    const f = args[0];
    const g = args[1];

    const piped: Val = {
      tag: "Native",
      name: "piped",
      arity: 1,
      fn: (innerArgs: Val[], innerS: any) => {
        // Apply f first
        const fResult = applyNative(f, innerArgs, innerS);
        if (fResult === null) {
          throw new Error("pipe: first function (f) must be Native");
        }
        // Then apply g
        const gResult = applyNative(g, [fResult], innerS);
        if (gResult === null) {
          throw new Error("pipe: second function (g) must be Native");
        }
        return { ...innerS, control: { tag: "Val", v: gResult } };
      }
    };

    return { ...s, control: { tag: "Val", v: piped } };
  }});

  // partial: (partial f a) => (lambda (b ...) (f a b ...))
  // Partially apply first argument
  def("partial", { tag: "Native", name: "partial", arity: 2, fn: (args, s) => {
    const f = args[0];
    const bound = args[1];

    const partialFn: Val = {
      tag: "Native",
      name: "partial",
      arity: "variadic",
      fn: (innerArgs: Val[], innerS: any) => {
        // Prepend bound arg
        const allArgs = [bound, ...innerArgs];
        const result = applyNative(f, allArgs, innerS);
        if (result === null) {
          throw new Error("partial: function must be Native");
        }
        return { ...innerS, control: { tag: "Val", v: result } };
      }
    };

    return { ...s, control: { tag: "Val", v: partialFn } };
  }});

  // apply: (apply f args-list) - call procedure with argument list
  // This is essential for metacircular evaluators
  def("apply", { tag: "Native", name: "apply", arity: 2, fn: (args, s) => {
    const f = args[0];
    const argList = args[1] as any;

    // Convert list to array
    const procArgs: Val[] = [];
    let cur = argList;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      procArgs.push(cur.items[0]);
      cur = cur.items[1];
    }

    if (f.tag === "Continuation") {
      if (procArgs.length !== 1) {
        throw new Error(`apply: continuation expects 1 argument, got ${procArgs.length}`);
      }
      const cont = f as any;
      return {
        ...s,
        control: { tag: "Val", v: procArgs[0] },
        env: cont.env,
        // Preserve current store to keep mutations performed before invoking continuation.
        store: s.store,
        kont: cont.kont.slice(),
        handlers: cont.handlers.slice(),
      };
    }

    // Apply based on procedure type
    if (f.tag === "Native") {
      const result = applyNative(f, procArgs, s);
      if (result === null) {
        throw new Error("apply: Native function did not return a value");
      }
      return { ...s, control: { tag: "Val", v: result } };
    }

    if (f.tag === "Closure") {
      // For Closure, we need to set up the machine state for application
      const closure = f as any;
      // Create a new environment with params bound to args
      const frame = new Map<string, number>();
      let currentStore = s.store;
      for (let i = 0; i < closure.params.length && i < procArgs.length; i++) {
        // alloc returns [Store, Addr] tuple - pass value to allocate
        const [newStore, addr] = currentStore.alloc(procArgs[i]);
        currentStore = newStore;
        frame.set(closure.params[i], addr);
      }
      const envWithArgs = { tag: "Ctx", frame, parent: closure.env };
      // Evaluate the body in the new environment
      return { ...s, store: currentStore, control: { tag: "Expr", e: closure.body }, env: envWithArgs };
    }

    if (f.tag === "OracleProc") {
      // OracleProc application would need effect handling - not directly available here
      throw new Error("apply: OracleProc requires effect handling; use host evaluator");
    }

    throw new Error(`apply: expected procedure, got ${f.tag}`);
  }});

  // identity: (identity x) => x
  def("identity", { tag: "Native", name: "identity", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0] } };
  }});

  // constantly: (constantly x) => (lambda (y) x)
  def("constantly", { tag: "Native", name: "constantly", arity: 1, fn: (args, s) => {
    const x = args[0];
    const constFn: Val = {
      tag: "Native",
      name: "const",
      arity: 1,
      fn: (_innerArgs: Val[], innerS: any) => {
        return { ...innerS, control: { tag: "Val", v: x } };
      }
    };
    return { ...s, control: { tag: "Val", v: constFn } };
  }});

  // andmap: like all - returns true if predicate is true for all elements
  def("andmap", { tag: "Native", name: "andmap", arity: 2, fn: (args, s) => {
    const pred = args[0];
    const lst = args[1] as any;

    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const item = cur.items[0];
      const result = applyNative(pred, [item], s);
      if (result === null) {
        throw new Error("andmap: only Native functions supported");
      }
      if (result.tag === "Bool" && !result.b) {
        return { ...s, control: { tag: "Val", v: VFalse } };
      }
      cur = cur.items[1];
    }
    return { ...s, control: { tag: "Val", v: VTrue } };
  }});

  // ormap: like any - returns true if predicate is true for any element
  def("ormap", { tag: "Native", name: "ormap", arity: 2, fn: (args, s) => {
    const pred = args[0];
    const lst = args[1] as any;

    let cur = lst;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const item = cur.items[0];
      const result = applyNative(pred, [item], s);
      if (result === null) {
        throw new Error("ormap: only Native functions supported");
      }
      if (result.tag === "Bool" && result.b) {
        return { ...s, control: { tag: "Val", v: VTrue } };
      }
      cur = cur.items[1];
    }
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // Promises (delay/force with memoization)
  // For lazy evaluation and streams
  // ─────────────────────────────────────────────────────────────────

  // make-promise: create a memoizing thunk from a procedure
  // The Promise value stores: {tag: "Promise", thunk, forced: bool, value?: Val}
  def("make-promise", { tag: "Native", name: "make-promise", arity: 1, fn: (args, s) => {
    const thunk = args[0];
    if (thunk.tag !== "Closure" && thunk.tag !== "Native") {
      throw new Error("make-promise: expected procedure");
    }
    const promise: Val = {
      tag: "Promise",
      thunk,
      forced: false,
      value: undefined,
    } as any;
    return { ...s, control: { tag: "Val", v: promise } };
  }});

  // force: evaluate a promise (memoized)
  // For Closure thunks, we return a state that evaluates the closure body.
  // The result will flow to the continuation; memoization happens via KMemoize frame.
  def("force", { tag: "Native", name: "force", arity: 1, fn: (args, s) => {
    const p = args[0] as any;
    if (p.tag !== "Promise") {
      // If not a promise, return as-is (idempotent)
      return { ...s, control: { tag: "Val", v: args[0] } };
    }
    if (p.forced) {
      // Already forced, return cached value
      return { ...s, control: { tag: "Val", v: p.value } };
    }
    // Need to force: call the thunk
    const thunk = p.thunk;
    if (thunk.tag === "Native") {
      const result = (thunk as any).fn([], s);
      if (result.control?.tag === "Val") {
        // Memoize the result
        p.forced = true;
        p.value = result.control.v;
        return result;
      }
    }
    // For Closure thunks, inline the body evaluation
    if (thunk.tag === "Closure") {
      // Add a KMemoize frame to cache the result when body evaluates
      // For now, use a simpler approach: wrap in a continuation that caches
      const memoizeFrame: Frame = {
        tag: "KCall",
        savedEnv: s.env,
        // We hack in memoization by also storing the promise reference
        // Actually, we can use a simpler trick: evaluate body, and the
        // Promise is mutated in-place after first force completes.
        // For simplicity, just evaluate without memoization for now.
      };

      // Return state that evaluates closure body with closure env
      return {
        ...s,
        control: { tag: "Expr", e: thunk.body },
        env: thunk.env,
        kont: [...s.kont, memoizeFrame],
      };
    }
    throw new Error(`force: unsupported thunk type ${thunk.tag}`);
  }});

  // promise?: check if value is a promise
  def("promise?", { tag: "Native", name: "promise?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    return { ...s, control: { tag: "Val", v: v.tag === "Promise" ? VTrue : VFalse } };
  }});

  // promise-forced?: check if promise has been forced
  def("promise-forced?", { tag: "Native", name: "promise-forced?", arity: 1, fn: (args, s) => {
    const p = args[0] as any;
    if (p.tag !== "Promise") return { ...s, control: { tag: "Val", v: VFalse } };
    return { ...s, control: { tag: "Val", v: p.forced ? VTrue : VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // Stream primitives
  // Streams are pairs where cdr is a promise
  // ─────────────────────────────────────────────────────────────────

  const isStreamEmptyVal = (v: Val): boolean => v.tag === "Unit" || (v.tag === "Vector" && v.items.length === 0);
  const isStreamVal = (v: Val): boolean => isStreamEmptyVal(v) || (v.tag === "Vector" && v.items.length >= 2);

  function forceStreamTailOutcome(tail: any, state: State): StepOutcome {
    if (tail.tag !== "Promise") {
      return { tag: "State", state: { ...state, control: { tag: "Val", v: tail } } };
    }
    if (tail.forced) {
      return { tag: "State", state: { ...state, control: { tag: "Val", v: tail.value } } };
    }
    const thunk = tail.thunk;
    if (thunk.tag === "Native") {
      const result = (thunk as any).fn([], state);
      if ((result as any).control?.tag === "Val") {
        tail.forced = true;
        tail.value = (result as any).control.v;
        return { tag: "State", state: { ...state, control: { tag: "Val", v: tail.value } } };
      }
      return result as StepOutcome;
    }
    if (thunk.tag === "Closure") {
      const memoizeFrame: Frame = { tag: "KCall", savedEnv: state.env };
      return {
        tag: "State",
        state: {
          ...state,
          control: { tag: "Expr", e: thunk.body },
          env: thunk.env,
          kont: [...state.kont, memoizeFrame],
        },
      };
    }
    throw new Error(`stream: unsupported thunk type ${(thunk as any).tag}`);
  }

  // the-empty-stream: sentinel for empty stream
  def("the-empty-stream", VUnit);

  // stream-null?: check if stream is empty
  def("stream-null?", { tag: "Native", name: "stream-null?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    const isEmpty = v.tag === "Unit" || (v.tag === "Vector" && v.items.length === 0);
    return { ...s, control: { tag: "Val", v: isEmpty ? VTrue : VFalse } };
  }});

  // stream-car: get first element (same as car)
  def("stream-car", { tag: "Native", name: "stream-car", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag === "Vector" && v.items.length >= 1) {
      return { ...s, control: { tag: "Val", v: v.items[0] } };
    }
    throw new Error("stream-car: expected stream pair");
  }});

  // stream-cdr: force the tail and return it
  def("stream-cdr", { tag: "Native", name: "stream-cdr", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    if (v.tag !== "Vector" || v.items.length < 2) {
      throw new Error("stream-cdr: expected stream pair");
    }
    const tail = v.items[1] as any;
    // Force the promise
    if (tail.tag === "Promise") {
      if (tail.forced) {
        return { ...s, control: { tag: "Val", v: tail.value } };
      }
      const thunk = tail.thunk;
      // Force native thunk
      if (thunk.tag === "Native") {
        const result = (thunk as any).fn([], s);
        if ((result as StepOutcome).tag) {
          return result as StepOutcome;
        }
        if (result.control?.tag === "Val") {
          tail.forced = true;
          tail.value = result.control.v;
          return { ...s, control: { tag: "Val", v: tail.value } };
        }
      }
      // For Closure thunks, inline the body evaluation
      if (thunk.tag === "Closure") {
        const memoizeFrame: Frame = { tag: "KCall", savedEnv: s.env };
        return {
          ...s,
          control: { tag: "Expr", e: thunk.body },
          env: thunk.env,
          kont: [...s.kont, memoizeFrame],
        };
      }
      throw new Error(`stream-cdr: unsupported thunk type ${thunk.tag}`);
    }
    // If not a promise, return as-is
    return { ...s, control: { tag: "Val", v: tail } };
  }});

  // list->stream: convert list to stream
  def("list->stream", { tag: "Native", name: "list->stream", arity: 1, fn: (args, s) => {
    // Already a list (cons cells), just need to wrap tails as promises
    // For simplicity, return the list directly - streams and lists share structure
    // The difference is conceptual: stream-cdr forces, cdr doesn't
    return { ...s, control: { tag: "Val", v: args[0] } };
  }});

  // stream->list: convert stream to list (eager, forces all)
  // (stream->list stream n) - take n elements from stream as a list
  def("stream->list", { tag: "Native", name: "stream->list", arity: 2, fn: (args, s) => {
    let stream = args[0] as any;
    const n = (args[1] as any).n;
    const items: Val[] = [];

    for (let i = 0; i < n; i++) {
      // Check if empty
      if (stream.tag === "Unit" || (stream.tag === "Vector" && stream.items.length === 0)) {
        break;
      }
      if (stream.tag !== "Vector" || stream.items.length < 2) {
        break;
      }
      // Get head
      items.push(stream.items[0]);
      // Force and get tail
      const tail = stream.items[1] as any;
      if (tail.tag === "Promise") {
        if (tail.forced) {
          stream = tail.value;
        } else if (tail.thunk.tag === "Native") {
          const result = (tail.thunk as any).fn([], s);
          if (result.control?.tag === "Val") {
            tail.forced = true;
            tail.value = result.control.v;
            stream = tail.value;
          } else {
            break;
          }
        } else {
          throw new Error("stream->list: Closure thunks require machine-level handling");
        }
      } else {
        stream = tail;
      }
    }

    // Build result list
    let result: Val = VUnit;
    for (let i = items.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [items[i], result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // stream-take: take n elements from stream, returns a new stream
  // (stream-take stream n) - returns stream of first n elements
  def("stream-take", { tag: "Native", name: "stream-take", arity: 2, fn: (args, s) => {
    const stream = args[0];
    const n = (args[1] as any).n;
    // Reuse stream->list logic
    const items: Val[] = [];
    let cur = stream as any;

    for (let i = 0; i < n; i++) {
      if (cur.tag === "Unit") break;
      if (cur.tag !== "Vector" || cur.items.length < 2) break;
      items.push(cur.items[0]);
      const tail = cur.items[1] as any;
      if (tail.tag === "Promise") {
        if (tail.forced) {
          cur = tail.value;
        } else if (tail.thunk.tag === "Native") {
          const result = (tail.thunk as any).fn([], s);
          if (result.control?.tag === "Val") {
            tail.forced = true;
            tail.value = result.control.v;
            cur = tail.value;
          } else break;
        } else {
          throw new Error("stream-take: Closure thunks require machine-level handling");
        }
      } else {
        cur = tail;
      }
    }

    let result: Val = VUnit;
    for (let i = items.length - 1; i >= 0; i--) {
      result = { tag: "Vector", items: [items[i], result] };
    }
    return { ...s, control: { tag: "Val", v: result } };
  }});

  const isEmptyStream = (v: Val): boolean => v.tag === "Unit" || (v.tag === "Vector" && v.items.length === 0);
  const isStreamLike = (v: Val): v is Val & { tag: "Vector"; items: Val[] } =>
    isEmptyStream(v) || (v.tag === "Vector" && v.items.length >= 2);

  const buildInterleave = (a: Val, b: Val, state: State): { v: Val; store: Store } => {
    if (!isStreamLike(a) || !isStreamLike(b)) {
      const tags = `(${(a as any)?.tag ?? "unknown"}, ${(b as any)?.tag ?? "unknown"})`;
      throw new Error(`stream-interleave: expected streams ${tags}`);
    }
    if (isEmptyStream(a)) {
      return { v: b, store: state.store };
    }

    const pair = a as any;
    const head = pair.items[0] as Val;

    // Capture s1/s2 in a closure thunk so existing promise forcing logic can run it later.
    let store = state.store;
    const [sAfterS1, addrS1] = store.alloc(a);
    store = sAfterS1;
    const [sAfterS2, addrS2] = store.alloc(b);
    store = sAfterS2;
    let envLocal = state.env;
    envLocal = envSet(envLocal, "s1", addrS1);
    envLocal = envSet(envLocal, "s2", addrS2);

    const tailExpr: Expr = {
      tag: "App",
      fn: { tag: "Var", name: "stream-interleave" },
      args: [
        { tag: "Var", name: "s2" },
        { tag: "App", fn: { tag: "Var", name: "stream-cdr" }, args: [{ tag: "Var", name: "s1" }] },
      ],
    };

    const thunk: Val = { tag: "Closure", params: [], body: tailExpr, env: envLocal };
    const promise: Val = { tag: "Promise", thunk, forced: false, value: undefined } as any;
    const stream: Val = { tag: "Vector", items: [head, promise] };
    return { v: stream, store };
  };

  // stream-interleave: fairly merge two streams
  def("stream-interleave", { tag: "Native", name: "stream-interleave", arity: 2, fn: (args, s) => {
    const [s1, s2] = args;
    const { v, store } = buildInterleave(s1, s2, s);
    return { ...s, store, control: { tag: "Val", v } };
  }});

  // stream-interleave-lazy: second argument is a thunk returning a stream
  def("stream-interleave-lazy", { tag: "Native", name: "stream-interleave-lazy", arity: 2, lazyArgs: [1], fn: (args, s) => {
    const [s1, thunkVal] = args;
    if (thunkVal.tag !== "Native" && thunkVal.tag !== "Closure") {
      throw new Error("stream-interleave-lazy: expected thunk returning stream");
    }

    const applied = applyProcedure(thunkVal as any, [], s);
    if ((applied as any).control?.tag !== "Val") {
      throw new Error("stream-interleave-lazy: thunk did not return stream");
    }
    const streamVal = (applied as any).control.v as Val;
    const { v, store } = buildInterleave(s1, streamVal, (applied as any).store ? (applied as State) : s);
    const nextState = (applied as any).store ? (applied as State) : s;
    return { ...nextState, store, control: { tag: "Val", v } };
  }});

  // stream-map: apply f to each element of stream (lazy)
  def("stream-map", { tag: "Native", name: "stream-map", arity: 2, fn: (args, s) => {
    const f = args[0];
    const stream = args[1] as any;

    if (stream.tag === "Unit") {
      return { ...s, control: { tag: "Val", v: VUnit } };
    }
    if (stream.tag !== "Vector" || stream.items.length < 2) {
      return { ...s, control: { tag: "Val", v: VUnit } };
    }

    // Apply f to head
    const head = stream.items[0];
    const mappedHead = applyNative(f, [head], s);
    if (mappedHead === null) {
      throw new Error("stream-map: only Native functions supported in primitive");
    }

    // Create lazy tail
    const tailThunk: Val = {
      tag: "Native",
      name: "stream-map-thunk",
      arity: 0,
      fn: (_: Val[], innerS: any) => {
        // Force original tail
        const origTail = stream.items[1] as any;
        let forcedTail: Val;
        if (origTail.tag === "Promise") {
          if (origTail.forced) {
            forcedTail = origTail.value;
          } else if (origTail.thunk.tag === "Native") {
            const r = (origTail.thunk as any).fn([], innerS);
            if (r.control?.tag === "Val") {
              origTail.forced = true;
              origTail.value = r.control.v;
              forcedTail = origTail.value;
            } else {
              return r;
            }
          } else {
            throw new Error("stream-map: Closure thunks in stream tail");
          }
        } else {
          forcedTail = origTail;
        }
        // Recursively stream-map on tail
        if (forcedTail.tag === "Unit") {
          return { ...innerS, control: { tag: "Val", v: VUnit } };
        }
        // Return mapped tail
        const mapFn = env; // closure over f
        // This is tricky - we need the stream-map function
        // For simplicity, inline the logic
        return streamMapRec(f, forcedTail, innerS);
      }
    } as any;

    function streamMapRec(fn: Val, str: Val, st: any): any {
      if ((str as any).tag === "Unit") {
        return { ...st, control: { tag: "Val", v: VUnit } };
      }
      const strAny = str as any;
      if (strAny.tag !== "Vector" || strAny.items.length < 2) {
        return { ...st, control: { tag: "Val", v: VUnit } };
      }
      const h = applyNative(fn, [strAny.items[0]], st);
      if (h === null) throw new Error("stream-map: Native required");
      const thunk: Val = {
        tag: "Native",
        name: "smap-thunk",
        arity: 0,
        fn: (_: Val[], is: any) => {
          const t = strAny.items[1] as any;
          let ft: Val;
          if (t.tag === "Promise") {
            if (t.forced) ft = t.value;
            else if (t.thunk.tag === "Native") {
              const rr = (t.thunk as any).fn([], is);
              if (rr.control?.tag === "Val") {
                t.forced = true;
                t.value = rr.control.v;
                ft = t.value;
              } else return rr;
            } else throw new Error("stream-map thunk");
          } else ft = t;
          return streamMapRec(fn, ft, is);
        }
      } as any;
      const promise: Val = { tag: "Promise", thunk, forced: false, value: undefined } as any;
      const result: Val = { tag: "Vector", items: [h, promise] };
      return { ...st, control: { tag: "Val", v: result } };
    }

    const promise: Val = { tag: "Promise", thunk: tailThunk, forced: false, value: undefined } as any;
    const result: Val = { tag: "Vector", items: [mappedHead, promise] };
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // stream-filter: filter stream by predicate (lazy)
  def("stream-filter", { tag: "Native", name: "stream-filter", arity: 2, fn: (args, s) => {
    const pred = args[0];
    const stream = args[1];

    function streamFilterRec(p: Val, str: Val, st: any): any {
      if ((str as any).tag === "Unit") {
        return { ...st, control: { tag: "Val", v: VUnit } };
      }
      const strAny = str as any;
      if (strAny.tag !== "Vector" || strAny.items.length < 2) {
        return { ...st, control: { tag: "Val", v: VUnit } };
      }

      const head = strAny.items[0];
      const testResult = applyNative(p, [head], st);
      if (testResult === null) {
        throw new Error("stream-filter: only Native functions supported");
      }

      // Force tail
      const tail = strAny.items[1] as any;
      let forcedTail: Val;
      if (tail.tag === "Promise") {
        if (tail.forced) {
          forcedTail = tail.value;
        } else if (tail.thunk.tag === "Native") {
          const r = (tail.thunk as any).fn([], st);
          if (r.control?.tag === "Val") {
            tail.forced = true;
            tail.value = r.control.v;
            forcedTail = tail.value;
          } else {
            throw new Error("stream-filter: thunk error");
          }
        } else {
          throw new Error("stream-filter: Closure thunks in stream tail");
        }
      } else {
        forcedTail = tail;
      }

      const keep = testResult.tag === "Bool" && testResult.b;
      if (keep) {
        // Include this element, create lazy filtered tail
        const thunk: Val = {
          tag: "Native",
          name: "filter-thunk",
          arity: 0,
          fn: (_: Val[], is: any) => streamFilterRec(p, forcedTail, is)
        } as any;
        const promise: Val = { tag: "Promise", thunk, forced: false, value: undefined } as any;
        const result: Val = { tag: "Vector", items: [head, promise] };
        return { ...st, control: { tag: "Val", v: result } };
      } else {
        // Skip this element, recurse on tail
        return streamFilterRec(p, forcedTail, st);
      }
    }

    return streamFilterRec(pred, stream, s);
  }});

  // ─────────────────────────────────────────────────────────────────
  // B1: Op-Table Primitives (SICP-style data-directed programming)
  // Operation tables map (op-name, type-tags...) -> procedure
  // ─────────────────────────────────────────────────────────────────

  // make-op-table: create a new operation table (returns a mutable Map-based value)
  def("make-op-table", { tag: "Native", name: "make-op-table", arity: 0, fn: (_args, s) => {
    const table: Val = {
      tag: "OpTable",
      entries: new Map<string, Val>()
    } as any;
    return { ...s, control: { tag: "Val", v: table } };
  }});

  // op-table-put: install a method - (op-table-put table op-name type-tags proc)
  // type-tags is a list of symbols, proc is a procedure
  def("op-table-put", { tag: "Native", name: "op-table-put", arity: 4, fn: (args, s) => {
    const table = args[0] as any;
    const opName = args[1] as any;
    const typeTags = args[2] as any;
    const proc = args[3];

    if (table.tag !== "OpTable") throw new Error("op-table-put: expected OpTable");
    if (opName.tag !== "Sym" && opName.tag !== "Str") throw new Error("op-table-put: op-name must be symbol or string");

    // Convert type-tags list to key string
    const tags: string[] = [];
    let cur = typeTags;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const tag = cur.items[0] as any;
      tags.push(tag.tag === "Sym" ? tag.name : tag.s ?? String(tag));
      cur = cur.items[1];
    }
    // Handle single symbol
    if (typeTags.tag === "Sym") {
      tags.push(typeTags.name);
    }

    const key = `${opName.tag === "Sym" ? opName.name : opName.s}:${tags.join(",")}`;
    table.entries.set(key, proc);

    return { ...s, control: { tag: "Val", v: VUnit } };
  }});

  // op-table-get: lookup a method - (op-table-get table op-name type-tags)
  def("op-table-get", { tag: "Native", name: "op-table-get", arity: 3, fn: (args, s) => {
    const table = args[0] as any;
    const opName = args[1] as any;
    const typeTags = args[2] as any;

    if (table.tag !== "OpTable") throw new Error("op-table-get: expected OpTable");
    if (opName.tag !== "Sym" && opName.tag !== "Str") throw new Error("op-table-get: op-name must be symbol or string");

    // Convert type-tags list to key string
    const tags: string[] = [];
    let cur = typeTags;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      const tag = cur.items[0] as any;
      tags.push(tag.tag === "Sym" ? tag.name : tag.s ?? String(tag));
      cur = cur.items[1];
    }
    // Handle single symbol
    if (typeTags.tag === "Sym") {
      tags.push(typeTags.name);
    }

    const key = `${opName.tag === "Sym" ? opName.name : opName.s}:${tags.join(",")}`;
    const proc = table.entries.get(key);

    if (proc) {
      return { ...s, control: { tag: "Val", v: proc } };
    }
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // op-table?: check if value is an op-table
  def("op-table?", { tag: "Native", name: "op-table?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    return { ...s, control: { tag: "Val", v: v.tag === "OpTable" ? VTrue : VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // B2: Tagged Data Protocol (attach-tag, type-tag, contents)
  // Tagged data: (type-symbol . contents)
  // ─────────────────────────────────────────────────────────────────

  // attach-tag: create tagged datum - (attach-tag type-tag contents)
  def("attach-tag", { tag: "Native", name: "attach-tag", arity: 2, fn: (args, s) => {
    const typeTag = args[0] as any;
    const contents = args[1];

    if (typeTag.tag !== "Sym" && typeTag.tag !== "Str") {
      throw new Error("attach-tag: type-tag must be symbol or string");
    }

    // Tagged datum is a pair: (type-tag . contents)
    const tagged: Val = {
      tag: "Tagged",
      typeTag: typeTag.tag === "Sym" ? typeTag.name : typeTag.s,
      contents
    } as any;
    return { ...s, control: { tag: "Val", v: tagged } };
  }});

  // type-tag: get the type tag of a tagged datum
  def("type-tag", { tag: "Native", name: "type-tag", arity: 1, fn: (args, s) => {
    const datum = args[0] as any;

    if (datum.tag === "Tagged") {
      return { ...s, control: { tag: "Val", v: { tag: "Sym", name: datum.typeTag } } };
    }
    // For primitive types, return their tag as symbol
    return { ...s, control: { tag: "Val", v: { tag: "Sym", name: datum.tag.toLowerCase() } } };
  }});

  // contents: get the contents of a tagged datum
  def("contents", { tag: "Native", name: "contents", arity: 1, fn: (args, s) => {
    const datum = args[0] as any;

    if (datum.tag === "Tagged") {
      return { ...s, control: { tag: "Val", v: datum.contents } };
    }
    // For primitive types, return the value itself
    return { ...s, control: { tag: "Val", v: args[0] } };
  }});

  // tagged?: check if value is a tagged datum
  def("tagged?", { tag: "Native", name: "tagged?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    return { ...s, control: { tag: "Val", v: v.tag === "Tagged" ? VTrue : VFalse } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // B3: apply-generic (with coercion fallback)
  // ─────────────────────────────────────────────────────────────────

  // apply-generic: dispatch based on type tags
  // (apply-generic op-table op-name . args)
  // First tries exact match, then attempts coercion
  def("apply-generic", { tag: "Native", name: "apply-generic", arity: "variadic", fn: (args, s) => {
    if (args.length < 2) throw new Error("apply-generic: expected at least (table op-name)");

    const table = args[0] as any;
    const opName = args[1] as any;
    const opArgs = args.slice(2);

    if (table.tag !== "OpTable") throw new Error("apply-generic: expected OpTable");

    // Extract type tags from arguments
    const tags: string[] = opArgs.map(arg => {
      const a = arg as any;
      if (a.tag === "Tagged") return a.typeTag;
      return a.tag.toLowerCase();
    });

    // Look up method
    const key = `${opName.tag === "Sym" ? opName.name : opName.s}:${tags.join(",")}`;
    const proc = table.entries.get(key);

    if (proc) {
      // Extract contents for tagged data
      const procArgs = opArgs.map(arg => {
        const a = arg as any;
        return a.tag === "Tagged" ? a.contents : arg;
      });

      // Apply the procedure
      const result = applyNative(proc, procArgs, s);
      if (result === null) {
        throw new Error("apply-generic: method must be Native function");
      }
      return { ...s, control: { tag: "Val", v: result } };
    }

    // No exact match - return false (caller can handle coercion)
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // apply-generic-coerced: dispatch with coercion table
  // (apply-generic-coerced op-table coerce-table op-name . args)
  def("apply-generic-coerced", { tag: "Native", name: "apply-generic-coerced", arity: "variadic", fn: (args, s) => {
    if (args.length < 3) throw new Error("apply-generic-coerced: expected at least (op-table coerce-table op-name)");

    const opTable = args[0] as any;
    const coerceTable = args[1] as any;
    const opName = args[2] as any;
    const opArgs = args.slice(3);

    if (opTable.tag !== "OpTable") throw new Error("apply-generic-coerced: expected OpTable");
    if (coerceTable.tag !== "CoercionTable") throw new Error("apply-generic-coerced: expected CoercionTable");

    // Extract type tags
    const tags: string[] = opArgs.map(arg => {
      const a = arg as any;
      if (a.tag === "Tagged") return a.typeTag;
      return a.tag.toLowerCase();
    });

    // Try exact match first
    const exactKey = `${opName.tag === "Sym" ? opName.name : opName.s}:${tags.join(",")}`;
    const exactProc = opTable.entries.get(exactKey);

    if (exactProc) {
      const procArgs = opArgs.map(arg => {
        const a = arg as any;
        return a.tag === "Tagged" ? a.contents : arg;
      });
      const result = applyNative(exactProc, procArgs, s);
      if (result === null) throw new Error("apply-generic-coerced: method must be Native");
      return { ...s, control: { tag: "Val", v: result } };
    }

    // Try coercion: for 2 args, try coercing arg1 to type of arg2 or vice versa
    if (opArgs.length === 2) {
      const type1 = tags[0], type2 = tags[1];

      // Try coercing type1 to type2
      const coerce1to2Key = `${type1}:${type2}`;
      const coerce1to2 = coerceTable.entries.get(coerce1to2Key);
      if (coerce1to2) {
        // Coerce first arg
        const coercedArg1 = applyNative(coerce1to2, [opArgs[0]], s);
        if (coercedArg1 !== null) {
          // Retry with coerced arg
          const newKey = `${opName.tag === "Sym" ? opName.name : opName.s}:${type2},${type2}`;
          const proc = opTable.entries.get(newKey);
          if (proc) {
            const procArgs = [coercedArg1, opArgs[1]].map(arg => {
              const a = arg as any;
              return a.tag === "Tagged" ? a.contents : arg;
            });
            const result = applyNative(proc, procArgs, s);
            if (result !== null) return { ...s, control: { tag: "Val", v: result } };
          }
        }
      }

      // Try coercing type2 to type1
      const coerce2to1Key = `${type2}:${type1}`;
      const coerce2to1 = coerceTable.entries.get(coerce2to1Key);
      if (coerce2to1) {
        const coercedArg2 = applyNative(coerce2to1, [opArgs[1]], s);
        if (coercedArg2 !== null) {
          const newKey = `${opName.tag === "Sym" ? opName.name : opName.s}:${type1},${type1}`;
          const proc = opTable.entries.get(newKey);
          if (proc) {
            const procArgs = [opArgs[0], coercedArg2].map(arg => {
              const a = arg as any;
              return a.tag === "Tagged" ? a.contents : arg;
            });
            const result = applyNative(proc, procArgs, s);
            if (result !== null) return { ...s, control: { tag: "Val", v: result } };
          }
        }
      }
    }

    // No method found
    throw new Error(`apply-generic-coerced: no method for ${exactKey}`);
  }});

  // ─────────────────────────────────────────────────────────────────
  // B4: Coercion Graph Utilities
  // ─────────────────────────────────────────────────────────────────

  // make-coercion-table: create a new coercion table
  def("make-coercion-table", { tag: "Native", name: "make-coercion-table", arity: 0, fn: (_args, s) => {
    const table: Val = {
      tag: "CoercionTable",
      entries: new Map<string, Val>(),  // "from:to" -> coercion procedure
      edges: new Map<string, string[]>(), // adjacency list for path finding
    } as any;
    return { ...s, control: { tag: "Val", v: table } };
  }});

  // put-coercion: install a coercion - (put-coercion table from-type to-type proc)
  def("put-coercion", { tag: "Native", name: "put-coercion", arity: 4, fn: (args, s) => {
    const table = args[0] as any;
    const fromType = args[1] as any;
    const toType = args[2] as any;
    const proc = args[3];

    if (table.tag !== "CoercionTable") throw new Error("put-coercion: expected CoercionTable");

    const from = fromType.tag === "Sym" ? fromType.name : fromType.s;
    const to = toType.tag === "Sym" ? toType.name : toType.s;
    const key = `${from}:${to}`;

    table.entries.set(key, proc);

    // Update edges for path finding
    if (!table.edges.has(from)) {
      table.edges.set(from, []);
    }
    if (!table.edges.get(from)!.includes(to)) {
      table.edges.get(from)!.push(to);
    }

    return { ...s, control: { tag: "Val", v: VUnit } };
  }});

  // get-coercion: lookup a coercion
  def("get-coercion", { tag: "Native", name: "get-coercion", arity: 3, fn: (args, s) => {
    const table = args[0] as any;
    const fromType = args[1] as any;
    const toType = args[2] as any;

    if (table.tag !== "CoercionTable") throw new Error("get-coercion: expected CoercionTable");

    const from = fromType.tag === "Sym" ? fromType.name : fromType.s;
    const to = toType.tag === "Sym" ? toType.name : toType.s;
    const key = `${from}:${to}`;

    const proc = table.entries.get(key);
    return { ...s, control: { tag: "Val", v: proc ?? VFalse } };
  }});

  // coercion-table?: check if value is a coercion table
  def("coercion-table?", { tag: "Native", name: "coercion-table?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    return { ...s, control: { tag: "Val", v: v.tag === "CoercionTable" ? VTrue : VFalse } };
  }});

  // find-coercion-path: find a path from one type to another
  // Returns a list of types from source to target, or false if no path
  def("find-coercion-path", { tag: "Native", name: "find-coercion-path", arity: 3, fn: (args, s) => {
    const table = args[0] as any;
    const fromType = args[1] as any;
    const toType = args[2] as any;

    if (table.tag !== "CoercionTable") throw new Error("find-coercion-path: expected CoercionTable");

    const from = fromType.tag === "Sym" ? fromType.name : fromType.s;
    const to = toType.tag === "Sym" ? toType.name : toType.s;

    if (from === to) {
      // No coercion needed
      let result: Val = VUnit;
      result = { tag: "Vector", items: [{ tag: "Sym", name: from }, result] };
      return { ...s, control: { tag: "Val", v: result } };
    }

    // BFS to find shortest path
    const visited = new Set<string>();
    const queue: Array<{ node: string; path: string[] }> = [{ node: from, path: [from] }];

    while (queue.length > 0) {
      const { node, path } = queue.shift()!;
      if (visited.has(node)) continue;
      visited.add(node);

      const neighbors = table.edges.get(node) ?? [];
      for (const neighbor of neighbors) {
        if (neighbor === to) {
          // Found path
          const fullPath = [...path, neighbor];
          let result: Val = VUnit;
          for (let i = fullPath.length - 1; i >= 0; i--) {
            result = { tag: "Vector", items: [{ tag: "Sym", name: fullPath[i] }, result] };
          }
          return { ...s, control: { tag: "Val", v: result } };
        }
        if (!visited.has(neighbor)) {
          queue.push({ node: neighbor, path: [...path, neighbor] });
        }
      }
    }

    // No path found
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // find-all-coercion-paths: find ALL paths from one type to another (for detecting ambiguity)
  // Returns a list of paths, where each path is a list of types
  def("find-all-coercion-paths", { tag: "Native", name: "find-all-coercion-paths", arity: 3, fn: (args, s) => {
    const table = args[0] as any;
    const fromType = args[1] as any;
    const toType = args[2] as any;

    if (table.tag !== "CoercionTable") throw new Error("find-all-coercion-paths: expected CoercionTable");

    const from = fromType.tag === "Sym" ? fromType.name : fromType.s;
    const to = toType.tag === "Sym" ? toType.name : toType.s;

    const allPaths: string[][] = [];

    // DFS to find all paths
    function dfs(node: string, path: string[], visited: Set<string>) {
      if (node === to) {
        allPaths.push([...path]);
        return;
      }
      visited.add(node);
      const neighbors = table.edges.get(node) ?? [];
      for (const neighbor of neighbors) {
        if (!visited.has(neighbor)) {
          path.push(neighbor);
          dfs(neighbor, path, visited);
          path.pop();
        }
      }
      visited.delete(node);
    }

    dfs(from, [from], new Set());

    // Convert to list of lists
    let result: Val = VUnit;
    for (let i = allPaths.length - 1; i >= 0; i--) {
      let pathList: Val = VUnit;
      for (let j = allPaths[i].length - 1; j >= 0; j--) {
        pathList = { tag: "Vector", items: [{ tag: "Sym", name: allPaths[i][j] }, pathList] };
      }
      result = { tag: "Vector", items: [pathList, result] };
    }

    return { ...s, control: { tag: "Val", v: result } };
  }});

  // coerce-value: apply coercion along a path
  // (coerce-value table value from-type to-type)
  def("coerce-value", { tag: "Native", name: "coerce-value", arity: 4, fn: (args, s) => {
    const table = args[0] as any;
    let value = args[1];
    const fromType = args[2] as any;
    const toType = args[3] as any;

    if (table.tag !== "CoercionTable") throw new Error("coerce-value: expected CoercionTable");

    const from = fromType.tag === "Sym" ? fromType.name : fromType.s;
    const to = toType.tag === "Sym" ? toType.name : toType.s;

    if (from === to) {
      return { ...s, control: { tag: "Val", v: value } };
    }

    // Find path
    const visited = new Set<string>();
    const queue: Array<{ node: string; path: string[] }> = [{ node: from, path: [from] }];
    let coercionPath: string[] | null = null;

    while (queue.length > 0) {
      const { node, path } = queue.shift()!;
      if (visited.has(node)) continue;
      visited.add(node);

      const neighbors = table.edges.get(node) ?? [];
      for (const neighbor of neighbors) {
        if (neighbor === to) {
          coercionPath = [...path, neighbor];
          break;
        }
        if (!visited.has(neighbor)) {
          queue.push({ node: neighbor, path: [...path, neighbor] });
        }
      }
      if (coercionPath) break;
    }

    if (!coercionPath) {
      throw new Error(`coerce-value: no coercion path from ${from} to ${to}`);
    }

    // Apply coercions along the path
    for (let i = 0; i < coercionPath.length - 1; i++) {
      const key = `${coercionPath[i]}:${coercionPath[i + 1]}`;
      const coerceProc = table.entries.get(key);
      if (!coerceProc) {
        throw new Error(`coerce-value: missing coercion ${key}`);
      }
      const result = applyNative(coerceProc, [value], s);
      if (result === null) {
        throw new Error("coerce-value: coercion function must be Native");
      }
      value = result;
    }

    return { ...s, control: { tag: "Val", v: value } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // B1 (Prompt 6): Term Rewriting System Primitives
  // Pattern-based AST transformation with strategies
  // ─────────────────────────────────────────────────────────────────

  // Store for rule collections (keyed by name)
  const ruleStore = new Map<string, Rule[]>();

  // make-rule: create a rewrite rule
  // (make-rule name pattern template) -> Rule
  def("make-rule", { tag: "Native", name: "make-rule", arity: 3, fn: (args, s) => {
    const nameVal = args[0] as any;
    const pattern = args[1];
    const template = args[2];

    if (nameVal.tag !== "Sym" && nameVal.tag !== "Str") {
      throw new Error("make-rule: name must be symbol or string");
    }
    const name = nameVal.tag === "Sym" ? nameVal.name : nameVal.s;

    const ruleVal: Val = {
      tag: "Rule",
      name,
      pattern,
      template
    } as any;

    return { ...s, control: { tag: "Val", v: ruleVal } };
  }});

  // make-rule-where: create a rule with a where predicate
  // (make-rule-where name pattern template pred) -> Rule
  // pred is a Native function that takes bindings map and returns bool
  def("make-rule-where", { tag: "Native", name: "make-rule-where", arity: 4, fn: (args, s) => {
    const nameVal = args[0] as any;
    const pattern = args[1];
    const template = args[2];
    const pred = args[3] as any;

    if (nameVal.tag !== "Sym" && nameVal.tag !== "Str") {
      throw new Error("make-rule-where: name must be symbol or string");
    }
    const name = nameVal.tag === "Sym" ? nameVal.name : nameVal.s;

    const ruleVal: Val = {
      tag: "Rule",
      name,
      pattern,
      template,
      wherePred: pred
    } as any;

    return { ...s, control: { tag: "Val", v: ruleVal } };
  }});

  // rule?: check if value is a rule
  def("rule?", { tag: "Native", name: "rule?", arity: 1, fn: (args, s) => {
    const v = args[0] as any;
    return { ...s, control: { tag: "Val", v: v.tag === "Rule" ? VTrue : VFalse } };
  }});

  // Helper to convert our Rule Val to the TRS Rule type
  function valToRule(v: Val): Rule {
    const r = v as any;
    if (r.tag !== "Rule") throw new Error("expected Rule");

    // Create where predicate if present
    let where: ((bindings: Record<string, unknown>) => boolean) | undefined;
    if (r.wherePred && r.wherePred.tag === "Native") {
      where = (bindings: Record<string, unknown>) => {
        // Convert bindings to a Map-like Val
        const entries: Array<[Val, Val]> = [];
        for (const [k, v] of Object.entries(bindings)) {
          entries.push([{ tag: "Sym", name: k }, v as Val]);
        }
        const bindingsVal: Val = { tag: "Map", entries };
        const result = (r.wherePred as any).fn([bindingsVal], {} as any);
        if (result.control?.tag === "Val") {
          const rv = result.control.v as any;
          return rv.tag === "Bool" && rv.b;
        }
        return false;
      };
    }

    return rule(r.name, r.pattern, r.template, where);
  }

  // Helper to convert list of Rule Vals to Rule[]
  function valListToRules(lst: Val): Rule[] {
    const rules: Rule[] = [];
    let cur = lst as any;
    while (cur.tag === "Vector" && cur.items.length >= 2) {
      rules.push(valToRule(cur.items[0]));
      cur = cur.items[1];
    }
    // Handle single rule
    if ((lst as any).tag === "Rule") {
      rules.push(valToRule(lst));
    }
    return rules;
  }

  // rewrite-once: apply rules once at first match
  // (rewrite-once rules expr) -> expr' or #f if no match
  // (rewrite-once rules expr 'topdown) -> with strategy
  def("rewrite-once", { tag: "Native", name: "rewrite-once", arity: "variadic", fn: (args, s) => {
    if (args.length < 2) throw new Error("rewrite-once: expected (rules expr [strategy])");

    const rulesVal = args[0];
    const expr = args[1];
    const strategyVal = args[2] as any;

    const rules = valListToRules(rulesVal);
    const strategy: Strategy = strategyVal?.tag === "Sym" && strategyVal.name === "bottomup"
      ? "bottomup" : "topdown";

    const result = rewriteOnce(rules, expr, strategy);

    if (result.changed) {
      // Return a pair: (expr' . rule-name)
      const resultPair: Val = {
        tag: "Vector",
        items: [
          result.result,
          { tag: "Sym", name: result.ruleName ?? "unknown" }
        ]
      };
      return { ...s, control: { tag: "Val", v: resultPair } };
    }

    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // rewrite-fixpoint: apply rules until no more changes or fuel exhausted
  // (rewrite-fixpoint rules expr) -> expr'
  // (rewrite-fixpoint rules expr fuel) -> with fuel limit
  // (rewrite-fixpoint rules expr fuel 'bottomup) -> with strategy
  def("rewrite-fixpoint", { tag: "Native", name: "rewrite-fixpoint", arity: "variadic", fn: (args, s) => {
    if (args.length < 2) throw new Error("rewrite-fixpoint: expected (rules expr [fuel] [strategy])");

    const rulesVal = args[0];
    const expr = args[1];
    const fuelVal = args[2] as any;
    const strategyVal = args[3] as any;

    const rules = valListToRules(rulesVal);
    const fuel = fuelVal?.tag === "Num" ? fuelVal.n : 100;
    const strategy: Strategy = strategyVal?.tag === "Sym" && strategyVal.name === "bottomup"
      ? "bottomup" : "topdown";

    const result = rewriteFixpoint(rules, expr, strategy, fuel);

    // Return a record with result, steps, and whether fixpoint was reached
    const resultVal: Val = {
      tag: "Map",
      entries: [
        [{ tag: "Sym", name: "result" }, result.result],
        [{ tag: "Sym", name: "steps" }, { tag: "Num", n: result.steps }],
        [{ tag: "Sym", name: "fixpoint?" }, result.reachedFixpoint ? VTrue : VFalse]
      ]
    };

    return { ...s, control: { tag: "Val", v: resultVal } };
  }});

  // rewrite-trace: apply rules and return full trace
  // (rewrite-trace rules expr) -> list of intermediate expressions
  def("rewrite-trace", { tag: "Native", name: "rewrite-trace", arity: "variadic", fn: (args, s) => {
    if (args.length < 2) throw new Error("rewrite-trace: expected (rules expr [fuel] [strategy])");

    const rulesVal = args[0];
    const expr = args[1];
    const fuelVal = args[2] as any;
    const strategyVal = args[3] as any;

    const rules = valListToRules(rulesVal);
    const fuel = fuelVal?.tag === "Num" ? fuelVal.n : 100;
    const strategy: Strategy = strategyVal?.tag === "Sym" && strategyVal.name === "bottomup"
      ? "bottomup" : "topdown";

    const result = rewriteTrace(rules, expr, strategy, fuel);

    // Convert trace to list
    let traceList: Val = VUnit;
    for (let i = result.trace.length - 1; i >= 0; i--) {
      const step = result.trace[i];
      const stepVal: Val = {
        tag: "Map",
        entries: [
          [{ tag: "Sym", name: "expr" }, step.expr],
          [{ tag: "Sym", name: "rule" }, { tag: "Sym", name: step.ruleName ?? "initial" }],
          [{ tag: "Sym", name: "position" }, { tag: "Str", s: step.position ?? "" }]
        ]
      };
      traceList = { tag: "Vector", items: [stepVal, traceList] };
    }

    return { ...s, control: { tag: "Val", v: traceList } };
  }});

  // rewrite-conflicts: detect potential non-confluence in rules
  // (rewrite-conflicts rules) -> list of conflict reports
  def("rewrite-conflicts", { tag: "Native", name: "rewrite-conflicts", arity: 1, fn: (args, s) => {
    const rulesVal = args[0];
    const rules = valListToRules(rulesVal);

    const conflicts = detectConflicts(rules);

    // Convert to list of reports
    let conflictList: Val = VUnit;
    for (let i = conflicts.length - 1; i >= 0; i--) {
      const c = conflicts[i];
      const reportVal: Val = {
        tag: "Map",
        entries: [
          [{ tag: "Sym", name: "rule1" }, { tag: "Sym", name: c.rule1 }],
          [{ tag: "Sym", name: "rule2" }, { tag: "Sym", name: c.rule2 }],
          [{ tag: "Sym", name: "overlap" }, { tag: "Sym", name: c.overlap }],
          [{ tag: "Sym", name: "description" }, { tag: "Str", s: c.description }]
        ]
      };
      conflictList = { tag: "Vector", items: [reportVal, conflictList] };
    }

    return { ...s, control: { tag: "Val", v: conflictList } };
  }});

  // match-pattern: test if a pattern matches an expression
  // (match-pattern pattern expr) -> bindings map or #f
  def("match-pattern", { tag: "Native", name: "match-pattern", arity: 2, fn: (args, s) => {
    const pattern = args[0];
    const expr = args[1];

    const result = matchAST(pattern, expr);

    if (result.ok) {
      // Convert bindings to Map Val
      const entries: Array<[Val, Val]> = [];
      for (const [k, v] of Object.entries(result.bindings)) {
        entries.push([{ tag: "Sym", name: k }, v as Val]);
      }
      return { ...s, control: { tag: "Val", v: { tag: "Map", entries } } };
    }

    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // substitute-template: apply bindings to a template
  // (substitute-template template bindings) -> expr
  def("substitute-template", { tag: "Native", name: "substitute-template", arity: 2, fn: (args, s) => {
    const template = args[0];
    const bindingsVal = args[1] as any;

    // Convert Map Val to bindings object
    const bindings: Record<string, unknown> = {};
    if (bindingsVal.tag === "Map") {
      for (const [k, v] of bindingsVal.entries) {
        const key = (k as any).tag === "Sym" ? (k as any).name : (k as any).s;
        bindings[key] = v;
      }
    }

    const result = substitute(template, bindings);
    return { ...s, control: { tag: "Val", v: result } };
  }});

  // ─────────────────────────────────────────────────────────────────
  // Evidence primitives
  // ─────────────────────────────────────────────────────────────────
  function extractEvidenceCandidate(value: unknown): Evidence | Evidence[] | undefined {
    if (isMeaning(value as any)) {
      const evs = (value as any).evidence;
      if (Array.isArray(evs) && evs.length > 0) {
        const evidences = evs.filter(isEvidenceVal);
        if (evidences.length === 1) return evidences[0] as Evidence;
        if (evidences.length > 1) return evidences as Evidence[];
      }
    }

    if (Array.isArray(value)) {
      const evidences = (value as any[]).filter(isEvidenceVal);
      if (evidences.length === 1) return evidences[0] as Evidence;
      if (evidences.length > 1) return evidences as Evidence[];
    }

    if (isEvidenceVal(value)) return value as Evidence;
    if (value && typeof value === "object" && typeof (value as any).tag === "string" && (value as any).tag.endsWith("Evidence")) {
      return value as Evidence;
    }

    return undefined;
  }

  def("evidence-id", { tag: "Native", name: "evidence-id", arity: 1, fn: (args, s) => {
    const target = extractEvidenceCandidate(args[0]);
    if (target) {
      const id = computeEvidenceId(target as any);
      return { ...s, control: { tag: "Val", v: { tag: "Str", s: id } } };
    }
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  def("verify-evidence", { tag: "Native", name: "verify-evidence", arity: 1, fn: (args, s) => {
    const v = args[0];
    const ok = isMeaning(v) && Array.isArray(v.evidence) && v.evidence.length > 0;
    return { ...s, control: { tag: "Val", v: ok ? VTrue : VFalse } };
  }});

  def("evidence-stale?", { tag: "Native", name: "evidence-stale?", arity: 1, fn: (args, s) => {
    const v = args[0];
    if (isMeaning(v) && v.evidence && v.evidence.length > 0) {
      return { ...s, control: { tag: "Val", v: VFalse } };
    }
    return { ...s, control: { tag: "Val", v: VTrue } };
  }});

  function isEvidenceVal(value: unknown): value is Evidence {
    if (typeof value !== "object" || value === null) return false;
    const tag = (value as any).tag as Evidence["tag"] | string | undefined;
    return typeof tag === "string" && EVIDENCE_TAGS.has(tag as Evidence["tag"]);
  }

  const EVIDENCE_TAGS = new Set<Evidence["tag"]>([
    "TestEvidence",
    "NoMatchEvidence",
    "EqExtEvidence",
    "OracleEvidence",
    "TransformEvidence",
    "DerivedEvidence",
  ]);

  // ─────────────────────────────────────────────────────────────────
  // Machine primitives (Prompt 8): Reified execution state
  // These enable stepping, forking, breakpoints, and time-travel debugging
  // ─────────────────────────────────────────────────────────────────

  // machine-new: Create a reified machine from an expression
  // (machine-new expr) -> Machine
  // (machine-new expr label) -> Machine with label
  def("machine-new", { tag: "Native", name: "machine-new", arity: "variadic", fn: (args, s) => {
    if (args.length < 1) throw new Error("machine-new: expected at least 1 argument");
    const exprVal = args[0];
    const label = args.length > 1 && args[1].tag === "Str" ? args[1].s : undefined;

    // Convert Val to an expression we can evaluate
    // For now, we expect a Syntax value that can be lowered to Expr
    // Or we can create a state that evaluates the value
    const machineId = `m${Date.now().toString(16)}${Math.random().toString(16).slice(2, 6)}`;

    const initialState: any = {
      control: { tag: "Val", v: exprVal },
      env: s.env,
      store: s.store,
      kont: [],
      handlers: s.handlers || [],
    };

    const machineVal: Val = {
      tag: "Machine",
      state: initialState,
      label,
      stepCount: 0,
      isDone: false,
      machineId,
    };

    return { ...s, control: { tag: "Val", v: machineVal } };
  }});

  // machine-step: Single-step a machine
  // (machine-step machine) -> Machine (updated)
  def("machine-step", { tag: "Native", name: "machine-step", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-step: expected Machine");
    if (m.isDone) {
      // Already done - return as-is
      return { ...s, control: { tag: "Val", v: m } };
    }

    // Import stepOnce dynamically to avoid circular deps
    const { stepOnce } = require("../../src/core/eval/machineStep");
    const outcome = stepOnce(m.state);

    const updated: Val = {
      ...m,
      stepCount: m.stepCount + 1,
      lastOutcome: outcome,
      isDone: outcome.tag === "Done",
      state: outcome.tag === "State" ? outcome.state :
             outcome.tag === "Done" ? outcome.state :
             outcome.tag === "Op" ? outcome.state : m.state,
    };

    return { ...s, control: { tag: "Val", v: updated } };
  }});

  // machine-run: Run machine to completion or breakpoint
  // (machine-run machine) -> Machine
  // (machine-run machine max-steps) -> Machine
  def("machine-run", { tag: "Native", name: "machine-run", arity: "variadic", fn: (args, s) => {
    if (args.length < 1) throw new Error("machine-run: expected at least 1 argument");
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-run: expected Machine");
    if (m.isDone) return { ...s, control: { tag: "Val", v: m } };

    const maxSteps = args.length > 1 && args[1].tag === "Num" ? args[1].n : 10000;
    const { stepOnce } = require("../../src/core/eval/machineStep");

    let current = m;
    for (let i = 0; i < maxSteps; i++) {
      if (current.isDone) break;

      const outcome = stepOnce(current.state);

      // Check for effect breakpoints
      if (outcome.tag === "Op" && current.breakOnOps?.has(outcome.opcall.op)) {
        current = {
          ...current,
          stepCount: current.stepCount + 1,
          lastOutcome: outcome,
          state: outcome.state,
        };
        break;
      }

      // Update machine
      current = {
        ...current,
        stepCount: current.stepCount + 1,
        lastOutcome: outcome,
        isDone: outcome.tag === "Done",
        state: outcome.tag === "State" ? outcome.state :
               outcome.tag === "Done" ? outcome.state :
               outcome.tag === "Op" ? outcome.state : current.state,
      };

      // Stop on effect emission (for debugging)
      if (outcome.tag === "Op") break;
    }

    return { ...s, control: { tag: "Val", v: current } };
  }});

  // machine-stack: Get the continuation stack as a list
  // (machine-stack machine) -> list of frame descriptions
  def("machine-stack", { tag: "Native", name: "machine-stack", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-stack: expected Machine");

    // Convert kont frames to list of symbols describing them
    const frames = m.state.kont || [];
    let result: Val = VUnit;
    for (let i = frames.length - 1; i >= 0; i--) {
      const fr = frames[i];
      const frameDesc: Val = { tag: "Sym", name: fr.tag };
      result = { tag: "Vector", items: [frameDesc, result] };
    }

    return { ...s, control: { tag: "Val", v: result } };
  }});

  // machine-control: Get the current control value
  // (machine-control machine) -> control (Expr or Val)
  def("machine-control", { tag: "Native", name: "machine-control", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-control: expected Machine");

    const ctrl = m.state.control;
    if (ctrl.tag === "Val") {
      return { ...s, control: { tag: "Val", v: ctrl.v } };
    }
    // For Expr, return a description
    return { ...s, control: { tag: "Val", v: { tag: "Sym", name: `Expr:${ctrl.e.tag}` } } };
  }});

  // machine-done?: Check if machine is in terminal state
  // (machine-done? machine) -> boolean
  def("machine-done?", { tag: "Native", name: "machine-done?", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-done?: expected Machine");
    return { ...s, control: { tag: "Val", v: m.isDone ? VTrue : VFalse } };
  }});

  // machine-value: Get the final value (if done)
  // (machine-value machine) -> value or error
  def("machine-value", { tag: "Native", name: "machine-value", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-value: expected Machine");
    if (!m.isDone) throw new Error("machine-value: machine not done");

    if (m.lastOutcome?.tag === "Done") {
      return { ...s, control: { tag: "Val", v: m.lastOutcome.value } };
    }
    if (m.state.control.tag === "Val") {
      return { ...s, control: { tag: "Val", v: m.state.control.v } };
    }
    throw new Error("machine-value: no value available");
  }});

  // machine-fork: Clone a machine for multi-shot exploration
  // (machine-fork machine) -> new Machine
  // (machine-fork machine label) -> new Machine with label
  def("machine-fork", { tag: "Native", name: "machine-fork", arity: "variadic", fn: (args, s) => {
    if (args.length < 1) throw new Error("machine-fork: expected at least 1 argument");
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-fork: expected Machine");
    const label = args.length > 1 && args[1].tag === "Str" ? args[1].s : undefined;

    const newId = `m${Date.now().toString(16)}${Math.random().toString(16).slice(2, 6)}`;

    const forked: Val = {
      tag: "Machine",
      state: JSON.parse(JSON.stringify(m.state)), // Deep clone
      label: label || m.label,
      stepCount: m.stepCount,
      breakOnOps: m.breakOnOps ? new Set(m.breakOnOps) : undefined,
      breakOnPatterns: m.breakOnPatterns?.slice(),
      lastOutcome: m.lastOutcome,
      isDone: m.isDone,
      parentId: m.machineId,
      machineId: newId,
    };

    return { ...s, control: { tag: "Val", v: forked } };
  }});

  // machine-resume: Resume a machine from an effect with a value
  // (machine-resume machine value) -> Machine
  def("machine-resume", { tag: "Native", name: "machine-resume", arity: 2, fn: (args, s) => {
    const m = args[0] as any;
    const value = args[1];
    if (m.tag !== "Machine") throw new Error("machine-resume: expected Machine");

    // Set the control to the provided value and clear effect state
    const resumed: Val = {
      ...m,
      state: {
        ...m.state,
        control: { tag: "Val", v: value },
      },
      lastOutcome: undefined,
    };

    return { ...s, control: { tag: "Val", v: resumed } };
  }});

  // machine-add-breakpoint: Add an effect breakpoint
  // (machine-add-breakpoint machine op-name) -> Machine
  def("machine-add-breakpoint", { tag: "Native", name: "machine-add-breakpoint", arity: 2, fn: (args, s) => {
    const m = args[0] as any;
    const opName = args[1] as any;
    if (m.tag !== "Machine") throw new Error("machine-add-breakpoint: expected Machine");
    if (opName.tag !== "Str" && opName.tag !== "Sym") {
      throw new Error("machine-add-breakpoint: op-name must be string or symbol");
    }

    const name = opName.tag === "Str" ? opName.s : opName.name;
    const breakpoints = m.breakOnOps ? new Set(m.breakOnOps) : new Set<string>();
    breakpoints.add(name);

    const updated: Val = {
      ...m,
      breakOnOps: breakpoints,
    };

    return { ...s, control: { tag: "Val", v: updated } };
  }});

  // machine-step-count: Get the step count
  // (machine-step-count machine) -> number
  def("machine-step-count", { tag: "Native", name: "machine-step-count", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-step-count: expected Machine");
    return { ...s, control: { tag: "Val", v: { tag: "Num", n: m.stepCount } } };
  }});

  // machine-last-op: Get the last operation (if any)
  // (machine-last-op machine) -> op-name or #f
  def("machine-last-op", { tag: "Native", name: "machine-last-op", arity: 1, fn: (args, s) => {
    const m = args[0] as any;
    if (m.tag !== "Machine") throw new Error("machine-last-op: expected Machine");

    if (m.lastOutcome?.tag === "Op") {
      return { ...s, control: { tag: "Val", v: { tag: "Sym", name: m.lastOutcome.opcall.op } } };
    }
    return { ...s, control: { tag: "Val", v: VFalse } };
  }});

  // machine?: Check if value is a Machine
  // (machine? x) -> boolean
  def("machine?", { tag: "Native", name: "machine?", arity: 1, fn: (args, s) => {
    return { ...s, control: { tag: "Val", v: args[0].tag === "Machine" ? VTrue : VFalse } };
  }});

  // Provenance primitives (provenance graph + evidence operations)
  registerProvenancePrims(def);

  // Solver primitives (budgeted search, fixpoints, repair loops, facts)
  registerSolverPrims(def, {
    applyProcedure,
    ensureArity,
    isCallable,
    emitAmb: (choices, state) => emitAmbChoose(choices, state),
  });

  return { env, store: st };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/context.ts
// ═══════════════════════════════════════════════════════════════════════════

import { ProvenanceGraph, type SourceChecker } from "./graph";

let currentGraph: ProvenanceGraph = new ProvenanceGraph();
let currentChecker: SourceChecker = { getSourceHash: () => undefined };

export function getProvenanceGraph(): ProvenanceGraph {
  return currentGraph;
}

export function setProvenanceGraph(graph: ProvenanceGraph): void {
  currentGraph = graph;
}

export function getSourceChecker(): SourceChecker {
  return currentChecker;
}

export function setSourceChecker(checker: SourceChecker): void {
  currentChecker = checker;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/evidence.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Expr } from "../ast";
import type { Val } from "../eval/values";
import { sha256JSON } from "../artifacts/hash";

export type TestEvidence = { tag: "TestEvidence"; passed: number; total: number; receipt?: string };
export type NoMatchEvidence = { tag: "NoMatchEvidence"; pattern: Expr; searched: number; found: number };
export type EqExtEvidence = {
  tag: "EqExtEvidence";
  tests: number;
  allPassed: boolean;
  failures?: Array<{ input: Val; expected: Val; got: Val }>;
};

export type OracleEvidence = { tag: "OracleEvidence"; receiptId: string; sourceHash: string; timestamp: number };
export type TransformEvidence = { tag: "TransformEvidence"; operation: string; inputEvidenceIds: string[] };
export type DerivedEvidence = { tag: "DerivedEvidence"; dependencies: string[]; derivationExpr: string };

export type Evidence =
  | TestEvidence
  | NoMatchEvidence
  | EqExtEvidence
  | OracleEvidence
  | TransformEvidence
  | DerivedEvidence;

export function evidenceId(ev: Evidence | Evidence[]): string {
  return sha256JSON(ev);
}

export function computeSourceHash(content: unknown): string {
  return sha256JSON(content);
}

function str(s: string): Val {
  return { tag: "Str", s };
}

function num(n: number): Val {
  return { tag: "Num", n };
}

function vector(items: Val[]): Val {
  return { tag: "Vector", items };
}

/** Convert an Evidence record into a Map Val for user-facing inspection. */
export function evidenceToVal(ev: Evidence): Val {
  const entries: Array<[Val, Val]> = [[str("tag"), str(ev.tag)]];

  switch (ev.tag) {
    case "TestEvidence":
      entries.push([str("passed"), num(ev.passed)]);
      entries.push([str("total"), num(ev.total)]);
      if (ev.receipt) entries.push([str("receipt"), str(ev.receipt)]);
      break;
    case "NoMatchEvidence":
      entries.push([str("searched"), num(ev.searched)]);
      entries.push([str("found"), num(ev.found)]);
      entries.push([str("pattern"), str(JSON.stringify(ev.pattern))]);
      break;
    case "EqExtEvidence":
      entries.push([str("tests"), num(ev.tests)]);
      entries.push([str("allPassed"), { tag: "Bool", b: ev.allPassed }]);
      if (ev.failures) entries.push([str("failures"), num(ev.failures.length)]);
      break;
    case "OracleEvidence":
      entries.push([str("receiptId"), str(ev.receiptId)]);
      entries.push([str("sourceHash"), str(ev.sourceHash)]);
      entries.push([str("timestamp"), num(ev.timestamp)]);
      break;
    case "TransformEvidence":
      entries.push([str("operation"), str(ev.operation)]);
      entries.push([str("inputs"), vector(ev.inputEvidenceIds.map(str))]);
      break;
    case "DerivedEvidence":
      entries.push([str("derivationExpr"), str(ev.derivationExpr)]);
      entries.push([str("dependencies"), vector(ev.dependencies.map(str))]);
      break;
    default:
      break;
  }

  return { tag: "Map", entries };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/graph.ts
// ═══════════════════════════════════════════════════════════════════════════

import { evidenceId, type Evidence, type OracleEvidence } from "./evidence";

export type ProvenanceNode = {
  id: string;
  evidence: Evidence;
  timestamp: number;
};

export type ProvenanceEdge = {
  from: string;
  to: string;
  relation: "derived-from" | "validated-by" | "depends-on";
};

export type ProvenanceGraphData = {
  nodes: ProvenanceNode[];
  edges: ProvenanceEdge[];
};

export type SourceChecker = {
  getSourceHash(receiptId: string): string | undefined;
};

export type StaleItem = {
  evidenceId: string;
  receiptId: string;
  originalHash: string;
  currentHash?: string;
};

export type StalenessReport = {
  isStale: boolean;
  staleItems: StaleItem[];
  totalSources: number;
};

export class ProvenanceGraph {
  private nodes: Map<string, ProvenanceNode> = new Map();
  private edges: ProvenanceEdge[] = [];
  private reverseIndex: Map<string, Set<string>> = new Map();

  addNode(evidence: Evidence): string {
    const id = evidenceId(evidence);
    if (!this.nodes.has(id)) {
      const ts = (evidence as any).timestamp ?? Date.now();
      this.nodes.set(id, { id, evidence, timestamp: ts });
    }
    return id;
  }

  addEdge(from: string, to: string, relation: ProvenanceEdge["relation"]): void {
    if (from === to) throw new Error("ProvenanceGraph: cannot create self-referential edge");
    if (!this.nodes.has(from) || !this.nodes.has(to)) {
      throw new Error("ProvenanceGraph: both nodes must exist before adding an edge");
    }
    this.edges.push({ from, to, relation });
    const rev = this.reverseIndex.get(to) ?? new Set<string>();
    rev.add(from);
    this.reverseIndex.set(to, rev);
  }

  derivedFrom(derived: Evidence, sources: Evidence[]): string {
    const derivedId = this.addNode(derived);
    for (const src of sources) {
      const srcId = this.addNode(src);
      this.addEdge(srcId, derivedId, "derived-from");
    }
    return derivedId;
  }

  getSources(targetId: string): ProvenanceNode[] {
    const seen = new Set<string>();
    const result: ProvenanceNode[] = [];
    const stack = [targetId];

    while (stack.length > 0) {
      const cur = stack.pop()!;
      const parents = this.reverseIndex.get(cur);
      if (!parents) continue;

      for (const p of parents) {
        if (seen.has(p)) continue;
        seen.add(p);
        const node = this.nodes.get(p);
        if (node) {
          result.push(node);
          stack.push(p);
        }
      }
    }

    return result;
  }

  checkStaleness(targetId: string, checker?: SourceChecker): StalenessReport {
    const oracleNodes: Map<string, ProvenanceNode & { evidence: OracleEvidence }> = new Map();

    const targetNode = this.nodes.get(targetId);
    if (targetNode && targetNode.evidence.tag === "OracleEvidence") {
      oracleNodes.set(targetNode.id, targetNode as any);
    }

    for (const n of this.getSources(targetId)) {
      if (n.evidence.tag === "OracleEvidence") {
        oracleNodes.set(n.id, n as any);
      }
    }

    const staleItems: StaleItem[] = [];
    if (checker) {
      for (const node of oracleNodes.values()) {
        const currentHash = checker.getSourceHash(node.evidence.receiptId);
        if (currentHash !== undefined && currentHash !== node.evidence.sourceHash) {
          staleItems.push({
            evidenceId: node.id,
            receiptId: node.evidence.receiptId,
            originalHash: node.evidence.sourceHash,
            currentHash,
          });
        }
      }
    }

    return {
      isStale: staleItems.length > 0,
      staleItems,
      totalSources: oracleNodes.size,
    };
  }

  toJSON(): ProvenanceGraphData {
    return {
      nodes: Array.from(this.nodes.values()),
      edges: this.edges.slice(),
    };
  }

  static fromJSON(data: ProvenanceGraphData): ProvenanceGraph {
    const g = new ProvenanceGraph();
    for (const n of data.nodes) {
      g.nodes.set(n.id, n);
    }
    g.edges = data.edges.slice();
    for (const e of g.edges) {
      const rev = g.reverseIndex.get(e.to) ?? new Set<string>();
      rev.add(e.from);
      g.reverseIndex.set(e.to, rev);
    }
    return g;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/prims.ts
// ═══════════════════════════════════════════════════════════════════════════

import { getProvenanceGraph, getSourceChecker } from "./context";
import { evidenceId, evidenceToVal, type DerivedEvidence, type Evidence } from "./evidence";
import type { Val } from "../eval/values";
import { VFalse, VUnit } from "../eval/values";
import { isMeaning, meaning as mkMeaning, type MeaningVal } from "../oracle/meaning";
import type { State } from "../eval/machine";
import type { SourceChecker, ProvenanceGraph } from "./graph";

type DefFn = (name: string, v: Val) => void;

function strVal(s: string): Val {
  return { tag: "Str", s };
}

function numVal(n: number): Val {
  return { tag: "Num", n };
}

function toList(items: Val[]): Val {
  let result: Val = VUnit;
  for (let i = items.length - 1; i >= 0; i--) {
    result = { tag: "Vector", items: [items[i], result] };
  }
  return result;
}

function listToArray(list: Val): Val[] {
  const out: Val[] = [];
  let cur: Val = list;
  while (cur.tag === "Vector" && cur.items.length === 2) {
    out.push(cur.items[0]);
    cur = cur.items[1];
  }
  return out;
}

function asString(v: Val): string {
  if (v.tag === "Str") return v.s;
  if (v.tag === "Sym") return v.name;
  if (v.tag === "Num") return String(v.n);
  if (v.tag === "Bool") return v.b ? "true" : "false";
  if (v.tag === "Unit") return "";
  return JSON.stringify(v);
}

function attachEvidence(val: Val, evidence: Evidence[]): Val {
  if (isMeaning(val)) {
    const existing = val.evidence ?? [];
    return { ...val, evidence: [...existing, ...evidence] } as MeaningVal;
  }
  return mkMeaning({ denotation: val, evidence });
}

function collectEvidenceFromList(listVal: Val): Evidence[] {
  const out: Evidence[] = [];
  for (const item of listToArray(listVal)) {
    if (isMeaning(item) && item.evidence) {
      out.push(...item.evidence);
    }
  }
  return out;
}

function getGraph(state: State): ProvenanceGraph {
  const st = state as any;
  if (st.provenanceGraph) return st.provenanceGraph as ProvenanceGraph;
  const g = getProvenanceGraph();
  st.provenanceGraph = g;
  return g;
}

function getChecker(state: State): SourceChecker {
  const st = state as any;
  return (st.provenanceSourceChecker as SourceChecker | undefined) ?? getSourceChecker();
}

export function registerProvenancePrims(def: DefFn): void {
  // Return a summary of the active graph
  def("provenance-graph", {
    tag: "Native",
    name: "provenance-graph",
    arity: 0,
    fn: (_args, s) => {
      const graph = getGraph(s as State);
      const data = graph.toJSON();
      const result: Val = {
        tag: "Map",
        entries: [
          [strVal("nodes"), numVal(data.nodes.length)],
          [strVal("edges"), numVal(data.edges.length)],
        ],
      };
      return { ...s, control: { tag: "Val", v: result } };
    },
  });

  // Explicitly record a derivation between values
  def("provenance-record", {
    tag: "Native",
    name: "provenance-record",
    arity: 3,
    fn: (args, s) => {
      const [derivedVal, sourcesVal, opVal] = args;
      const graph = getGraph(s as State);
      const sources = collectEvidenceFromList(sourcesVal);
      const derivation: DerivedEvidence = {
        tag: "DerivedEvidence",
        dependencies: sources.map(evidenceId),
        derivationExpr: asString(opVal),
      };

      graph.derivedFrom(derivation, sources);
      const annotated = attachEvidence(derivedVal, [derivation]);
      return { ...s, control: { tag: "Val", v: annotated } };
    },
  });

  // Trace a value back to source evidence
  def("provenance-trace", {
    tag: "Native",
    name: "provenance-trace",
    arity: 1,
    fn: (args, s) => {
      const target = args[0];
      if (!isMeaning(target) || !target.evidence || target.evidence.length === 0) {
        return { ...s, control: { tag: "Val", v: VUnit } };
      }
      const graph = getGraph(s as State);
      const rootId = evidenceId(target.evidence[0]);
      const sources = graph.getSources(rootId);
      const ids = sources.map(src => strVal(src.id));
      return { ...s, control: { tag: "Val", v: toList(ids) } };
    },
  });

  // Check whether upstream oracle evidence has changed
  def("provenance-check-staleness", {
    tag: "Native",
    name: "provenance-check-staleness",
    arity: 1,
    fn: (args, s) => {
      const target = args[0];
      if (!isMeaning(target) || !target.evidence || target.evidence.length === 0) {
        const fallback: Val = {
          tag: "Map",
          entries: [
            [strVal("stale?"), { tag: "Bool", b: true }],
            [strVal("stale-count"), numVal(0)],
            [strVal("total-sources"), numVal(0)],
          ],
        };
        return { ...s, control: { tag: "Val", v: fallback } };
      }

      const graph = getGraph(s as State);
      const rootId = evidenceId(target.evidence[0]);
      const report = graph.checkStaleness(rootId, getChecker(s as State));
      const result: Val = {
        tag: "Map",
        entries: [
          [strVal("stale?"), { tag: "Bool", b: report.isStale }],
          [strVal("stale-count"), numVal(report.staleItems.length)],
          [strVal("total-sources"), numVal(report.totalSources)],
        ],
      };
      return { ...s, control: { tag: "Val", v: result } };
    },
  });

  // Convert evidence data to a Value (useful for inspection)
  def("evidence->val", {
    tag: "Native",
    name: "evidence->val",
    arity: 1,
    fn: (args, s) => {
      const ev = args[0] as any;
      if (!ev || typeof ev !== "object" || !("tag" in ev)) {
        return { ...s, control: { tag: "Val", v: VFalse } };
      }
      return { ...s, control: { tag: "Val", v: evidenceToVal(ev as Evidence) } };
    },
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/store/file.ts
// ═══════════════════════════════════════════════════════════════════════════

import * as fs from "node:fs/promises";
import * as path from "node:path";
import type { ProvenanceGraphData } from "../graph";
import { matchesFilter, type ProvenanceStore, type ReceiptFilter, type StoredReceipt } from "./interface";

async function ensureDir(dir: string): Promise<void> {
  await fs.mkdir(dir, { recursive: true });
}

export class FileProvenanceStore implements ProvenanceStore {
  private receiptsDir: string;
  private graphFile: string;

  constructor(private basePath: string) {
    this.receiptsDir = path.join(basePath, "receipts");
    this.graphFile = path.join(basePath, "graph.json");
  }

  async storeReceipt(receipt: StoredReceipt): Promise<void> {
    await ensureDir(this.receiptsDir);
    const file = path.join(this.receiptsDir, `${receipt.id}.json`);
    await fs.writeFile(file, JSON.stringify(receipt, null, 2), "utf8");
  }

  async getReceipt(id: string): Promise<StoredReceipt | undefined> {
    const file = path.join(this.receiptsDir, `${id}.json`);
    try {
      const data = await fs.readFile(file, "utf8");
      return JSON.parse(data) as StoredReceipt;
    } catch (e: any) {
      if (e?.code === "ENOENT") return undefined;
      throw e;
    }
  }

  async queryReceipts(filter?: ReceiptFilter): Promise<StoredReceipt[]> {
    try {
      const entries = await fs.readdir(this.receiptsDir);
      const receipts: StoredReceipt[] = [];
      for (const entry of entries) {
        if (!entry.endsWith(".json")) continue;
        const id = entry.replace(/\.json$/, "");
        const r = await this.getReceipt(id);
        if (r && matchesFilter(r, filter)) {
          receipts.push(r);
        }
      }
      return receipts;
    } catch (e: any) {
      if (e?.code === "ENOENT") return [];
      throw e;
    }
  }

  async storeGraph(graph: ProvenanceGraphData): Promise<void> {
    await ensureDir(this.basePath);
    await fs.writeFile(this.graphFile, JSON.stringify(graph, null, 2), "utf8");
  }

  async loadGraph(): Promise<ProvenanceGraphData | undefined> {
    try {
      const data = await fs.readFile(this.graphFile, "utf8");
      return JSON.parse(data) as ProvenanceGraphData;
    } catch (e: any) {
      if (e?.code === "ENOENT") return undefined;
      throw e;
    }
  }

  async pruneOlderThan(timestamp: number): Promise<number> {
    const receipts = await this.queryReceipts({ before: timestamp });
    let removed = 0;
    for (const r of receipts) {
      const file = path.join(this.receiptsDir, `${r.id}.json`);
      await fs.rm(file, { force: true });
      removed += 1;
    }
    return removed;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/provenance/store/interface.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ProvenanceGraphData } from "../graph";

export type ReceiptFilter = {
  before?: number;
  after?: number;
  idPrefix?: string;
};

export type StoredReceipt = {
  id: string;
  timestamp: number;
  request: unknown;
  response: unknown;
  sourceHash?: string;
};

export interface ProvenanceStore {
  storeReceipt(receipt: StoredReceipt): Promise<void>;
  getReceipt(id: string): Promise<StoredReceipt | undefined>;
  queryReceipts(filter?: ReceiptFilter): Promise<StoredReceipt[]>;

  storeGraph(graph: ProvenanceGraphData): Promise<void>;
  loadGraph(): Promise<ProvenanceGraphData | undefined>;

  pruneOlderThan(timestamp: number): Promise<number>;
}

export function matchesFilter(r: StoredReceipt, filter?: ReceiptFilter): boolean {
  if (!filter) return true;
  const ts = r.timestamp ?? 0;
  if (filter.after !== undefined && ts <= filter.after) return false;
  if (filter.before !== undefined && ts >= filter.before) return false;
  if (filter.idPrefix && !r.id.startsWith(filter.idPrefix)) return false;
  return true;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/reader/datum.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-5.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

export type Sym = { sym: string };

export type Datum =
  | number
  | string
  | boolean
  | null
  | Sym
  | Datum[];

export const sym = (s: string): Sym => ({ sym: s });
export const isSym = (d: Datum): d is Sym => typeof d === "object" && d !== null && !Array.isArray(d) && "sym" in d;
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/reader/parse.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-5.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Tok } from "./tokenize";
import type { Datum } from "./datum";
import { sym } from "./datum";

export function parseAll(toks: Tok[]): Datum[] {
  const out: Datum[] = [];
  let i = 0;

  function parseOne(): Datum {
    const t = toks[i];
    if (!t) throw new Error("parse: unexpected EOF");

    if (t.tag === "Quote") {
      i++;
      const d = parseOne();
      return [sym("quote"), d];
    }

    if (t.tag === "LParen") {
      i++;
      const items: Datum[] = [];
      while (true) {
        const u = toks[i];
        if (!u) throw new Error("parse: missing ')'");
        if (u.tag === "RParen") { i++; break; }
        items.push(parseOne());
      }
      return items;
    }

    if (t.tag === "RParen") {
      throw new Error("parse: unexpected ')'");
    }

    if (t.tag === "Str") {
      i++;
      return t.s;
    }

    // Atom: booleans, numbers, or symbol
    if (t.tag === "Atom") {
      i++;
      const s = t.s;

      if (s === "#t") return true;
      if (s === "#f") return false;

      // number
      if (/^-?\d+(\.\d+)?$/.test(s)) return Number(s);

      // null-ish
      if (s === "null") return null;

      return sym(s);
    }

    throw new Error("parse: unreachable");
  }

  while (i < toks.length) {
    out.push(parseOne());
  }
  return out;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/reader/tokenize.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-5.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

export type Tok =
  | { tag: "LParen" }
  | { tag: "RParen" }
  | { tag: "Quote" }
  | { tag: "Str"; s: string }
  | { tag: "Atom"; s: string };

export function tokenize(src: string): Tok[] {
  const toks: Tok[] = [];
  let i = 0;

  const isWS = (c: string) => c === " " || c === "\t" || c === "\n" || c === "\r";

  while (i < src.length) {
    const c = src[i];

    // comments
    if (c === ";") {
      while (i < src.length && src[i] !== "\n") i++;
      continue;
    }

    if (isWS(c)) { i++; continue; }

    if (c === "(") { toks.push({ tag: "LParen" }); i++; continue; }
    if (c === ")") { toks.push({ tag: "RParen" }); i++; continue; }
    if (c === "'") { toks.push({ tag: "Quote" }); i++; continue; }

    if (c === "\"") {
      i++;
      let s = "";
      while (i < src.length) {
        const d = src[i];
        if (d === "\"") { i++; break; }
        if (d === "\\") {
          const e = src[i + 1];
          if (e === "n") { s += "\n"; i += 2; continue; }
          if (e === "t") { s += "\t"; i += 2; continue; }
          s += e ?? "";
          i += 2;
          continue;
        }
        s += d;
        i++;
      }
      toks.push({ tag: "Str", s });
      continue;
    }

    // atom: read until whitespace or delimiter
    let a = "";
    while (i < src.length) {
      const d = src[i];
      if (isWS(d) || d === "(" || d === ")" || d === "'" || d === ";") break;
      a += d;
      i++;
    }
    if (a.length === 0) throw new Error("tokenize: internal error");
    toks.push({ tag: "Atom", s: a });
  }

  return toks;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/reader/toSyntax.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-5.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Datum } from "./datum";
import { isSym } from "./datum";
import type { Syntax } from "../syntax/syntax";

export function datumToSyntax(d: Datum): Syntax {
  if (isSym(d)) {
    return { tag: "Ident", name: d.sym, scopes: [] };
  }
  if (Array.isArray(d)) {
    return { tag: "List", items: d.map(datumToSyntax), scopes: [] };
  }
  // atoms
  return { tag: "Atom", value: d, scopes: [] };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./serializer";
export * from "./nativeRegistry";
export * from "./solverRegistry";
export * from "./reader";
export * from "./jump";
export * from "./writer";
export * from "./render";
export * from "./types";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/jump.ts
// ═══════════════════════════════════════════════════════════════════════════

import { SessionReader } from "./reader";
import { stepOnce } from "../eval/machineStep";
import { captureValueResumption } from "../effects/capture";
import type { State } from "../eval/machine";
import type { Val } from "../eval/values";

export type JumpResult = {
  state: State;
  seq: number;
  replayedSteps: number;
  usedReceipts: string[];
};

function responseToVal(responseContent: string): Val {
  return { tag: "Str", s: responseContent };
}

export class JumpController {
  constructor(private reader: SessionReader) {}

  async jumpTo(targetSeq: number): Promise<JumpResult> {
    const checkpoint = this.reader.findCheckpointBefore(targetSeq);

    if (!checkpoint) {
      throw new Error(`No checkpoint found before seq ${targetSeq}`);
    }

    let state = this.reader.getCheckpointState(checkpoint.stateId);
    const usedReceipts = new Set<string>();
    let replayedSteps = 0;
    let pending: { resumption: { invoke: (v: Val) => State }; receiptKey?: string } | null = null;

    const events = this.reader.getEventsInRange(checkpoint.seq + 1, targetSeq);
    for (const event of events) {
      if (!("seq" in event)) continue;

      switch (event.type) {
        case "step": {
          const result = stepOnce(state);
          if (result.tag === "State") {
            state = result.state;
          } else if (result.tag === "Done") {
            state = result.state;
          } else if (result.tag === "Op") {
            pending = { resumption: captureValueResumption(result.state) };
            state = result.state;
          }
          replayedSteps += 1;
          break;
        }
        case "llm_req":
          if (pending) {
            pending.receiptKey = event.receiptKey;
          }
          break;
        case "llm_resp": {
          const receipt = this.reader.getReceipt(event.receiptKey);
          if (!receipt) {
            throw new Error(`Receipt not found: ${event.receiptKey}`);
          }
          usedReceipts.add(event.receiptKey);
          const content = typeof receipt.response?.content === "string"
            ? receipt.response.content
            : JSON.stringify(receipt.response ?? "");
          const cachedVal = responseToVal(content);
          if (pending) {
            state = pending.resumption.invoke(cachedVal);
            pending = null;
          } else {
            const resumption = captureValueResumption(state);
            state = resumption.invoke(cachedVal);
          }
          break;
        }
        case "checkpoint":
          state = this.reader.getCheckpointState(event.stateId);
          pending = null;
          break;
        case "resume":
        case "effect":
        case "input":
        case "result":
        case "error":
          break;
      }
    }

    return {
      state,
      seq: targetSeq,
      replayedSteps,
      usedReceipts: Array.from(usedReceipts),
    };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/nativeRegistry.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Val } from "../eval/values";
import type { Store } from "../eval/store";

/**
 * Build a registry of Native functions by scanning the primed store.
 * Used during deserialization to restore Native.fn from Native.name.
 */
export function buildNativeRegistry(store: Store): Map<string, Val> {
  const registry = new Map<string, Val>();

  for (let addr = 0; addr < store.next; addr++) {
    try {
      const val = store.read(addr);
      if (val && (val as any).tag === "Native") {
        registry.set((val as any).name, val);
      }
    } catch {
      // Skip invalid addresses
    }
  }

  return registry;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/reader.ts
// ═══════════════════════════════════════════════════════════════════════════

import * as fs from "fs";
import * as readline from "readline";
import type { SessionEvent, SessionIndex, CheckpointIndex, LLMReceipt } from "./types";
import { deserializeState } from "./serializer";
import type { State } from "../eval/machine";
import type { Val } from "../eval/values";

export type CheckpointView = CheckpointIndex & { rawSeq: number };

export class SessionReader {
  private events: SessionEvent[] = [];
  private index: SessionIndex;
  private solverRegistry?: Map<string, Val>;

  constructor(
    private eventFile: string,
    private indexFile: string,
    private nativeRegistry: Map<string, Val>,
    solverRegistry?: Map<string, Val>
  ) {
    this.index = JSON.parse(fs.readFileSync(indexFile, "utf8"));
    this.solverRegistry = solverRegistry;
  }

  async loadAll(): Promise<void> {
    this.events = [];

    const fileStream = fs.createReadStream(this.eventFile);
    const rl = readline.createInterface({ input: fileStream });

    try {
      for await (const line of rl) {
        if (line.trim()) {
          this.events.push(JSON.parse(line));
        }
      }
    } finally {
      rl.close();
      await new Promise<void>(resolve => {
        if (fileStream.closed || fileStream.destroyed) {
          resolve();
          return;
        }
        fileStream.once("close", resolve);
        fileStream.close();
      });
    }
  }

  getEventCount(): number {
    return this.index.eventCount;
  }

  getEvent(seq: number): SessionEvent | undefined {
    return this.events.find(e => "seq" in e && (e as any).seq === seq);
  }

  getCheckpoints(): CheckpointView[] {
    return this.index.checkpoints.map(cp => this.decorateCheckpoint(cp));
  }

  findCheckpointBefore(targetSeq: number): CheckpointView | undefined {
    let best: CheckpointIndex | undefined;
    for (const cp of this.index.checkpoints) {
      if (cp.seq <= targetSeq && (!best || cp.seq > best.seq)) {
        best = cp;
      }
    }
    return best ? this.decorateCheckpoint(best) : undefined;
  }

  getCheckpointState(stateId: string): State {
    const serialized = this.index.states[stateId];
    if (!serialized) {
      throw new Error(`State not found: ${stateId}`);
    }
    return deserializeState(serialized, this.nativeRegistry, this.solverRegistry);
  }

  getReceipt(key: string): LLMReceipt | undefined {
    return this.index.receipts[key];
  }

  getAllEvents(): SessionEvent[] {
    return this.events;
  }

  getEventsInRange(startSeq: number, endSeq: number): SessionEvent[] {
    return this.events.filter(e => {
      if (!("seq" in e)) return false;
      const seq = (e as any).seq;
      return seq >= startSeq && seq <= endSeq;
    });
  }

  private decorateCheckpoint(cp: CheckpointIndex): CheckpointView {
    return { ...cp, rawSeq: cp.seq };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/render.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { SessionEvent } from "./types";

export type RenderOptions = {
  showTime?: boolean;
  showSeq?: boolean;
  maxValueWidth?: number;
  colors?: boolean;
};

const DEFAULT_OPTIONS: Required<RenderOptions> = {
  showTime: false,
  showSeq: true,
  maxValueWidth: 60,
  colors: false,
};

const SEQ_WIDTH = 3;
const SOURCE_WIDTH = 4;
const INDENT_UNIT = "  ";
const LLM_METADATA_BUFFER = 20;
const ELLIPSIS = "...";

export function renderEvent(event: SessionEvent, opts: RenderOptions = {}): string {
  const options = { ...DEFAULT_OPTIONS, ...opts };

  if (event.type === "session") {
    return `=== Session ${event.id} (${event.created}) ===`;
  }

  if (!("seq" in event)) {
    return "";
  }

  const depth = "d" in event && typeof event.d === "number" ? Math.max(0, event.d) : 0;
  const indent = INDENT_UNIT.repeat(depth);
  const maxWidth = Math.max(0, options.maxValueWidth ?? DEFAULT_OPTIONS.maxValueWidth);
  const seqPart = options.showSeq ? `[${String(event.seq).padStart(SEQ_WIDTH, "0")}] ` : "";
  const timePart = options.showTime && "ts" in event ? `${new Date(event.ts).toISOString()} ` : "";

  const parts = renderParts(event, maxWidth);
  if (!parts) {
    return "";
  }

  const { source, symbol, content } = parts;

  return `${seqPart}${timePart}${indent}${source} ${symbol} ${content}`;
}

export function renderTrace(events: SessionEvent[], opts: RenderOptions = {}): string {
  return events
    .map((event) => renderEvent(event, opts))
    .filter((line) => line.length > 0)
    .join("\n");
}

type RenderParts = {
  source: string;
  symbol: string;
  content: string;
};

function renderParts(event: SessionEvent, maxWidth: number): RenderParts | undefined {
  switch (event.type) {
    case "input":
      return {
        source: formatTag("REPL"),
        symbol: ">",
        content: truncate(event.code, maxWidth),
      };

    case "step":
      return {
        source: formatTag("EVAL"),
        symbol: "~",
        content: truncate(event.ctrl, maxWidth),
      };

    case "checkpoint":
      return {
        source: formatTag("SAVE"),
        symbol: "*",
        content: truncate(`checkpoint (${event.reason})`, maxWidth),
      };

    case "effect": {
      const args = event.argsPreview ? ` ${event.argsPreview}` : "";
      return {
        source: formatTag("EFCT"),
        symbol: "!",
        content: truncate(`${event.op}${args}`, maxWidth),
      };
    }

    case "llm_req": {
      const promptWidth = Math.max(0, maxWidth - LLM_METADATA_BUFFER);
      return {
        source: formatTag("LLM"),
        symbol: "->",
        content: `${event.model}: ${truncate(event.promptPreview, promptWidth)}`,
      };
    }

    case "llm_resp": {
      const valueWidth = Math.max(0, maxWidth - LLM_METADATA_BUFFER);
      const duration = `${event.durationMs}ms`;
      return {
        source: formatTag("LLM"),
        symbol: "<-",
        content: `${truncate(event.valuePreview, valueWidth)} (${duration})`,
      };
    }

    case "resume":
      return {
        source: formatTag("RSME"),
        symbol: "<~",
        content: truncate(event.valuePreview, maxWidth),
      };

    case "result":
      return {
        source: formatTag("OUT"),
        symbol: "=>",
        content: truncate(event.value, maxWidth),
      };

    case "error":
      return {
        source: formatTag("ERR"),
        symbol: "!!",
        content: truncate(event.message, maxWidth),
      };

    default:
      return undefined;
  }
}

function formatTag(tag: string): string {
  return tag.padEnd(SOURCE_WIDTH, " ").slice(0, SOURCE_WIDTH);
}

function truncate(value: string, max: number): string {
  if (!isFinite(max) || max <= 0) return "";
  if (value.length <= max) return value;
  if (max <= ELLIPSIS.length) return ELLIPSIS.slice(0, max);
  return `${value.slice(0, max - ELLIPSIS.length)}${ELLIPSIS}`;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/serializer.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Expr } from "../ast";
import type { ConditionVal, RestartBinding, RestartPoint } from "../conditions/types";
import type { Ctx } from "../ctx/ctx";
import type { Control, Frame, HandlerFrame, State } from "../eval/machine";
import type { Store } from "../eval/store";
import { COWStore } from "../eval/store";
import type { Val } from "../eval/values";

export type SerializedCtx = {
  id: string;
  parentId: string | null;
  frameEntries: Array<[string, number]>;
  profile: string;
  caps: string[];
  budgets: Record<string, unknown>;
  constraints: unknown[];
  sealed: boolean;
  evidence: unknown[];
};

export type SerializedHandlerFrame = {
  hid: string;
  envId: string;
  on: [string, { op: string; params: string[]; k: string; body: Expr }][];
  ret?: { v: string; body: Expr };
  fin?: { body: Expr };
};

export type SerializedRestartPoint = {
  name: string;
  description?: string;
  kont: SerializedFrame[];
  envId: string;
  storeEntries: [number, SerializedVal][];
  handlers: SerializedHandlerFrame[];
};

export type SerializedRestartBinding = {
  name: string;
  description?: string;
  fn: SerializedVal;
};

export type SerializedFrame =
  | { tag: "KIf"; conseq: Expr; alt: Expr; envId: string }
  | { tag: "KBegin"; rest: Expr[]; envId: string }
  | { tag: "KDefine"; name: string; envId: string }
  | { tag: "KSet"; name: string; envId: string }
  | { tag: "KAppFun"; args: Expr[]; envId: string }
  | { tag: "KAppArg"; fnVal: SerializedVal; pending: Expr[]; acc: SerializedVal[]; envId: string }
  | { tag: "KAppArgLazy"; fnVal: SerializedVal; pending: Array<{ expr: Expr; idx: number }>; acc: Array<{ idx: number; val: SerializedVal }>; envId: string; totalArgs: number; currentIdx: number }
  | { tag: "KCall"; savedEnvId: string }
  | { tag: "KEffect"; op: string; pending: Expr[]; acc: SerializedVal[]; envId: string }
  | { tag: "KHandleBoundary"; hid: string; savedHandlersDepth: number; resumeTo?: { kont: SerializedFrame[]; handlersDepth: number } }
  | { tag: "KHandleReturn"; mode: "exit" | "resume"; hid: string; targetKont: SerializedFrame[]; targetHandlersDepth: number; savedHandlersDepth: number }
  | { tag: "KPrompt"; promptTag: SerializedVal; handler: SerializedVal; envId: string; savedKont: SerializedFrame[]; savedHandlersDepth: number }
  | { tag: "KMatch"; clauses: Array<{ pat: unknown; body: Expr }>; envId: string }
  | { tag: "KOracleLambda"; params: string[]; envId: string }
  | { tag: "KBind"; fn: SerializedVal; envId: string }
  | { tag: "KHandlerBind"; handlers: Array<{ type: string | "*"; handler: SerializedVal }> }
  | { tag: "KRestartBind"; restarts: SerializedRestartBinding[]; savedKont: SerializedFrame[]; envId: string; storeEntries: [number, SerializedVal][]; handlers: SerializedHandlerFrame[] }
  | { tag: "KSignaling"; condition: SerializedVal; required: boolean }
  | { tag: string; [key: string]: unknown };

export type SerializedControl =
  | { tag: "Expr"; e: Expr }
  | { tag: "Val"; v: SerializedVal };

export type SerializedState = {
  control: SerializedControl;
  envId: string;
  storeEntries: [number, SerializedVal][];
  storeNext?: number;
  kont: SerializedFrame[];
  handlers: SerializedHandlerFrame[];
  ctxTable: Record<string, SerializedCtx>;
  profile?: unknown;
  budget?: unknown;
  sec?: { caps?: string[] };
};

export type SerializedVal =
  | { tag: "Unit" }
  | { tag: "Uninit" }
  | { tag: "Num"; n: number }
  | { tag: "Int"; value: string }
  | { tag: "Bool"; b: boolean }
  | { tag: "Str"; s: string }
  | { tag: "Sym"; name: string }
  | { tag: "Err"; message?: string }
  | { tag: "Pair"; car: SerializedVal; cdr: SerializedVal }
  | { tag: "Vector"; items: SerializedVal[] }
  | { tag: "List"; elements: SerializedVal[] }
  | { tag: "Map"; entries: Array<[SerializedVal, SerializedVal]> }
  | { tag: "Tagged"; typeTag: string; payload: SerializedVal }
  | { tag: "Syntax"; stx: unknown }
  | { tag: "Closure"; params: string[]; body: Expr; envId: string }
  | { tag: "Native"; name: string; arity: number | "variadic"; lazyArgs?: number[] }
  | { tag: "Cont"; hid: string; boundaryIndex: number; resumption: { rid: string; baseState: SerializedState } }
  | { tag: "OracleProc"; params: string[]; spec: SerializedVal; envId: string; policyDigest?: string }
  | { tag: "Continuation"; kont: SerializedFrame[]; envId: string; storeEntries: [number, SerializedVal][]; handlers: SerializedHandlerFrame[] }
  | { tag: "Machine"; state: SerializedState; label?: string; stepCount: number; breakOnOps?: string[]; breakOnPatterns?: string[]; lastOutcome?: unknown; isDone: boolean; machineId: string; parentId?: string }
  | { tag: "Dist"; support: Array<{ v: SerializedVal; w: number }>; normalized?: boolean; meta?: unknown }
  | { tag: "Meaning"; denotation?: SerializedVal; residual?: SerializedVal; rewrite?: SerializedVal; invariants?: SerializedVal; effects?: SerializedVal; cost?: SerializedVal; paths?: SerializedVal; deps?: SerializedVal; memo?: SerializedVal; obligation?: SerializedVal; obligations?: unknown[]; evidence?: unknown[]; confidence?: number; trace?: SerializedVal; adoptEnvRef?: string; adoptStateRef?: string }
  | { tag: "Profile"; profileId: string; profile: any }
  | { tag: "Ctx"; ctxId: string }
  | { tag: "Module"; moduleId: any; sealedCtxId: string; exports: string[]; meta?: any }
  | { tag: "ReceiptRef"; rid: any; kind: string }
  | { tag: "ConnRef"; id: string; netId: string; name?: string }
  | { tag: "NetRef"; id: string; name?: string }
  | { tag: "Explanation"; kind: string; conn?: SerializedVal; valueHash?: string; because?: SerializedVal; rule?: string; deps?: SerializedVal[]; left?: SerializedVal; right?: SerializedVal; message?: string; op?: string; reason?: string; profile?: string }
  | { tag: "Contradiction"; explanation: SerializedVal; constraintId?: string; netId?: string }
  | { tag: "Fiber"; id: number; name?: string }
  | { tag: "Mutex"; id: string; name?: string }
  | { tag: "IVar"; id: string; name?: string }
  | { tag: "Channel"; id: string; bufferSize: number; name?: string }
  | { tag: "Actor"; id: string; fiberId: number; name?: string }
  | { tag: "Promise"; id: string; label?: string }
  | { tag: "GenericRegistry"; id: string; name?: string }
  | { tag: "GenericMiss"; op: string; signature: string[]; argsPreview: SerializedVal[]; registryId: string; profileName?: string }
  | { tag: "Stream"; isEmpty: boolean; head?: SerializedVal; tail?: SerializedVal }
  | { tag: "IR"; form: string; digest: string; irRef: string; label?: string }
  | { tag: "Budget"; tokens: number; calls: number; time: number }
  | { tag: "Result"; kind: string; solution?: SerializedVal; remaining?: SerializedVal; reason?: string; cost: number }
  | { tag: "CostEstimate"; minCost: number; maxCost: number; expectedCost: number; confidence: number }
  | { tag: "Solver"; name: string }
  | { tag: "FactStore"; factsEntries: Array<[string, SerializedVal]> }
  | { tag: "Condition"; kind: string; message?: string; payload?: SerializedVal; restarts?: SerializedRestartPoint[] }
  | { tag: string; [key: string]: unknown };

function serializeProfile(profile: any): any {
  if (!profile) return profile;
  return {
    ...profile,
    allowedCaps: profile.allowedCaps ? Array.from(profile.allowedCaps) : undefined,
    allowedOps: profile.allowedOps ? Array.from(profile.allowedOps) : undefined,
    allowedOracleReqTags: profile.allowedOracleReqTags ? Array.from(profile.allowedOracleReqTags) : undefined,
  };
}

function deserializeProfile(profile: any): any {
  if (!profile) return profile;
  return {
    ...profile,
    allowedCaps: profile.allowedCaps ? new Set(profile.allowedCaps) : undefined,
    allowedOps: profile.allowedOps ? new Set(profile.allowedOps) : undefined,
    allowedOracleReqTags: profile.allowedOracleReqTags ? new Set(profile.allowedOracleReqTags) : undefined,
  };
}

export function serializeState(state: State): SerializedState {
  const ctxTable: Record<string, SerializedCtx> = {};
  const ctxIds = new Map<Ctx, string>();

  const controlInput: Control | undefined = (state as any).control ?? (state as any).ctrl;
  if (!controlInput) {
    throw new Error("State missing control");
  }

  function collectCtx(ctx: Ctx | undefined): string {
    if (!ctx) return "null";
    const existing = ctxIds.get(ctx);
    if (existing) return existing;
    const id = (ctx as any).cid ?? `ctx-${ctxIds.size}`;
    ctxIds.set(ctx, id);
    ctxTable[id] = {
      id,
      parentId: (ctx as any).parent ? collectCtx((ctx as any).parent) : null,
      frameEntries: Array.from((ctx as any).frame?.entries?.() ?? []),
      profile: (ctx as any).profile,
      caps: Array.from((ctx as any).caps ?? []),
      budgets: (ctx as any).budgets ?? {},
      constraints: (ctx as any).constraints ?? [],
      sealed: !!(ctx as any).sealed,
      evidence: (ctx as any).evidence ?? [],
    };
    return id;
  }

  function serializeStore(store: Store | undefined): [number, SerializedVal][] {
    const entries: [number, SerializedVal][] = [];
    if (!store) return entries;
    const max = (store as any).next ?? 0;
    for (let addr = 0; addr < max; addr++) {
      try {
        const val = store.read(addr);
        entries.push([addr, serializeVal(val)]);
      } catch {
        // Ignore holes
      }
    }
    return entries;
  }

  function serializeRestartPoint(r: RestartPoint): SerializedRestartPoint {
    return {
      name: (r.name as any)?.toString?.() ?? "restart",
      description: r.description,
      kont: (r.kont ?? []).map(serializeFrame),
      envId: collectCtx(r.env as Ctx),
      storeEntries: serializeStore(r.store),
      handlers: (r.handlers ?? []).map(serializeHandler),
    };
  }

  function serializeRestartBinding(r: RestartBinding): SerializedRestartBinding {
    return {
      name: (r.name as any)?.toString?.() ?? "restart",
      description: r.description,
      fn: serializeVal(r.fn),
    };
  }

  function serializeCondition(v: ConditionVal): SerializedVal {
    return {
      tag: "Condition",
      kind: (v.type as any)?.toString?.() ?? "condition",
      message: v.message,
      payload: serializeVal(v.data),
      restarts: (v.restarts ?? []).map(serializeRestartPoint),
    };
  }

  function serializeVal(v: Val): SerializedVal {
    if (!v || typeof v !== "object") {
      return { tag: "Unit" };
    }

    switch ((v as any).tag) {
      case "Unit":
      case "Uninit":
      case "Bool":
      case "Num":
      case "Str":
      case "Sym":
      case "Err":
        return v as SerializedVal;
      case "Int":
        return { tag: "Int", value: (v as any).value.toString() };
      case "Pair":
        return { tag: "Pair", car: serializeVal((v as any).car), cdr: serializeVal((v as any).cdr) };
      case "Vector":
        return { tag: "Vector", items: ((v as any).items ?? []).map(serializeVal) };
      case "List":
        return { tag: "List", elements: ((v as any).elements ?? []).map(serializeVal) };
      case "Map":
        return {
          tag: "Map",
          entries: ((v as any).entries ?? []).map(([k, val]: [Val, Val]) => [serializeVal(k), serializeVal(val)]),
        };
      case "Tagged":
        return { tag: "Tagged", typeTag: (v as any).typeTag, payload: serializeVal((v as any).payload) };
      case "Syntax":
        return { tag: "Syntax", stx: (v as any).stx };
      case "Closure":
        return { tag: "Closure", params: (v as any).params, body: (v as any).body, envId: collectCtx((v as any).env) };
      case "Native":
        return { tag: "Native", name: (v as any).name, arity: (v as any).arity, lazyArgs: (v as any).lazyArgs };
      case "OracleProc":
        return {
          tag: "OracleProc",
          params: (v as any).params,
          spec: serializeVal((v as any).spec),
          envId: collectCtx((v as any).env),
          policyDigest: (v as any).policyDigest,
        };
      case "Continuation":
        return {
          tag: "Continuation",
          kont: ((v as any).kont ?? []).map(serializeFrame),
          envId: collectCtx((v as any).env),
          storeEntries: serializeStore((v as any).store),
          handlers: ((v as any).handlers ?? []).map(serializeHandler),
        };
      case "Machine":
        return {
          tag: "Machine",
          state: serializeState((v as any).state),
          label: (v as any).label,
          stepCount: (v as any).stepCount ?? 0,
          breakOnOps: (v as any).breakOnOps ? Array.from((v as any).breakOnOps) : undefined,
          breakOnPatterns: (v as any).breakOnPatterns,
          lastOutcome: (v as any).lastOutcome,
          isDone: !!(v as any).isDone,
          machineId: (v as any).machineId ?? "",
          parentId: (v as any).parentId,
        };
      case "Dist":
        return {
          tag: "Dist",
          support: ((v as any).support ?? []).map((it: any) => ({ v: serializeVal(it.v), w: it.w })),
          normalized: (v as any).normalized,
          meta: (v as any).meta,
        };
      case "Meaning": {
        const mv: any = v as any;
        return {
          tag: "Meaning",
          denotation: mv.denotation !== undefined ? serializeVal(mv.denotation as any) : undefined,
          residual: mv.residual !== undefined ? serializeVal(mv.residual as any) : undefined,
          rewrite: mv.rewrite !== undefined ? serializeVal(mv.rewrite as any) : undefined,
          invariants: mv.invariants !== undefined ? serializeVal(mv.invariants as any) : undefined,
          effects: mv.effects !== undefined ? serializeVal(mv.effects as any) : undefined,
          cost: mv.cost !== undefined ? serializeVal(mv.cost as any) : undefined,
          paths: mv.paths !== undefined ? serializeVal(mv.paths as any) : undefined,
          deps: mv.deps !== undefined ? serializeVal(mv.deps as any) : undefined,
          memo: mv.memo !== undefined ? serializeVal(mv.memo as any) : undefined,
          obligation: mv.obligation !== undefined ? serializeVal(mv.obligation as any) : undefined,
          obligations: mv.obligations,
          evidence: mv.evidence,
          confidence: mv.confidence,
          trace: mv.trace !== undefined ? serializeVal(mv.trace as any) : undefined,
          adoptEnvRef: mv.adoptEnvRef,
          adoptStateRef: mv.adoptStateRef,
        };
      }
      case "Profile":
        return { tag: "Profile", profileId: (v as any).profileId, profile: serializeProfile((v as any).profile) };
      case "Ctx": {
        const id = collectCtx((v as any).ctx);
        return { tag: "Ctx", ctxId: id };
      }
      case "Module":
        return {
          tag: "Module",
          moduleId: (v as any).moduleId,
          sealedCtxId: collectCtx((v as any).sealedCtx),
          exports: Array.from((v as any).exports ?? []),
          meta: (v as any).meta,
        };
      case "ReceiptRef":
        return { tag: "ReceiptRef", rid: (v as any).rid, kind: (v as any).kind };
      case "ConnRef":
        return { tag: "ConnRef", id: (v as any).id, netId: (v as any).netId, name: (v as any).name };
      case "NetRef":
        return { tag: "NetRef", id: (v as any).id, name: (v as any).name };
      case "Explanation":
        return {
          tag: "Explanation",
          kind: (v as any).kind,
          conn: (v as any).conn ? serializeVal((v as any).conn) : undefined,
          valueHash: (v as any).valueHash,
          because: (v as any).because ? serializeVal((v as any).because) : undefined,
          rule: (v as any).rule,
          deps: (v as any).deps ? (v as any).deps.map((d: any) => serializeVal(d)) : undefined,
          left: (v as any).left ? serializeVal((v as any).left) : undefined,
          right: (v as any).right ? serializeVal((v as any).right) : undefined,
          message: (v as any).message,
          op: (v as any).op,
          reason: (v as any).reason,
          profile: (v as any).profile,
        };
      case "Contradiction":
        return {
          tag: "Contradiction",
          explanation: serializeVal((v as any).explanation),
          constraintId: (v as any).constraintId,
          netId: (v as any).netId,
        };
      case "Fiber":
      case "Mutex":
      case "IVar":
      case "Channel":
      case "Actor":
      case "Promise":
      case "GenericRegistry":
      case "IR":
      case "Budget":
      case "CostEstimate":
      case "Stream":
      case "Result":
      case "GenericMiss":
        return {
          ...(v as any),
          head: (v as any).head ? serializeVal((v as any).head) : (v as any).head,
          tail: (v as any).tail ? serializeVal((v as any).tail) : (v as any).tail,
          solution: (v as any).solution ? serializeVal((v as any).solution) : (v as any).solution,
          remaining: (v as any).remaining ? serializeVal((v as any).remaining) : (v as any).remaining,
        } as SerializedVal;
      case "FactStore":
        return {
          tag: "FactStore",
          factsEntries: Array.from(((v as any).facts ?? new Map()).entries()).map(([k, val]) => [k, serializeVal(val as any)]),
        };
      case "Condition":
        return serializeCondition(v as ConditionVal);
      case "Cont":
        return {
          tag: "Cont",
          hid: (v as any).hid,
          boundaryIndex: (v as any).boundaryIndex,
          resumption: { rid: (v as any).resumption.rid, baseState: serializeState((v as any).resumption.base) },
        };
      case "Solver":
        return { tag: "Solver", name: (v as any).name };
      default: {
        const copy: any = {};
        for (const [key, val] of Object.entries(v as any)) {
          if (typeof val === "function") continue;
          if (val instanceof Map) {
            copy[key] = Array.from(val.entries());
          } else if (val instanceof Set) {
            copy[key] = Array.from(val);
          } else {
            copy[key] = val;
          }
        }
        copy.tag = (v as any).tag ?? "Unknown";
        return copy as SerializedVal;
      }
    }
  }

  function serializeFrame(f: Frame): SerializedFrame {
    switch (f.tag) {
      case "KIf":
        return { tag: "KIf", conseq: (f as any).conseq, alt: (f as any).alt, envId: collectCtx((f as any).env) };
      case "KBegin":
        return { tag: "KBegin", rest: (f as any).rest, envId: collectCtx((f as any).env) };
      case "KDefine":
        return { tag: "KDefine", name: (f as any).name, envId: collectCtx((f as any).env) };
      case "KSet":
        return { tag: "KSet", name: (f as any).name, envId: collectCtx((f as any).env) };
      case "KAppFun":
        return { tag: "KAppFun", args: (f as any).args, envId: collectCtx((f as any).env) };
      case "KAppArg":
        return {
          tag: "KAppArg",
          fnVal: serializeVal((f as any).fnVal),
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map(serializeVal),
          envId: collectCtx((f as any).env),
        };
      case "KAppArgLazy":
        return {
          tag: "KAppArgLazy",
          fnVal: serializeVal((f as any).fnVal),
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map((it: any) => ({ idx: it.idx, val: serializeVal(it.val) })),
          envId: collectCtx((f as any).env),
          totalArgs: (f as any).totalArgs,
          currentIdx: (f as any).currentIdx,
        };
      case "KCall":
        return { tag: "KCall", savedEnvId: collectCtx((f as any).savedEnv) };
      case "KEffect":
        return {
          tag: "KEffect",
          op: (f as any).op,
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map(serializeVal),
          envId: collectCtx((f as any).env),
        };
      case "KHandleBoundary":
        return {
          tag: "KHandleBoundary",
          hid: (f as any).hid,
          savedHandlersDepth: (f as any).savedHandlersDepth,
          resumeTo: (f as any).resumeTo
            ? { kont: (f as any).resumeTo.kont.map(serializeFrame), handlersDepth: (f as any).resumeTo.handlersDepth }
            : undefined,
        };
      case "KHandleReturn":
        return {
          tag: "KHandleReturn",
          mode: (f as any).mode,
          hid: (f as any).hid,
          targetKont: (f as any).targetKont.map(serializeFrame),
          targetHandlersDepth: (f as any).targetHandlersDepth,
          savedHandlersDepth: (f as any).savedHandlersDepth,
        };
      case "KPrompt":
        return {
          tag: "KPrompt",
          promptTag: serializeVal((f as any).promptTag),
          handler: serializeVal((f as any).handler),
          envId: collectCtx((f as any).env),
          savedKont: (f as any).savedKont.map(serializeFrame),
          savedHandlersDepth: (f as any).savedHandlersDepth,
        };
      case "KMatch":
        return { tag: "KMatch", clauses: (f as any).clauses, envId: collectCtx((f as any).env) };
      case "KOracleLambda":
        return { tag: "KOracleLambda", params: (f as any).params, envId: collectCtx((f as any).env) };
      case "KBind":
        return { tag: "KBind", fn: serializeVal((f as any).fn), envId: collectCtx((f as any).env) };
      case "KHandlerBind":
        return {
          tag: "KHandlerBind",
          handlers: ((f as any).handlers ?? []).map((h: any) => ({
            type: (h.type as any)?.toString?.() ?? h.type,
            handler: serializeVal(h.handler),
          })),
        };
      case "KRestartBind":
        return {
          tag: "KRestartBind",
          restarts: ((f as any).restarts ?? []).map(serializeRestartBinding),
          savedKont: (f as any).savedKont.map(serializeFrame),
          envId: collectCtx((f as any).env),
          storeEntries: serializeStore((f as any).store),
          handlers: ((f as any).handlers ?? []).map(serializeHandler),
        };
      case "KSignaling":
        return { tag: "KSignaling", condition: serializeVal((f as any).condition), required: (f as any).required };
      default:
        return f as any;
    }
  }

  function serializeHandler(h: HandlerFrame): SerializedHandlerFrame {
    return {
      hid: (h as any).hid,
      envId: collectCtx((h as any).env),
      on: Array.from(((h as any).on ?? new Map()).entries()),
      ret: (h as any).ret,
      fin: (h as any).fin,
    };
  }

  const control: SerializedControl =
    controlInput.tag === "Expr"
      ? { tag: "Expr", e: (controlInput as any).e }
      : { tag: "Val", v: serializeVal((controlInput as any).v) };

  const envId = state.env ? collectCtx(state.env as Ctx) : "null";
  const storeEntries = serializeStore(state.store);

  return {
    control,
    envId,
    storeEntries,
    storeNext: (state.store as any)?.next ?? storeEntries.length,
    kont: (state.kont ?? []).map(serializeFrame),
    handlers: (state.handlers ?? []).map(serializeHandler),
    ctxTable,
    profile: serializeProfile((state as any).profile),
    budget: (state as any).budget ? { ...(state as any).budget } : undefined,
    sec: (state as any).sec ? { caps: (state as any).sec.caps ? Array.from((state as any).sec.caps) : undefined } : undefined,
  };
}

export function deserializeState(
  s: SerializedState,
  nativeRegistry: Map<string, Val>,
  solverRegistry?: Map<string, Val>
): State {
  const ctxInstances: Record<string, Ctx> = {};

  function rebuildCtx(id: string | null | undefined): Ctx | undefined {
    if (!id || id === "null") return undefined;
    if (ctxInstances[id]) return ctxInstances[id];
    const ser = s.ctxTable[id];
    if (!ser) {
      throw new Error(`Missing ctx in table: ${id}`);
    }
    const ctx: Ctx = {
      tag: "Ctx",
      cid: ser.id,
      parent: ser.parentId ? rebuildCtx(ser.parentId) : undefined,
      frame: new Map(ser.frameEntries),
      profile: ser.profile,
      caps: new Set(ser.caps) as any,
      budgets: ser.budgets as any,
      constraints: ser.constraints as any,
      sealed: ser.sealed,
      evidence: ser.evidence as any,
    };
    ctxInstances[id] = ctx;
    return ctx;
  }

  function deserializeStore(entries: [number, SerializedVal][], storeNext?: number): Store {
    const cells = new Map<number, Val>();
    let max = -1;
    for (const [addr, val] of entries) {
      cells.set(addr, deserializeVal(val));
      if (addr > max) max = addr;
    }
    const next = storeNext !== undefined ? storeNext : max + 1;
    return new COWStore(next < 0 ? 0 : next, cells);
  }

  function deserializeRestartPoint(r: SerializedRestartPoint): RestartPoint {
    return {
      name: Symbol.for(r.name ?? "restart"),
      description: r.description,
      kont: (r.kont ?? []).map(deserializeFrame),
      env: rebuildCtx(r.envId) as any,
      store: deserializeStore(r.storeEntries ?? []),
      handlers: (r.handlers ?? []).map(deserializeHandler),
    } as any;
  }

  function deserializeRestartBinding(r: SerializedRestartBinding): RestartBinding {
    return {
      name: Symbol.for(r.name ?? "restart"),
      description: r.description,
      fn: deserializeVal(r.fn),
    } as any;
  }

  function deserializeCondition(v: any): ConditionVal {
    return {
      tag: "Condition",
      type: Symbol.for(v.kind ?? "condition"),
      message: v.message ?? "",
      data: v.payload ? deserializeVal(v.payload) : ({ tag: "Unit" } as Val),
      restarts: (v.restarts ?? []).map(deserializeRestartPoint),
    } as any;
  }

  function restoreNative(name: string, arity: number | "variadic", lazyArgs?: number[]): Val {
    const native = nativeRegistry.get(name);
    if (native) return native;
    return {
      tag: "Native",
      name,
      arity,
      lazyArgs,
      fn: () => {
        throw new Error(`Native function not found: ${name}`);
      },
    } as any;
  }

  function restoreSolver(name: string): Val {
    const solver = solverRegistry?.get(name);
    if (solver) return solver;
    return {
      tag: "Solver",
      name,
      solve: () => {
        throw new Error(`Solver not found: ${name}`);
      },
      estimate: () => {
        throw new Error(`Solver not found: ${name}`);
      },
    } as any;
  }

  function deserializeVal(v: SerializedVal): Val {
    switch ((v as any).tag) {
      case "Unit":
      case "Uninit":
      case "Bool":
      case "Num":
      case "Str":
      case "Sym":
      case "Err":
        return v as Val;
      case "Int":
        return { tag: "Int", value: BigInt((v as any).value) } as any;
      case "Pair":
        return { tag: "Pair", car: deserializeVal((v as any).car), cdr: deserializeVal((v as any).cdr) } as Val;
      case "Vector":
        return { tag: "Vector", items: ((v as any).items ?? []).map(deserializeVal) } as Val;
      case "List":
        return { tag: "List", elements: ((v as any).elements ?? []).map(deserializeVal) } as Val;
      case "Map":
        return {
          tag: "Map",
          entries: ((v as any).entries ?? []).map(([k, val]: [SerializedVal, SerializedVal]) => [deserializeVal(k), deserializeVal(val)]),
        } as any;
      case "Tagged":
        return { tag: "Tagged", typeTag: (v as any).typeTag, payload: deserializeVal((v as any).payload) } as any;
      case "Syntax":
        return { tag: "Syntax", stx: (v as any).stx } as any;
      case "Closure":
        return {
          tag: "Closure",
          params: (v as any).params,
          body: (v as any).body,
          env: rebuildCtx((v as any).envId) as any,
        } as any;
      case "Native":
        return restoreNative((v as any).name, (v as any).arity, (v as any).lazyArgs);
      case "OracleProc":
        return {
          tag: "OracleProc",
          params: (v as any).params,
          spec: deserializeVal((v as any).spec),
          env: rebuildCtx((v as any).envId) as any,
          policyDigest: (v as any).policyDigest,
        } as any;
      case "Continuation":
        return {
          tag: "Continuation",
          kont: ((v as any).kont ?? []).map(deserializeFrame),
          env: rebuildCtx((v as any).envId) as any,
          store: deserializeStore((v as any).storeEntries ?? []),
          handlers: ((v as any).handlers ?? []).map(deserializeHandler),
        } as any;
      case "Machine":
        return {
          tag: "Machine",
          state: deserializeState((v as any).state, nativeRegistry, solverRegistry),
          label: (v as any).label,
          stepCount: (v as any).stepCount ?? 0,
          breakOnOps: (v as any).breakOnOps ? new Set((v as any).breakOnOps) : undefined,
          breakOnPatterns: (v as any).breakOnPatterns,
          lastOutcome: (v as any).lastOutcome,
          isDone: !!(v as any).isDone,
          machineId: (v as any).machineId,
          parentId: (v as any).parentId,
        } as any;
      case "Dist":
        return {
          tag: "Dist",
          support: ((v as any).support ?? []).map((it: any) => ({ v: deserializeVal(it.v), w: it.w })),
          normalized: (v as any).normalized,
          meta: (v as any).meta,
        } as any;
      case "Meaning": {
        const mv: any = v;
        return {
          tag: "Meaning",
          denotation: mv.denotation !== undefined ? deserializeVal(mv.denotation as any) : undefined,
          residual: mv.residual !== undefined ? deserializeVal(mv.residual as any) : undefined,
          rewrite: mv.rewrite !== undefined ? deserializeVal(mv.rewrite as any) : undefined,
          invariants: mv.invariants !== undefined ? deserializeVal(mv.invariants as any) : undefined,
          effects: mv.effects !== undefined ? deserializeVal(mv.effects as any) : undefined,
          cost: mv.cost !== undefined ? deserializeVal(mv.cost as any) : undefined,
          paths: mv.paths !== undefined ? deserializeVal(mv.paths as any) : undefined,
          deps: mv.deps !== undefined ? deserializeVal(mv.deps as any) : undefined,
          memo: mv.memo !== undefined ? deserializeVal(mv.memo as any) : undefined,
          obligation: mv.obligation !== undefined ? deserializeVal(mv.obligation as any) : undefined,
          obligations: mv.obligations,
          evidence: mv.evidence,
          confidence: mv.confidence,
          trace: mv.trace !== undefined ? deserializeVal(mv.trace as any) : undefined,
          adoptEnvRef: mv.adoptEnvRef,
          adoptStateRef: mv.adoptStateRef,
        } as any;
      }
      case "Profile":
        return { tag: "Profile", profileId: (v as any).profileId, profile: deserializeProfile((v as any).profile) } as any;
      case "Ctx": {
        return { tag: "Ctx", ctx: rebuildCtx((v as any).ctxId) } as any;
      }
      case "Module":
        return {
          tag: "Module",
          moduleId: (v as any).moduleId,
          sealedCtx: rebuildCtx((v as any).sealedCtxId) as any,
          exports: new Set((v as any).exports ?? []),
          meta: (v as any).meta,
        } as any;
      case "ReceiptRef":
        return { tag: "ReceiptRef", rid: (v as any).rid, kind: (v as any).kind } as any;
      case "ConnRef":
        return { tag: "ConnRef", id: (v as any).id, netId: (v as any).netId, name: (v as any).name } as any;
      case "NetRef":
        return { tag: "NetRef", id: (v as any).id, name: (v as any).name } as any;
      case "Explanation":
        return {
          tag: "Explanation",
          kind: (v as any).kind,
          conn: (v as any).conn ? deserializeVal((v as any).conn) : undefined,
          valueHash: (v as any).valueHash,
          because: (v as any).because ? deserializeVal((v as any).because) : undefined,
          rule: (v as any).rule,
          deps: (v as any).deps ? (v as any).deps.map((d: any) => deserializeVal(d)) : undefined,
          left: (v as any).left ? deserializeVal((v as any).left) : undefined,
          right: (v as any).right ? deserializeVal((v as any).right) : undefined,
          message: (v as any).message,
          op: (v as any).op,
          reason: (v as any).reason,
          profile: (v as any).profile,
        } as any;
      case "Contradiction":
        return {
          tag: "Contradiction",
          explanation: deserializeVal((v as any).explanation),
          constraintId: (v as any).constraintId,
          netId: (v as any).netId,
        } as any;
      case "FactStore":
        return {
          tag: "FactStore",
          facts: new Map(((v as any).factsEntries ?? []).map(([k, val]: [string, SerializedVal]) => [k, deserializeVal(val)])),
        } as any;
      case "Stream":
        return {
          tag: "Stream",
          isEmpty: (v as any).isEmpty,
          head: (v as any).head ? deserializeVal((v as any).head) : undefined,
          tail: (v as any).tail ? deserializeVal((v as any).tail) : undefined,
        } as any;
      case "IR":
      case "Budget":
      case "CostEstimate":
      case "Fiber":
      case "Mutex":
      case "IVar":
      case "Channel":
      case "Actor":
      case "Promise":
      case "GenericRegistry":
      case "GenericMiss":
      case "Result":
        return {
          ...(v as any),
          head: (v as any).head ? deserializeVal((v as any).head) : (v as any).head,
          tail: (v as any).tail ? deserializeVal((v as any).tail) : (v as any).tail,
          solution: (v as any).solution ? deserializeVal((v as any).solution) : (v as any).solution,
          remaining: (v as any).remaining ? deserializeVal((v as any).remaining) : (v as any).remaining,
        } as any;
      case "Condition":
        return deserializeCondition(v);
      case "Cont": {
        const base = deserializeState((v as any).resumption.baseState, nativeRegistry, solverRegistry);
        return {
          tag: "Cont",
          hid: (v as any).hid,
          boundaryIndex: (v as any).boundaryIndex,
          resumption: {
            rid: (v as any).resumption.rid,
            base,
            invoke: (val: Val) => {
              const nextStore = (base.store as any)?.snapshot ? (base.store as any).snapshot() : base.store;
              const resumed: State = { ...base, control: { tag: "Val", v: val }, store: nextStore };
              (resumed as any).ctrl = resumed.control;
              return resumed;
            },
            digest: () => ((base.store as any)?.digest ? (base.store as any).digest() : String((v as any).resumption.rid)),
          },
        } as any;
      }
      case "Solver":
        return restoreSolver((v as any).name);
      default:
        return v as any;
    }
  }

  function deserializeFrame(f: SerializedFrame): Frame {
    switch ((f as any).tag) {
      case "KIf":
        return { tag: "KIf", conseq: (f as any).conseq, alt: (f as any).alt, env: rebuildCtx((f as any).envId) as any };
      case "KBegin":
        return { tag: "KBegin", rest: (f as any).rest, env: rebuildCtx((f as any).envId) as any };
      case "KDefine":
        return { tag: "KDefine", name: (f as any).name, env: rebuildCtx((f as any).envId) as any };
      case "KSet":
        return { tag: "KSet", name: (f as any).name, env: rebuildCtx((f as any).envId) as any };
      case "KAppFun":
        return { tag: "KAppFun", args: (f as any).args, env: rebuildCtx((f as any).envId) as any };
      case "KAppArg":
        return {
          tag: "KAppArg",
          fnVal: deserializeVal((f as any).fnVal),
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map(deserializeVal),
          env: rebuildCtx((f as any).envId) as any,
        };
      case "KAppArgLazy":
        return {
          tag: "KAppArgLazy",
          fnVal: deserializeVal((f as any).fnVal),
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map((it: any) => ({ idx: it.idx, val: deserializeVal(it.val) })),
          env: rebuildCtx((f as any).envId) as any,
          totalArgs: (f as any).totalArgs,
          currentIdx: (f as any).currentIdx,
        };
      case "KCall":
        return { tag: "KCall", savedEnv: rebuildCtx((f as any).savedEnvId) as any };
      case "KEffect":
        return {
          tag: "KEffect",
          op: (f as any).op,
          pending: (f as any).pending,
          acc: ((f as any).acc ?? []).map(deserializeVal),
          env: rebuildCtx((f as any).envId) as any,
        };
      case "KHandleBoundary":
        return {
          tag: "KHandleBoundary",
          hid: (f as any).hid,
          savedHandlersDepth: (f as any).savedHandlersDepth,
          resumeTo: (f as any).resumeTo
            ? { kont: (f as any).resumeTo.kont.map(deserializeFrame), handlersDepth: (f as any).resumeTo.handlersDepth }
            : undefined,
        };
      case "KHandleReturn":
        return {
          tag: "KHandleReturn",
          mode: (f as any).mode,
          hid: (f as any).hid,
          targetKont: (f as any).targetKont.map(deserializeFrame),
          targetHandlersDepth: (f as any).targetHandlersDepth,
          savedHandlersDepth: (f as any).savedHandlersDepth,
        };
      case "KPrompt":
        return {
          tag: "KPrompt",
          promptTag: deserializeVal((f as any).promptTag),
          handler: deserializeVal((f as any).handler),
          env: rebuildCtx((f as any).envId) as any,
          savedKont: (f as any).savedKont.map(deserializeFrame),
          savedHandlersDepth: (f as any).savedHandlersDepth,
        };
      case "KMatch":
        return { tag: "KMatch", clauses: (f as any).clauses, env: rebuildCtx((f as any).envId) as any };
      case "KOracleLambda":
        return { tag: "KOracleLambda", params: (f as any).params, env: rebuildCtx((f as any).envId) as any };
      case "KBind":
        return { tag: "KBind", fn: deserializeVal((f as any).fn), env: rebuildCtx((f as any).envId) as any };
      case "KHandlerBind":
        return {
          tag: "KHandlerBind",
          handlers: ((f as any).handlers ?? []).map((h: any) => ({
            type: (h as any).type === "*" ? "*" : Symbol.for((h as any).type ?? "handler"),
            handler: deserializeVal((h as any).handler),
          })),
        } as any;
      case "KRestartBind":
        return {
          tag: "KRestartBind",
          restarts: ((f as any).restarts ?? []).map(deserializeRestartBinding),
          savedKont: (f as any).savedKont.map(deserializeFrame),
          env: rebuildCtx((f as any).envId) as any,
          store: deserializeStore((f as any).storeEntries ?? []),
          handlers: ((f as any).handlers ?? []).map(deserializeHandler),
        } as any;
      case "KSignaling":
        return { tag: "KSignaling", condition: deserializeVal((f as any).condition), required: (f as any).required } as any;
      default:
        return f as any;
    }
  }

  function deserializeHandler(h: SerializedHandlerFrame): HandlerFrame {
    return {
      hid: (h as any).hid,
      env: rebuildCtx((h as any).envId) as any,
      on: new Map((h as any).on ?? []),
      ret: (h as any).ret,
      fin: (h as any).fin,
    } as any;
  }

  const control: Control =
    s.control.tag === "Expr"
      ? { tag: "Expr", e: (s.control as any).e }
      : { tag: "Val", v: deserializeVal((s.control as any).v) };

  const env = rebuildCtx(s.envId) as any;
  const store = deserializeStore(s.storeEntries, s.storeNext);
  const state: State = {
    control,
    env: env as any,
    store,
    kont: (s.kont ?? []).map(deserializeFrame),
    handlers: (s.handlers ?? []).map(deserializeHandler),
    profile: deserializeProfile(s.profile),
    budget: s.budget as any,
    sec: s.sec ? ({ caps: s.sec.caps ? new Set(s.sec.caps) : undefined } as any) : undefined,
  };
  (state as any).ctrl = control;
  return state;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/solverRegistry.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Store } from "../eval/store";
import type { Val } from "../eval/values";

export type SolverRegistry = Map<string, Val>;

export function buildSolverRegistry(store: Store): SolverRegistry {
  const registry: SolverRegistry = new Map();

  for (let addr = 0; addr < store.next; addr++) {
    try {
      const val = store.read(addr);
      if (val && (val as any).tag === "Solver") {
        registry.set((val as any).name, val);
      }
    } catch {
      // Skip invalid addresses
    }
  }

  return registry;
}

export function registerSolver(registry: SolverRegistry, name: string, solver: Val): void {
  if ((solver as any).tag !== "Solver") {
    throw new Error(`Not a Solver: ${name}`);
  }
  registry.set(name, solver);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/types.ts
// ═══════════════════════════════════════════════════════════════════════════

export type SessionEvent =
  | SessionHeaderEvent
  | InputEvent
  | StepEvent
  | CheckpointEvent
  | LLMRequestEvent
  | LLMResponseEvent
  | EffectEvent
  | ResumeEvent
  | ResultEvent
  | ErrorEvent;

export type SessionHeaderEvent = {
  type: "session";
  version: 1;
  id: string;
  created: string;
  profile?: string;
};

export type InputEvent = {
  seq: number;
  ts: number;
  type: "input";
  code: string;
};

export type StepEvent = {
  seq: number;
  ts: number;
  type: "step";
  d: number;
  ctrl: string;
};

export type CheckpointEvent = {
  seq: number;
  ts: number;
  type: "checkpoint";
  d: number;
  reason: "llm_boundary" | "periodic" | "manual" | "effect";
  stateId: string;
};

export type LLMRequestEvent = {
  seq: number;
  ts: number;
  type: "llm_req";
  d: number;
  model: string;
  promptPreview: string;
  receiptKey: string;
};

export type LLMResponseEvent = {
  seq: number;
  ts: number;
  type: "llm_resp";
  d: number;
  valuePreview: string;
  tokens?: number;
  durationMs: number;
  receiptKey: string;
};

export type EffectEvent = {
  seq: number;
  ts: number;
  type: "effect";
  d: number;
  op: string;
  argsPreview: string;
};

export type ResumeEvent = {
  seq: number;
  ts: number;
  type: "resume";
  d: number;
  valuePreview: string;
};

export type ResultEvent = {
  seq: number;
  ts: number;
  type: "result";
  value: string;
};

export type ErrorEvent = {
  seq: number;
  ts: number;
  type: "error";
  d: number;
  message: string;
  stack?: string;
};

export type SessionIndex = {
  sessionId: string;
  eventCount: number;
  checkpoints: CheckpointIndex[];
  states: Record<string, any>;
  receipts: Record<string, LLMReceipt>;
};

export type CheckpointIndex = {
  seq: number;
  byteOffset: number;
  stateId: string;
  reason: string;
};

export type LLMReceipt = {
  key: string;
  request: any;
  response: any;
  timestamp: number;
  durationMs: number;
  tokens?: number;
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/session/writer.ts
// ═══════════════════════════════════════════════════════════════════════════

import * as fs from "fs";
import * as path from "path";
import { serializeState } from "./serializer";
import type { SessionEvent, SessionIndex, CheckpointIndex } from "./types";
import type { State } from "../eval/machine";
import { sha256JSON } from "../artifacts/hash";

const PREVIEW_LIMIT = 200;

export type SessionWriterOptions = {
  append?: boolean;
  index?: SessionIndex;
};

export class SessionWriter {
  private sessionId: string;
  private sessionDir: string;
  private eventFile: string;
  private indexFile: string;

  private seq = 0;
  private depth = 0;
  private checkpoints: CheckpointIndex[] = [];
  private states: Record<string, any> = {};
  private receipts: Record<string, any> = {};
  private byteOffset = 0;

  constructor(sessionDir: string, sessionId?: string, options: SessionWriterOptions = {}) {
    this.sessionDir = sessionDir;
    this.sessionId = sessionId || `session-${Date.now().toString(36)}`;
    const append = options.append === true;

    // Ensure directories exist before writing any files.
    fs.mkdirSync(path.join(sessionDir, "sessions"), { recursive: true });
    fs.mkdirSync(path.join(sessionDir, "receipts"), { recursive: true });

    this.eventFile = path.join(sessionDir, "sessions", `${this.sessionId}.jsonl`);
    this.indexFile = path.join(sessionDir, "sessions", `${this.sessionId}.index.json`);

    const eventExists = fs.existsSync(this.eventFile);

    if (append && eventExists) {
      const index = options.index ?? (fs.existsSync(this.indexFile)
        ? JSON.parse(fs.readFileSync(this.indexFile, "utf8"))
        : undefined);
      if (index) {
        this.seq = index.eventCount ?? 0;
        this.checkpoints = index.checkpoints ?? [];
        this.states = index.states ?? {};
        this.receipts = index.receipts ?? {};
      } else {
        try {
          const content = fs.readFileSync(this.eventFile, "utf8");
          let maxSeq = -1;
          for (const line of content.split(/\r?\n/)) {
            if (!line.trim()) continue;
            const event = JSON.parse(line);
            if (typeof event?.seq === "number") {
              maxSeq = Math.max(maxSeq, event.seq);
            }
          }
          this.seq = maxSeq + 1;
        } catch {
          this.seq = 0;
        }
      }
      this.byteOffset = fs.statSync(this.eventFile).size;
      return;
    }

    // Start a fresh event log for this session.
    fs.writeFileSync(this.eventFile, "");

    // Write session header as the first event.
    this.writeEvent({
      type: "session",
      version: 1,
      id: this.sessionId,
      created: new Date().toISOString(),
    });
  }

  private writeEvent(event: SessionEvent): void {
    const line = `${JSON.stringify(event)}\n`;
    fs.appendFileSync(this.eventFile, line);
    this.byteOffset += Buffer.byteLength(line, "utf8");
    if ("seq" in event) {
      this.seq = event.seq + 1;
    }
  }

  private saveIndex(): void {
    const index: SessionIndex = {
      sessionId: this.sessionId,
      eventCount: this.seq,
      checkpoints: this.checkpoints,
      states: this.states,
      receipts: this.receipts,
    };
    fs.writeFileSync(this.indexFile, JSON.stringify(index, null, 2));
  }

  getSessionId(): string {
    return this.sessionId;
  }

  getSeq(): number {
    return this.seq;
  }

  pushDepth(): void {
    this.depth++;
  }

  popDepth(): void {
    this.depth = Math.max(0, this.depth - 1);
  }

  input(code: string): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "input",
      code,
    });
  }

  step(controlSummary: string): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "step",
      d: this.depth,
      ctrl: controlSummary,
    });
  }

  checkpoint(state: State, reason: "llm_boundary" | "periodic" | "manual" | "effect"): void {
    const stateId = `state-${this.seq}`;
    const serialized = serializeState(state);

    this.states[stateId] = serialized;

    this.checkpoints.push({
      seq: this.seq,
      byteOffset: this.byteOffset,
      stateId,
      reason,
    });

    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "checkpoint",
      d: this.depth,
      reason,
      stateId,
    });

    this.saveIndex();
  }

  effect(op: string, args: any[]): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "effect",
      d: this.depth,
      op,
      argsPreview: this.preview(args),
    });
  }

  llmRequest(model: string, prompt: string, fullRequest: any): string {
    const receiptKey = sha256JSON(fullRequest);

    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "llm_req",
      d: this.depth,
      model,
      promptPreview: this.preview(prompt),
      receiptKey,
    });

    return receiptKey;
  }

  llmResponse(receiptKey: string, value: string, fullResponse: any, durationMs: number, tokens?: number): void {
    this.receipts[receiptKey] = {
      key: receiptKey,
      request: fullResponse?.request,
      response: fullResponse?.response,
      timestamp: Date.now(),
      durationMs,
      tokens,
    };

    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "llm_resp",
      d: this.depth,
      valuePreview: this.preview(value),
      tokens,
      durationMs,
      receiptKey,
    });

    this.saveIndex();
  }

  resume(value: string): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "resume",
      d: this.depth,
      valuePreview: this.preview(value),
    });
  }

  result(value: string): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "result",
      value,
    });
    this.saveIndex();
  }

  error(message: string, stack?: string): void {
    this.writeEvent({
      seq: this.seq,
      ts: Date.now(),
      type: "error",
      d: this.depth,
      message,
      stack,
    });
    this.saveIndex();
  }

  close(): void {
    this.saveIndex();
  }

  private preview(value: any): string {
    if (typeof value === "string") {
      return value.slice(0, PREVIEW_LIMIT);
    }
    try {
      return JSON.stringify(value).slice(0, PREVIEW_LIMIT);
    } catch {
      return String(value).slice(0, PREVIEW_LIMIT);
    }
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/sexp/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/sexp/index.ts
// S-expression utilities

export {
  type Sexp,
  sym,
  num,
  str,
  bool,
  list,
  sexpEq,
  sexpToString,
  parseSexp,
} from "./sexp";

export {
  type Bindings,
  type MatchResult,
  matchSexp,
} from "./patternMatch";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/sexp/patternMatch.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/sexp/patternMatch.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-19.md
// Pattern matcher with _, ?x, and ... ellipsis support (backtracking)

import type { Sexp } from "./sexp";
import { sexpEq, sexpToString } from "./sexp";

export type Bindings = Map<string, Sexp>;

export type MatchResult =
  | { ok: true; bindings: Bindings }
  | { ok: false; reason: string };

export function matchSexp(pattern: Sexp, value: Sexp): MatchResult {
  const b = new Map<string, Sexp>();
  const r = match(pattern, value, b, /*inEllipsis*/ false);
  if (!r.ok) return r;
  return { ok: true, bindings: r.bindings };
}

function match(p: Sexp, v: Sexp, b: Bindings, inEllipsis: boolean): MatchResult {
  // Wildcard _
  if (p.tag === "Sym" && p.name === "_") return { ok: true, bindings: b };

  // Pattern var ?x
  if (p.tag === "Sym" && p.name.startsWith("?") && p.name.length > 1) {
    return bindVar(p.name.slice(1), v, b, inEllipsis);
  }

  // Lists: handle ellipsis
  if (p.tag === "List") {
    if (v.tag !== "List") return fail(`expected list, got ${v.tag}`);
    return matchListWithContext(p.items, v.items, b, inEllipsis);
  }

  // Atoms: structural equality
  if (!sexpEq(p, v)) return fail(`literal mismatch: ${sexpToString(p)} != ${sexpToString(v)}`);
  return { ok: true, bindings: b };
}

function matchList(pats: Sexp[], vals: Sexp[], b: Bindings): MatchResult {
  return matchListWithContext(pats, vals, b, false);
}

function matchListWithContext(pats: Sexp[], vals: Sexp[], b: Bindings, parentInEllipsis: boolean): MatchResult {
  // classic recursive descent with ellipsis: (p ... rest)
  function go(pi: number, vi: number, b0: Bindings): MatchResult {
    // done
    if (pi === pats.length && vi === vals.length) return { ok: true, bindings: b0 };
    if (pi === pats.length) return fail("pattern ended early");

    // ellipsis form: pats[pi], pats[pi+1] == Sym("...")
    const p = pats[pi]!;
    const p2 = pats[pi + 1];
    if (p2 && p2.tag === "Sym" && p2.name === "...") {
      const rest = pats.slice(pi + 2);

      // Extract all pattern variables from p to initialize them
      const varsInPattern = extractPatternVars(p);

      // try k repetitions, backtracking
      for (let k = 0; k <= (vals.length - vi); k++) {
        const bTry = cloneBindings(b0);

        // Initialize all pattern vars to empty lists if k=0
        // (they will be accumulated during matching if k>0)
        for (const varName of varsInPattern) {
          if (!bTry.has(varName)) {
            bTry.set(varName, { tag: "List", items: [] });
          }
        }

        // match p repeated k times against vals[vi .. vi+k)
        let okRep = true;
        for (let j = 0; j < k; j++) {
          const r1 = match(p, vals[vi + j]!, bTry, /*inEllipsis*/ true);
          if (!r1.ok) { okRep = false; break; }
        }
        if (!okRep) continue;

        // then match rest against remainder (use parentInEllipsis for continuity)
        const r2 = matchListWithContext(rest, vals.slice(vi + k), bTry, parentInEllipsis);
        if (r2.ok) return r2;
      }

      return fail("ellipsis backtracking exhausted");
    }

    // normal element - propagate parent ellipsis context
    if (vi >= vals.length) return fail("value list ended early");
    const r = match(p, vals[vi]!, b0, /*inEllipsis*/ parentInEllipsis);
    if (!r.ok) return r;
    return go(pi + 1, vi + 1, r.bindings);
  }

  return go(0, 0, b);
}

/**
 * Extract all pattern variable names (e.g., ?x -> "x") from a pattern.
 */
function extractPatternVars(p: Sexp): string[] {
  const vars: string[] = [];

  function walk(s: Sexp): void {
    if (s.tag === "Sym" && s.name.startsWith("?") && s.name.length > 1) {
      vars.push(s.name.slice(1));
    } else if (s.tag === "List") {
      for (const item of s.items) {
        // Skip the ellipsis symbol itself
        if (item.tag === "Sym" && item.name === "...") continue;
        walk(item);
      }
    }
  }

  walk(p);
  return vars;
}

function bindVar(name: string, v: Sexp, b: Bindings, inEllipsis: boolean): MatchResult {
  const existing = b.get(name);

  if (!existing) {
    // If we're inside ellipsis, accumulate as a list
    if (inEllipsis) {
      b.set(name, { tag: "List", items: [v] });
    } else {
      b.set(name, v);
    }
    return { ok: true, bindings: b };
  }

  // Existing binding - check if it's a list (for ellipsis accumulation)
  if (existing.tag === "List") {
    if (inEllipsis) {
      // Inside ellipsis: append to the list
      existing.items.push(v);
      return { ok: true, bindings: b };
    }

    // Outside ellipsis with an existing list binding
    // This happens when a var was used in an ellipsis earlier but now used as scalar
    if (existing.items.length !== 1) {
      return fail(`var ?${name} bound to repeated list, used as scalar`);
    }
    if (!sexpEq(existing.items[0]!, v)) {
      return fail(`var ?${name} mismatch`);
    }
    return { ok: true, bindings: b };
  }

  // Scalar binding
  if (inEllipsis) {
    // Upgrade scalar -> list (first occurrence + new)
    b.set(name, { tag: "List", items: [existing, v] });
    return { ok: true, bindings: b };
  }

  if (!sexpEq(existing, v)) return fail(`var ?${name} mismatch`);
  return { ok: true, bindings: b };
}

function cloneBindings(b: Bindings): Bindings {
  const out = new Map<string, Sexp>();
  for (const [k, v] of b.entries()) {
    // Deep-copy only lists (so ellipsis append doesn't mutate other branches)
    if (v.tag === "List") out.set(k, { tag: "List", items: [...v.items] });
    else out.set(k, v);
  }
  return out;
}

function fail(reason: string): MatchResult {
  return { ok: false, reason };
}

// Re-export for convenience
export { sexpToString } from "./sexp";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/sexp/sexp.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/sexp/sexp.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-19.md
// S-expression parser, printer, and structural equality

export type Sexp =
  | { tag: "Sym"; name: string }
  | { tag: "Num"; n: number }
  | { tag: "Str"; s: string }
  | { tag: "Bool"; b: boolean }
  | { tag: "List"; items: Sexp[] };

export function sym(name: string): Sexp { return { tag: "Sym", name }; }
export function num(n: number): Sexp { return { tag: "Num", n }; }
export function str(s: string): Sexp { return { tag: "Str", s }; }
export function bool(b: boolean): Sexp { return { tag: "Bool", b }; }
export function list(items: Sexp[]): Sexp { return { tag: "List", items }; }

export function sexpEq(a: Sexp, b: Sexp): boolean {
  if (a.tag !== b.tag) return false;
  switch (a.tag) {
    case "Sym": return a.name === (b as typeof a).name;
    case "Num": return a.n === (b as typeof a).n;
    case "Str": return a.s === (b as typeof a).s;
    case "Bool": return a.b === (b as typeof a).b;
    case "List": {
      const aa = a.items, bb = (b as typeof a).items;
      if (aa.length !== bb.length) return false;
      for (let i = 0; i < aa.length; i++) if (!sexpEq(aa[i]!, bb[i]!)) return false;
      return true;
    }
  }
}

export function sexpToString(x: Sexp): string {
  switch (x.tag) {
    case "Sym": return x.name;
    case "Num": return Number.isFinite(x.n) ? String(x.n) : "nan";
    case "Str": return JSON.stringify(x.s);
    case "Bool": return x.b ? "#t" : "#f";
    case "List": {
      // Pretty-print quote sugar when possible
      if (x.items.length === 2 && x.items[0]?.tag === "Sym" && x.items[0].name === "quote") {
        return `'${sexpToString(x.items[1]!)}`;
      }
      return `(${x.items.map(sexpToString).join(" ")})`;
    }
  }
}

// ----- Parser -----

type Tok =
  | { tag: "LP" }
  | { tag: "RP" }
  | { tag: "QUOTE" }
  | { tag: "STR"; s: string }
  | { tag: "ATOM"; s: string };

export function parseSexp(src: string): Sexp {
  const toks = tokenize(src);
  let i = 0;

  function peek(): Tok | undefined { return toks[i]; }
  function take(): Tok {
    const t = toks[i];
    if (!t) throw new Error("unexpected EOF");
    i++;
    return t;
  }

  function parseOne(): Sexp {
    const t = take();
    if (t.tag === "LP") {
      const items: Sexp[] = [];
      while (true) {
        const p = peek();
        if (!p) throw new Error("unterminated list");
        if (p.tag === "RP") { take(); break; }
        items.push(parseOne());
      }
      return list(items);
    }
    if (t.tag === "RP") throw new Error("unexpected ')'");
    if (t.tag === "QUOTE") {
      const inner = parseOne();
      return list([sym("quote"), inner]);
    }
    if (t.tag === "STR") return str(t.s);

    // ATOM
    return atomToSexp(t.s);
  }

  const out = parseOne();
  if (i !== toks.length) throw new Error("trailing tokens after first expression");
  return out;
}

function atomToSexp(a: string): Sexp {
  if (a === "#t" || a === "true") return bool(true);
  if (a === "#f" || a === "false") return bool(false);

  // Number (int or float)
  if (/^[+-]?\d+(\.\d+)?$/.test(a)) return num(Number(a));

  // Symbol
  return sym(a);
}

function tokenize(src: string): Tok[] {
  const out: Tok[] = [];
  let i = 0;

  function isWS(c: string) { return c === " " || c === "\t" || c === "\n" || c === "\r"; }

  while (i < src.length) {
    const c = src[i]!;
    // Skip whitespace
    if (isWS(c)) { i++; continue; }

    // Comments ;... to end of line
    if (c === ";") {
      while (i < src.length && src[i] !== "\n") i++;
      continue;
    }

    if (c === "(") { out.push({ tag: "LP" }); i++; continue; }
    if (c === ")") { out.push({ tag: "RP" }); i++; continue; }
    if (c === "'") { out.push({ tag: "QUOTE" }); i++; continue; }

    // String
    if (c === "\"") {
      i++;
      let s = "";
      while (i < src.length) {
        const d = src[i]!;
        if (d === "\"") { i++; break; }
        if (d === "\\") {
          i++;
          if (i >= src.length) throw new Error("unterminated escape");
          const e = src[i]!;
          if (e === "n") s += "\n";
          else if (e === "t") s += "\t";
          else if (e === "r") s += "\r";
          else if (e === "\"") s += "\"";
          else if (e === "\\") s += "\\";
          else s += e;
          i++;
          continue;
        }
        s += d;
        i++;
      }
      out.push({ tag: "STR", s });
      continue;
    }

    // Atom
    let a = "";
    while (i < src.length) {
      const d = src[i]!;
      if (isWS(d) || d === "(" || d === ")" || d === "'" || d === ";" ) break;
      a += d;
      i++;
    }
    if (a.length === 0) throw new Error("lexer error");
    out.push({ tag: "ATOM", s: a });
  }

  return out;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/budget.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { BudgetVal } from "./types";
import { asNumber } from "./common";

export function makeBudget(tokens: number, calls: number, time: number): BudgetVal {
  return { tag: "Budget", tokens, calls, time };
}

export function asBudget(v: any): BudgetVal {
  if (v && v.tag === "Budget") return v as BudgetVal;
  throw new Error("expected Budget");
}

export function budgetSplit(budget: BudgetVal, n: number): BudgetVal[] {
  if (n <= 0) {
    throw new Error("Cannot split into zero or negative parts");
  }
  const tokensEach = Math.floor(budget.tokens / n);
  const callsEach = Math.floor(budget.calls / n);
  const timeEach = Math.floor(budget.time / n);
  return Array.from({ length: n }, () => ({
    tag: "Budget",
    tokens: tokensEach,
    calls: callsEach,
    time: timeEach,
  }));
}

export function budgetAllocate(budget: BudgetVal, weights: number[]): BudgetVal[] {
  if (weights.length === 0) {
    throw new Error("Weights list cannot be empty");
  }
  const total = weights.reduce((a, b) => a + b, 0);
  if (total <= 0) {
    throw new Error("Weights must sum to a positive value");
  }

  return weights.map(w => ({
    tag: "Budget",
    tokens: Math.floor(budget.tokens * (w / total)),
    calls: Math.floor(budget.calls * (w / total)),
    time: Math.floor(budget.time * (w / total)),
  }));
}

export function budgetFromArgs(args: any[]): BudgetVal {
  const tokens = asNumber(args[0], "tokens");
  const calls = asNumber(args[1], "calls");
  const time = asNumber(args[2], "time");
  return makeBudget(tokens, calls, time);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/combinators.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { SolverVal, BudgetVal, ResultVal, CostEstimateVal } from "./types";
import type { Val } from "../eval/values";
import type { State } from "../eval/machine";
import type { ApplyFn } from "./common";
import { budgetSplit } from "./budget";
import { makeResultVal } from "./common";

type SolverRun = { results: ResultVal[]; state: State };

function firstResult(run: SolverRun): ResultVal | undefined {
  return run.results[0];
}

function cloneState(state: State): State {
  return { ...state, store: state.store.snapshot() };
}

function defaultEstimate(name: string): CostEstimateVal {
  return { tag: "CostEstimate", minCost: 0, maxCost: 0, expectedCost: 0, confidence: 1 };
}

export function composeSequential(solvers: SolverVal[], apply: ApplyFn): SolverVal {
  const name = `sequential(${solvers.map(s => s.name).join(", ")})`;
  return {
    tag: "Solver",
    name,
    solve: (problem: Val, budget: BudgetVal, state: State): SolverRun => {
      if (solvers.length === 0) {
        return { results: [makeResultVal("success", problem, undefined, undefined, 0)], state };
      }
      const parts = budgetSplit(budget, solvers.length);
      let current = problem;
      let currentState = state;

      for (let i = 0; i < solvers.length; i++) {
        const run = solvers[i].solve(current, parts[i], currentState, apply);
        const res = firstResult(run);
        currentState = run.state;
        if (!res || res.kind === "failure") {
          return { results: [makeResultVal("failure", undefined, undefined, `Stage ${i} failed`, 0)], state: currentState };
        }
        current = res.solution ?? current;
      }

      return { results: [makeResultVal("success", current, undefined, undefined, 0)], state: currentState };
    },
    estimate: (problem: Val, state: State): { estimate: CostEstimateVal; state: State } => {
      let min = 0, max = 0, exp = 0, conf = 1;
      for (const solver of solvers) {
        const { estimate } = solver.estimate(problem, state, apply);
        min += estimate.minCost;
        max += estimate.maxCost;
        exp += estimate.expectedCost;
        conf *= estimate.confidence;
      }
      return { estimate: { tag: "CostEstimate", minCost: min, maxCost: max, expectedCost: exp, confidence: conf }, state };
    }
  };
}

export function composeParallel(solvers: SolverVal[], apply: ApplyFn): SolverVal {
  const name = `parallel(${solvers.map(s => s.name).join(", ")})`;
  return {
    tag: "Solver",
    name,
    solve: (problem: Val, budget: BudgetVal, state: State): SolverRun => {
      if (solvers.length === 0) return { results: [], state };
      const parts = budgetSplit(budget, solvers.length);
      const all: ResultVal[] = [];
      for (let i = 0; i < solvers.length; i++) {
        const childState = cloneState(state);
        const run = solvers[i].solve(problem, parts[i], childState, apply);
        all.push(...run.results);
      }
      return { results: all, state };
    },
    estimate: (problem: Val, state: State): { estimate: CostEstimateVal; state: State } => {
      if (solvers.length === 0) return { estimate: defaultEstimate(name), state };
      const estimates = solvers.map(s => s.estimate(problem, state, apply).estimate);
      return {
        estimate: {
          tag: "CostEstimate",
          minCost: Math.min(...estimates.map(e => e.minCost)),
          maxCost: Math.max(...estimates.map(e => e.maxCost)),
          expectedCost: estimates.reduce((a, e) => a + e.expectedCost, 0) / estimates.length,
          confidence: Math.max(...estimates.map(e => e.confidence)),
        },
        state,
      };
    }
  };
}

export function composeFallback(solvers: SolverVal[], apply: ApplyFn): SolverVal {
  const name = `fallback(${solvers.map(s => s.name).join(", ")})`;
  return {
    tag: "Solver",
    name,
    solve: (problem: Val, budget: BudgetVal, state: State): SolverRun => {
      const parts = budgetSplit(budget, Math.max(solvers.length, 1));
      let currentState = state;
      for (let i = 0; i < solvers.length; i++) {
        const run = solvers[i].solve(problem, parts[i], currentState, apply);
        const res = firstResult(run);
        currentState = run.state;
        if (res && res.kind !== "failure") {
          return { results: [res], state: currentState };
        }
      }
      return { results: [makeResultVal("failure", undefined, undefined, "All fallbacks failed", 0)], state: currentState };
    },
    estimate: (problem: Val, state: State): { estimate: CostEstimateVal; state: State } => {
      if (solvers.length === 0) return { estimate: defaultEstimate(name), state };
      return solvers[0].estimate(problem, state, apply);
    }
  };
}

export function composeRetry(solver: SolverVal, maxRetries: number, apply: ApplyFn): SolverVal {
  const name = `retry(${solver.name}, ${maxRetries})`;
  return {
    tag: "Solver",
    name,
    solve: (problem: Val, budget: BudgetVal, state: State): SolverRun => {
      const parts = budgetSplit(budget, Math.max(maxRetries, 1));
      let currentState = state;
      for (let i = 0; i < maxRetries; i++) {
        const run = solver.solve(problem, parts[i], currentState, apply);
        const res = firstResult(run);
        currentState = run.state;
        if (res && res.kind !== "failure") {
          return { results: [res], state: currentState };
        }
      }
      return { results: [makeResultVal("failure", undefined, undefined, `Failed after ${maxRetries} retries`, 0)], state: currentState };
    },
    estimate: (problem: Val, state: State): { estimate: CostEstimateVal; state: State } => {
      const { estimate } = solver.estimate(problem, state, apply);
      return { estimate: { ...estimate, maxCost: estimate.maxCost * Math.max(1, maxRetries) }, state };
    }
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/common.ts
// ═══════════════════════════════════════════════════════════════════════════

import { stepOnce } from "../eval/machineStep";
import type { State, StepOutcome } from "../eval/machine";
import type { Val } from "../eval/values";
import type { ResultVal } from "./types";

export type ApplyFn = (proc: Val, args: Val[], state: State) => State | StepOutcome;

export function asNumber(v: Val, name = "number"): number {
  if (v.tag === "Num") return v.n;
  throw new Error(`expected ${name}`);
}

export function asString(v: Val, name = "string"): string {
  if (v.tag === "Str") return v.s;
  if (v.tag === "Sym") return v.name;
  throw new Error(`expected ${name}`);
}

export function isTruthy(v: Val): boolean {
  if (v.tag === "Bool") return v.b;
  if (v.tag === "Unit") return false;
  return true;
}

/**
 * Evaluate a procedure to a value, stopping on the first effect.
 * Effects are not handled here to keep solver helpers deterministic;
 * callers should avoid effectful solver functions.
 */
export function evalProcedureToValue(
  proc: Val,
  args: Val[],
  state: State,
  apply: ApplyFn
): { value: Val; state: State } {
  const first = apply(proc, args, state);
  let currentState: State;

  if (!first) {
    // Defensive: treat missing return as no state change.
    currentState = state;
  } else if ((first as StepOutcome).tag === "Op") {
    throw new Error("solver evaluation emitted an effect; unsupported in solver helpers");
  } else if ((first as StepOutcome).tag === "Done") {
    const done = first as Extract<StepOutcome, { tag: "Done" }>;
    return { value: done.value, state: done.state ?? state };
  } else if ((first as StepOutcome).tag === "State") {
    currentState = (first as Extract<StepOutcome, { tag: "State" }>).state;
  } else {
    currentState = first as State;
  }

  while (true) {
    const step = stepOnce(currentState);
    if (step.tag === "State") {
      currentState = step.state;
      continue;
    }
    if (step.tag === "Done") {
      return { value: step.value, state: step.state ?? currentState };
    }
    if (step.tag === "Op") {
      throw new Error("solver evaluation emitted an effect; unsupported in solver helpers");
    }
  }
}

export function makeResultVal(
  kind: "success" | "partial" | "failure" | string,
  solution?: Val,
  remaining?: Val,
  reason?: string,
  cost = 0
): ResultVal {
  return {
    tag: "Result",
    kind,
    solution,
    remaining,
    reason,
    cost,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/facts.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FactStoreVal } from "./types";
import type { Val } from "../eval/values";

function valEquals(a: Val, b: Val): boolean {
  if (a.tag !== b.tag) return false;
  switch (a.tag) {
    case "Num": return (b as any).n === a.n;
    case "Str": return (b as any).s === a.s;
    case "Bool": return (b as any).b === a.b;
    case "Sym": return (b as any).name === a.name;
    case "Unit": return true;
    case "Vector": {
      const bb = b as any;
      if (bb.items.length !== a.items.length) return false;
      for (let i = 0; i < a.items.length; i++) {
        if (!valEquals(a.items[i], bb.items[i])) return false;
      }
      return true;
    }
    default:
      return JSON.stringify(a) === JSON.stringify(b);
  }
}

export function createFactStore(): FactStoreVal {
  return { tag: "FactStore", facts: new Map() };
}

export function asFactStore(v: any): FactStoreVal {
  if (v && v.tag === "FactStore") return v as FactStoreVal;
  throw new Error("expected FactStore");
}

export function assertFact(store: FactStoreVal, key: string, value: Val): FactStoreVal {
  const facts = store.facts as Map<string, Val>;
  if (facts.has(key)) {
    const existing = facts.get(key)!;
    if (!valEquals(existing, value)) {
      throw new Error(`Fact ${key} already exists with different value`);
    }
    return store;
  }
  const newFacts = new Map(facts);
  newFacts.set(key, value);
  return { tag: "FactStore", facts: newFacts };
}

export function queryFact(store: FactStoreVal, key: string): Val | undefined {
  const facts = store.facts as Map<string, Val>;
  return facts.get(key);
}

export function queryFactsByPattern(store: FactStoreVal, pattern: string): Array<[string, Val]> {
  let regex: RegExp;
  try {
    regex = new RegExp(pattern);
  } catch (e) {
    throw new Error(`Invalid regex pattern: ${pattern}`);
  }
  const results: Array<[string, Val]> = [];
  const facts = store.facts as Map<string, Val>;
  for (const [k, v] of facts.entries()) {
    if (regex.test(k)) {
      results.push([k, v]);
    }
  }
  return results;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/fixpoint.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { State } from "../eval/machine";
import type { Val } from "../eval/values";
import type { ApplyFn } from "./common";
import { asString, evalProcedureToValue, isTruthy, makeResultVal } from "./common";

export function fixpoint(
  initial: Val,
  stepFn: Val,
  equalFn: Val,
  maxIterations: number,
  state: State,
  apply: ApplyFn
) {
  if (maxIterations < 0) {
    throw new Error("Max iterations must be non-negative");
  }

  let current = initial;
  let currentState = state;

  for (let i = 0; i < maxIterations; i++) {
    const { value: next, state: afterStep } = evalProcedureToValue(stepFn, [current], currentState, apply);
    currentState = afterStep;
    const { value: isEqual, state: afterEq } = evalProcedureToValue(equalFn, [current, next], currentState, apply);
    currentState = afterEq;

    if (isTruthy(isEqual)) {
      return makeResultVal("success", next, undefined, undefined, i + 1);
    }

    current = next;
  }

  return makeResultVal("partial", current, undefined, `Did not converge in ${maxIterations} iterations`, maxIterations);
}

export function fixpointWithCycleDetection(
  initial: Val,
  stepFn: Val,
  hashFn: Val,
  maxIterations: number,
  state: State,
  apply: ApplyFn
) {
  if (maxIterations < 0) {
    throw new Error("Max iterations must be non-negative");
  }

  let current = initial;
  let currentState = state;
  const seen = new Set<string>();

  for (let i = 0; i < maxIterations; i++) {
    const { value: hashVal, state: afterHash } = evalProcedureToValue(hashFn, [current], currentState, apply);
    currentState = afterHash;
    const hash = asString(hashVal, "hash");

    if (seen.has(hash)) {
      return makeResultVal("failure", undefined, undefined, `Cycle detected at iteration ${i}`, i);
    }
    seen.add(hash);

    const { value: next, state: afterStep } = evalProcedureToValue(stepFn, [current], currentState, apply);
    currentState = afterStep;

    const { value: nextHashVal, state: afterNextHash } = evalProcedureToValue(hashFn, [next], currentState, apply);
    currentState = afterNextHash;
    const nextHash = asString(nextHashVal, "hash");

    if (nextHash === hash) {
      return makeResultVal("success", next, undefined, undefined, i + 1);
    }

    current = next;
  }

  return makeResultVal("partial", current, undefined, `Max iterations (${maxIterations}) reached without convergence or cycle`, maxIterations);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/prims.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { State, StepOutcome } from "../eval/machine";
import type { Val } from "../eval/values";
import { VFalse, VTrue } from "../eval/values";
import { envSet } from "../eval/env";
import { asString, asNumber, evalProcedureToValue, makeResultVal } from "./common";
import type { SolverVal, CostEstimateVal, ResultVal, BudgetVal, FactStoreVal } from "./types";
import { isSolver } from "./types";
import { makeBudget, budgetSplit, budgetAllocate, asBudget, budgetFromArgs } from "./budget";
import { composeSequential, composeParallel, composeFallback, composeRetry } from "./combinators";
import { repairUntilValid } from "./repair";
import { fixpoint, fixpointWithCycleDetection } from "./fixpoint";
import { createFactStore, assertFact, queryFact, queryFactsByPattern, asFactStore } from "./facts";

export type SolverPrimHelpers = {
  applyProcedure: (proc: Val, args: Val[], state: State) => State | StepOutcome;
  ensureArity: (proc: Val, expected: number, name: string) => void;
  isCallable: (proc: Val) => proc is Val;
  emitAmb: (choices: Val[], state: State) => StepOutcome;
};

function asSolver(val: Val): SolverVal {
  if (isSolver(val)) return val;
  throw new Error("expected solver");
}

function asList(v: Val): Val[] {
  const out: Val[] = [];
  let cur: Val = v;
  while (cur.tag === "Vector" && cur.items.length === 2) {
    out.push(cur.items[0]);
    cur = cur.items[1];
  }
  if (cur.tag !== "Unit") {
    throw new Error("expected proper list");
  }
  return out;
}

function listFromArray(items: Val[]): Val {
  let result: Val = { tag: "Unit" };
  for (let i = items.length - 1; i >= 0; i--) {
    result = { tag: "Vector", items: [items[i], result] };
  }
  return result;
}

function makeEstimate(minCost: number, maxCost: number, expectedCost: number, confidence: number): CostEstimateVal {
  return { tag: "CostEstimate", minCost, maxCost, expectedCost, confidence };
}

let resultThunkCounter = 0;
function wrapResultsAsThunks(results: ResultVal[], baseState: State): { thunks: Val[]; state: State } {
  let workingState = baseState;
  const thunks: Val[] = [];

  for (const res of results) {
    const binding = `__solver_result_${resultThunkCounter++}`;
    const [store2, addr] = workingState.store.alloc(res as Val);
    const envForThunk = envSet(workingState.env, binding, addr);
    const thunk: Val = { tag: "Closure", params: [], body: { tag: "Var", name: binding }, env: envForThunk };
    thunks.push(thunk);
    workingState = { ...workingState, store: store2 };
  }

  return { thunks, state: workingState };
}

export function registerSolverPrims(def: (name: string, v: Val) => void, helpers: SolverPrimHelpers): void {
  // make-solver: wraps callable solve/estimate into a Solver value
  def("make-solver", {
    tag: "Native",
    name: "make-solver",
    arity: 3,
    fn: (args, state) => {
      const [nameVal, solveFn, estimateFn] = args;
      if (!helpers.isCallable(solveFn)) throw new Error("solver solve function must be a procedure");
      if (!helpers.isCallable(estimateFn)) throw new Error("solver estimate function must be a procedure");
      const solver: SolverVal = {
        tag: "Solver",
        name: asString(nameVal, "solver name"),
        solve: (problem: Val, budget: BudgetVal, st: State) => {
          const { value, state: nextState } = evalProcedureToValue(solveFn, [problem, budget], st, helpers.applyProcedure);
          const result = (value as ResultVal).tag === "Result" ? (value as ResultVal) : makeResultVal("success", value, undefined, undefined, 0);
          return { results: [result], state: nextState };
        },
        estimate: (problem: Val, st: State) => {
          const { value, state: nextState } = evalProcedureToValue(estimateFn, [problem], st, helpers.applyProcedure);
          if ((value as any).tag !== "CostEstimate") {
            throw new Error("solver estimate must return CostEstimate");
          }
          return { estimate: value as CostEstimateVal, state: nextState };
        },
      };
      return { ...state, control: { tag: "Val", v: solver } };
    },
  });

  def("solver?", {
    tag: "Native",
    name: "solver?",
    arity: 1,
    fn: (args, state) => ({ ...state, control: { tag: "Val", v: isSolver(args[0]) ? VTrue : VFalse } }),
  });

  def("solver-name", {
    tag: "Native",
    name: "solver-name",
    arity: 1,
    fn: (args, state) => {
      const solver = asSolver(args[0]);
      return { ...state, control: { tag: "Val", v: { tag: "Sym", name: solver.name } } };
    },
  });

  def("solver-estimate", {
    tag: "Native",
    name: "solver-estimate",
    arity: 2,
    fn: (args, state) => {
      const solver = asSolver(args[0]);
      const { estimate } = solver.estimate(args[1], state, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: estimate } };
    },
  });

  def("solver-solve", {
    tag: "Native",
    name: "solver-solve",
    arity: 3,
    fn: (args, state) => {
      const solver = asSolver(args[0]);
      const problem = args[1];
      const budget = asBudget(args[2]);
      const { results, state: nextState } = solver.solve(problem, budget, state, helpers.applyProcedure);
      if (results.length === 0) {
        const failure = makeResultVal("failure", undefined, undefined, "No results", 0);
        return { ...nextState, control: { tag: "Val", v: failure } };
      }
      if (results.length === 1) {
        return { ...nextState, control: { tag: "Val", v: results[0] } };
      }
      const { thunks, state: branchState } = wrapResultsAsThunks(results, nextState);
      return helpers.emitAmb(thunks, branchState);
    },
  });

  // Result / estimate constructors
  def("make-result", {
    tag: "Native",
    name: "make-result",
    arity: "variadic",
    fn: (args, state) => {
      if (args.length < 2) throw new Error("make-result: expected at least kind and solution");
      const kindVal = args[0];
      const kind = kindVal.tag === "Sym" ? kindVal.name : asString(kindVal, "result kind");
      const solution = args[1];
      let remaining: Val | undefined;
      let reason: string | undefined;
      let cost = 0;
      if (kind === "failure") {
        reason = args.length >= 3 ? asString(args[2], "reason") : undefined;
        cost = args.length >= 4 ? asNumber(args[3], "cost") : 0;
      } else if (kind === "partial") {
        remaining = args.length >= 3 ? args[2] : undefined;
        cost = args.length >= 4 ? asNumber(args[3], "cost") : 0;
      } else {
        cost = args.length >= 3 ? asNumber(args[2], "cost") : 0;
      }
      const res = makeResultVal(kind, solution, remaining, reason, cost);
      return { ...state, control: { tag: "Val", v: res } };
    },
  });

  def("make-estimate", {
    tag: "Native",
    name: "make-estimate",
    arity: 4,
    fn: (args, state) => {
      const est = makeEstimate(asNumber(args[0], "minCost"), asNumber(args[1], "maxCost"), asNumber(args[2], "expectedCost"), asNumber(args[3], "confidence"));
      return { ...state, control: { tag: "Val", v: est } };
    },
  });

  // Budget primitives
  def("make-budget", {
    tag: "Native",
    name: "make-budget",
    arity: 3,
    fn: (args, state) => ({ ...state, control: { tag: "Val", v: budgetFromArgs(args) } }),
  });

  def("budget-split", {
    tag: "Native",
    name: "budget-split",
    arity: 2,
    fn: (args, state) => {
      const budget = asBudget(args[0]);
      const n = asNumber(args[1], "parts");
      const parts = budgetSplit(budget, n);
      return { ...state, control: { tag: "Val", v: listFromArray(parts as Val[]) } };
    },
  });

  def("budget-allocate", {
    tag: "Native",
    name: "budget-allocate",
    arity: 2,
    fn: (args, state) => {
      const budget = asBudget(args[0]);
      const weights = asList(args[1]).map(v => asNumber(v, "weight"));
      const parts = budgetAllocate(budget, weights);
      return { ...state, control: { tag: "Val", v: listFromArray(parts as Val[]) } };
    },
  });

  // Combinators
  def("compose-sequential", {
    tag: "Native",
    name: "compose-sequential",
    arity: 1,
    fn: (args, state) => {
      const solvers = asList(args[0]).map(asSolver);
      const composed = composeSequential(solvers, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: composed } };
    },
  });

  def("compose-parallel", {
    tag: "Native",
    name: "compose-parallel",
    arity: 1,
    fn: (args, state) => {
      const solvers = asList(args[0]).map(asSolver);
      const composed = composeParallel(solvers, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: composed } };
    },
  });

  def("compose-fallback", {
    tag: "Native",
    name: "compose-fallback",
    arity: 1,
    fn: (args, state) => {
      const solvers = asList(args[0]).map(asSolver);
      const composed = composeFallback(solvers, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: composed } };
    },
  });

  def("compose-retry", {
    tag: "Native",
    name: "compose-retry",
    arity: 2,
    fn: (args, state) => {
      const solver = asSolver(args[0]);
      const retries = asNumber(args[1], "maxRetries");
      const composed = composeRetry(solver, retries, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: composed } };
    },
  });

  // Repair / fixpoint
  def("repair-until-valid", {
    tag: "Native",
    name: "repair-until-valid",
    arity: 4,
    fn: (args, state) => {
      const [initial, validator, repairFn, maxIterVal] = args;
      if (!helpers.isCallable(validator)) throw new Error("Validator must be a procedure");
      if (!helpers.isCallable(repairFn)) throw new Error("Repair function must be a procedure");
      const maxIter = asNumber(maxIterVal, "maxIterations");
      const result = repairUntilValid(initial, validator, repairFn, maxIter, state, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: result } };
    },
  });

  def("fixpoint", {
    tag: "Native",
    name: "fixpoint",
    arity: 4,
    fn: (args, state) => {
      const [initial, stepFn, equalFn, maxIterVal] = args;
      if (!helpers.isCallable(stepFn)) throw new Error("Step function must be a procedure");
      if (!helpers.isCallable(equalFn)) throw new Error("Equality function must be a procedure");
      const maxIter = asNumber(maxIterVal, "maxIterations");
      const result = fixpoint(initial, stepFn, equalFn, maxIter, state, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: result } };
    },
  });

  def("fixpoint-detect-cycle", {
    tag: "Native",
    name: "fixpoint-detect-cycle",
    arity: 4,
    fn: (args, state) => {
      const [initial, stepFn, hashFn, maxIterVal] = args;
      if (!helpers.isCallable(stepFn)) throw new Error("Step function must be a procedure");
      if (!helpers.isCallable(hashFn)) throw new Error("Hash function must be a procedure");
      const maxIter = asNumber(maxIterVal, "maxIterations");
      const result = fixpointWithCycleDetection(initial, stepFn, hashFn, maxIter, state, helpers.applyProcedure);
      return { ...state, control: { tag: "Val", v: result } };
    },
  });

  // Fact store
  def("make-fact-store", {
    tag: "Native",
    name: "make-fact-store",
    arity: 0,
    fn: (_args, state) => ({ ...state, control: { tag: "Val", v: createFactStore() as Val } }),
  });

  def("fact-store?", {
    tag: "Native",
    name: "fact-store?",
    arity: 1,
    fn: (args, state) => ({ ...state, control: { tag: "Val", v: (args[0] as FactStoreVal)?.tag === "FactStore" ? VTrue : VFalse } }),
  });

  def("assert-fact", {
    tag: "Native",
    name: "assert-fact",
    arity: 3,
    fn: (args, state) => {
      const store = asFactStore(args[0]);
      const key = asString(args[1], "key");
      const value = args[2];
      return { ...state, control: { tag: "Val", v: assertFact(store, key, value) as Val } };
    },
  });

  def("query-fact", {
    tag: "Native",
    name: "query-fact",
    arity: 2,
    fn: (args, state) => {
      const store = asFactStore(args[0]);
      const key = asString(args[1], "key");
      const result = queryFact(store, key);
      return { ...state, control: { tag: "Val", v: result ?? VFalse } };
    },
  });

  def("query-facts", {
    tag: "Native",
    name: "query-facts",
    arity: 2,
    fn: (args, state) => {
      const store = asFactStore(args[0]);
      const pattern = asString(args[1], "pattern");
      const results = queryFactsByPattern(store, pattern);
      const pairs = results.map(([k, v]) => listFromArray([{ tag: "Str", s: k } as Val, v]));
      return { ...state, control: { tag: "Val", v: listFromArray(pairs as Val[]) } };
    },
  });
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/repair.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { State } from "../eval/machine";
import type { Val } from "../eval/values";
import type { ApplyFn } from "./common";
import { evalProcedureToValue, isTruthy, makeResultVal } from "./common";
import type { ResultVal } from "./types";

export function repairUntilValid(
  initial: Val,
  validator: Val,
  repairFn: Val,
  maxIterations: number,
  state: State,
  apply: ApplyFn
): ResultVal {
  if (maxIterations < 0) {
    throw new Error("Max iterations must be non-negative");
  }

  let current = initial;
  let currentState = state;

  for (let i = 0; i < maxIterations; i++) {
    const { value: isValidVal, state: afterCheck } = evalProcedureToValue(validator, [current], currentState, apply);
    currentState = afterCheck;

    if (isTruthy(isValidVal)) {
      return makeResultVal("success", current, undefined, undefined, i);
    }

    const { value: repaired, state: afterRepair } = evalProcedureToValue(repairFn, [current], currentState, apply);
    currentState = afterRepair;

    if ((repaired as any)?.tag === "Result") {
      const res = repaired as ResultVal;
      if (res.kind === "failure") {
        return res;
      }
      current = res.solution ?? current;
      continue;
    }

    current = repaired;
  }

  return makeResultVal("partial", current, undefined, `Max iterations (${maxIterations}) reached`, maxIterations);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/solver/types.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Val, SolverVal, ResultVal, CostEstimateVal, BudgetVal, FactStoreVal } from "../eval/values";

export type { SolverVal, ResultVal, CostEstimateVal, BudgetVal, FactStoreVal } from "../eval/values";

export function isSolver(val: Val): val is SolverVal {
  return (val as any)?.tag === "Solver";
}

export function isResult(val: Val): val is ResultVal {
  return (val as any)?.tag === "Result";
}

export function isBudget(val: Val): val is BudgetVal {
  return (val as any)?.tag === "Budget";
}

export function isFactStore(val: Val): val is FactStoreVal {
  return (val as any)?.tag === "FactStore";
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/stream/analysis.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/stream/analysis.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 16: Stream analysis - strictness, productivity, fusion, space leaks

import type { Val, PromiseId } from "../eval/values";
import { VUnit } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type {
  StreamContext,
  StrictnessInfo,
  ProductivityInfo,
  FusionCandidate,
  SpaceLeakInfo,
  StreamAnalysisResult,
  PromiseEvent,
} from "./types";
import { createStreamContext } from "./types";
import {
  countTotalForceStarts,
  countCacheHits,
  getTotalOracleCallsFromEvents,
  findMultiForced,
  getAllPromiseIds,
  getForcedPromiseIds,
  getUnforcedPromiseIds,
} from "./promise";
import {
  isStreamNull,
  streamCar,
  streamCdr,
  isStream,
  forceN,
} from "./stream";

// ─────────────────────────────────────────────────────────────────
// Strictness Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Analyze strictness based on current context state.
 *
 * Call this after forcing a stream to see how many elements were demanded vs forced.
 */
export function analyzeStrictness(
  ctx: StreamContext,
  demandedCount: number
): StrictnessInfo {
  const forceStarts = countTotalForceStarts(ctx);
  const cacheHits = countCacheHits(ctx);
  const oracleCalls = ctx.oracleCallCount;
  const multiForced = findMultiForced(ctx);

  // Check if we forced more than demanded (forced ahead)
  const forcedAhead = forceStarts > demandedCount;

  return {
    demandedCount,
    forcedCount: forceStarts,
    forcedAhead,
    multiForced,
    oracleCalls,
  };
}

// ─────────────────────────────────────────────────────────────────
// Productivity Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Analyze productivity of a stream.
 *
 * Productivity = "forcing the next cell terminates within fuel"
 */
export function analyzeProductivity(
  ctx: StreamContext,
  stream: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number },
  fuel?: number
): ProductivityInfo {
  // Save original fuel
  const originalFuel = ctx.fuel;
  const maxFuel = fuel ?? ctx.config.maxFuel;
  ctx.fuel = maxFuel;

  let producedCount = 0;
  let current = stream;
  let productive = true;
  let reason: string | undefined;

  try {
    while (!isStreamNull(current) && ctx.fuel > 0) {
      // Try to access the head (should be immediate)
      streamCar(current);
      producedCount++;

      // Try to force the tail (this is where non-productivity shows)
      const fuelBefore = ctx.fuel;
      current = streamCdr(ctx, current, evaluator);

      // If we used all fuel on one step, might be non-productive
      if (ctx.fuel <= 0 && fuelBefore > 0 && !isStreamNull(current)) {
        productive = false;
        reason = "Tail force consumed all remaining fuel";
        break;
      }
    }
  } catch (e) {
    productive = false;
    reason = e instanceof Error ? e.message : "Unknown error during productivity check";
  }

  const fuelRemaining = Math.max(0, ctx.fuel);
  ctx.fuel = originalFuel; // Restore fuel

  return {
    productive,
    producedCount,
    fuelRemaining,
    reason,
  };
}

// ─────────────────────────────────────────────────────────────────
// Fusion / Deforestation Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Identify fusion candidates in a stream pipeline.
 */
export function identifyFusionCandidates(
  ctx: StreamContext,
  pipelineDescription: Val
): FusionCandidate[] {
  const candidates: FusionCandidate[] = [];

  // Look for CSE opportunities
  const cseCandidate = findCSEOpportunity(ctx);
  if (cseCandidate) {
    candidates.push(cseCandidate);
  }

  // Look for map-map fusion
  const mapMapCandidate = findMapMapFusion(pipelineDescription);
  if (mapMapCandidate) {
    candidates.push(mapMapCandidate);
  }

  // Look for filter-map fusion
  const filterMapCandidate = findFilterMapFusion(pipelineDescription);
  if (filterMapCandidate) {
    candidates.push(filterMapCandidate);
  }

  return candidates;
}

/**
 * Find common subexpression elimination opportunities.
 */
function findCSEOpportunity(ctx: StreamContext): FusionCandidate | null {
  const oracleCalls = new Map<string, number>();

  for (const event of ctx.events) {
    if (event.tag === "PromiseForceDone" && event.oracleCalls > 0) {
      const key = event.id.split("-")[0];
      oracleCalls.set(key, (oracleCalls.get(key) ?? 0) + 1);
    }
  }

  for (const [key, count] of oracleCalls) {
    if (count > 1) {
      return {
        id: `cse-${key}`,
        kind: "cse",
        description: `Operation '${key}' called ${count} times - consider memoizing`,
        estimatedSaving: count - 1,
        pattern: { tag: "Sym", name: key },
        rewrite: { tag: "Sym", name: `memoized-${key}` },
        confidence: 0.7,
      };
    }
  }

  return null;
}

/**
 * Find map-map fusion opportunities.
 */
function findMapMapFusion(desc: Val): FusionCandidate | null {
  if (desc.tag === "List" && desc.elements.length >= 1) {
    const head = desc.elements[0];
    if (head.tag === "Sym" && head.name === "map-map") {
      return {
        id: "map-map-fusion",
        kind: "map-map",
        description: "Two consecutive stream-map operations can be fused",
        estimatedSaving: 1,
        pattern: desc,
        rewrite: {
          tag: "List",
          elements: [
            { tag: "Sym", name: "map" },
            { tag: "Sym", name: "composed" },
          ],
        },
        confidence: 0.9,
      };
    }
  }
  return null;
}

/**
 * Find filter-map fusion opportunities.
 */
function findFilterMapFusion(desc: Val): FusionCandidate | null {
  if (desc.tag === "List" && desc.elements.length >= 1) {
    const head = desc.elements[0];
    if (head.tag === "Sym" && head.name === "filter-map") {
      return {
        id: "filter-map-fusion",
        kind: "filter-map",
        description: "Filter after map might be fusible",
        estimatedSaving: 0.5,
        pattern: desc,
        rewrite: { tag: "Sym", name: "fused-filter-map" },
        confidence: 0.6,
      };
    }
  }
  return null;
}

/**
 * Apply a fusion rewrite.
 */
export function applyFusion(
  ctx: StreamContext,
  candidate: FusionCandidate
): Val {
  // Return the rewritten pattern
  return candidate.rewrite;
}

/**
 * Compare oracle cost with and without fusion.
 */
export function compareFusionCost(
  ctx: StreamContext,
  candidate: FusionCandidate,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): {
  originalCost: number;
  fusedCost: number;
  saving: number;
  percentSaved: number;
} {
  const originalCost = ctx.oracleCallCount;
  const estimatedSaving = candidate.estimatedSaving;
  const fusedCost = Math.max(0, originalCost - estimatedSaving);
  const saving = estimatedSaving;
  const percentSaved = originalCost > 0 ? (saving / originalCost) * 100 : 0;

  return {
    originalCost,
    fusedCost,
    saving,
    percentSaved,
  };
}

// ─────────────────────────────────────────────────────────────────
// Space Leak Detection
// ─────────────────────────────────────────────────────────────────

/**
 * Analyze potential space leaks in stream processing.
 */
export function analyzeSpaceLeaks(ctx: StreamContext): SpaceLeakInfo {
  const total = ctx.store.size;
  const forcedIds = getForcedPromiseIds(ctx);
  const unforcedIds = getUnforcedPromiseIds(ctx);

  // Calculate growth rate based on unforced vs forced ratio
  const growthRate = total > 0 ? unforcedIds.length / total : 0;

  // Long retained = unforced promises
  const longRetained = unforcedIds.slice(0, 10);

  // Determine cause and suggestion
  let cause: SpaceLeakInfo["cause"];
  let suggestion: string | undefined;
  let leakSuspected = false;

  if (unforcedIds.length > 10) {
    leakSuspected = true;
    if (growthRate > 0.5) {
      cause = "head-retention";
      suggestion = "Avoid retaining reference to stream head while traversing. Use stream-fold instead.";
    } else {
      cause = "closure-capture";
      suggestion = "Check for closures that capture stream references.";
    }
  }

  return {
    leakSuspected,
    retainedGrowthRate: growthRate,
    longRetained,
    cause,
    suggestion,
  };
}

// ─────────────────────────────────────────────────────────────────
// Event Filtering
// ─────────────────────────────────────────────────────────────────

/**
 * Get all events for a specific promise ID.
 */
export function getPromiseEventsForId(
  ctx: StreamContext,
  id: PromiseId
): PromiseEvent[] {
  return ctx.events.filter(e => {
    if ("id" in e) {
      return e.id === id;
    }
    return false;
  });
}

/**
 * Get the force timeline (all force-related events in order).
 */
export function getForceTimeline(ctx: StreamContext): PromiseEvent[] {
  return ctx.events
    .filter(e =>
      e.tag === "PromiseForceStart" ||
      e.tag === "PromiseForceDone" ||
      e.tag === "PromiseForceHit" ||
      e.tag === "PromiseForceJoin"
    )
    .sort((a, b) => a.timestamp - b.timestamp);
}

// ─────────────────────────────────────────────────────────────────
// Combined Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Run a comprehensive analysis on a stream pipeline.
 */
export function analyzeStream(
  ctx: StreamContext,
  stream: Val,
  options: {
    strictness?: boolean;
    productivity?: boolean;
    fusion?: boolean;
    spaceLeaks?: boolean;
    demandCount?: number;
    fuel?: number;
    evaluator?: (thunk: Val) => { value: Val; oracleCalls: number };
  } = {}
): StreamAnalysisResult {
  const result: StreamAnalysisResult = {
    events: ctx.events,
  };

  const demandCount = options.demandCount ?? 10;

  if (options.strictness !== false) {
    result.strictness = analyzeStrictness(ctx, demandCount);
  }

  if (options.productivity !== false) {
    result.productivity = analyzeProductivity(
      ctx,
      stream,
      options.evaluator,
      options.fuel
    );
  }

  if (options.fusion) {
    result.fusionCandidates = identifyFusionCandidates(ctx, stream);
  }

  if (options.spaceLeaks) {
    result.spaceLeaks = analyzeSpaceLeaks(ctx);
  }

  return result;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/stream/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/stream/index.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 16: Streams + Laziness - Module exports

// ─────────────────────────────────────────────────────────────────
// Types
// ─────────────────────────────────────────────────────────────────

export type {
  // Promise types
  PromiseCell,
  PromiseStore,
  PromiseEvent,
  // Stream types
  StreamCell,
  StreamSegment,
  StreamReceipt,
  // Analysis types
  StrictnessInfo,
  ProductivityInfo,
  FusionCandidate,
  SpaceLeakInfo,
  StreamAnalysisResult,
  // Configuration
  StreamConfig,
  StreamContext,
} from "./types";

export {
  DEFAULT_STREAM_CONFIG,
  createStreamContext,
  EMPTY_STREAM_SYMBOL,
  isEmptyStreamSentinel,
  makeEmptyStream,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Promise Operations
// ─────────────────────────────────────────────────────────────────

export type { ForceResult } from "./promise";

export {
  // ID generation
  freshPromiseId,
  resetPromiseIds,
  // Store operations
  createPromiseStore,
  createPromise,
  getPromiseCell,
  isPromiseForced,
  isPromiseForcing,
  getForcedValue,
  // Force operations
  beginForce,
  completeForce,
  forceSync,
  // Introspection
  getPromiseStats,
  getAllPromiseIds,
  getForcedPromiseIds,
  getUnforcedPromiseIds,
  // Event analysis
  countForceStarts,
  countTotalForceStarts,
  countCacheHits,
  getTotalOracleCallsFromEvents,
  findMultiForced,
  // Value helpers
  isPromise,
  makePromiseVal,
  // Reset
  clearStreamContext,
  resetPromiseState,
} from "./promise";

// ─────────────────────────────────────────────────────────────────
// Stream Operations
// ─────────────────────────────────────────────────────────────────

export {
  // Constructors
  emptyStream,
  consStream,
  consStreamWithPromise,
  // Accessors
  streamCar,
  streamCdr,
  streamCdrPromise,
  isStreamEmpty,
  isStreamNull,
  isStream,
  // Combinators
  streamMap,
  streamFilter,
  streamTake,
  streamDrop,
  streamAppend,
  streamFlatMap,
  streamZip,
  streamFold,
  streamReduce,
  // Generators
  streamRepeat,
  streamIterate,
  streamRange,
  listToStream,
  // Collectors
  streamToList,
  streamForEach,
  streamLength,
  // Segment operations
  materializeSegment,
  createStreamReceipt,
  hydrateFromReceipt,
  // Force helpers
  forceHead,
  forceTail,
  deepForce,
  forceN,
  // Cleanup
  clearThunkRegistry,
} from "./stream";

// ─────────────────────────────────────────────────────────────────
// Analysis Operations
// ─────────────────────────────────────────────────────────────────

export {
  // Core analysis
  analyzeStream,
  // Individual analyses
  analyzeStrictness,
  analyzeProductivity,
  analyzeSpaceLeaks,
  identifyFusionCandidates,
  // Fusion utilities
  compareFusionCost,
  applyFusion,
  // Event filtering
  getPromiseEventsForId,
  getForceTimeline,
} from "./analysis";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/stream/promise.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/stream/promise.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 16: Memoized promises for lazy evaluation

import type { Val, PromiseId, PromiseVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type {
  PromiseCell,
  PromiseStore,
  PromiseEvent,
  StreamContext,
} from "./types";

// ─────────────────────────────────────────────────────────────────
// Promise ID Generation
// ─────────────────────────────────────────────────────────────────

let nextPromiseId = 0;

/**
 * Generate a fresh promise ID.
 */
export function freshPromiseId(): PromiseId {
  return `promise-${nextPromiseId++}`;
}

/**
 * Reset promise ID counter (for testing).
 */
export function resetPromiseIds(): void {
  nextPromiseId = 0;
}

// ─────────────────────────────────────────────────────────────────
// Promise Store Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Create an empty promise store.
 */
export function createPromiseStore(): PromiseStore {
  return new Map();
}

/**
 * Create a new promise in the store.
 */
export function createPromise(
  ctx: StreamContext,
  thunk: Val,
  label?: string
): PromiseVal {
  const id = freshPromiseId();
  const cell: PromiseCell = {
    tag: "Unforced",
    thunk,
    createdAt: Date.now(),
  };

  ctx.store.set(id, cell);

  if (ctx.config.logging) {
    const thunkHash = sha256JSON(thunk);
    ctx.events.push({
      tag: "PromiseCreated",
      id,
      thunkHash,
      timestamp: Date.now(),
    });
  }

  return { tag: "Promise", id, label };
}

/**
 * Get the current state of a promise.
 */
export function getPromiseCell(ctx: StreamContext, id: PromiseId): PromiseCell | undefined {
  return ctx.store.get(id);
}

/**
 * Check if a promise is forced.
 */
export function isPromiseForced(ctx: StreamContext, id: PromiseId): boolean {
  const cell = ctx.store.get(id);
  return cell?.tag === "Forced";
}

/**
 * Check if a promise is currently being forced.
 */
export function isPromiseForcing(ctx: StreamContext, id: PromiseId): boolean {
  const cell = ctx.store.get(id);
  return cell?.tag === "Forcing";
}

/**
 * Get the cached value of a forced promise.
 */
export function getForcedValue(ctx: StreamContext, id: PromiseId): Val | undefined {
  const cell = ctx.store.get(id);
  if (cell?.tag === "Forced") {
    return cell.value;
  }
  return undefined;
}

// ─────────────────────────────────────────────────────────────────
// Promise Force Operations
// ─────────────────────────────────────────────────────────────────

/**
 * ForceResult: Result of forcing a promise.
 */
export type ForceResult =
  | { tag: "value"; value: Val; cached: boolean }
  | { tag: "thunk"; thunk: Val }
  | { tag: "waiting"; ivarId: string }
  | { tag: "error"; message: string };

/**
 * Begin forcing a promise.
 *
 * Returns:
 * - { tag: "value", value, cached: true } if already forced
 * - { tag: "thunk", thunk } if needs to evaluate
 * - { tag: "waiting", ivarId } if another fiber is forcing (singleflight)
 * - { tag: "error", message } if promise doesn't exist
 */
export function beginForce(ctx: StreamContext, id: PromiseId): ForceResult {
  const cell = ctx.store.get(id);

  if (!cell) {
    return { tag: "error", message: `Promise ${id} not found` };
  }

  switch (cell.tag) {
    case "Forced":
      // Already forced - return cached value
      if (ctx.config.logging) {
        ctx.events.push({
          tag: "PromiseForceHit",
          id,
          timestamp: Date.now(),
        });
      }
      return { tag: "value", value: cell.value, cached: true };

    case "Forcing":
      // Another force is in progress - singleflight
      if (ctx.config.singleflight) {
        if (ctx.config.logging) {
          ctx.events.push({
            tag: "PromiseForceJoin",
            id,
            waiterId: "current",
            timestamp: Date.now(),
          });
        }
        return { tag: "waiting", ivarId: cell.ivarId };
      }
      // Fall through if singleflight disabled (not recommended)
      return { tag: "error", message: `Promise ${id} is being forced (no singleflight)` };

    case "Unforced":
      // Start forcing
      if (ctx.config.logging) {
        ctx.events.push({
          tag: "PromiseForceStart",
          id,
          timestamp: Date.now(),
        });
      }

      ctx.forceCount++;

      // Transition to Forcing state
      const ivarId = `ivar-${id}`;
      ctx.store.set(id, {
        tag: "Forcing",
        ivarId,
        startedAt: Date.now(),
      });

      return { tag: "thunk", thunk: cell.thunk };
  }
}

/**
 * Complete forcing a promise with the computed value.
 */
export function completeForce(
  ctx: StreamContext,
  id: PromiseId,
  value: Val,
  oracleCalls: number = 0
): void {
  ctx.store.set(id, {
    tag: "Forced",
    value,
    forcedAt: Date.now(),
  });

  ctx.oracleCallCount += oracleCalls;

  if (ctx.config.logging) {
    const valueHash = sha256JSON(value);
    ctx.events.push({
      tag: "PromiseForceDone",
      id,
      valueHash,
      oracleCalls,
      timestamp: Date.now(),
    });
  }
}

/**
 * Force a promise synchronously (for simple cases where thunk is pure).
 *
 * Note: In a real evaluator, forcing would be handled by the machine.
 * This is a simplified version for testing and pure computations.
 */
export function forceSync(
  ctx: StreamContext,
  promise: PromiseVal,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  const result = beginForce(ctx, promise.id);

  switch (result.tag) {
    case "value":
      return result.value;

    case "error":
      throw new Error(result.message);

    case "waiting":
      // In a real system, we'd wait on the IVar
      // For sync version, this shouldn't happen if singleflight is off
      throw new Error(`Cannot wait synchronously on ${result.ivarId}`);

    case "thunk":
      if (!evaluator) {
        // No evaluator provided - return thunk as-is for now
        completeForce(ctx, promise.id, result.thunk, 0);
        return result.thunk;
      }

      // Evaluate the thunk
      const { value, oracleCalls } = evaluator(result.thunk);
      completeForce(ctx, promise.id, value, oracleCalls);
      return value;
  }
}

// ─────────────────────────────────────────────────────────────────
// Promise Introspection
// ─────────────────────────────────────────────────────────────────

/**
 * Get statistics about promises in the store.
 */
export function getPromiseStats(ctx: StreamContext): {
  total: number;
  unforced: number;
  forcing: number;
  forced: number;
  oracleCalls: number;
} {
  let unforced = 0;
  let forcing = 0;
  let forced = 0;

  for (const cell of ctx.store.values()) {
    switch (cell.tag) {
      case "Unforced":
        unforced++;
        break;
      case "Forcing":
        forcing++;
        break;
      case "Forced":
        forced++;
        break;
    }
  }

  return {
    total: ctx.store.size,
    unforced,
    forcing,
    forced,
    oracleCalls: ctx.oracleCallCount,
  };
}

/**
 * Get all promise IDs in the store.
 */
export function getAllPromiseIds(ctx: StreamContext): PromiseId[] {
  return Array.from(ctx.store.keys());
}

/**
 * Get forced promise IDs only.
 */
export function getForcedPromiseIds(ctx: StreamContext): PromiseId[] {
  const ids: PromiseId[] = [];
  for (const [id, cell] of ctx.store.entries()) {
    if (cell.tag === "Forced") {
      ids.push(id);
    }
  }
  return ids;
}

/**
 * Get unforced promise IDs only.
 */
export function getUnforcedPromiseIds(ctx: StreamContext): PromiseId[] {
  const ids: PromiseId[] = [];
  for (const [id, cell] of ctx.store.entries()) {
    if (cell.tag === "Unforced") {
      ids.push(id);
    }
  }
  return ids;
}

// ─────────────────────────────────────────────────────────────────
// Event Analysis
// ─────────────────────────────────────────────────────────────────

/**
 * Count force starts for a specific promise.
 */
export function countForceStarts(ctx: StreamContext, id: PromiseId): number {
  return ctx.events.filter(
    e => e.tag === "PromiseForceStart" && e.id === id
  ).length;
}

/**
 * Count total force starts.
 */
export function countTotalForceStarts(ctx: StreamContext): number {
  return ctx.events.filter(e => e.tag === "PromiseForceStart").length;
}

/**
 * Count cache hits.
 */
export function countCacheHits(ctx: StreamContext): number {
  return ctx.events.filter(e => e.tag === "PromiseForceHit").length;
}

/**
 * Get total oracle calls from events.
 */
export function getTotalOracleCallsFromEvents(ctx: StreamContext): number {
  return ctx.events
    .filter((e): e is Extract<PromiseEvent, { tag: "PromiseForceDone" }> =>
      e.tag === "PromiseForceDone"
    )
    .reduce((sum, e) => sum + e.oracleCalls, 0);
}

/**
 * Find promises that were forced multiple times (should be 0 with memoization).
 */
export function findMultiForced(ctx: StreamContext): PromiseId[] {
  const forceCounts = new Map<PromiseId, number>();

  for (const event of ctx.events) {
    if (event.tag === "PromiseForceStart") {
      forceCounts.set(event.id, (forceCounts.get(event.id) ?? 0) + 1);
    }
  }

  const multiForced: PromiseId[] = [];
  for (const [id, count] of forceCounts) {
    if (count > 1) {
      multiForced.push(id);
    }
  }

  return multiForced;
}

// ─────────────────────────────────────────────────────────────────
// Promise Value Helpers
// ─────────────────────────────────────────────────────────────────

/**
 * Check if a value is a promise.
 */
export function isPromise(v: Val): v is PromiseVal {
  return v.tag === "Promise";
}

/**
 * Make a promise value (without creating in store).
 */
export function makePromiseVal(id: PromiseId, label?: string): PromiseVal {
  return { tag: "Promise", id, label };
}

// ─────────────────────────────────────────────────────────────────
// Reset State (for testing)
// ─────────────────────────────────────────────────────────────────

/**
 * Clear a stream context.
 */
export function clearStreamContext(ctx: StreamContext): void {
  ctx.store.clear();
  ctx.events.length = 0;
  ctx.oracleCallCount = 0;
  ctx.forceCount = 0;
  ctx.fuel = ctx.config.maxFuel;
}

/**
 * Reset all promise state (for testing).
 */
export function resetPromiseState(): void {
  resetPromiseIds();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/stream/stream.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/stream/stream.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 16: Stream primitives and combinators (SICP-style)

import type { Val, PromiseVal, ReceiptRefVal, ListVal, IntVal } from "../eval/values";
import { VUnit } from "../eval/values";
import type { Hash } from "../artifacts/hash";
import { sha256JSON } from "../artifacts/hash";
import type {
  StreamCell,
  StreamContext,
  StreamSegment,
  StreamReceipt,
} from "./types";
import { makeEmptyStream, isEmptyStreamSentinel, createStreamContext } from "./types";
import {
  createPromise,
  isPromise,
  forceSync,
  beginForce,
  completeForce,
  isPromiseForced,
  getForcedValue,
} from "./promise";

// ─────────────────────────────────────────────────────────────────
// Thunk Registry (module-level for simplicity)
// ─────────────────────────────────────────────────────────────────

const MAX_THUNKS = 500; // Hard limit to prevent memory issues
const thunkRegistry = new Map<string, () => Val>();
let thunkCounter = 0;

function registerThunk(fn: () => Val): string {
  if (thunkRegistry.size >= MAX_THUNKS) {
    // Clear old thunks to prevent memory growth
    const keysToRemove = Array.from(thunkRegistry.keys()).slice(0, 100);
    for (const key of keysToRemove) {
      thunkRegistry.delete(key);
    }
  }

  const id = `thunk-${thunkCounter++}`;
  thunkRegistry.set(id, fn);
  return id;
}

function getThunk(id: string): (() => Val) | undefined {
  return thunkRegistry.get(id);
}

export function clearThunkRegistry(): void {
  thunkRegistry.clear();
  thunkCounter = 0;
}

// ─────────────────────────────────────────────────────────────────
// Stream Constructors
// ─────────────────────────────────────────────────────────────────

/**
 * Create the empty stream.
 */
export function emptyStream(): Val {
  return makeEmptyStream();
}

/**
 * Check if a value is the empty stream.
 */
export function isStreamNull(v: Val): boolean {
  return isEmptyStreamSentinel(v);
}

/**
 * Alias for isStreamNull.
 */
export function isStreamEmpty(v: Val): boolean {
  return isStreamNull(v);
}

/**
 * Create a stream cons cell: (head . tail-promise).
 *
 * The tailThunk is a function that produces the tail when called.
 * It's wrapped in a promise for lazy evaluation.
 */
export function consStream(
  ctx: StreamContext,
  head: Val,
  tailThunk: () => Val,
  label?: string
): Val {
  // Register the thunk and create a reference value
  const thunkId = registerThunk(tailThunk);
  const thunkVal: Val = {
    tag: "Str",
    s: `__thunk:${thunkId}`,
  };

  const tailPromise = createPromise(ctx, thunkVal, label);
  return { tag: "Pair", car: head, cdr: tailPromise };
}

/**
 * Create a stream cons cell with an already-created promise.
 */
export function consStreamWithPromise(head: Val, tailPromise: PromiseVal): Val {
  return { tag: "Pair", car: head, cdr: tailPromise };
}

/**
 * Create a stream cons cell with a receipt ref (for receipt-backed streams).
 */
export function consStreamWithReceipt(head: Val, receiptRef: ReceiptRefVal): Val {
  return { tag: "Pair", car: head, cdr: receiptRef };
}

// ─────────────────────────────────────────────────────────────────
// Stream Accessors
// ─────────────────────────────────────────────────────────────────

/**
 * Get the head of a stream.
 */
export function streamCar(s: Val): Val {
  if (isStreamNull(s)) {
    throw new Error("stream-car: empty stream");
  }
  if (s.tag !== "Pair") {
    throw new Error("stream-car: not a stream");
  }
  return s.car;
}

/**
 * Get the tail promise of a stream (without forcing).
 */
export function streamCdrPromise(s: Val): Val {
  if (isStreamNull(s)) {
    throw new Error("stream-cdr: empty stream");
  }
  if (s.tag !== "Pair") {
    throw new Error("stream-cdr: not a stream");
  }
  return s.cdr;
}

/**
 * Custom thunk evaluator that handles our stream thunks.
 */
function evaluateThunk(
  thunk: Val,
  userEvaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): { value: Val; oracleCalls: number } {
  // Check if it's our stream thunk marker
  if (thunk.tag === "Str" && thunk.s.startsWith("__thunk:")) {
    const thunkId = thunk.s.slice(8);
    const thunkFn = getThunk(thunkId);
    if (thunkFn) {
      const result = thunkFn();
      return { value: result, oracleCalls: 0 };
    }
  }

  // Fall back to user evaluator or identity
  if (userEvaluator) {
    return userEvaluator(thunk);
  }
  return { value: thunk, oracleCalls: 0 };
}

/**
 * Get the tail of a stream (forcing the tail promise).
 */
export function streamCdr(
  ctx: StreamContext,
  s: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s)) {
    throw new Error("stream-cdr: empty stream");
  }
  if (s.tag !== "Pair") {
    throw new Error("stream-cdr: not a stream");
  }

  const tail = s.cdr;

  // Case 1: Tail is a promise - force it
  if (isPromise(tail)) {
    const combinedEvaluator = (thunk: Val) => evaluateThunk(thunk, evaluator);
    return forceSync(ctx, tail, combinedEvaluator);
  }

  // Case 2: Tail is a receipt ref - hydrate it
  if (tail.tag === "ReceiptRef") {
    return hydrateStreamTail(ctx, tail);
  }

  // Case 3: Tail is already a value (should not happen in normal use)
  return tail;
}

/**
 * Hydrate a stream tail from a receipt reference.
 */
export function hydrateStreamTail(ctx: StreamContext, receiptRef: ReceiptRefVal): Val {
  if (ctx.config.logging) {
    ctx.events.push({
      tag: "PromiseForceStart",
      id: `hydrate-${receiptRef.rid}`,
      timestamp: Date.now(),
    });
    ctx.events.push({
      tag: "PromiseForceDone",
      id: `hydrate-${receiptRef.rid}`,
      valueHash: sha256JSON(makeEmptyStream()),
      oracleCalls: 0,
      timestamp: Date.now(),
    });
  }

  return makeEmptyStream();
}

// ─────────────────────────────────────────────────────────────────
// Stream Combinators
// ─────────────────────────────────────────────────────────────────

/**
 * Map a function over a stream.
 */
export function streamMap(
  ctx: StreamContext,
  s: Val,
  f: (x: Val) => Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s)) {
    return emptyStream();
  }

  const head = streamCar(s);
  const mappedHead = f(head);
  const stream = s; // Capture for closure

  return consStream(ctx, mappedHead, () => {
    const tail = streamCdr(ctx, stream, evaluator);
    return streamMap(ctx, tail, f, evaluator);
  }, "stream-map-tail");
}

/**
 * Filter a stream by a predicate.
 */
export function streamFilter(
  ctx: StreamContext,
  s: Val,
  p: (x: Val) => boolean,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  let current = s;

  while (!isStreamNull(current)) {
    if (ctx.fuel <= 0) {
      throw new Error("stream-filter: fuel exhausted");
    }
    ctx.fuel--;

    const head = streamCar(current);

    if (p(head)) {
      const currStream = current;
      return consStream(ctx, head, () => {
        const tail = streamCdr(ctx, currStream, evaluator);
        return streamFilter(ctx, tail, p, evaluator);
      }, "stream-filter-tail");
    }

    current = streamCdr(ctx, current, evaluator);
  }

  return emptyStream();
}

/**
 * Take the first n elements of a stream.
 */
export function streamTake(
  ctx: StreamContext,
  s: Val,
  n: number,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (n <= 0 || isStreamNull(s)) {
    return emptyStream();
  }

  const head = streamCar(s);
  const stream = s;
  const remaining = n;

  return consStream(ctx, head, () => {
    const tail = streamCdr(ctx, stream, evaluator);
    return streamTake(ctx, tail, remaining - 1, evaluator);
  }, "stream-take-tail");
}

/**
 * Drop the first n elements of a stream.
 */
export function streamDrop(
  ctx: StreamContext,
  s: Val,
  n: number,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  let current = s;
  let remaining = n;

  while (remaining > 0 && !isStreamNull(current)) {
    if (ctx.fuel <= 0) {
      throw new Error("stream-drop: fuel exhausted");
    }
    ctx.fuel--;

    current = streamCdr(ctx, current, evaluator);
    remaining--;
  }

  return current;
}

/**
 * Append two streams.
 */
export function streamAppend(
  ctx: StreamContext,
  s1: Val,
  s2Thunk: () => Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s1)) {
    return s2Thunk();
  }

  const head = streamCar(s1);
  const stream = s1;

  return consStream(ctx, head, () => {
    const tail = streamCdr(ctx, stream, evaluator);
    return streamAppend(ctx, tail, s2Thunk, evaluator);
  }, "stream-append-tail");
}

/**
 * Flatmap over a stream.
 */
export function streamFlatMap(
  ctx: StreamContext,
  s: Val,
  f: (x: Val) => Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s)) {
    return emptyStream();
  }

  const head = streamCar(s);
  const mappedHead = f(head);
  const stream = s;

  return streamAppend(ctx, mappedHead, () => {
    const tail = streamCdr(ctx, stream, evaluator);
    return streamFlatMap(ctx, tail, f, evaluator);
  }, evaluator);
}

/**
 * Zip two streams together.
 */
export function streamZip(
  ctx: StreamContext,
  s1: Val,
  s2: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s1) || isStreamNull(s2)) {
    return emptyStream();
  }

  const head1 = streamCar(s1);
  const head2 = streamCar(s2);
  const pair: ListVal = { tag: "List", elements: [head1, head2] };
  const stream1 = s1;
  const stream2 = s2;

  return consStream(ctx, pair, () => {
    const tail1 = streamCdr(ctx, stream1, evaluator);
    const tail2 = streamCdr(ctx, stream2, evaluator);
    return streamZip(ctx, tail1, tail2, evaluator);
  }, "stream-zip-tail");
}

/**
 * Fairly interleave two streams: s1[0], s2[0], s1[1], s2[1], ...
 */
export function streamInterleave(
  ctx: StreamContext,
  s1: Val,
  s2: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (!isStream(s1) || !isStream(s2)) {
    throw new Error("stream-interleave: expected streams");
  }

  if (isStreamNull(s1)) {
    return s2;
  }

  const head = streamCar(s1);
  const stream1 = s1;

  return consStream(ctx, head, () => {
    const tail1 = streamCdr(ctx, stream1, evaluator);
    return streamInterleave(ctx, s2, tail1, evaluator);
  }, "stream-interleave-tail");
}

// ─────────────────────────────────────────────────────────────────
// Stream Generators
// ─────────────────────────────────────────────────────────────────

/**
 * Create an infinite stream of a constant value.
 */
export function streamRepeat(ctx: StreamContext, value: Val): Val {
  const v = value;
  return consStream(ctx, v, () => streamRepeat(ctx, v), "stream-repeat-tail");
}

/**
 * Create a stream from a range.
 */
export function streamRange(ctx: StreamContext, start: number, end: number): Val {
  if (start >= end) {
    return emptyStream();
  }

  const head: IntVal = { tag: "Int", value: BigInt(start) };
  const s = start;
  const e = end;

  return consStream(ctx, head, () => streamRange(ctx, s + 1, e), "stream-range-tail");
}

/**
 * Create a stream from a list value.
 */
export function listToStream(ctx: StreamContext, list: ListVal): Val {
  const items = list.elements;
  if (items.length === 0) {
    return emptyStream();
  }

  function buildFromIndex(i: number): Val {
    if (i >= items.length) {
      return emptyStream();
    }
    return consStream(ctx, items[i], () => buildFromIndex(i + 1), `list-item-${i}`);
  }

  return buildFromIndex(0);
}

/**
 * Create a stream from a generator function.
 */
export function streamIterate(
  ctx: StreamContext,
  seed: Val,
  f: (x: Val) => Val
): Val {
  const s = seed;
  return consStream(ctx, s, () => {
    const next = f(s);
    return streamIterate(ctx, next, f);
  }, "stream-iterate-tail");
}

// ─────────────────────────────────────────────────────────────────
// Stream to List Conversion
// ─────────────────────────────────────────────────────────────────

/**
 * Convert a finite stream to a list.
 */
export function streamToList(
  ctx: StreamContext,
  s: Val,
  maxElements: number = 1000,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val[] {
  const result: Val[] = [];
  let current = s;
  let count = 0;

  while (!isStreamNull(current) && count < maxElements) {
    if (ctx.fuel <= 0) {
      throw new Error("stream->list: fuel exhausted");
    }
    ctx.fuel--;

    result.push(streamCar(current));
    current = streamCdr(ctx, current, evaluator);
    count++;
  }

  if (count >= maxElements && !isStreamNull(current)) {
    throw new Error(`stream->list: exceeded max elements (${maxElements})`);
  }

  return result;
}

/**
 * Force the first n elements of a stream into an array.
 */
export function forceN(
  ctx: StreamContext,
  s: Val,
  n: number,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val[] {
  const result: Val[] = [];
  let current = s;
  let remaining = n;

  while (remaining > 0 && !isStreamNull(current)) {
    if (ctx.fuel <= 0) {
      break;
    }
    ctx.fuel--;

    result.push(streamCar(current));
    current = streamCdr(ctx, current, evaluator);
    remaining--;
  }

  return result;
}

/**
 * Force the head of a stream.
 */
export function forceHead(
  ctx: StreamContext,
  s: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val | null {
  if (isStreamNull(s)) {
    return null;
  }
  return streamCar(s);
}

/**
 * Force the tail of a stream.
 */
export function forceTail(
  ctx: StreamContext,
  s: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val | null {
  if (isStreamNull(s)) {
    return null;
  }
  return streamCdr(ctx, s, evaluator);
}

/**
 * Deep force a stream up to n elements.
 */
export function deepForce(
  ctx: StreamContext,
  s: Val,
  n: number,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val[] {
  return forceN(ctx, s, n, evaluator);
}

/**
 * For each element in a stream, call a function.
 */
export function streamForEach(
  ctx: StreamContext,
  s: Val,
  f: (x: Val) => void,
  maxElements: number = 1000,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): void {
  let current = s;
  let count = 0;

  while (!isStreamNull(current) && count < maxElements) {
    if (ctx.fuel <= 0) {
      break;
    }
    ctx.fuel--;

    f(streamCar(current));
    current = streamCdr(ctx, current, evaluator);
    count++;
  }
}

// ─────────────────────────────────────────────────────────────────
// Stream Fold Operations
// ─────────────────────────────────────────────────────────────────

/**
 * Fold over a stream from the left.
 */
export function streamFold(
  ctx: StreamContext,
  s: Val,
  init: Val,
  f: (acc: Val, x: Val) => Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  let acc = init;
  let current = s;

  while (!isStreamNull(current)) {
    if (ctx.fuel <= 0) {
      throw new Error("stream-fold: fuel exhausted");
    }
    ctx.fuel--;

    acc = f(acc, streamCar(current));
    current = streamCdr(ctx, current, evaluator);
  }

  return acc;
}

/**
 * Reduce a stream (fold with first element as init).
 */
export function streamReduce(
  ctx: StreamContext,
  s: Val,
  f: (acc: Val, x: Val) => Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): Val {
  if (isStreamNull(s)) {
    throw new Error("stream-reduce: empty stream");
  }

  const init = streamCar(s);
  const rest = streamCdr(ctx, s, evaluator);

  return streamFold(ctx, rest, init, f, evaluator);
}

// ─────────────────────────────────────────────────────────────────
// Stream Segment Operations (for receipt-backed staging)
// ─────────────────────────────────────────────────────────────────

/**
 * Materialize a prefix of a stream into a segment.
 */
export function materializeSegment(
  ctx: StreamContext,
  s: Val,
  n: number,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): StreamSegment {
  const elements = forceN(ctx, s, n, evaluator);

  // Try to get current position
  let current = s;
  for (let i = 0; i < elements.length && !isStreamNull(current); i++) {
    current = streamCdr(ctx, current, evaluator);
  }

  return {
    elements,
    continuationHash: isStreamNull(current) ? undefined : sha256JSON({ remaining: true }),
    terminal: isStreamNull(current),
  };
}

/**
 * Create a receipt for a stream segment.
 */
export function createStreamReceipt(segment: StreamSegment): StreamReceipt {
  return {
    rid: sha256JSON({ segment: segment.elements.length, time: Date.now() }),
    segmentHash: sha256JSON(segment.elements),
    elementCount: segment.elements.length,
    createdAt: Date.now(),
  };
}

/**
 * Hydrate a stream from a receipt and segment.
 */
export function hydrateFromReceipt(
  ctx: StreamContext,
  receipt: StreamReceipt,
  segment: StreamSegment,
  continuation: () => Val
): Val {
  if (segment.elements.length === 0) {
    return continuation();
  }

  function buildFromIndex(i: number): Val {
    if (i >= segment.elements.length) {
      if (segment.terminal) {
        return emptyStream();
      }
      return continuation();
    }
    return consStream(ctx, segment.elements[i], () => buildFromIndex(i + 1), `hydrate-${i}`);
  }

  return buildFromIndex(0);
}

// ─────────────────────────────────────────────────────────────────
// Stream Utilities
// ─────────────────────────────────────────────────────────────────

/**
 * Get the length of a finite stream.
 */
export function streamLength(
  ctx: StreamContext,
  s: Val,
  evaluator?: (thunk: Val) => { value: Val; oracleCalls: number }
): number {
  let count = 0;
  let current = s;

  while (!isStreamNull(current)) {
    if (ctx.fuel <= 0) {
      throw new Error("stream-length: fuel exhausted");
    }
    ctx.fuel--;

    count++;
    current = streamCdr(ctx, current, evaluator);
  }

  return count;
}

/**
 * Check if a value is a stream (pair with promise/receipt cdr, or empty).
 */
export function isStream(v: Val): boolean {
  if (isStreamNull(v)) return true;
  if (v.tag !== "Pair") return false;
  const cdr = v.cdr;
  return isPromise(cdr) || cdr.tag === "ReceiptRef";
}

/**
 * Get the ref (promise or receipt) in the stream's cdr.
 */
export function streamTailRef(s: Val): Val | null {
  if (isStreamNull(s)) return null;
  if (s.tag !== "Pair") return null;
  return s.cdr;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/stream/types.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/stream/types.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-16.md
// Prompt 16: Streams + Laziness - Core types

import type { Val, PromiseId } from "../eval/values";
import type { Hash } from "../artifacts/hash";

// ─────────────────────────────────────────────────────────────────
// Promise Store Types
// ─────────────────────────────────────────────────────────────────

/**
 * PromiseCell: Store-side state for a promise.
 *
 * Three states:
 * - Unforced: Has a thunk waiting to be evaluated
 * - Forcing: Currently being evaluated (singleflight coordination)
 * - Forced: Evaluation complete, value cached
 */
export type PromiseCell =
  | { tag: "Unforced"; thunk: Val; createdAt: number }
  | { tag: "Forcing"; ivarId: string; startedAt: number }
  | { tag: "Forced"; value: Val; forcedAt: number };

/**
 * PromiseStore: Store for managing promise state.
 */
export type PromiseStore = Map<PromiseId, PromiseCell>;

/**
 * PromiseEvent: Events logged during promise operations.
 */
export type PromiseEvent =
  | { tag: "PromiseCreated"; id: PromiseId; thunkHash: Hash; timestamp: number }
  | { tag: "PromiseForceStart"; id: PromiseId; timestamp: number }
  | { tag: "PromiseForceHit"; id: PromiseId; timestamp: number }
  | { tag: "PromiseForceDone"; id: PromiseId; valueHash: Hash; oracleCalls: number; timestamp: number }
  | { tag: "PromiseForceJoin"; id: PromiseId; waiterId: string; timestamp: number };

// ─────────────────────────────────────────────────────────────────
// Stream Types
// ─────────────────────────────────────────────────────────────────

/**
 * StreamCell: Representation of a stream cell.
 *
 * Either empty or a head with a tail (promise or receipt ref).
 */
export type StreamCell =
  | { tag: "Empty" }
  | { tag: "Cons"; head: Val; tail: Val };

/**
 * StreamSegment: A materialized segment of a stream.
 *
 * Used for receipt-backed staging.
 */
export type StreamSegment = {
  /** Elements in this segment */
  elements: Val[];
  /** Hash of the continuation (if any) */
  continuationHash?: Hash;
  /** Whether this segment is terminal */
  terminal: boolean;
};

/**
 * StreamReceipt: Receipt for a stream segment.
 */
export type StreamReceipt = {
  rid: Hash;
  segmentHash: Hash;
  elementCount: number;
  createdAt: number;
};

// ─────────────────────────────────────────────────────────────────
// Stream Analysis Types
// ─────────────────────────────────────────────────────────────────

/**
 * StrictnessInfo: Information about demand/strictness.
 */
export type StrictnessInfo = {
  /** How many elements were demanded */
  demandedCount: number;
  /** How many promises were forced */
  forcedCount: number;
  /** Whether the consumer forced beyond demanded prefix */
  forcedAhead: boolean;
  /** Promises that were forced multiple times (potential bug) */
  multiForced: PromiseId[];
  /** Oracle calls triggered */
  oracleCalls: number;
};

/**
 * ProductivityInfo: Information about productivity.
 */
export type ProductivityInfo = {
  /** Whether the stream is productive under the given fuel */
  productive: boolean;
  /** How many elements were produced before fuel exhaustion */
  producedCount: number;
  /** Fuel remaining */
  fuelRemaining: number;
  /** Reason if non-productive */
  reason?: string;
};

/**
 * FusionCandidate: A candidate for stream fusion.
 */
export type FusionCandidate = {
  id: string;
  kind: "map-map" | "filter-map" | "map-filter" | "cse" | "deforest";
  description: string;
  /** Estimated oracle call reduction */
  estimatedSaving: number;
  /** Original pattern (AST-like) */
  pattern: Val;
  /** Rewritten pattern */
  rewrite: Val;
  /** Confidence score */
  confidence: number;
};

/**
 * SpaceLeakInfo: Information about potential space leaks.
 */
export type SpaceLeakInfo = {
  /** Whether a leak is suspected */
  leakSuspected: boolean;
  /** Growth rate of retained promises */
  retainedGrowthRate: number;
  /** Promises that are retained longer than expected */
  longRetained: PromiseId[];
  /** Suspected cause */
  cause?: "head-retention" | "closure-capture" | "accumulator" | "unknown";
  /** Suggested fix */
  suggestion?: string;
};

/**
 * StreamAnalysisResult: Result of stream analysis.
 */
export type StreamAnalysisResult = {
  strictness?: StrictnessInfo;
  productivity?: ProductivityInfo;
  fusionCandidates?: FusionCandidate[];
  spaceLeaks?: SpaceLeakInfo;
  /** Events collected during analysis */
  events: PromiseEvent[];
};

// ─────────────────────────────────────────────────────────────────
// Stream Configuration
// ─────────────────────────────────────────────────────────────────

/**
 * StreamConfig: Configuration for stream operations.
 */
export type StreamConfig = {
  /** Maximum fuel for productivity analysis */
  maxFuel: number;
  /** Enable event logging */
  logging: boolean;
  /** Enable memoization (normally always on) */
  memoization: boolean;
  /** Enable singleflight for concurrent forces */
  singleflight: boolean;
  /** Profile name for governance */
  profileName?: string;
};

export const DEFAULT_STREAM_CONFIG: StreamConfig = {
  maxFuel: 1000,
  logging: true,
  memoization: true,
  singleflight: true,
};

// ─────────────────────────────────────────────────────────────────
// Stream Context
// ─────────────────────────────────────────────────────────────────

/**
 * StreamContext: Context for stream operations.
 */
export type StreamContext = {
  /** Promise store */
  store: PromiseStore;
  /** Event log */
  events: PromiseEvent[];
  /** Configuration */
  config: StreamConfig;
  /** Oracle call counter */
  oracleCallCount: number;
  /** Force counter (for debugging) */
  forceCount: number;
  /** Current fuel (for bounded execution) */
  fuel: number;
};

/**
 * Create a fresh stream context.
 */
export function createStreamContext(config: Partial<StreamConfig> = {}): StreamContext {
  return {
    store: new Map(),
    events: [],
    config: { ...DEFAULT_STREAM_CONFIG, ...config },
    oracleCallCount: 0,
    forceCount: 0,
    fuel: config.maxFuel ?? DEFAULT_STREAM_CONFIG.maxFuel,
  };
}

/**
 * Empty stream sentinel.
 */
export const EMPTY_STREAM_SYMBOL = Symbol.for("empty-stream");

/**
 * Check if a value is the empty stream sentinel.
 */
export function isEmptyStreamSentinel(v: Val): boolean {
  return v.tag === "Sym" && v.name === "empty-stream";
}

/**
 * Create the empty stream value.
 */
export function makeEmptyStream(): Val {
  return { tag: "Sym", name: "empty-stream" };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/syntax/alpha.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-3.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Expr } from "../ast";

type Env = Map<string, string>;

type Supply = { n: number };

function fresh(s: Supply): string {
  const name = `x${s.n}`;
  s.n += 1;
  return name;
}

export function alphaNormalize(e: Expr): Expr {
  const supply: Supply = { n: 0 };
  return norm(e, new Map(), supply);
}

function norm(e: Expr, env: Env, supply: Supply): Expr {
  switch (e.tag) {
    case "Lit":
    case "Quote":
      return e;

    case "Var": {
      const n = env.get(e.name);
      return n ? { ...e, name: n } : e;
    }

    case "Lambda": {
      const env2 = new Map(env);
      const params2: string[] = [];
      for (const p of e.params) {
        const p2 = fresh(supply);
        env2.set(p, p2);
        params2.push(p2);
      }
      return { ...e, params: params2, body: norm(e.body, env2, supply) };
    }

    case "If":
      return { ...e, test: norm(e.test, env, supply), conseq: norm(e.conseq, env, supply), alt: norm(e.alt, env, supply) };

    case "Begin":
      return { ...e, exprs: e.exprs.map(x => norm(x, env, supply)) };

    case "App":
      return { ...e, fn: norm(e.fn, env, supply), args: e.args.map(a => norm(a, env, supply)) };

    case "Effect":
      return { ...e, args: e.args.map(a => norm(a, env, supply)) };

    case "Set":
      // set! targets an existing binding; rename if bound
      return { ...e, name: env.get(e.name) ?? e.name, rhs: norm(e.rhs, env, supply) };

    case "Define":
      // For alpha-eq of *expressions*, you often keep Define names stable.
      // For module-level comparisons, you may normalize top-level defines too, but be careful about exports.
      return { ...e, rhs: norm(e.rhs, env, supply) };

    case "Handle":
      // If handler contains expressions, normalize them too (depends on handler IR).
      return { ...e, body: norm(e.body, env, supply) };

    case "Match": {
      // If patterns bind vars, you need to extend env accordingly per clause.
      // Reference-grade: treat patterns as opaque; normalize bodies under same env.
      return {
        ...e,
        scrutinee: norm(e.scrutinee, env, supply),
        clauses: e.clauses.map(c => ({ ...c, body: norm(c.body, env, supply) })),
      };
    }

    case "QuoteSyntax":
      return e;

    case "Let":
    case "Letrec":
      return {
        ...e,
        bindings: e.bindings.map(b => ({ ...b, init: norm(b.init, env, supply) })),
        body: norm(e.body, env, supply),
      };

    default:
      return e;
  }
}

export function alphaEqual(a: Expr, b: Expr): boolean {
  const an = alphaNormalize(a);
  const bn = alphaNormalize(b);
  return JSON.stringify(an) === JSON.stringify(bn);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/syntax/binding.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.

import type { Scope, SIdent } from "./syntax";

export type BindingKind = "value" | "syntax";

export type Binding = {
  bid: string;
  name: string;
  scopes: Scope[];
  phase: number;
  kind: BindingKind;
  value: unknown;
};

export type Env = Binding[];

function subset(a: Scope[], b: Scope[]): boolean {
  for (const sc of a) if (!b.includes(sc)) return false;
  return true;
}

/**
 * Backwards-compatible resolver:
 *   - old: resolveIdent(id, env, phase)
 *   - new: resolveIdent(id, env, phase, kind)
 */
export function resolveIdent(id: SIdent, env: Env, phase: number, kind: BindingKind = "value"): Binding | null {
  const candidates = env.filter(b =>
    b.phase === phase &&
    b.kind === kind &&
    b.name === id.name &&
    subset(b.scopes, id.scopes)
  );

  if (candidates.length === 0) return null;
  candidates.sort((a, b) => b.scopes.length - a.scopes.length);
  const best = candidates[0];
  const second = candidates[1];
  if (second && second.scopes.length === best.scopes.length) {
    throw new Error(`resolveIdent ambiguity: ${id.name} at phase ${phase} kind ${kind}`);
  }
  return best;
}

/**
 * Backwards-compatible free-identifier=? used by syntax-rules literals.
 * Signature kept as: (idDef, envDef, phase, idUse, envUse)
 */
export function freeIdentifierEq(
  id1: SIdent, env1: Env, phase: number,
  id2: SIdent, env2: Env,
  kind: BindingKind = "value"
): boolean {
  const b1 = resolveIdent(id1, env1, phase, kind);
  const b2 = resolveIdent(id2, env2, phase, kind);
  if (b1 && b2) return b1.bid === b2.bid;
  if (!b1 && !b2) return id1.name === id2.name;
  return false;
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/syntax/syntax.ts
// ═══════════════════════════════════════════════════════════════════════════

// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-11.md
// AUTO-EXTRACTED - Do not edit directly. Edit the source document.
// Prompt 15: Extended with source location support

export type Scope = string;

/**
 * SourceLocation: Source file location for syntax objects.
 * Used for error reporting and debugging.
 */
export type SourceLocation = {
  file?: string;
  line?: number;
  col?: number;
  span?: number;
};

/**
 * Syntax: First-class syntax object with scopes for hygiene.
 *
 * This implements the set-of-scopes model from Racket:
 * - Each syntax object carries a set of scopes
 * - Identifier resolution uses scope sets to find bindings
 * - Macros add/flip scopes to maintain hygiene
 */
export type Syntax =
  | { tag: "Atom"; value: any; scopes: Scope[]; srcloc?: SourceLocation }
  | { tag: "Ident"; name: string; scopes: Scope[]; srcloc?: SourceLocation }
  | { tag: "List"; items: Syntax[]; scopes: Scope[]; srcloc?: SourceLocation };

export type SIdent = Extract<Syntax, { tag: "Ident" }>;
export type SList = Extract<Syntax, { tag: "List" }>;

export function isIdent(x: Syntax): x is SIdent {
  return x.tag === "Ident";
}

export function isList(x: Syntax): x is SList {
  return x.tag === "List";
}

/** Add scope to every node (so identifier nodes carry scopes). */
export function addScope(stx: Syntax, sc: Scope): Syntax {
  switch (stx.tag) {
    case "Atom":
      return { ...stx, scopes: stx.scopes.concat([sc]) };
    case "Ident":
      return { ...stx, scopes: stx.scopes.concat([sc]) };
    case "List":
      return { ...stx, scopes: stx.scopes.concat([sc]), items: stx.items.map(it => addScope(it, sc)) };
  }
}

/** Deterministic fresh scope ids using an explicit counter object. */
export function freshScope(counter: { n: number }): Scope {
  counter.n += 1;
  return `s#${counter.n}`;
}

/**
 * Check if a syntax object is an atom.
 */
export function isAtom(x: Syntax): x is Extract<Syntax, { tag: "Atom" }> {
  return x.tag === "Atom";
}

/**
 * Create a syntax object from a datum (symbol, number, string, list).
 */
export function datum(value: any, scopes: Scope[] = [], srcloc?: SourceLocation): Syntax {
  if (value === null || value === undefined) {
    return { tag: "Atom", value, scopes, srcloc };
  }

  if (typeof value === "symbol") {
    return { tag: "Ident", name: value.description ?? String(value), scopes, srcloc };
  }

  if (Array.isArray(value)) {
    return {
      tag: "List",
      items: value.map(v => datum(v, scopes, srcloc)),
      scopes,
      srcloc,
    };
  }

  return { tag: "Atom", value, scopes, srcloc };
}

/**
 * Remove a scope from a syntax object.
 */
export function removeScope(stx: Syntax, sc: Scope): Syntax {
  switch (stx.tag) {
    case "Atom":
      return { ...stx, scopes: stx.scopes.filter(s => s !== sc) };
    case "Ident":
      return { ...stx, scopes: stx.scopes.filter(s => s !== sc) };
    case "List":
      return {
        ...stx,
        scopes: stx.scopes.filter(s => s !== sc),
        items: stx.items.map(it => removeScope(it, sc)),
      };
  }
}

/**
 * Flip a scope on a syntax object (add if missing, remove if present).
 */
export function flipScope(stx: Syntax, sc: Scope): Syntax {
  switch (stx.tag) {
    case "Atom": {
      const scopes = stx.scopes.includes(sc)
        ? stx.scopes.filter(s => s !== sc)
        : stx.scopes.concat([sc]);
      return { ...stx, scopes };
    }
    case "Ident": {
      const scopes = stx.scopes.includes(sc)
        ? stx.scopes.filter(s => s !== sc)
        : stx.scopes.concat([sc]);
      return { ...stx, scopes };
    }
    case "List": {
      const scopes = stx.scopes.includes(sc)
        ? stx.scopes.filter(s => s !== sc)
        : stx.scopes.concat([sc]);
      return {
        ...stx,
        scopes,
        items: stx.items.map(it => flipScope(it, sc)),
      };
    }
  }
}

/**
 * Get the source location of a syntax object.
 */
export function getSrcloc(stx: Syntax): SourceLocation | undefined {
  return stx.srcloc;
}

/**
 * Set the source location of a syntax object.
 */
export function withSrcloc(stx: Syntax, srcloc: SourceLocation): Syntax {
  return { ...stx, srcloc };
}

/**
 * Copy scopes from one syntax object to another.
 */
export function copyScopes(from: Syntax, to: Syntax): Syntax {
  return { ...to, scopes: [...from.scopes] };
}
// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/test/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/test/index.ts
// Test runner exports

export {
  type OmegaTestCase,
  type OmegaTestSpec,
  type CommandTestSpec,
  type TestSpec,
  type TestCaseResult,
  type TestReport,
  type EvalInEnv,
  type ShowVal,
  type RunCommand,
  TestRunner,
  createTestRunner,
} from "./testRunner";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/test/testRunner.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/test/testRunner.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Test runner with OmegaTests and CommandTests support

import type { Hash } from "../artifacts/hash";
import type { BudgetLimits } from "../governance/budgets";
import type { Budget } from "../governance/budgets";
import { budgetConsumeToolCall } from "../governance/budgets";
import type { CapSet } from "../governance/caps";
import { capRequire } from "../governance/caps";
import type { Val } from "../eval/values";

// =========================================================================
// Test Specification Types
// =========================================================================

export type OmegaTestCase = {
  name?: string;
  expr: string;
  expect: string;
};

export type OmegaTestSpec = {
  tag: "OmegaTests";
  cases: OmegaTestCase[];
  stepsLimit?: number;
};

export type CommandTestSpec = {
  tag: "CommandTests";
  argv: string[];
  cwd?: string;
};

export type TestSpec = OmegaTestSpec | CommandTestSpec;

// =========================================================================
// Test Report Types
// =========================================================================

export type TestCaseResult = {
  name: string;
  passed: boolean;
  actual?: string;
  expected?: string;
  error?: string;
};

export type TestReport = {
  tag: "TestReport";
  passed: boolean;
  cases: TestCaseResult[];
};

// =========================================================================
// Dependency Injection Types
// =========================================================================

export type EvalInEnv = (
  exprText: string,
  envRef: Hash,
  opts?: { stepsLimit?: number }
) => Promise<{ v: Val; envRef: Hash }>;

export type ShowVal = (v: Val) => string;

export type RunCommand = (
  argv: string[],
  cwd?: string
) => Promise<{ ok: boolean; stdout: string; stderr: string; code: number | null }>;

// =========================================================================
// Test Runner
// =========================================================================

export class TestRunner {
  constructor(
    private readonly evalInEnv: EvalInEnv,
    private readonly showVal: ShowVal,
    private readonly runCommand: RunCommand,
  ) {}

  async run(
    spec: TestSpec,
    envRef: Hash,
    caps: CapSet,
    budget: Budget,
  ): Promise<{ report: TestReport; budget: Budget }> {
    capRequire(caps, "test", "ReqTest");
    let b = budgetConsumeToolCall(budget); // Tests count as tool calls for budget

    if (spec.tag === "OmegaTests") {
      const cases: TestCaseResult[] = [];

      for (const tc of spec.cases) {
        const name = tc.name ?? tc.expr;
        try {
          const { v: actual } = await this.evalInEnv(tc.expr, envRef, { stepsLimit: spec.stepsLimit });
          const { v: expected } = await this.evalInEnv(tc.expect, envRef, { stepsLimit: spec.stepsLimit });

          const aS = this.showVal(actual);
          const eS = this.showVal(expected);
          const ok = aS === eS;

          cases.push({ name, passed: ok, actual: aS, expected: eS });
        } catch (e: unknown) {
          const msg = e instanceof Error ? e.message : String(e);
          cases.push({ name, passed: false, error: msg });
        }
      }

      const report: TestReport = {
        tag: "TestReport",
        passed: cases.every(c => c.passed),
        cases,
      };

      return { report, budget: b };
    }

    if (spec.tag === "CommandTests") {
      const { ok, stdout, stderr, code } = await this.runCommand(spec.argv, spec.cwd);

      const report: TestReport = {
        tag: "TestReport",
        passed: ok,
        cases: [{
          name: `command: ${spec.argv.join(" ")}`,
          passed: ok,
          actual: stdout.slice(0, 10_000),
          expected: "exitCode=0",
          error: ok ? undefined : (stderr.slice(0, 10_000) || `exitCode=${code}`),
        }],
      };

      return { report, budget: b };
    }

    // Unknown spec type
    const report: TestReport = {
      tag: "TestReport",
      passed: false,
      cases: [{ name: "unknown TestSpec", passed: false, error: "unknown TestSpec tag" }],
    };

    return { report, budget: b };
  }
}

// =========================================================================
// Convenience Factory
// =========================================================================

export function createTestRunner(
  evalInEnv: EvalInEnv,
  showVal: ShowVal,
  runCommand: RunCommand,
): TestRunner {
  return new TestRunner(evalInEnv, showVal, runCommand);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/tool/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/tool/index.ts
// Tool runner exports

export {
  type ToolCallBash,
  type ToolCallFSRead,
  type ToolCallFSWrite,
  type ToolCall,
  type ToolResultOk,
  type ToolResultFile,
  type ToolResultErr,
  type ToolResult,
  ToolRunner,
  createToolRunner,
} from "./toolRunner";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/tool/toolRunner.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/tool/toolRunner.ts
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-13-IMPLEMENTATION-18.md
// Tool runner with capability gating and budget enforcement

import { spawn } from "child_process";
import { promises as fs } from "fs";

import type { Budget } from "../governance/budgets";
import { budgetConsumeToolCall } from "../governance/budgets";
import type { CapSet } from "../governance/caps";
import { capRequire, capHas } from "../governance/caps";

// =========================================================================
// Tool Call Types
// =========================================================================

export type ToolCallBash = {
  tag: "ToolBash";
  argv: string[];
  cwd?: string;
  stdin?: string;
  timeoutMs?: number;
};

export type ToolCallFSRead = {
  tag: "ToolFSRead";
  path: string;
  encoding?: BufferEncoding;
};

export type ToolCallFSWrite = {
  tag: "ToolFSWrite";
  path: string;
  content: string;
  encoding?: BufferEncoding;
};

export type ToolCall = ToolCallBash | ToolCallFSRead | ToolCallFSWrite;

// =========================================================================
// Tool Result Types
// =========================================================================

export type ToolResultOk = {
  tag: "ToolOk";
  stdout?: string;
  stderr?: string;
  exitCode?: number;
};

export type ToolResultFile = {
  tag: "ToolFile";
  path: string;
  content: string;
};

export type ToolResultErr = {
  tag: "ToolErr";
  message: string;
  stderr?: string;
  exitCode?: number;
};

export type ToolResult = ToolResultOk | ToolResultFile | ToolResultErr;

// =========================================================================
// Tool Runner
// =========================================================================

export class ToolRunner {
  async run(
    call: ToolCall,
    caps: CapSet,
    budget: Budget,
  ): Promise<{ result: ToolResult; budget: Budget }> {
    // Capability checks - fine-grained per tool type
    if (call.tag === "ToolBash") {
      capRequire(caps, "tool.bash", "ReqTool(ToolBash)");
    }
    if (call.tag === "ToolFSRead") {
      capRequire(caps, "tool.fs.read", "ReqTool(ToolFSRead)");
    }
    if (call.tag === "ToolFSWrite") {
      capRequire(caps, "tool.fs.write", "ReqTool(ToolFSWrite)");
    }

    // Budget check
    const b = budgetConsumeToolCall(budget);

    // Execute the tool
    if (call.tag === "ToolFSRead") {
      try {
        const enc = call.encoding ?? "utf8";
        const content = await fs.readFile(call.path, { encoding: enc });
        return {
          result: { tag: "ToolFile", path: call.path, content: content.toString() },
          budget: b,
        };
      } catch (e: unknown) {
        const msg = e instanceof Error ? e.message : String(e);
        return {
          result: { tag: "ToolErr", message: `read failed: ${msg}` },
          budget: b,
        };
      }
    }

    if (call.tag === "ToolFSWrite") {
      try {
        const enc = call.encoding ?? "utf8";
        await fs.writeFile(call.path, call.content, { encoding: enc });
        return {
          result: { tag: "ToolOk", stdout: `wrote ${call.path}` },
          budget: b,
        };
      } catch (e: unknown) {
        const msg = e instanceof Error ? e.message : String(e);
        return {
          result: { tag: "ToolErr", message: `write failed: ${msg}` },
          budget: b,
        };
      }
    }

    if (call.tag === "ToolBash") {
      const res = await runCommand(call.argv, call.cwd, call.stdin, call.timeoutMs);
      if (!res.ok) {
        return {
          result: {
            tag: "ToolErr",
            message: "command failed",
            stderr: res.stderr,
            exitCode: res.code ?? undefined,
          },
          budget: b,
        };
      }
      return {
        result: {
          tag: "ToolOk",
          stdout: res.stdout,
          stderr: res.stderr,
          exitCode: res.code ?? undefined,
        },
        budget: b,
      };
    }

    return {
      result: { tag: "ToolErr", message: `unknown ToolCall tag ${(call as ToolCall).tag}` },
      budget: b,
    };
  }
}

// =========================================================================
// Command Runner Helper
// =========================================================================

async function runCommand(
  argv: string[],
  cwd?: string,
  stdin?: string,
  timeoutMs?: number
): Promise<{ ok: boolean; stdout: string; stderr: string; code: number | null }> {
  const [cmd, ...args] = argv;
  if (!cmd) return { ok: false, stdout: "", stderr: "empty argv", code: 127 };

  return await new Promise((resolve) => {
    const child = spawn(cmd, args, { cwd, stdio: "pipe", shell: process.platform === "win32" });

    let stdout = "";
    let stderr = "";

    child.stdout.setEncoding("utf8");
    child.stderr.setEncoding("utf8");

    child.stdout.on("data", (d) => { stdout += d; });
    child.stderr.on("data", (d) => { stderr += d; });

    if (stdin != null) {
      child.stdin.write(stdin);
      child.stdin.end();
    }

    let killed = false;
    let t: ReturnType<typeof setTimeout> | undefined;
    if (timeoutMs != null) {
      t = setTimeout(() => {
        killed = true;
        child.kill("SIGKILL");
      }, timeoutMs);
    }

    child.on("close", (code) => {
      if (t) clearTimeout(t);
      const ok = !killed && (code === 0);
      resolve({ ok, stdout, stderr, code });
    });

    child.on("error", (err) => {
      if (t) clearTimeout(t);
      resolve({ ok: false, stdout, stderr: err.message, code: null });
    });
  });
}

// =========================================================================
// Convenience Factory
// =========================================================================

export function createToolRunner(): ToolRunner {
  return new ToolRunner();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/tools/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/tools/index.ts
// Tool system exports

export {
  ToolRegistry,
  ToolResult,
  ToolDef,
  createShellTool,
  createReadFileTool,
  createWriteFileTool,
  createGrepTool,
  getDefaultRegistry,
  setDefaultRegistry,
} from "./registry";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/core/tools/registry.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/core/tools/registry.ts
// Tool Registry for executing oracle tool calls
// SOURCE: REQUIREMENTS.md Section 2-3

import type { ToolCall } from "../oracle/protocol";
import type { Val } from "../eval/values";
import { capRequire, capHas, type CapSet } from "../governance/caps";
import type { BudgetTracker } from "../governance/budgets";

/**
 * Tool execution result.
 */
export type ToolResult = {
  success: boolean;
  output?: string;
  error?: string;
  exitCode?: number;
  durationMs?: number;
};

/**
 * Tool definition.
 */
export type ToolDef = {
  name: string;
  description?: string;
  requiredCap?: string;  // Capability required to use this tool
  handler: (call: ToolCall) => Promise<ToolResult>;
};

/**
 * Tool Registry - manages tool registration and execution.
 */
export class ToolRegistry {
  private tools = new Map<string, ToolDef>();
  private caps?: CapSet;
  private budget?: BudgetTracker;

  constructor(opts?: { caps?: CapSet; budget?: BudgetTracker }) {
    this.caps = opts?.caps;
    this.budget = opts?.budget;
  }

  /** Set capabilities for tool authorization. */
  setCapSet(caps: CapSet): void {
    this.caps = caps;
  }

  /** Set budget tracker for tool call accounting. */
  setBudget(budget: BudgetTracker): void {
    this.budget = budget;
  }

  /** Register a tool. */
  register(def: ToolDef): void {
    this.tools.set(def.name, def);
  }

  /** Unregister a tool. */
  unregister(name: string): boolean {
    return this.tools.delete(name);
  }

  /** Check if a tool is registered. */
  has(name: string): boolean {
    return this.tools.has(name);
  }

  /** Get tool definition. */
  get(name: string): ToolDef | undefined {
    return this.tools.get(name);
  }

  /** List all registered tool names. */
  list(): string[] {
    return Array.from(this.tools.keys());
  }

  /**
   * Execute a tool call.
   * Enforces capabilities and budget constraints.
   */
  async execute(call: ToolCall): Promise<ToolResult> {
    const tool = this.tools.get(call.name);
    if (!tool) {
      return {
        success: false,
        error: `unknown tool: ${call.name}`,
      };
    }

    // Check capability
    if (tool.requiredCap && this.caps) {
      if (!capHas(this.caps, tool.requiredCap)) {
        return {
          success: false,
          error: `missing capability for tool ${call.name}: requires ${tool.requiredCap}`,
        };
      }
    }

    // Consume budget
    this.budget?.consumeToolCall();

    // Execute with timing
    const t0 = Date.now();
    try {
      const result = await tool.handler(call);
      result.durationMs = Date.now() - t0;
      return result;
    } catch (e: any) {
      return {
        success: false,
        error: e?.message ?? String(e),
        durationMs: Date.now() - t0,
      };
    }
  }
}

/**
 * Create a shell tool that executes commands.
 * This is a factory function - the actual execution is delegated to a shell adapter.
 */
export function createShellTool(
  shellAdapter: (cmd: string, opts: { cwd?: string; stdin?: string; timeoutMs?: number }) => Promise<{ stdout: string; stderr: string; exitCode: number }>
): ToolDef {
  return {
    name: "shell",
    description: "Execute a shell command",
    requiredCap: "tool.shell",
    handler: async (call: ToolCall): Promise<ToolResult> => {
      const cmd = [call.name, ...call.argv].join(" ");
      try {
        const { stdout, stderr, exitCode } = await shellAdapter(cmd, {
          cwd: call.cwd,
          stdin: call.stdin,
          timeoutMs: call.timeoutMs ?? 30000,
        });
        return {
          success: exitCode === 0,
          output: stdout + (stderr ? `\n[stderr]: ${stderr}` : ""),
          exitCode,
        };
      } catch (e: any) {
        return {
          success: false,
          error: e?.message ?? String(e),
        };
      }
    },
  };
}

/**
 * Create a read-file tool.
 */
export function createReadFileTool(
  readFile: (path: string) => Promise<string>
): ToolDef {
  return {
    name: "read_file",
    description: "Read contents of a file",
    requiredCap: "tool.fs.read",
    handler: async (call: ToolCall): Promise<ToolResult> => {
      const path = call.argv[0];
      if (!path) {
        return { success: false, error: "read_file requires a path argument" };
      }
      try {
        const content = await readFile(path);
        return { success: true, output: content };
      } catch (e: any) {
        return { success: false, error: e?.message ?? String(e) };
      }
    },
  };
}

/**
 * Create a write-file tool.
 */
export function createWriteFileTool(
  writeFile: (path: string, content: string) => Promise<void>
): ToolDef {
  return {
    name: "write_file",
    description: "Write contents to a file",
    requiredCap: "tool.fs.write",
    handler: async (call: ToolCall): Promise<ToolResult> => {
      const path = call.argv[0];
      const content = call.stdin ?? call.argv[1];
      if (!path) {
        return { success: false, error: "write_file requires a path argument" };
      }
      if (content === undefined) {
        return { success: false, error: "write_file requires content (stdin or second arg)" };
      }
      try {
        await writeFile(path, content);
        return { success: true, output: `wrote ${content.length} bytes to ${path}` };
      } catch (e: any) {
        return { success: false, error: e?.message ?? String(e) };
      }
    },
  };
}

/**
 * Create a grep tool for searching files.
 */
export function createGrepTool(
  grep: (pattern: string, paths: string[]) => Promise<{ matches: Array<{ file: string; line: number; text: string }> }>
): ToolDef {
  return {
    name: "grep",
    description: "Search for pattern in files",
    requiredCap: "tool.fs.read",
    handler: async (call: ToolCall): Promise<ToolResult> => {
      const [pattern, ...paths] = call.argv;
      if (!pattern) {
        return { success: false, error: "grep requires a pattern argument" };
      }
      try {
        const { matches } = await grep(pattern, paths.length > 0 ? paths : ["."]);
        const output = matches.map(m => `${m.file}:${m.line}: ${m.text}`).join("\n");
        return { success: true, output: output || "(no matches)" };
      } catch (e: any) {
        return { success: false, error: e?.message ?? String(e) };
      }
    },
  };
}

// Default global registry instance
let defaultRegistry: ToolRegistry | undefined;

/** Get or create the default global tool registry. */
export function getDefaultRegistry(): ToolRegistry {
  if (!defaultRegistry) {
    defaultRegistry = new ToolRegistry();
  }
  return defaultRegistry;
}

/** Set the default global tool registry. */
export function setDefaultRegistry(registry: ToolRegistry): void {
  defaultRegistry = registry;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/devtools/beadsMismatch.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/devtools/beadsMismatch.ts
// Helpers for parsing and resolving beads repository mismatch warnings.

export const BEADS_REPO_MISMATCH_MARKER = "DATABASE MISMATCH DETECTED!";

const DATABASE_REPO_ID_PATTERN = /Database repo ID:\s*([0-9a-fA-F]+)/;
const CURRENT_REPO_ID_PATTERN = /Current repo ID:\s*([0-9a-fA-F]+)/;
const MISSING_IDS_MESSAGE = "Beads mismatch message missing repository IDs.";

export type BeadsRepoMismatch = {
  databaseRepoId: string;
  currentRepoId: string;
};

export type BeadsRepoMismatchFix = {
  action: string;
  reason: string;
  risk?: "low" | "medium" | "high";
};

const RECOMMENDED_FIXES: BeadsRepoMismatchFix[] = [
  {
    action: "bd migrate --update-repo-id",
    reason: "Update the database repo fingerprint to match the current repository.",
    risk: "low",
  },
  {
    action: "rm -rf .beads && bd init",
    reason: "Recreate the local beads database if it belongs to a different repository.",
    risk: "medium",
  },
  {
    action: "BEADS_IGNORE_REPO_MISMATCH=1 bd daemon",
    reason: "Ignore the mismatch warning to access data (use only if you trust the database).",
    risk: "high",
  },
];

const STRING_TYPE_ERROR = "Beads mismatch message must be a string.";

function requireNonEmptyRepoId(value: unknown, label: string): string {
  if (typeof value !== "string" || value.trim().length === 0) {
    throw new Error(`${label} repo id is required.`);
  }
  return value.trim();
}

export function parseBeadsRepoMismatch(message: unknown): BeadsRepoMismatch | null {
  if (typeof message !== "string") {
    throw new TypeError(STRING_TYPE_ERROR);
  }

  if (!message.includes(BEADS_REPO_MISMATCH_MARKER)) {
    return null;
  }

  const databaseMatch = message.match(DATABASE_REPO_ID_PATTERN);
  const currentMatch = message.match(CURRENT_REPO_ID_PATTERN);

  if (!databaseMatch || !currentMatch) {
    throw new Error(MISSING_IDS_MESSAGE);
  }

  return {
    databaseRepoId: requireNonEmptyRepoId(databaseMatch[1], "Database"),
    currentRepoId: requireNonEmptyRepoId(currentMatch[1], "Current"),
  };
}

export function getBeadsRepoMismatchFixes(mismatch: BeadsRepoMismatch): BeadsRepoMismatchFix[] {
  if (!mismatch || typeof mismatch !== "object") {
    throw new TypeError("Beads mismatch details are required.");
  }

  requireNonEmptyRepoId(mismatch.databaseRepoId, "Database");
  requireNonEmptyRepoId(mismatch.currentRepoId, "Current");

  return RECOMMENDED_FIXES.map((fix) => ({ ...fix }));
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir.ts
// ═══════════════════════════════════════════════════════════════════════════

import { createHash } from "crypto";

// FrameIR base value type: deterministic JSON-compatible structure
export type ScalarIR = string | number | boolean | null;
export type ValueIR = ScalarIR | ValueIR[] | { [key: string]: ValueIR };

export type MessageIR = {
  role: string;
  content: ValueIR | string;
  name?: string;
  metadata?: ValueIR;
};

export type PromptIR = {
  kind: "prompt";
  messages: MessageIR[];
  metadata?: ValueIR;
};

export type FlowStepIR = {
  id: string;
  prompt: PromptIR;
  input?: ValueIR;
  metadata?: ValueIR;
};

export type FlowIR = {
  kind: "flow";
  steps: FlowStepIR[];
  metadata?: ValueIR;
};

export type FrameValue = ValueIR | PromptIR | FlowIR;

export type MerkleObjectEntry = { key: string; node: MerkleNode };
export type MerkleObjectNode = { type: "object"; entries: MerkleObjectEntry[]; hash: string };
export type MerkleArrayNode = { type: "array"; items: MerkleNode[]; hash: string };
export type MerkleValueNode = { type: "value"; value: ScalarIR; hash: string };
export type MerkleNode = MerkleObjectNode | MerkleArrayNode | MerkleValueNode;

type CanonicalValue = ScalarIR | CanonicalValue[] | { [key: string]: CanonicalValue };

/**
 * Encode FrameIR into canonical JSON (sorted object keys, rejects non-JSON inputs).
 */
export function canonicalJson(value: FrameValue): string {
  const canonical = canonicalize(value);
  return JSON.stringify(canonical);
}

/**
 * Compute a merkle hash (sha256 hex) of the canonical JSON encoding.
 */
export function merkleHash(value: FrameValue): string {
  const canonical = canonicalize(value);
  return sha256Hex(JSON.stringify(canonical));
}

/**
 * Build a merkle tree for the given FrameIR value.
 */
export function merkleize(value: FrameValue): MerkleNode {
  const canonical = canonicalize(value);
  return buildMerkleNode(canonical);
}

function canonicalize(value: unknown): CanonicalValue {
  if (value === null) return null;

  const t = typeof value;

  if (t === "string" || t === "boolean") return value as CanonicalValue;

  if (t === "number") {
    if (Number.isNaN(value)) throw new Error("canonicalJson: NaN is not supported");
    if (!Number.isFinite(value)) throw new Error("canonicalJson: expected finite number");
    return value as CanonicalValue;
  }

  if (Array.isArray(value)) {
    return value.map(canonicalize);
  }

  if (t === "object") {
    const proto = Object.getPrototypeOf(value as object);
    if (proto !== Object.prototype && proto !== null) {
      throw new Error("Unsupported type for canonicalJson: object prototype not supported");
    }

    const source = value as Record<string, unknown>;
    const keys = Object.keys(source).sort();
    const out: Record<string, CanonicalValue> = {};

    for (const key of keys) {
      const v = source[key];
      if (typeof v === "undefined") throw new Error("canonicalJson: undefined values are not supported");
      out[key] = canonicalize(v);
    }
    return out;
  }

  throw new Error(`Unsupported type for canonicalJson: ${t}`);
}

function buildMerkleNode(value: CanonicalValue): MerkleNode {
  if (Array.isArray(value)) {
    const items = value.map(buildMerkleNode);
    return {
      type: "array",
      items,
      hash: sha256Hex(JSON.stringify(value)),
    };
  }

  if (value !== null && typeof value === "object") {
    const entries = Object.keys(value)
      .sort()
      .map(key => ({ key, node: buildMerkleNode((value as Record<string, CanonicalValue>)[key]) }));
    return {
      type: "object",
      entries,
      hash: sha256Hex(JSON.stringify(value)),
    };
  }

  return {
    type: "value",
    value: value as ScalarIR,
    hash: sha256Hex(JSON.stringify(value)),
  };
}

function sha256Hex(s: string): string {
  return createHash("sha256").update(s).digest("hex");
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/bundle.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { IRVersion } from "./version";
import type { ValueIR } from "./value";
import type { FlowIR } from "./flow";
import type { SchemaIR } from "./schema";
import type { ToolContractIR } from "./contract";

// Closure-converted function definition
export interface FnDefIR extends NodeBase {
  tag: "FnDef";
  fnId: string;
  params: string[];
  body: FlowIR | ValueIR;
  captures?: ValueIR;
}

// Complete IR bundle (the unit of compilation/caching)
export interface IRBundle {
  v: IRVersion;
  entry: FlowIR;
  fns: Record<string, FnDefIR>;
  schemas: Record<string, SchemaIR>;
  toolContracts: Record<string, ToolContractIR>;
  modules?: Record<string, string[]>;
  docs?: Record<string, string>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/codec.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";

/**
 * Encode an IR node to a canonical JSON string.
 * - Object keys are sorted lexicographically
 * - Optional meta is excluded unless explicitly requested
 * - Arrays preserve order
 */
export function encodeCanonical(node: NodeBase, options?: { includeMeta?: boolean }): string {
  return JSON.stringify(node, (_key, value) => {
    if (!options?.includeMeta && _key === "meta") {
      return undefined;
    }

    if (value && typeof value === "object" && !Array.isArray(value)) {
      const sorted: Record<string, unknown> = {};
      for (const k of Object.keys(value).sort()) {
        sorted[k] = (value as Record<string, unknown>)[k];
      }
      return sorted;
    }

    return value;
  });
}

/**
 * Decode a canonical JSON string into an IR node.
 * Validates that the required discriminator fields exist.
 */
export function decode<T extends NodeBase>(json: string): T {
  const node = JSON.parse(json);
  if (!node || typeof node !== "object") {
    throw new Error("Invalid IR node: expected object");
  }
  if (!("v" in node)) {
    throw new Error("Invalid IR node: missing v");
  }
  if (!("tag" in node)) {
    throw new Error("Invalid IR node: missing tag");
  }
  return node as T;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/contract.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { VRef } from "./value";

export interface ToolContractIR extends NodeBase {
  tag: "ToolContract";
  id: string;
  name: string;
  version: string;

  inputSchema: VRef;
  outputSchema: VRef;
  errorSchema?: VRef;

  idempotency: "idempotent" | "non-idempotent" | "unknown";
  capabilityTag: string;
  quotaGroup?: string;

  resourceModel?: {
    typicalTimeMs?: number;
    worstTimeMs?: number;
    typicalTokens?: number;
  };

  provenancePolicy?: {
    mustAttachEvidence?: boolean;
    evidenceMode?: Array<"observed" | "measured" | "derived">;
    stalenessInputs?: Array<"toolContract" | "schema" | "sourceFingerprint" | "oracleConfig">;
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/expr.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { ValueIR } from "./value";

// Boolean ops
export interface EIf extends NodeBase { tag: "EIf"; cond: ValueIR; then: ValueIR; else: ValueIR }
export interface EEq extends NodeBase { tag: "EEq"; a: ValueIR; b: ValueIR }
export interface ENot extends NodeBase { tag: "ENot"; x: ValueIR }
export interface EAnd extends NodeBase { tag: "EAnd"; xs: ValueIR[] }
export interface EOr extends NodeBase { tag: "EOr"; xs: ValueIR[] }

// Arithmetic ops
export interface EAdd extends NodeBase { tag: "EAdd"; xs: ValueIR[] }
export interface ESub extends NodeBase { tag: "ESub"; xs: ValueIR[] }
export interface EMul extends NodeBase { tag: "EMul"; xs: ValueIR[] }
export interface EDiv extends NodeBase { tag: "EDiv"; a: ValueIR; b: ValueIR }
export interface EMod extends NodeBase { tag: "EMod"; a: ValueIR; b: ValueIR }

// Map ops
export interface EGet extends NodeBase { tag: "EGet"; map: ValueIR; key: ValueIR; default?: ValueIR }
export interface EAssoc extends NodeBase { tag: "EAssoc"; map: ValueIR; key: ValueIR; val: ValueIR }

// Primitive call
export interface ECallPrim extends NodeBase {
  tag: "ECallPrim";
  prim: string;
  args: ValueIR[];
}

export type VExpr =
  | EIf | EEq | ENot | EAnd | EOr
  | EAdd | ESub | EMul | EDiv | EMod
  | EGet | EAssoc
  | ECallPrim;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/flow.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { ValueIR, VRef } from "./value";
import type { PromptIR } from "./prompt";

// Pure value
export interface FPure extends NodeBase { tag: "FPure"; value: ValueIR }

// Monadic bind (binder is Fn reference, closure-converted)
export interface FBind extends NodeBase {
  tag: "FBind";
  flow: FlowIR;
  k: VRef;
}

// Error handling
export interface FCatch extends NodeBase {
  tag: "FCatch";
  flow: FlowIR;
  handler: VRef;
}

export interface FFail extends NodeBase {
  tag: "FFail";
  reason: ValueIR;
  ctx?: ValueIR;
}

// Resource control
export interface FWithBudget extends NodeBase {
  tag: "FWithBudget";
  budget: ValueIR;
  flow: FlowIR;
}

export interface FWithTimeout extends NodeBase {
  tag: "FWithTimeout";
  ms: ValueIR;
  flow: FlowIR;
}

// Concurrency
export interface FAll extends NodeBase { tag: "FAll"; flows: FlowIR[] }
export interface FRace extends NodeBase { tag: "FRace"; flows: FlowIR[] }
export interface FAny extends NodeBase { tag: "FAny"; flows: FlowIR[] }
export interface FSequence extends NodeBase { tag: "FSequence"; flows: FlowIR[] }

// Control flow
export interface FBranch extends NodeBase {
  tag: "FBranch";
  pred: ValueIR;
  then: FlowIR;
  else: FlowIR;
}

export interface FLoop extends NodeBase {
  tag: "FLoop";
  init: ValueIR;
  step: VRef;
  until: VRef;
}

// Effects (PortEffects - must emit spans, be replay-loggable)
export interface FInfer extends NodeBase {
  tag: "FInfer";
  prompt: PromptIR;
  options?: ValueIR;
}

export interface FToolCall extends NodeBase {
  tag: "FToolCall";
  tool: ValueIR;
  args: ValueIR;
  contract?: VRef;
}

export interface FValidate extends NodeBase {
  tag: "FValidate";
  schema: VRef;
  value: ValueIR;
}

export interface FCommit extends NodeBase {
  tag: "FCommit";
  store: VRef;
  key: ValueIR;
  value: ValueIR;
}

export interface FEmit extends NodeBase {
  tag: "FEmit";
  sink: VRef;
  item: ValueIR;
}

export interface FObserve extends NodeBase {
  tag: "FObserve";
  source: VRef;
  query?: ValueIR;
}

export interface FSuspend extends NodeBase {
  tag: "FSuspend";
  reason: ValueIR;
}

// Union of all flow types
export type FlowIR =
  | FPure
  | FBind
  | FCatch
  | FFail
  | FWithBudget
  | FWithTimeout
  | FAll | FRace | FAny | FSequence
  | FBranch
  | FLoop
  | FInfer
  | FToolCall
  | FValidate
  | FCommit
  | FEmit
  | FObserve
  | FSuspend;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/hash.ts
// ═══════════════════════════════════════════════════════════════════════════

import { createHash } from "crypto";
import type { NodeBase } from "./meta";
import { encodeCanonical } from "./codec";
import type { FlowIR } from "./flow";

export type NodeHash = `ir:sha256:${string}`;

/**
 * Compute a semantic hash for an IR node. Meta is excluded by default.
 */
export function hashNode(node: NodeBase, semanticSalt?: string): NodeHash {
  const canonical = encodeCanonical(node, { includeMeta: false });
  const input = semanticSalt ? `${canonical}:${semanticSalt}` : canonical;
  const digest = createHash("sha256").update(input).digest("hex").slice(0, 32);
  return `ir:sha256:${digest}`;
}

/**
 * Compute a merkle hash for a flow graph. Each node hash includes child hashes.
 */
export function merkleize(flow: FlowIR): Map<FlowIR, NodeHash> {
  const hashes = new Map<FlowIR, NodeHash>();

  const visit = (node: FlowIR): NodeHash => {
    if (hashes.has(node)) return hashes.get(node)!;
    const nodeWithChildHashes = replaceChildFlowsWithHashes(node, visit);
    const hash = hashNode(nodeWithChildHashes);
    hashes.set(node, hash);
    return hash;
  };

  visit(flow);
  return hashes;
}

function replaceChildFlowsWithHashes(node: FlowIR, getHash: (f: FlowIR) => NodeHash): NodeBase {
  switch (node.tag) {
    case "FBind":
      return { ...node, flow: getHash(node.flow) } as unknown as NodeBase;

    case "FCatch":
      return { ...node, flow: getHash(node.flow) } as unknown as NodeBase;

    case "FWithBudget":
      return { ...node, flow: getHash(node.flow) } as unknown as NodeBase;

    case "FWithTimeout":
      return { ...node, flow: getHash(node.flow) } as unknown as NodeBase;

    case "FAll":
    case "FRace":
    case "FAny":
    case "FSequence":
      return { ...node, flows: node.flows.map(getHash) } as unknown as NodeBase;

    case "FBranch":
      return { ...node, then: getHash(node.then), else: getHash(node.else) } as unknown as NodeBase;

    // Nodes without child flows
    case "FPure":
    case "FFail":
    case "FLoop":
    case "FInfer":
    case "FToolCall":
    case "FValidate":
    case "FCommit":
    case "FEmit":
    case "FObserve":
    case "FSuspend":
      return { ...node };
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./version";
export * from "./meta";
export * from "./value";
export * from "./expr";
export * from "./prompt";
export * from "./flow";
export * from "./bundle";
export * from "./schema";
export * from "./contract";
export * from "./codec";
export * from "./hash";
export * from "./normalize";
export * from "./visitor";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/meta.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { IRVersion } from "./version";

export interface Span {
  file?: string;
  startLine?: number;
  startCol?: number;
  endLine?: number;
  endCol?: number;
}

export interface Meta {
  span?: Span;
  doc?: string;
  attrs?: Record<string, unknown>;
}

export interface NodeBase {
  v: IRVersion;
  tag: string;
  meta?: Meta;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/normalize.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { PromptIR, PromptDoc, PromptPart } from "./prompt";
import type { FlowIR, FSequence, FAll, FPure } from "./flow";
import type { VList } from "./value";
import { CURRENT_IR_VERSION } from "./version";

/**
 * Normalize prompt document:
 * - Flattens nested PromptDoc parts
 * - Removes empty text segments
 * - Recursively normalizes inner prompt containers
 */
export function normalizePrompt(prompt: PromptIR): PromptIR {
  const flattenPart = (part: PromptPart | PromptDoc): PromptPart[] => {
    if ((part as PromptDoc).tag === "PromptDoc") {
      return normalizePrompt(part as PromptDoc).parts;
    }

    switch (part.tag) {
      case "PXml":
      case "PTransform":
      case "PAttachSchema":
      case "PAttachFormat":
      case "PAttachTools": {
        const innerNormalized = normalizePrompt(part.inner);
        return [{ ...part, inner: innerNormalized } as PromptPart];
      }
      case "PNumbered": {
        return [{ ...part, items: part.items.map(normalizePrompt) } as PromptPart];
      }
      default:
        return [part as PromptPart];
    }
  };

  const flatParts: PromptPart[] = [];
  for (const part of prompt.parts) {
    flatParts.push(...flattenPart(part));
  }

  const nonEmpty = flatParts.filter(p => {
    if (p.tag === "PSystem" || p.tag === "PUser" || p.tag === "PAssistant") {
      return (p as { text: string }).text.trim().length > 0;
    }
    return true;
  });

  const merged: PromptPart[] = [];
  for (const part of nonEmpty) {
    const last = merged[merged.length - 1];
    if (
      last &&
      ("text" in last) &&
      ("text" in part) &&
      (last as any).tag === (part as any).tag
    ) {
      merged[merged.length - 1] = { ...(last as any), text: `${(last as any).text}${(last as any).text ? "\n" : ""}${(part as any).text}` };
    } else {
      merged.push(part);
    }
  }

  return {
    v: prompt.v ?? CURRENT_IR_VERSION,
    tag: "PromptDoc",
    parts: merged,
    meta: prompt.meta,
  };
}

/**
 * Normalize flow graph:
 * - Flattens nested FSequence nodes
 * - Collapses FAll([]) into FPure([]) for deterministic semantics
 */
export function normalizeFlow(flow: FlowIR): FlowIR {
  switch (flow.tag) {
    case "FSequence": {
      const normalizedChildren = flow.flows.map(normalizeFlow);
      const flat: FlowIR[] = [];
      for (const child of normalizedChildren) {
        if (child.tag === "FSequence") {
          flat.push(...(child as FSequence).flows);
        } else {
          flat.push(child);
        }
      }
      return { ...flow, flows: flat };
    }

    case "FAll": {
      if (flow.flows.length === 0) {
        return {
          v: flow.v ?? CURRENT_IR_VERSION,
          tag: "FPure",
          value: { v: flow.v ?? CURRENT_IR_VERSION, tag: "VList", items: [] } as VList,
        } as FPure;
      }
      return { ...flow, flows: flow.flows.map(normalizeFlow) };
    }

    case "FAny":
    case "FRace":
      return { ...flow, flows: flow.flows.map(normalizeFlow) };

    case "FBind":
    case "FCatch":
    case "FWithBudget":
    case "FWithTimeout":
      return { ...flow, flow: normalizeFlow(flow.flow) };

    case "FBranch":
      return { ...flow, then: normalizeFlow(flow.then), else: normalizeFlow(flow.else) };

    case "FCommit":
    case "FEmit":
    case "FFail":
    case "FInfer":
    case "FLoop":
    case "FObserve":
    case "FValidate":
    case "FToolCall":
    case "FPure":
    case "FSuspend":
      return flow;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/prompt.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { ValueIR, VRef } from "./value";

// Role-based segments
export interface PSystem extends NodeBase { tag: "PSystem"; text: string }
export interface PUser extends NodeBase { tag: "PUser"; text: string }
export interface PAssistant extends NodeBase { tag: "PAssistant"; text: string }

// Few-shot examples
export interface PFewShot extends NodeBase {
  tag: "PFewShot";
  examples: Array<{ user: string; assistant: string }>;
}

// Data embedding
export interface PData extends NodeBase { tag: "PData"; value: ValueIR }

// Structure wrappers
export interface PXml extends NodeBase { tag: "PXml"; tagName: string; inner: PromptIR }
export interface PCodeBlock extends NodeBase { tag: "PCodeBlock"; lang: string; code: string }
export interface PNumbered extends NodeBase { tag: "PNumbered"; items: PromptIR[] }

// Attachments (for tools/schemas)
export interface PAttachTools extends NodeBase {
  tag: "PAttachTools";
  tools: VRef[];
  inner: PromptIR;
}

export interface PAttachSchema extends NodeBase {
  tag: "PAttachSchema";
  schema: VRef;
  inner: PromptIR;
}

export interface PAttachFormat extends NodeBase {
  tag: "PAttachFormat";
  format: { kind: "json" | "xml" | "text"; details?: ValueIR };
  inner: PromptIR;
}

// Transforms
export interface PTransform extends NodeBase {
  tag: "PTransform";
  transform: string;
  inner: PromptIR;
}

export type PromptPart =
  | PSystem | PUser | PAssistant
  | PFewShot
  | PData
  | PXml | PCodeBlock | PNumbered
  | PAttachTools | PAttachSchema | PAttachFormat
  | PTransform;

// Top-level prompt document
export interface PromptDoc extends NodeBase {
  tag: "PromptDoc";
  parts: PromptPart[];
}

export type PromptIR = PromptDoc;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/schema.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";

// Atomic schema nodes
export interface SAny extends NodeBase { tag: "SAny" }
export interface SString extends NodeBase { tag: "SString" }
export interface SNumber extends NodeBase { tag: "SNumber" }
export interface SInt extends NodeBase { tag: "SInt" }
export interface SBool extends NodeBase { tag: "SBool" }
export interface SNil extends NodeBase { tag: "SNil" }

// Compound schema nodes
export interface SList extends NodeBase { tag: "SList"; item: FrameSchemaNode }
export interface SRecord extends NodeBase {
  tag: "SRecord";
  fields: Array<{ key: string; schema: FrameSchemaNode; optional?: boolean }>;
  closed?: boolean;
}
export interface SUnion extends NodeBase { tag: "SUnion"; options: FrameSchemaNode[] }
export interface SRef extends NodeBase { tag: "SRef"; schemaId: string }

export type FrameSchemaNode =
  | SAny | SString | SNumber | SInt | SBool | SNil
  | SList | SRecord
  | SUnion
  | SRef;

// Top-level schema (supports both FrameSchema and JSON Schema)
export interface SchemaIR extends NodeBase {
  tag: "Schema";
  id: string;
  kind: "JsonSchema" | "FrameSchema";
  jsonSchema?: unknown;
  frameSchema?: FrameSchemaNode;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/value.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { NodeBase } from "./meta";
import type { VExpr } from "./expr";

// Primitive values
export interface VNil extends NodeBase { tag: "VNil" }
export interface VBool extends NodeBase { tag: "VBool"; value: boolean }
export interface VInt extends NodeBase { tag: "VInt"; value: string }
export interface VFloat extends NodeBase { tag: "VFloat"; value: string }
export interface VStr extends NodeBase { tag: "VStr"; value: string }
export interface VSymbol extends NodeBase { tag: "VSymbol"; name: string }
export interface VKeyword extends NodeBase { tag: "VKeyword"; name: string }

// Compound values
export interface VList extends NodeBase { tag: "VList"; items: ValueIR[] }
export interface VRecord extends NodeBase {
  tag: "VRecord";
  entries: Array<{ k: ValueIR; v: ValueIR }>;
}

// References (into bundle or external resources)
export type RefKind = "Global" | "Fn" | "ToolContract" | "Schema" | "Store" | "Sink" | "Source";

export interface VRef extends NodeBase {
  tag: "VRef";
  ref: {
    kind: RefKind;
    id: string;
    name?: string;
  };
}

// Union of all value types
export type ValueIR =
  | VNil | VBool | VInt | VFloat | VStr | VSymbol | VKeyword
  | VList | VRecord
  | VRef
  | VExpr;

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/version.ts
// ═══════════════════════════════════════════════════════════════════════════

export type IRVersion = "frameir@1";

export const CURRENT_IR_VERSION: IRVersion = "frameir@1";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/frameir/visitor.ts
// ═══════════════════════════════════════════════════════════════════════════

import type {
  FlowIR,
  FPure,
  FBind,
  FCatch,
  FFail,
  FWithBudget,
  FWithTimeout,
  FAll,
  FRace,
  FAny,
  FSequence,
  FBranch,
  FLoop,
  FInfer,
  FToolCall,
  FValidate,
  FCommit,
  FEmit,
  FObserve,
  FSuspend,
} from "./flow";

export interface FlowVisitor<R> {
  visitFPure?(node: FPure): R;
  visitFBind?(node: FBind): R;
  visitFCatch?(node: FCatch): R;
  visitFFail?(node: FFail): R;
  visitFWithBudget?(node: FWithBudget): R;
  visitFWithTimeout?(node: FWithTimeout): R;
  visitFAll?(node: FAll): R;
  visitFRace?(node: FRace): R;
  visitFAny?(node: FAny): R;
  visitFSequence?(node: FSequence): R;
  visitFBranch?(node: FBranch): R;
  visitFLoop?(node: FLoop): R;
  visitFInfer?(node: FInfer): R;
  visitFToolCall?(node: FToolCall): R;
  visitFValidate?(node: FValidate): R;
  visitFCommit?(node: FCommit): R;
  visitFEmit?(node: FEmit): R;
  visitFObserve?(node: FObserve): R;
  visitFSuspend?(node: FSuspend): R;
  default(node: FlowIR): R;
}

export function visitFlow<R>(flow: FlowIR, visitor: FlowVisitor<R>): R {
  const method = visitor[`visit${flow.tag}` as keyof FlowVisitor<R>];
  if (typeof method === "function") {
    return (method as (n: FlowIR) => R)(flow);
  }
  return visitor.default(flow);
}

/**
 * Recursively rewrite a flow graph by applying a transform to each node.
 * If transform returns a non-null node, it replaces the current node without descending.
 */
export function rewriteFlow(
  flow: FlowIR,
  transform: (node: FlowIR) => FlowIR | null
): FlowIR {
  const transformed = transform(flow);
  if (transformed !== null) {
    return transformed;
  }

  switch (flow.tag) {
    case "FBind":
    case "FCatch":
    case "FWithBudget":
    case "FWithTimeout": {
      const rewritten = rewriteFlow(flow.flow, transform);
      return rewritten === flow.flow ? flow : { ...flow, flow: rewritten };
    }

    case "FAll":
    case "FRace":
    case "FAny":
    case "FSequence": {
      const rewritten = flow.flows.map(f => rewriteFlow(f, transform));
      const changed = rewritten.some((f, i) => f !== flow.flows[i]);
      return changed ? { ...flow, flows: rewritten } : flow;
    }

    case "FBranch": {
      const thenFlow = rewriteFlow(flow.then, transform);
      const elseFlow = rewriteFlow(flow.else, transform);
      if (thenFlow === flow.then && elseFlow === flow.else) {
        return flow;
      }
      return { ...flow, then: thenFlow, else: elseFlow };
    }

    case "FPure":
    case "FFail":
    case "FLoop":
    case "FInfer":
    case "FToolCall":
    case "FValidate":
    case "FCommit":
    case "FEmit":
    case "FObserve":
    case "FSuspend":
      return flow;
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/index.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/index.ts
// Omega Language - Public API
//
// Clean interface for VS Code extensions, CLI tools, and external integrations.

// ═══════════════════════════════════════════════════════════════════════════════
// CORE RUNTIME
// ═══════════════════════════════════════════════════════════════════════════════

export { OmegaRuntime, evalOmegaCode, type OmegaConfig, type EvalResult, type InferResult } from "./runtime";

// Outcomes and diagnostics
export {
  ok,
  err,
  failure,
  warn,
  info,
  error as diagnosticError,
  isOk,
  isErr,
  FAILURE_CODES,
  type Outcome,
  type Ok,
  type Err,
  type Failure,
  type FailureCode,
  type Diagnostic,
  type DiagnosticSpan,
  type DiagnosticPosition,
  type DiagnosticSeverity,
} from "./core/outcome";

// ═══════════════════════════════════════════════════════════════════════════════
// FRAME IR PACKAGE
// ═══════════════════════════════════════════════════════════════════════════════

export {
  canonicalJson,
  merkleHash,
  merkleize,
  type FrameValue,
  type FlowIR,
  type FlowStepIR,
  type MerkleArrayNode,
  type MerkleNode,
  type MerkleObjectEntry,
  type MerkleObjectNode,
  type MerkleValueNode,
  type MessageIR,
  type PromptIR,
  type ScalarIR,
  type ValueIR,
} from "./frameir";

// ═══════════════════════════════════════════════════════════════════════════════
// VALUES & TYPES
// ═══════════════════════════════════════════════════════════════════════════════

export type { Val } from "./core/eval/values";
export type { DistVal, DistItem } from "./core/eval/dist";
export { dist, distNormalize, distSample, distTopK, distFrom, isDist } from "./core/eval/dist";

// ═══════════════════════════════════════════════════════════════════════════════
// ORACLE PROTOCOL
// ═══════════════════════════════════════════════════════════════════════════════

export type { OracleReq, OracleResp, Meaning, QExpr } from "./core/oracle/protocol";
export type { OracleAdapter, OracleInit } from "./core/oracle/adapter";
export type { MeaningVal } from "./core/oracle/meaning";
export { meaning, isMeaning } from "./core/oracle/meaning";
export { matchAST } from "./core/oracle/match";

// ═══════════════════════════════════════════════════════════════════════════════
// ADAPTERS (LLM Backends)
// ═══════════════════════════════════════════════════════════════════════════════

export type { LLMConfig, AdapterCaps, ToolDef, OracleAdapterWithCaps } from "./core/oracle/adapters/types";
export { DepthTrackingAdapter, TracingAdapter } from "./core/oracle/adapters/types";
export { AnthropicAdapter, createAnthropicAdapter } from "./core/oracle/adapters/anthropicAdapter";
export { MCPClientAdapter, OmegaMCPServer, BidirectionalMCPAdapter } from "./core/oracle/adapters/mcpAdapter";

// ═══════════════════════════════════════════════════════════════════════════════
// GOVERNANCE
// ═══════════════════════════════════════════════════════════════════════════════

export type { Cap, CapSet } from "./core/governance/caps";
export { capHas, capRequire, DEFAULT_CAPS, FULL_CAPS } from "./core/governance/caps";
export type { BudgetLimits, Budget } from "./core/governance/budgets";
export { budgetDefault, budgetRemaining, budgetConsumeOracleTurn, budgetConsumeEvalStep, budgetConsumeToolCall } from "./core/governance/budgets";
export type { Profile, TruthRegime } from "./core/governance/profile";
export { PROFILE_SPECULATIVE, PROFILE_TEST_CERTIFIED, PROFILE_PROOF_CERTIFIED, DEFAULT_PROFILE } from "./core/governance/profile";

// ═══════════════════════════════════════════════════════════════════════════════
// CONTEXT (Env = Ctx)
// ═══════════════════════════════════════════════════════════════════════════════

export type { Ctx, Constraint, Evidence } from "./core/ctx/ctx";
export {
  ctxDefine,
  ctxLookup,
  ctxExtend,
  ctxSeal,
  ctxAddEvidence,
  ctxApplyProfile,
  ctxRootFromProfile,
  ctxProject,
  isCtx,
} from "./core/ctx/ctx";

// ═══════════════════════════════════════════════════════════════════════════════
// CONTEXT RECEIPTS (Snapshot/Compress/Hydrate)
// ═══════════════════════════════════════════════════════════════════════════════

export type { CtxReceipt } from "./core/oracle/ctxReceipts";
export { CtxReceiptRepo } from "./core/oracle/ctxReceipts";

// ═══════════════════════════════════════════════════════════════════════════════
// PROVENANCE
// ═══════════════════════════════════════════════════════════════════════════════

export { ProvenanceGraph } from "./core/provenance/graph";
export type { ProvenanceGraphData, StalenessReport, StaleItem, SourceChecker } from "./core/provenance/graph";
export { evidenceId, computeSourceHash } from "./core/provenance/evidence";
export { FileProvenanceStore } from "./core/provenance/store/file";
export type { ProvenanceStore, StoredReceipt, ReceiptFilter } from "./core/provenance/store/interface";

// ═══════════════════════════════════════════════════════════════════════════════
// FRAMEIR (Canonical IR)
// ═══════════════════════════════════════════════════════════════════════════════

export * from "./frameir";
export * from "./outcome";

// ═══════════════════════════════════════════════════════════════════════════════
// REGISTRY (Primitive descriptors)
// ═══════════════════════════════════════════════════════════════════════════════

export * from "./registry";

// ═══════════════════════════════════════════════════════════════════════════════
// CLI TOOLS - CEKS Machine (Low-Level Debugging Support)
// ═══════════════════════════════════════════════════════════════════════════════

// Store (Copy-on-Write memory)
export { COWStore, type Store } from "./core/eval/store";

// Single-step execution (for debugger)
export { stepOnce, type StepResult } from "./core/eval/machineStep";

// Run to completion (for REPL)
export { runToCompletionWithState, runToCompletion } from "./core/eval/run";

// Machine state types
export type { State, Frame } from "./core/eval/machine";

// Environment type
export type { Env } from "./core/eval/env";

// Compilation (text -> AST)
export { compileTextToExpr } from "./core/pipeline/compileText";

// Effects runtime (for handling oracle calls)
export { RuntimeImpl } from "./core/effects/runtimeImpl";

// Oracle state management
export { SnapshotRepo } from "./core/oracle/snapshots";
export { InMemoryReceiptStore, type ReceiptStore } from "./core/oracle/receipts";

// OpenAI adapter (Anthropic already exported above)
export { createOpenAIAdapter } from "./core/oracle/adapters";

// Primitive installation (for initializing REPL environment)
export { installPrims } from "./core/prims";

// Session management
export {
  SessionWriter,
  SessionReader,
  JumpController,
  serializeState,
  deserializeState,
  renderEvent,
  renderTrace,
} from "./core/session";
export type { SessionEvent, SessionIndex, LLMReceipt } from "./core/session";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/analysis/dominators.ts
// ═══════════════════════════════════════════════════════════════════════════

import type {
  FlowIR,
  FAll,
  FAny,
  FBind,
  FBranch,
  FCatch,
  FLoop,
  FRace,
  FSequence,
  FWithBudget,
  FWithTimeout,
} from "../../frameir/flow";

export interface FlowNode {
  id: string;
  flow: FlowIR;
  children: string[];
  parents: string[];
}

export interface FlowGraph {
  nodes: Map<string, FlowNode>;
  entryId: string;
}

/**
  * Build a flow graph with parent/child relationships for dominator analysis.
  */
export function buildFlowGraph(flow: FlowIR): FlowGraph {
  const nodes = new Map<string, FlowNode>();
  let nextId = 0;

  const addNode = (f: FlowIR, parentId?: string): string => {
    const id = `n${nextId++}`;
    const node: FlowNode = { id, flow: f, children: [], parents: parentId ? [parentId] : [] };
    nodes.set(id, node);

    if (parentId) {
      const parent = nodes.get(parentId);
      if (parent) {
        parent.children.push(id);
      }
    }

    switch (f.tag) {
      case "FBind": {
        const bind = f as FBind;
        addNode(bind.flow, id);
        break;
      }
      case "FCatch": {
        const caught = f as FCatch;
        addNode(caught.flow, id);
        break;
      }
      case "FWithBudget": {
        const wb = f as FWithBudget;
        addNode(wb.flow, id);
        break;
      }
      case "FWithTimeout": {
        const wt = f as FWithTimeout;
        addNode(wt.flow, id);
        break;
      }
      case "FSequence": {
        const seq = f as FSequence;
        let prev = id;
        for (const child of seq.flows) {
          prev = addNode(child, prev);
        }
        break;
      }
      case "FBranch": {
        const br = f as FBranch;
        addNode(br.then, id);
        addNode(br.else, id);
        break;
      }
      case "FAll":
      case "FRace":
      case "FAny": {
        const par = f as FAll | FRace | FAny;
        for (const child of par.flows) {
          addNode(child, id);
        }
        break;
      }
      case "FLoop": {
        // Loop references functions; no direct Flow child.
        break;
      }
      case "FPure":
      case "FFail":
      case "FInfer":
      case "FToolCall":
      case "FValidate":
      case "FCommit":
      case "FEmit":
      case "FObserve":
      case "FSuspend":
        break;
    }

    return id;
  };

  const entryId = addNode(flow);
  return { nodes, entryId };
}

/**
 * Compute dominators for each node in the graph.
 */
export function computeDominators(graph: FlowGraph): Map<string, Set<string>> {
  const { nodes, entryId } = graph;
  const dominators = new Map<string, Set<string>>();
  const allIds = new Set(nodes.keys());

  for (const id of nodes.keys()) {
    if (id === entryId) {
      dominators.set(id, new Set([id]));
    } else {
      dominators.set(id, new Set(allIds));
    }
  }

  let changed = true;
  while (changed) {
    changed = false;

    for (const [id, node] of nodes) {
      if (id === entryId) continue;

      const predDoms = node.parents.map(p => dominators.get(p) ?? new Set<string>());
      const intersection = buildIntersection(predDoms);
      intersection.add(id);

      const current = dominators.get(id)!;
      const currentStr = [...current].sort().join(",");
      const nextStr = [...intersection].sort().join(",");
      if (currentStr !== nextStr) {
        dominators.set(id, intersection);
        changed = true;
      }
    }
  }

  return dominators;
}

function buildIntersection(sets: Array<Set<string>>): Set<string> {
  if (sets.length === 0) {
    return new Set<string>();
  }

  const intersection = new Set<string>(sets[0]);
  for (let i = 1; i < sets.length; i++) {
    for (const value of Array.from(intersection)) {
      if (!sets[i].has(value)) {
        intersection.delete(value);
      }
    }
  }
  return intersection;
}

/**
 * Build a lookup map from FlowIR node references to graph node ids.
 */
export function indexNodesByRef(graph: FlowGraph): Map<FlowIR, string> {
  const index = new Map<FlowIR, string>();
  for (const [id, node] of graph.nodes) {
    index.set(node.flow, id);
  }
  return index;
}

/**
 * Check if nodeId is dominated by any node with the given tag.
 */
export function isDominatedBy(
  nodeId: string,
  tag: FlowIR["tag"],
  graph: FlowGraph,
  dominators: Map<string, Set<string>>
): boolean {
  const doms = dominators.get(nodeId);
  if (!doms) return false;

  for (const domId of doms) {
    const domNode = graph.nodes.get(domId);
    if (domNode?.flow.tag === tag) {
      return true;
    }
  }
  return false;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/analysis/effects.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowIR } from "../../frameir/flow";
import type { PrimitiveRegistry } from "../../registry";
import type { Effect } from "../../registry/types";

/**
 * Compute effects associated with a single node via registry lookup.
 */
export function nodeEffects(flow: FlowIR, registry: PrimitiveRegistry): Set<Effect> {
  const descriptor = registry.getByIrTag(flow.tag);
  const effects = new Set<Effect>();
  if (!descriptor) return effects;

  for (const effect of descriptor.effects) {
    effects.add(effect);
  }
  return effects;
}

export function requiresEffect(flow: FlowIR, effect: Effect, registry: PrimitiveRegistry): boolean {
  return nodeEffects(flow, registry).has(effect);
}

/**
 * Collect nodes that require a particular effect.
 */
export function collectByEffect(flow: FlowIR, effect: Effect, registry: PrimitiveRegistry): FlowIR[] {
  const nodes: FlowIR[] = [];

  const visit = (node: FlowIR): void => {
    if (requiresEffect(node, effect, registry)) {
      nodes.push(node);
    }

    switch (node.tag) {
      case "FBind":
      case "FCatch":
      case "FWithBudget":
      case "FWithTimeout":
        visit((node as any).flow);
        break;

      case "FSequence":
      case "FAll":
      case "FRace":
      case "FAny":
        for (const child of (node as any).flows) {
          visit(child);
        }
        break;

      case "FBranch":
        visit((node as any).then);
        visit((node as any).else);
        break;

      case "FLoop":
      case "FPure":
      case "FFail":
      case "FInfer":
      case "FToolCall":
      case "FValidate":
      case "FCommit":
      case "FEmit":
      case "FObserve":
      case "FSuspend":
        break;
    }
  };

  visit(flow);
  return nodes;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./types";
export * from "./runner";
export * from "./analysis/dominators";
export * from "./analysis/effects";
export * from "./passes/budgetDominator";
export * from "./passes/timeoutGuard";
export * from "./passes/toolContract";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/passes/budgetDominator.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowIR } from "../../frameir/flow";
import type { IRBundle } from "../../frameir/bundle";
import { errorDiag, type Diagnostic } from "../../outcome/diagnostic";
import type { PrimitiveRegistry } from "../../registry";
import { buildFlowGraph, computeDominators, isDominatedBy } from "../analysis/dominators";
import type { Pass, PassResult } from "../types";

export const budgetDominatorPass: Pass = {
  id: "lint/budget-dominator",
  name: "Budget Dominator Check",
  phase: "lint",
  run(bundle: IRBundle, registry: PrimitiveRegistry): PassResult {
    const diagnostics: Diagnostic[] = [];

    const graph = buildFlowGraph(bundle.entry);
    const dominators = computeDominators(graph);

    for (const node of graph.nodes.values()) {
      const descriptor = registry.getByIrTag(node.flow.tag);
      if (!requiresBudgetGuard(descriptor)) continue;

      if (!isDominatedBy(node.id, "FWithBudget", graph, dominators)) {
        diagnostics.push(
          errorDiag(selectBudgetCode(descriptor?.effects ?? [], node.flow), budgetMessage(node.flow), {
            span: node.flow.meta?.span,
            data: { tag: node.flow.tag },
          })
        );
      }
    }

    return { diagnostics };
  },
};

function requiresBudgetGuard(descriptor: ReturnType<PrimitiveRegistry["getByIrTag"]>): boolean {
  return descriptor?.constraints?.mustBeDominatedByBudget === true;
}

function selectBudgetCode(effects: string[], flow: FlowIR): string {
  if (effects.includes("Tool")) return "E0601";
  if (effects.includes("Oracle")) return "E0600";
  return `E06-${flow.tag}`;
}

function budgetMessage(flow: FlowIR): string {
  if (flow.tag === "FToolCall") return "Tool call is not dominated by with-budget";
  if (flow.tag === "FInfer") return "Oracle call is not dominated by with-budget";
  return `${flow.tag} requires a budget guard`;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/passes/timeoutGuard.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowIR } from "../../frameir/flow";
import type { IRBundle } from "../../frameir/bundle";
import { warnDiag, type Diagnostic } from "../../outcome/diagnostic";
import type { PrimitiveRegistry } from "../../registry";
import { buildFlowGraph, computeDominators, isDominatedBy } from "../analysis/dominators";
import type { Pass, PassResult } from "../types";

export const timeoutGuardPass: Pass = {
  id: "lint/timeout-guard",
  name: "Timeout Guard Check",
  phase: "lint",
  run(bundle: IRBundle, registry: PrimitiveRegistry): PassResult {
    const diagnostics: Diagnostic[] = [];
    const graph = buildFlowGraph(bundle.entry);
    const dominators = computeDominators(graph);

    for (const node of graph.nodes.values()) {
      const descriptor = registry.getByIrTag(node.flow.tag);
      if (!requiresTimeoutGuard(descriptor)) continue;

      const dominated = isDominatedBy(node.id, "FWithTimeout", graph, dominators);
      if (!dominated) {
        diagnostics.push(
          warnDiag("W0010", timeoutMessage(node.flow), {
            span: node.flow.meta?.span,
            data: { tag: node.flow.tag },
          })
        );
      }
    }

    return { diagnostics };
  },
};

function requiresTimeoutGuard(descriptor: ReturnType<PrimitiveRegistry["getByIrTag"]>): boolean {
  return descriptor?.constraints?.mustBeDominatedByTimeout === true;
}

function timeoutMessage(flow: FlowIR): string {
  if (flow.tag === "FInfer") return "Oracle call is not guarded by with-timeout";
  return `${flow.tag} is not guarded by with-timeout`;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/passes/toolContract.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { FlowIR, FToolCall } from "../../frameir/flow";
import type { IRBundle } from "../../frameir/bundle";
import { errorDiag, type Diagnostic } from "../../outcome/diagnostic";
import type { PrimitiveRegistry } from "../../registry";
import type { Pass, PassResult } from "../types";
import type { ToolContractIR } from "../../frameir/contract";
import type { Span } from "../../frameir/meta";
import type { VRef } from "../../frameir/value";

export const toolContractPass: Pass = {
  id: "lint/tool-contract",
  name: "Tool Contract Check",
  phase: "lint",
  run(bundle: IRBundle, registry: PrimitiveRegistry): PassResult {
    const diagnostics: Diagnostic[] = [];
    const validatedContracts = new Set<string>();

    traverse(bundle.entry, node => {
      const descriptor = registry.getByIrTag(node.tag);
      if (!requiresToolContract(descriptor) || node.tag !== "FToolCall") return;

      const toolNode = node as FToolCall;
      const contractRef = toolNode.contract;
      if (!contractRef) {
        diagnostics.push(
          errorDiag("E0610", "Tool call is missing a contract reference", {
            span: node.meta?.span,
            data: { tool: toolNode.tool },
          })
        );
        return;
      }

      const contractId = contractRef.ref?.id;
      if (!contractId || !bundle.toolContracts[contractId]) {
        diagnostics.push(
          errorDiag("E0611", `Tool contract not found: ${contractId ?? "unknown"}`, {
            span: node.meta?.span,
            data: { tool: toolNode.tool, contractId: contractId ?? null },
          })
        );
        return;
      }

      if (!validatedContracts.has(contractId)) {
        validatedContracts.add(contractId);
        diagnostics.push(
          ...validateContractSchemas(bundle.toolContracts[contractId], bundle, node.meta?.span)
        );
      }
    });

    return { diagnostics };
  },
};

function validateContractSchemas(contract: ToolContractIR, bundle: IRBundle, span?: Span): Diagnostic[] {
  const diags: Diagnostic[] = [];
  const checks: Array<{ field: "inputSchema" | "outputSchema" | "errorSchema"; code: string; ref?: VRef }> = [
    { field: "inputSchema", code: "E0612", ref: contract.inputSchema },
    { field: "outputSchema", code: "E0613", ref: contract.outputSchema },
    { field: "errorSchema", code: "E0614", ref: contract.errorSchema },
  ];

  for (const check of checks) {
    if (!check.ref) {
      if (check.field === "errorSchema") continue;
      diags.push(
        errorDiag(check.code, `Tool contract ${contract.id} missing ${check.field} reference`, {
          span,
          data: { contractId: contract.id },
        })
      );
      continue;
    }

    const schemaId = check.ref.ref?.id;
    const kind = check.ref.ref?.kind;
    const exists = kind === "Schema" && schemaId && bundle.schemas[schemaId];
    if (!exists) {
      diags.push(
        errorDiag(check.code, `Tool contract ${contract.id} references missing schema: ${schemaId ?? "unknown"}`, {
          span,
          data: { contractId: contract.id, schemaId: schemaId ?? null, field: check.field },
        })
      );
    }
  }

  return diags;
}

function traverse(flow: FlowIR, visit: (node: FlowIR) => void): void {
  visit(flow);

  switch (flow.tag) {
    case "FBind":
    case "FCatch":
    case "FWithBudget":
    case "FWithTimeout":
      traverse(flow.flow, visit);
      break;
    case "FSequence":
    case "FAll":
    case "FAny":
    case "FRace":
      flow.flows.forEach(f => traverse(f, visit));
      break;
    case "FBranch":
      traverse(flow.then, visit);
      traverse(flow.else, visit);
      break;
    case "FPure":
    case "FFail":
    case "FLoop":
    case "FInfer":
    case "FToolCall":
    case "FValidate":
    case "FCommit":
    case "FEmit":
    case "FObserve":
    case "FSuspend":
      break;
  }
}

function requiresToolContract(descriptor: ReturnType<PrimitiveRegistry["getByIrTag"]>): boolean {
  return descriptor?.constraints?.requiresToolContract === true;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/runner.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { IRBundle } from "../frameir/bundle";
import type { Diagnostic } from "../outcome/diagnostic";
import { defaultRegistry, PrimitiveRegistry } from "../registry";
import { budgetDominatorPass } from "./passes/budgetDominator";
import { timeoutGuardPass } from "./passes/timeoutGuard";
import { toolContractPass } from "./passes/toolContract";
import type { LintConfig, Pass, PassConfig, PassPhase, PassResult } from "./types";

const DEFAULT_CONFIG: LintConfig = { passes: {} };
const PHASE_ORDER: PassPhase[] = ["parsing", "lowering", "normalize", "lint", "optimize"];

export class LintRunner {
  private passes: Map<string, Pass> = new Map();
  private config: LintConfig;
  private registry: PrimitiveRegistry;

  constructor(config: Partial<LintConfig> = DEFAULT_CONFIG, registry: PrimitiveRegistry = defaultRegistry) {
    this.config = { passes: config?.passes ?? {} };
    this.registry = registry;
  }

  register(pass: Pass): void {
    this.passes.set(pass.id, pass);
  }

  run(bundle: IRBundle): { bundle: IRBundle; diagnostics: Diagnostic[]; passResults: Map<string, PassResult> } {
    let currentBundle = bundle;
    const diagnostics: Diagnostic[] = [];
    const passResults = new Map<string, PassResult>();
    const sorted = this.resolvePassOrder();

    for (const pass of sorted) {
      const config = this.getPassConfig(pass.id);
      const result = pass.run(currentBundle, this.registry);
      passResults.set(pass.id, result);

      diagnostics.push(...applySeverityOverride(result.diagnostics, config.severityOverride));

      if (result.transformed) {
        currentBundle = result.transformed;
      }
    }

    return { bundle: currentBundle, diagnostics, passResults };
  }

  hasErrors(diags: Diagnostic[]): boolean {
    return diags.some(d => d.severity === "error");
  }

  private resolvePassOrder(): Pass[] {
    const enabledPasses = Array.from(this.passes.values()).filter(p => this.isPassEnabled(p.id));
    const passLookup = new Map(enabledPasses.map(p => [p.id, p]));
    const ordered: Pass[] = [];
    const executed = new Set<string>();

    for (const pass of enabledPasses) {
      for (const dep of this.enabledDependencies(pass)) {
        if (!passLookup.has(dep)) {
          throw new Error(`Pass dependency not registered: ${dep}`);
        }
      }
    }

    for (const phase of PHASE_ORDER) {
      const phasePasses = enabledPasses.filter(p => p.phase === phase);
      if (phasePasses.length === 0) continue;

      const indegree = new Map<string, number>();
      const edges = new Map<string, Set<string>>();

      for (const pass of phasePasses) {
        indegree.set(pass.id, 0);
        edges.set(pass.id, new Set());
      }

      for (const pass of phasePasses) {
        for (const dep of this.enabledDependencies(pass)) {
          const depPass = passLookup.get(dep);
          if (!depPass) {
            continue;
          }

          const depPhaseIndex = this.phaseIndex(depPass.phase);
          const passPhaseIndex = this.phaseIndex(pass.phase);

          if (depPhaseIndex > passPhaseIndex) {
            throw new Error(`Pass ${pass.id} depends on ${dep} in later phase ${depPass.phase}`);
          }

          if (depPhaseIndex < passPhaseIndex) {
            if (!executed.has(dep)) {
              throw new Error(`Pass dependency has not run: ${dep} (required by ${pass.id})`);
            }
            continue;
          }

          edges.get(dep)!.add(pass.id);
          indegree.set(pass.id, (indegree.get(pass.id) ?? 0) + 1);
        }
      }

      const ready = phasePasses
        .filter(p => (indegree.get(p.id) ?? 0) === 0)
        .sort((a, b) => a.id.localeCompare(b.id));

      let processed = 0;
      while (ready.length > 0) {
        const next = ready.shift()!;
        ordered.push(next);
        executed.add(next.id);
        processed++;

        for (const target of edges.get(next.id) ?? []) {
          const updated = (indegree.get(target) ?? 0) - 1;
          indegree.set(target, updated);
          if (updated === 0) {
            ready.push(passLookup.get(target)!);
            ready.sort((a, b) => a.id.localeCompare(b.id));
          }
        }
      }

      if (processed !== phasePasses.length) {
        throw new Error(`Pass dependency cycle detected in phase ${phase}`);
      }
    }

    return ordered;
  }

  private getPassConfig(passId: string): PassConfig {
    return this.config.passes[passId] ?? { enabled: true };
  }

  private isPassEnabled(passId: string): boolean {
    const config = this.getPassConfig(passId);
    return config.enabled !== false && config.severityOverride !== "off";
  }

  private enabledDependencies(pass: Pass): string[] {
    return (pass.dependencies ?? []).filter(dep => this.isPassEnabled(dep));
  }

  private phaseIndex(phase: PassPhase): number {
    const idx = PHASE_ORDER.indexOf(phase);
    if (idx === -1) {
      throw new Error(`Unknown pass phase: ${phase}`);
    }
    return idx;
  }
}

function applySeverityOverride(
  diagnostics: Diagnostic[],
  override?: PassConfigSeverity
): Diagnostic[] {
  if (!override || override === "off") {
    return diagnostics;
  }
  return diagnostics.map(d => ({ ...d, severity: override }));
}

type PassConfigSeverity = "error" | "warning" | "info" | "off" | undefined;

export function createDefaultRunner(
  config?: Partial<LintConfig>,
  registry: PrimitiveRegistry = defaultRegistry
): LintRunner {
  const runner = new LintRunner(config ?? DEFAULT_CONFIG, registry);
  runner.register(budgetDominatorPass);
  runner.register(timeoutGuardPass);
  runner.register(toolContractPass);
  return runner;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/lint/types.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { IRBundle } from "../frameir/bundle";
import type { Diagnostic } from "../outcome/diagnostic";
import type { PrimitiveRegistry } from "../registry";

export interface PassResult {
  diagnostics: Diagnostic[];
  transformed?: IRBundle;
  metadata?: Record<string, unknown>;
}

export type PassPhase =
  | "parsing"
  | "lowering"
  | "normalize"
  | "lint"
  | "optimize";

export interface Pass {
  id: string;
  name: string;
  phase: PassPhase;
  dependencies?: string[];
  run(bundle: IRBundle, registry: PrimitiveRegistry): PassResult;
}

export interface PassConfig {
  enabled: boolean;
  options?: Record<string, unknown>;
  severityOverride?: "error" | "warning" | "info" | "off";
}

export interface LintConfig {
  passes: Record<string, PassConfig>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/codes.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Span } from "../frameir/meta";
import type { Diagnostic, DiagnosticSeverity } from "./diagnostic";

interface DiagCodeDef {
  code: string;
  severity: DiagnosticSeverity;
  category: string;
  template: string;
}

export const DIAGNOSTIC_CODES: Record<string, DiagCodeDef> = {
  E0001: { code: "E0001", severity: "error", category: "Syntax", template: "Malformed expression" },
  E0002: { code: "E0002", severity: "error", category: "Syntax", template: "Unbalanced parentheses" },
  E0003: { code: "E0003", severity: "error", category: "Syntax", template: "Invalid string literal" },

  E0100: { code: "E0100", severity: "error", category: "Type", template: "Type mismatch: expected {expected}, got {actual}" },
  E0101: { code: "E0101", severity: "error", category: "Type", template: "Undefined variable: {name}" },
  E0102: { code: "E0102", severity: "error", category: "Type", template: "Wrong number of arguments: expected {expected}, got {actual}" },

  E0200: { code: "E0200", severity: "error", category: "Runtime", template: "Division by zero" },
  E0201: { code: "E0201", severity: "error", category: "Runtime", template: "Index out of bounds: {index}" },
  E0202: { code: "E0202", severity: "error", category: "Runtime", template: "Null pointer dereference" },

  E0300: { code: "E0300", severity: "error", category: "Oracle", template: "Oracle timeout after {ms}ms" },
  E0301: { code: "E0301", severity: "error", category: "Oracle", template: "Budget exhausted: {resource}" },
  E0302: { code: "E0302", severity: "error", category: "Oracle", template: "Invalid response format" },
  E0303: { code: "E0303", severity: "error", category: "Oracle", template: "Tool call failed: {tool}" },

  E0400: { code: "E0400", severity: "error", category: "Validation", template: "Schema validation failed" },
  E0401: { code: "E0401", severity: "error", category: "Validation", template: "Required field missing: {field}" },
  E0402: { code: "E0402", severity: "error", category: "Validation", template: "Invalid value for field: {field}" },

  E0500: { code: "E0500", severity: "error", category: "Capability", template: "Missing capability: {cap}" },
  E0501: { code: "E0501", severity: "error", category: "Capability", template: "Tool not allowed: {tool}" },
  E0502: { code: "E0502", severity: "error", category: "Capability", template: "Model not allowed: {model}" },

  W0001: { code: "W0001", severity: "warning", category: "Performance", template: "Large context: {tokens} tokens" },
  W0002: { code: "W0002", severity: "warning", category: "Performance", template: "Deep recursion: depth {depth}" },
  W0003: { code: "W0003", severity: "warning", category: "Style", template: "Unused variable: {name}" },
  W0004: { code: "W0004", severity: "warning", category: "Style", template: "Unreachable code" },
  W0005: { code: "W0005", severity: "warning", category: "Oracle", template: "Low confidence response: {confidence}" },
};

export function makeDiagnostic(
  code: keyof typeof DIAGNOSTIC_CODES,
  params?: Record<string, string | number>,
  span?: Span
): Diagnostic {
  const def = DIAGNOSTIC_CODES[code];
  if (!def) {
    throw new Error(`Unknown diagnostic code: ${String(code)}`);
  }

  let message = def.template;
  if (params) {
    for (const [key, value] of Object.entries(params)) {
      message = message.replace(`{${key}}`, String(value));
    }
  }

  return {
    code: def.code,
    severity: def.severity,
    message,
    span,
    data: params as Record<string, unknown> | undefined,
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/constructors.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Done, Fail, Pause, OutcomeMeta, Suspended } from "./outcome";
import type { Failure, FailureReason } from "./failure";
import { failure } from "./failure";
import { makeDiagnostic } from "./codes";
import { warnDiag, type Diagnostic } from "./diagnostic";

export function done<A>(value: A, meta: OutcomeMeta = {}): Done<A> {
  return { tag: "Done", value, meta };
}

export const ok = done;

export function fail(f: Failure, meta: OutcomeMeta = {}): Fail {
  return { tag: "Fail", failure: f, meta };
}

export function err(
  failureOrReason: Failure | FailureReason,
  messageOrMeta?: string | OutcomeMeta,
  opts?: Partial<Omit<Failure, "reason" | "message">>,
  meta: OutcomeMeta = {}
): Fail {
  if (typeof failureOrReason === "string") {
    const message = typeof messageOrMeta === "string" ? messageOrMeta : "";
    const finalMeta =
      typeof messageOrMeta === "object" && messageOrMeta !== null && !Array.isArray(messageOrMeta)
        ? (messageOrMeta as OutcomeMeta)
        : meta;
    return fail(failure(failureOrReason, message, opts), finalMeta ?? {});
  }

  const finalMeta =
    typeof messageOrMeta === "object" && messageOrMeta !== null && !Array.isArray(messageOrMeta)
      ? (messageOrMeta as OutcomeMeta)
      : meta;
  return fail(failureOrReason, finalMeta ?? {});
}

export function pause<A>(suspended: Suspended<A>, meta: OutcomeMeta = {}): Pause<A> {
  return { tag: "Pause", suspended, meta };
}

export function budgetExceeded(resource: string, meta: OutcomeMeta = {}): Fail {
  return fail(
    failure("budget-exceeded", `Budget exceeded: ${resource}`, {
      diagnostics: [makeDiagnostic("E0301", { resource })],
      recoverable: false,
    }),
    meta
  );
}

export function timeout(ms: number, meta: OutcomeMeta = {}): Fail {
  return fail(
    failure("timeout", `Timeout after ${ms}ms`, {
      diagnostics: [makeDiagnostic("E0300", { ms })],
      recoverable: true,
    }),
    meta
  );
}

export function validationFailed(
  message: string,
  context?: Record<string, unknown>,
  meta: OutcomeMeta = {}
): Fail {
  return fail(
    failure("validation-failed", message, {
      diagnostics: [makeDiagnostic("E0400")],
      context,
      recoverable: true,
    }),
    meta
  );
}

export function toolError(tool: string, error: string, meta: OutcomeMeta = {}): Fail {
  return fail(
    failure("tool-error", `Tool ${tool} failed: ${error}`, {
      diagnostics: [makeDiagnostic("E0303", { tool })],
      recoverable: true,
    }),
    meta
  );
}

export function capabilityDenied(cap: string, meta: OutcomeMeta = {}): Fail {
  return fail(
    failure("precondition-failed", `Missing capability: ${cap}`, {
      diagnostics: [makeDiagnostic("E0500", { cap })],
      recoverable: false,
    }),
    meta
  );
}

export function warn(code: string, message: string, opts?: Partial<Omit<Diagnostic, "code" | "message" | "severity">>) {
  return warnDiag(code, message, opts);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/diagnostic.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Span } from "../frameir/meta";

export type DiagnosticSeverity = "error" | "warning" | "info" | "hint";

export interface DiagnosticFix {
  description: string;
  replacement?: string;
  span?: Span;
}

export interface Diagnostic {
  code: string;
  severity: DiagnosticSeverity;
  message: string;
  span?: Span;
  data?: Record<string, unknown>;
  related?: Diagnostic[];
  fixes?: DiagnosticFix[];
}

type DiagnosticOpts = Partial<Omit<Diagnostic, "code" | "message" | "severity">>;

export function errorDiag(code: string, message: string, opts?: DiagnosticOpts): Diagnostic {
  return { code, message, severity: "error", ...opts };
}

export function warnDiag(code: string, message: string, opts?: DiagnosticOpts): Diagnostic {
  return { code, message, severity: "warning", ...opts };
}

export function infoDiag(code: string, message: string, opts?: DiagnosticOpts): Diagnostic {
  return { code, message, severity: "info", ...opts };
}

export function hintDiag(code: string, message: string, opts?: DiagnosticOpts): Diagnostic {
  return { code, message, severity: "hint", ...opts };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/failure.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Diagnostic } from "./diagnostic";

export type FailureReason =
  | "budget-exceeded"
  | "timeout"
  | "rate-limited"
  | "validation-failed"
  | "schema-mismatch"
  | "type-error"
  | "oracle-error"
  | "oracle-timeout"
  | "invalid-response"
  | "tool-error"
  | "tool-not-found"
  | "tool-contract-violation"
  | "user-cancelled"
  | "precondition-failed"
  | "invariant-violated"
  | "internal-error"
  | "not-implemented"
  | `custom:${string}`;

export interface Failure {
  reason: FailureReason;
  message: string;
  context?: Record<string, unknown>;
  diagnostics: Diagnostic[];
  cause?: Failure;
  recoverable: boolean;
  suggestions?: string[];
}

export function failure(
  reason: FailureReason,
  message: string,
  opts?: Partial<Omit<Failure, "reason" | "message">>
): Failure {
  return {
    reason,
    message,
    diagnostics: opts?.diagnostics ?? [],
    recoverable: opts?.recoverable ?? false,
    context: opts?.context,
    cause: opts?.cause,
    suggestions: opts?.suggestions,
  };
}

export function wrapFailure(
  inner: Failure,
  message: string,
  context?: Record<string, unknown>
): Failure {
  return {
    ...inner,
    message,
    context: { ...inner.context, ...context },
    cause: inner,
  };
}

export function isFailureReason(f: Failure, reason: FailureReason): boolean {
  return f.reason === reason;
}

export function allDiagnostics(f: Failure, seen = new Set<Diagnostic>()): Diagnostic[] {
  const collected: Diagnostic[] = [];
  for (const diag of f.diagnostics ?? []) {
    if (!seen.has(diag)) {
      seen.add(diag);
      collected.push(diag);
    }
  }
  if (f.cause) {
    collected.push(...allDiagnostics(f.cause, seen));
  }
  return collected;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./outcome";
export * from "./failure";
export * from "./diagnostic";
export * from "./codes";
export * from "./constructors";
export * from "./matchers";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/matchers.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Outcome, Done, Fail, Pause } from "./outcome";
import { isDone, isFail, isPause } from "./outcome";

export function match<A, R>(
  outcome: Outcome<A>,
  handlers: {
    done: (d: Done<A>) => R;
    fail: (f: Fail) => R;
    pause: (p: Pause<A>) => R;
  }
): R {
  switch (outcome.tag) {
    case "Done":
      return handlers.done(outcome);
    case "Fail":
      return handlers.fail(outcome);
    case "Pause":
      return handlers.pause(outcome);
  }
}

export function mapOutcome<A, B>(o: Outcome<A>, fn: (a: A) => B): Outcome<B> {
  if (isDone(o)) {
    return { ...o, value: fn(o.value) };
  }
  return o as unknown as Outcome<B>;
}

export async function flatMapOutcome<A, B>(
  o: Outcome<A>,
  fn: (a: A) => Promise<Outcome<B>> | Outcome<B>
): Promise<Outcome<B>> {
  if (isDone(o)) {
    return await fn(o.value);
  }
  return o as unknown as Outcome<B>;
}

export function unwrap<A>(o: Outcome<A>): A {
  if (isDone(o)) {
    return o.value;
  }
  if (isFail(o)) {
    throw new Error(o.failure.message);
  }
  throw new Error("Cannot unwrap paused outcome");
}

export function unwrapOr<A>(o: Outcome<A>, defaultValue: A): A {
  return isDone(o) ? o.value : defaultValue;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/outcome/outcome.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Failure } from "./failure";
import type { Span } from "../frameir/meta";

export interface OutcomeMeta {
  span?: Span;
  durationMs?: number;
  budgetUsed?: {
    llmCalls?: number;
    tokens?: number;
    timeMs?: number;
    toolCalls?: number;
  };
  evidenceIds?: string[];
}

export interface Done<A> {
  readonly tag: "Done";
  readonly value: A;
  readonly meta: OutcomeMeta;
}

export interface Fail {
  readonly tag: "Fail";
  readonly failure: Failure;
  readonly meta: OutcomeMeta;
}

export interface Suspended<A> {
  reason: SuspendReason;
  resume: (input: unknown) => Promise<Outcome<A>>;
  state?: unknown;
}

export type SuspendReason =
  | { tag: "AwaitingHumanInput"; prompt: string }
  | { tag: "AwaitingApproval"; action: string }
  | { tag: "ResourceExhausted"; resource: string }
  | { tag: "Custom"; reason: string; data?: unknown };

export interface Pause<A> {
  readonly tag: "Pause";
  readonly suspended: Suspended<A>;
  readonly meta: OutcomeMeta;
}

export type Outcome<A> = Done<A> | Fail | Pause<A>;
export type Ok<A> = Done<A>;
export type Err = Fail;

export function isDone<A>(o: Outcome<A>): o is Done<A> {
  return o.tag === "Done";
}

export function isFail<A>(o: Outcome<A>): o is Fail {
  return o.tag === "Fail";
}

export function isPause<A>(o: Outcome<A>): o is Pause<A> {
  return o.tag === "Pause";
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/clock.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Clock port interface.
 * MUST be used for all time access to enable deterministic replay.
 */
export interface ClockPort {
  /**
   * Get current time in milliseconds.
   * In replay mode, returns logged time.
   */
  nowMs(ctx: ExecContext): number;

  /**
   * Sleep for specified duration.
   * In replay mode, may be no-op or use logged time.
   */
  sleepMs(ms: number, ctx: ExecContext): Promise<void>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/composite.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ClockPort } from "./clock";
import type { OraclePort } from "./oracle";
import type { RngPort } from "./rng";
import type { SinkPort } from "./sink";
import type { SourcePort } from "./source";
import type { StorePort } from "./store";
import type { ToolPort } from "./tool";

/**
 * Complete set of ports for execution.
 */
export interface PortSet {
  oracle: OraclePort;
  tool: ToolPort;
  store: StorePort;
  sink: SinkPort;
  source: SourcePort;
  clock: ClockPort;
  rng: RngPort;
}

/**
 * Create a port set with all required ports.
 */
export function createPortSet(ports: PortSet): PortSet {
  return ports;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./types";
export * from "./oracle";
export * from "./tool";
export * from "./store";
export * from "./sink";
export * from "./source";
export * from "./clock";
export * from "./rng";
export * from "./composite";

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/oracle.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Request to oracle (LLM).
 */
export interface OracleRequest {
  /** Model identifier */
  model: string;

  /** Rendered prompt text */
  prompt: string;

  /** Tool specifications (for tool-augmented chat) */
  tools?: unknown[];

  /** Output schema for structured mode */
  outputSchema?: unknown;

  /** Sampling temperature */
  temperature?: number;

  /** Max tokens to generate */
  maxTokens?: number;

  /** Seed for reproducibility */
  seed?: number;

  /** Provider-specific metadata */
  metadata?: Record<string, unknown>;
}

/**
 * Response from oracle.
 */
export interface OracleResponse {
  /** Generated text */
  text: string;

  /** Token usage statistics */
  usage?: {
    promptTokens?: number;
    completionTokens?: number;
    totalTokens?: number;
  };

  /** Tool calls requested by model */
  toolCalls?: Array<{
    id: string;
    name: string;
    arguments: string;
  }>;

  /** Provider-specific raw response */
  raw?: unknown;
}

/**
 * Oracle port interface.
 */
export interface OraclePort {
  /**
   * Send inference request to oracle.
   * @throws if capability check fails or oracle error
   */
  infer(req: OracleRequest, ctx: ExecContext): Promise<OracleResponse>;
}

/**
 * Validate oracle request against capabilities.
 */
export function validateOracleCap(req: OracleRequest, ctx: ExecContext): void {
  const cap = ctx.caps.oracleCap;
  if (!cap) {
    throw new Error("No OracleCap in context");
  }
  if (!cap.allowedModels.includes(req.model)) {
    throw new Error(`Model ${req.model} not allowed by capability`);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/rng.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * RNG port interface.
 * MUST be used for all randomness to enable deterministic replay.
 */
export interface RngPort {
  /**
   * Get next random 32-bit unsigned integer.
   * In replay mode, returns logged value.
   */
  nextU32(ctx: ExecContext): number;

  /**
   * Get random float in [0, 1).
   */
  nextFloat(ctx: ExecContext): number;

  /**
   * Get random integer in [min, max).
   */
  nextInt(min: number, max: number, ctx: ExecContext): number;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/sink.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Sink port interface.
 * For emitting items to output streams.
 */
export interface SinkPort {
  /**
   * Emit item to sink.
   */
  emit(sinkId: string, item: unknown, ctx: ExecContext): Promise<void>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/source.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Source port interface.
 * For observing from input streams.
 */
export interface SourcePort {
  /**
   * Observe from source.
   * @param query - Optional query/filter
   * @returns Observed value
   */
  observe(sourceId: string, query: unknown | undefined, ctx: ExecContext): Promise<unknown>;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/store.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Store port interface.
 * Persistent key-value storage.
 */
export interface StorePort {
  /**
   * Get value by key.
   * @returns value or null if not found
   */
  get(storeId: string, key: string, ctx: ExecContext): Promise<unknown | null>;

  /**
   * Put value by key.
   */
  put(storeId: string, key: string, value: unknown, ctx: ExecContext): Promise<void>;

  /**
   * Check if key exists.
   */
  has(storeId: string, key: string, ctx: ExecContext): Promise<boolean>;

  /**
   * Delete key.
   */
  delete(storeId: string, key: string, ctx: ExecContext): Promise<void>;
}

/**
 * Validate store operation against capabilities.
 */
export function validateStoreCap(storeId: string, op: "get" | "put" | "delete", ctx: ExecContext): void {
  const cap = ctx.caps.storeCap;
  if (!cap) {
    throw new Error("No StoreCap in context");
  }
  if (!cap.allowedStores.has(storeId)) {
    throw new Error(`Store ${storeId} not allowed by capability`);
  }
  if (cap.readOnly && (op === "put" || op === "delete")) {
    throw new Error(`Store ${storeId} is read-only`);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/tool.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { ExecContext } from "./types";

/**
 * Tool call request.
 */
export interface ToolCall {
  /** Tool name */
  name: string;

  /** Arguments (validated against contract.inputSchema before call) */
  args: unknown;

  /** Contract ID for audited execution */
  contractId: string;
}

/**
 * Tool call result.
 */
export interface ToolResult {
  /** Whether call succeeded */
  ok: boolean;

  /** Result value (validated against contract.outputSchema) */
  value?: unknown;

  /** Error info if failed */
  error?: {
    type: string;
    message: string;
    data?: unknown;
  };

  /** Provider-specific raw result */
  raw?: unknown;
}

/**
 * Tool port interface.
 * All external tool invocation must go through this port.
 */
export interface ToolPort {
  /**
   * Call an external tool.
   * @param call - The tool call request
   * @param ctx - Execution context
   * @returns Tool result
   */
  call(call: ToolCall, ctx: ExecContext): Promise<ToolResult>;
}

/**
 * Validate tool call against capabilities.
 */
export function validateToolCap(call: ToolCall, ctx: ExecContext): void {
  const cap = ctx.caps.toolCap;
  if (!cap) {
    throw new Error("No ToolCap in context");
  }
  if (!cap.allowedContracts.has(call.contractId)) {
    throw new Error(`Contract ${call.contractId} not allowed by capability`);
  }
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/ports/types.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { Span } from "../frameir/meta";

/**
 * Budget state for resource tracking.
 */
export interface BudgetState {
  llmCalls?: { used: number; limit: number };
  tokens?: { used: number; limit: number };
  timeMs?: { used: number; limit: number };
  toolCalls?: { used: number; limit: number };
}

/**
 * Capability tokens for object-capability security.
 */
export interface CapabilitySet {
  /** Allowed oracle models */
  oracleCap?: {
    allowedModels: string[];
    constraints?: Record<string, unknown>;
  };

  /** Allowed tool contracts */
  toolCap?: {
    allowedContracts: Set<string>;
  };

  /** Allowed stores */
  storeCap?: {
    allowedStores: Set<string>;
    readOnly?: boolean;
  };

  /** Allowed sinks */
  sinkCap?: {
    allowedSinks: Set<string>;
  };

  /** Allowed sources */
  sourceCap?: {
    allowedSources: Set<string>;
  };
}

/**
 * Trace event types for replay logging.
 */
export type TraceEvent =
  | { tag: "E_OracleCall"; id: string; durationMs: number }
  | { tag: "E_ToolCall"; id: string; tool: string; durationMs: number }
  | { tag: "E_StoreOp"; id: string; op: "get" | "put"; key: string }
  | { tag: "E_SinkEmit"; id: string; sink: string }
  | { tag: "E_SourceObserve"; id: string; source: string }
  | { tag: "E_ClockRead"; id: string; valueMs: number }
  | { tag: "E_RngRead"; id: string; value: number }
  | { tag: "E_SchedulerDecision"; fiberId: string; choice: number };

/**
 * Trace sink for logging events.
 */
export interface TraceSink {
  emit(event: TraceEvent): void;
}

/**
 * Execution context passed to all port operations.
 */
export interface ExecContext {
  /** Correlation ID for the entire execution */
  runId: string;

  /** Current span for provenance */
  span?: Span;

  /** Remaining budget */
  budget?: BudgetState;

  /** Capability tokens */
  caps: CapabilitySet;

  /** Trace event sink */
  trace: TraceSink;
}

/**
 * Create a child context with updated span.
 */
export function childContext(parent: ExecContext, span: Span): ExecContext {
  return { ...parent, span };
}

/**
 * Create a context with restricted capabilities.
 */
export function restrictCaps(ctx: ExecContext, caps: Partial<CapabilitySet>): ExecContext {
  return {
    ...ctx,
    caps: {
      ...ctx.caps,
      ...caps,
    },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/descriptors/framelisp.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { PrimitiveDescriptor } from "../types";

export const frameLispDescriptors: PrimitiveDescriptor[] = [
  // === Core Effects ===
  {
    id: "framelisp/infer",
    layer: "FrameLisp",
    kind: "SpecialForm",
    signature: {
      params: [
        { name: "prompt", type: "Prompt" },
        { name: "options", type: "Record", optional: true },
      ],
      returns: "Str",
    },
    effects: ["Oracle"],
    resources: {
      estimate: { llmCalls: 1, tokens: "promptTokens + maxTokens" },
    },
    doc: {
      summary: "Core LLM inference primitive.",
      detail: "Sends prompt to oracle and returns response text. Subject to budget constraints.",
      laws: [
        "infer(prompt) is referentially opaque (Oracle effect).",
        "infer must be dominated by with-budget in linted bundles.",
      ],
      examples: [
        { input: '(infer "What is 2+2?")', output: '"4"', description: "Simple inference" },
      ],
    },
    lowering: { kind: "Intrinsic", irTag: "FInfer" },
    constraints: { mustBeDominatedByBudget: true },
    version: "1.0.0",
  },

  {
    id: "framelisp/call-tool",
    layer: "FrameLisp",
    kind: "SpecialForm",
    signature: {
      params: [
        { name: "name", type: "Str" },
        { name: "args", type: "Record" },
        { name: "contract", type: "ToolContract", optional: true },
      ],
      returns: "Any",
    },
    effects: ["Tool"],
    resources: {
      estimate: { toolCalls: 1 },
    },
    doc: {
      summary: "Call an external tool with validated arguments.",
      laws: [
        "call-tool must have associated ToolContract for audited execution.",
        "Arguments validated against contract.inputSchema before call.",
      ],
    },
    lowering: { kind: "Intrinsic", irTag: "FToolCall" },
    constraints: { requiresToolContract: true },
    version: "1.0.0",
  },

  // === Monad Operations ===
  {
    id: "framelisp/bind",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "m", type: "Flow[A]" },
        { name: "k", type: "Fn[A -> Flow[B]]" },
      ],
      returns: "Flow[B]",
    },
    effects: ["Control"],
    doc: {
      summary: "Monadic bind for Flow.",
      laws: [
        "Left identity: bind(pure(x), k) == k(x).",
        "Right identity: bind(m, pure) == m.",
        "Associativity: bind(bind(m, f), g) == bind(m, (lambda x. bind(f(x), g))).",
      ],
    },
    lowering: { kind: "Intrinsic", irTag: "FBind" },
    version: "1.0.0",
  },

  {
    id: "framelisp/pure",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [{ name: "x", type: "A" }],
      returns: "Flow[A]",
    },
    effects: ["Pure"],
    doc: {
      summary: "Lift a value into Flow.",
      laws: ["pure(x) has no effects."],
    },
    lowering: { kind: "Intrinsic", irTag: "FPure" },
    version: "1.0.0",
  },

  {
    id: "framelisp/fail",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "reason", type: "Keyword" },
        { name: "ctx", type: "Record", optional: true },
      ],
      returns: "Flow[Never]",
    },
    effects: ["Control"],
    doc: {
      summary: "Signal a failure.",
      detail: "Unwinds until a catch handler is found.",
    },
    lowering: { kind: "Intrinsic", irTag: "FFail" },
    version: "1.0.0",
  },

  {
    id: "framelisp/catch",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "flow", type: "Flow[A]" },
        { name: "handler", type: "Fn[Failure -> Flow[A]]" },
      ],
      returns: "Flow[A]",
    },
    effects: ["Control"],
    doc: {
      summary: "Handle failures from a flow.",
      laws: [
        "catch(pure(x), h) == pure(x).",
        "catch(fail(r), h) == h(Failure(r)).",
      ],
    },
    lowering: { kind: "Intrinsic", irTag: "FCatch" },
    version: "1.0.0",
  },

  // === Resource Control ===
  {
    id: "framelisp/with-budget",
    layer: "FrameLisp",
    kind: "SpecialForm",
    signature: {
      params: [
        { name: "budget", type: "Budget" },
        { name: "flow", type: "Flow[A]" },
      ],
      returns: "Flow[A]",
    },
    effects: ["Control"],
    doc: {
      summary: "Run flow with budget constraint.",
      detail: "Fails with :budget-exceeded if resources exhausted.",
    },
    lowering: { kind: "Intrinsic", irTag: "FWithBudget" },
    version: "1.0.0",
  },

  {
    id: "framelisp/with-timeout",
    layer: "FrameLisp",
    kind: "SpecialForm",
    signature: {
      params: [
        { name: "ms", type: "Int" },
        { name: "flow", type: "Flow[A]" },
      ],
      returns: "Flow[A]",
    },
    effects: ["Control", "Clock"],
    doc: {
      summary: "Run flow with timeout.",
      detail: "Fails with :timeout if time exceeded.",
    },
    lowering: { kind: "Intrinsic", irTag: "FWithTimeout" },
    version: "1.0.0",
  },

  // === Concurrency ===
  {
    id: "framelisp/all",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [{ name: "flows", type: "List[Flow[A]]" }],
      returns: "Flow[List[A]]",
    },
    effects: ["Concurrency"],
    doc: {
      summary: "Run all flows, collect all results.",
      detail: "Fails if any flow fails (fail-fast by default).",
    },
    lowering: { kind: "Intrinsic", irTag: "FAll" },
    version: "1.0.0",
  },

  {
    id: "framelisp/race",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [{ name: "flows", type: "List[Flow[A]]" }],
      returns: "Flow[A]",
    },
    effects: ["Concurrency"],
    doc: {
      summary: "Run flows, return first success.",
      detail: "Cancels remaining flows after first completion.",
    },
    lowering: { kind: "Intrinsic", irTag: "FRace" },
    version: "1.0.0",
  },

  {
    id: "framelisp/any",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [{ name: "flows", type: "List[Flow[A]]" }],
      returns: "Flow[A]",
    },
    effects: ["Concurrency"],
    doc: {
      summary: "Run flows, return first non-failure.",
      detail: "Tries flows in order, returns first success.",
    },
    lowering: { kind: "Intrinsic", irTag: "FAny" },
    version: "1.0.0",
  },

  // === Storage & IO ===
  {
    id: "framelisp/commit",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "store", type: "StoreRef" },
        { name: "key", type: "Str" },
        { name: "value", type: "Any" },
      ],
      returns: "Flow[Unit]",
    },
    effects: ["Store"],
    doc: {
      summary: "Write value to persistent store.",
    },
    lowering: { kind: "Intrinsic", irTag: "FCommit" },
    version: "1.0.0",
  },

  {
    id: "framelisp/emit",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "sink", type: "SinkRef" },
        { name: "item", type: "Any" },
      ],
      returns: "Flow[Unit]",
    },
    effects: ["Sink"],
    doc: {
      summary: "Emit item to output sink.",
    },
    lowering: { kind: "Intrinsic", irTag: "FEmit" },
    version: "1.0.0",
  },

  {
    id: "framelisp/observe",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "source", type: "SourceRef" },
        { name: "query", type: "Any", optional: true },
      ],
      returns: "Flow[Any]",
    },
    effects: ["Source"],
    doc: {
      summary: "Observe from input source.",
    },
    lowering: { kind: "Intrinsic", irTag: "FObserve" },
    version: "1.0.0",
  },

  // === Validation ===
  {
    id: "framelisp/validate",
    layer: "FrameLisp",
    kind: "Function",
    signature: {
      params: [
        { name: "schema", type: "SchemaRef" },
        { name: "value", type: "Any" },
      ],
      returns: "Flow[Any]",
    },
    effects: ["Pure"],
    doc: {
      summary: "Validate value against schema.",
      detail: "Fails with :validation-failed if invalid.",
    },
    lowering: { kind: "Intrinsic", irTag: "FValidate" },
    version: "1.0.0",
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/descriptors/lambdallm.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { PrimitiveDescriptor } from "../types";

export const lambdaLLMDescriptors: PrimitiveDescriptor[] = [
  {
    id: "lambdallm.llm/complete",
    layer: "LambdaLLM",
    kind: "Function",
    signature: {
      params: [
        { name: "prompt", type: "Prompt" },
        { name: "system", type: "Str", optional: true },
      ],
      returns: "Str",
    },
    effects: ["Oracle"],
    resources: { estimate: { llmCalls: 1, tokens: "promptTokens + maxTokens" } },
    doc: {
      summary: "High-level completion wrapper over FrameLisp infer.",
      detail: "Packages prompt and optional system instructions into a single inference call.",
    },
    lowering: { kind: "MacroExpand", irTag: "FInfer" },
    constraints: { mustBeDominatedByBudget: true },
    version: "1.0.0",
  },
  {
    id: "lambdallm.llm/chat",
    layer: "LambdaLLM",
    kind: "Function",
    signature: {
      params: [
        { name: "messages", type: "List[Message]" },
        { name: "tools", type: "List[ToolDef]", optional: true },
      ],
      returns: "Message",
    },
    effects: ["Oracle", "Tool"],
    resources: { estimate: { llmCalls: 1, tokens: "promptTokens + responseTokens" } },
    doc: {
      summary: "Multi-turn chat with optional tool calls.",
      detail: "Expands to FrameLisp infer with tool contracts included when provided.",
    },
    lowering: { kind: "LowerHook", hook: "lambdallm.lower/chat" },
    constraints: { mustBeDominatedByBudget: true, requiresToolContract: true },
    version: "1.0.0",
  },
  {
    id: "lambdallm.prompt/prompt+",
    layer: "LambdaLLM",
    kind: "Function",
    signature: {
      params: [
        { name: "p1", type: "Prompt" },
        { name: "p2", type: "Prompt" },
      ],
      returns: "Prompt",
    },
    effects: ["Pure"],
    doc: {
      summary: "Concatenate prompts in sequence.",
      detail: "Used to build larger prompts from reusable blocks.",
      laws: ["prompt+(p1, p2) is associative."],
    },
    lowering: { kind: "MacroExpand", hook: "lambdallm.lower/promptConcat" },
    version: "1.0.0",
  },
  {
    id: "lambdallm.tooling/with-tools",
    layer: "LambdaLLM",
    kind: "Macro",
    signature: {
      params: [
        { name: "tools", type: "List[ToolContract]" },
        { name: "body", type: "Flow[A]" },
      ],
      returns: "Flow[A]",
    },
    effects: ["Control", "Tool"],
    doc: {
      summary: "Scope tool availability for a body of code.",
      detail: "Ensures tool contracts are attached and validated in the compiled bundle.",
    },
    lowering: { kind: "LowerHook", hook: "lambdallm.lower/withTools" },
    constraints: { requiresToolContract: true },
    version: "1.0.0",
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/descriptors/lambdarlm.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { PrimitiveDescriptor } from "../types";

export const lambdaRLMDescriptors: PrimitiveDescriptor[] = [
  {
    id: "lambdarlm/compose-sequential",
    layer: "LambdaRLM",
    kind: "Function",
    signature: {
      params: [
        { name: "s1", type: "Solver" },
        { name: "s2", type: "Solver" },
      ],
      returns: "Solver",
    },
    effects: ["Control"],
    doc: {
      summary: "Pipe the output of s1 into s2 sequentially.",
      laws: [
        "compose-sequential is associative when solver metadata merge is associative.",
      ],
    },
    lowering: { kind: "LowerHook", hook: "lambdarlm.lower/composeSequential" },
    version: "1.0.0",
  },
  {
    id: "lambdarlm/compose-parallel",
    layer: "LambdaRLM",
    kind: "Function",
    signature: {
      params: [
        { name: "solvers", type: "List[Solver]" },
        { name: "merger", type: "Fn[List[Result] -> Result]" },
      ],
      returns: "Solver",
    },
    effects: ["Concurrency"],
    doc: {
      summary: "Run solvers in parallel and merge the results.",
      detail: "Useful for exploration where the best answer is chosen by a reducer.",
    },
    lowering: { kind: "LowerHook", hook: "lambdarlm.lower/composeParallel" },
    version: "1.0.0",
  },
  {
    id: "lambdarlm/repair-until-valid",
    layer: "LambdaRLM",
    kind: "Function",
    signature: {
      params: [
        { name: "generator", type: "Fn[Problem -> Candidate]" },
        { name: "validate", type: "Fn[Candidate -> Bool]" },
        { name: "repair", type: "Fn[Candidate -> Candidate]" },
        { name: "maxIters", type: "Int", optional: true },
      ],
      returns: "Result",
    },
    effects: ["Constraint", "Control"],
    doc: {
      summary: "Iteratively generate, validate, and repair until the candidate passes validation.",
    },
    lowering: { kind: "LowerHook", hook: "lambdarlm.lower/repairUntilValid" },
    version: "1.0.0",
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/descriptors/omegallm.ts
// ═══════════════════════════════════════════════════════════════════════════

import type { PrimitiveDescriptor } from "../types";

export const omegaLLMDescriptors: PrimitiveDescriptor[] = [
  {
    id: "omegallm/runtime/eval-omega",
    layer: "OmegaLLM",
    kind: "Function",
    signature: {
      params: [{ name: "source", type: "Str" }],
      returns: "Outcome",
    },
    effects: ["Control"],
    doc: {
      summary: "Evaluate Omega code and return an Outcome.",
      detail: "Entry point for running small snippets inside the runtime evaluator.",
    },
    lowering: { kind: "LowerHook", hook: "omega.runtime/eval" },
    version: "1.0.0",
  },
  {
    id: "omegallm/stream/map",
    layer: "OmegaLLM",
    kind: "Function",
    signature: {
      params: [
        { name: "f", type: "Fn[A -> B]" },
        { name: "stream", type: "Stream[A]" },
      ],
      returns: "Stream[B]",
    },
    effects: ["Pure"],
    doc: {
      summary: "Map over a lazy stream.",
      detail: "Pure transformation; evaluation is deferred to stream forcing.",
    },
    lowering: { kind: "Intrinsic", irTag: "StreamMap" },
    version: "1.0.0",
  },
  {
    id: "omegallm/provenance/log-evidence",
    layer: "OmegaLLM",
    kind: "Function",
    signature: {
      params: [
        { name: "evidence", type: "Evidence" },
        { name: "sink", type: "SinkRef", optional: true },
      ],
      returns: "Unit",
    },
    effects: ["Sink"],
    doc: {
      summary: "Record provenance evidence to a sink.",
      detail: "Used by runtime to emit receipts and provenance metadata.",
    },
    lowering: { kind: "LowerHook", hook: "omega.provenance/logEvidence" },
    version: "1.0.0",
  },
];

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/docgen.ts
// ═══════════════════════════════════════════════════════════════════════════

import { PrimitiveRegistry } from "./registry";
import type { PrimitiveDescriptor } from "./types";

/**
 * Generate markdown documentation from registry.
 */
export function generateMarkdown(registry: PrimitiveRegistry): string {
  const lines: string[] = [];

  lines.push("# Generated Primitive Reference\n");
  lines.push(`Generated: ${new Date().toISOString()}\n`);
  lines.push(`Total primitives: ${registry.getAll().length}\n`);
  lines.push("---\n");

  const layers = ["FrameLisp", "LambdaLLM", "OmegaLLM", "LambdaRLM"];

  for (const layer of layers) {
    const descriptors = registry.getByLayer(layer);
    if (descriptors.length === 0) continue;

    lines.push(`## ${layer}\n`);

    const byKind = new Map<string, PrimitiveDescriptor[]>();
    for (const d of descriptors) {
      if (!byKind.has(d.kind)) byKind.set(d.kind, []);
      byKind.get(d.kind)!.push(d);
    }

    for (const [kind, descs] of byKind) {
      lines.push(`### ${kind}s\n`);
      lines.push("| Function | Signature | Effects | Description |");
      lines.push("|----------|-----------|---------|-------------|");

      for (const d of descs.sort((a, b) => a.id.localeCompare(b.id))) {
        const name = d.id.split("/")[1];
        const sig = formatSignature(d.signature);
        const effects = d.effects.join(", ") || "Pure";
        const desc = d.doc.summary;
        lines.push(`| \`${name}\` | \`${sig}\` | ${effects} | ${desc} |`);
      }

      lines.push("");
    }
  }

  return lines.join("\n");
}

function formatSignature(sig: { params: Array<{ name: string; type: string; optional?: boolean }>; returns: string }): string {
  const params = sig.params
    .map(p => p.optional ? `${p.name}?` : p.name)
    .join(", ");
  return `(${params}) -> ${sig.returns}`;
}

/**
 * Generate JSON API reference.
 */
export function generateJSON(registry: PrimitiveRegistry): string {
  return JSON.stringify(registry.toJSON(), null, 2);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/index.ts
// ═══════════════════════════════════════════════════════════════════════════

export * from "./types";
export * from "./registry";
export * from "./query";
export { generateMarkdown, generateJSON } from "./docgen";
export * from "./validate";

import { defaultRegistry } from "./registry";
import { frameLispDescriptors } from "./descriptors/framelisp";
import { lambdaLLMDescriptors } from "./descriptors/lambdallm";
import { lambdaRLMDescriptors } from "./descriptors/lambdarlm";
import { omegaLLMDescriptors } from "./descriptors/omegallm";

const seeds = [
  ...frameLispDescriptors,
  ...lambdaLLMDescriptors,
  ...lambdaRLMDescriptors,
  ...omegaLLMDescriptors,
];

for (const desc of seeds) {
  defaultRegistry.register(desc);
}

export {
  frameLispDescriptors,
  lambdaLLMDescriptors,
  lambdaRLMDescriptors,
  omegaLLMDescriptors,
  defaultRegistry,
};

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/query.ts
// ═══════════════════════════════════════════════════════════════════════════

import { PrimitiveRegistry } from "./registry";
import type { Effect, PrimitiveDescriptor } from "./types";

export function findPrimitive(registry: PrimitiveRegistry, id: string): PrimitiveDescriptor | undefined {
  return registry.get(id);
}

export function apropos(registry: PrimitiveRegistry, query: string): PrimitiveDescriptor[] {
  return registry.search(query);
}

export function filterByLayer(registry: PrimitiveRegistry, layer: string): PrimitiveDescriptor[] {
  return registry.getByLayer(layer);
}

export function filterByEffect(registry: PrimitiveRegistry, effect: Effect): PrimitiveDescriptor[] {
  return registry.getByEffect(effect);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/registry.ts
// ═══════════════════════════════════════════════════════════════════════════

import { type Effect, type PrimitiveDescriptor } from "./types";

export class PrimitiveRegistry {
  private descriptors: Map<string, PrimitiveDescriptor> = new Map();
  private byLayer: Map<string, Set<string>> = new Map();
  private byEffect: Map<Effect, Set<string>> = new Map();

  /**
   * Register a primitive descriptor.
   * @throws if id already registered
   */
  register(descriptor: PrimitiveDescriptor): void {
    if (this.descriptors.has(descriptor.id)) {
      throw new Error(`Primitive already registered: ${descriptor.id}`);
    }

    this.descriptors.set(descriptor.id, descriptor);

    if (!this.byLayer.has(descriptor.layer)) {
      this.byLayer.set(descriptor.layer, new Set());
    }
    this.byLayer.get(descriptor.layer)!.add(descriptor.id);

    for (const effect of descriptor.effects) {
      if (!this.byEffect.has(effect)) {
        this.byEffect.set(effect, new Set());
      }
      this.byEffect.get(effect)!.add(descriptor.id);
    }
  }

  /**
   * Get descriptor by ID.
   */
  get(id: string): PrimitiveDescriptor | undefined {
    return this.descriptors.get(id);
  }

  /**
   * Get all descriptors.
   */
  getAll(): PrimitiveDescriptor[] {
    return Array.from(this.descriptors.values());
  }

  /**
   * Get all descriptors for a layer.
   */
  getByLayer(layer: string): PrimitiveDescriptor[] {
    const ids = this.byLayer.get(layer);
    if (!ids) return [];
    return Array.from(ids).map(id => this.descriptors.get(id)!).filter(Boolean);
  }

  /**
   * Get all descriptors with a specific effect.
   */
  getByEffect(effect: Effect): PrimitiveDescriptor[] {
    const ids = this.byEffect.get(effect);
    if (!ids) return [];
    return Array.from(ids).map(id => this.descriptors.get(id)!).filter(Boolean);
  }

  /**
   * Search descriptors by text (apropos).
   * Matches against id, summary, and detail.
   */
  search(query: string): PrimitiveDescriptor[] {
    const q = query.toLowerCase();
    if (!q) return [];
    return this.getAll().filter(d =>
      d.id.toLowerCase().includes(q) ||
      d.doc.summary.toLowerCase().includes(q) ||
      (d.doc.detail?.toLowerCase().includes(q) ?? false)
    );
  }

  /**
   * Get lowering rule for an IR tag.
   */
  getByIrTag(irTag: string): PrimitiveDescriptor | undefined {
    return this.getAll().find(d => d.lowering?.irTag === irTag);
  }

  /**
   * Validate registry completeness.
   */
  validate(): { valid: boolean; errors: string[] } {
    const errors: string[] = [];

    for (const [id, desc] of this.descriptors) {
      if (!desc.signature) {
        errors.push(`${id}: missing signature`);
      }
      if (!desc.doc?.summary) {
        errors.push(`${id}: missing doc.summary`);
      }
      if (!desc.version) {
        errors.push(`${id}: missing version`);
      }
      if (!desc.effects || desc.effects.length === 0) {
        errors.push(`${id}: missing effects`);
      }

      if (desc.effects.includes("Oracle") && !desc.constraints?.mustBeDominatedByBudget) {
        errors.push(`${id}: Oracle effect should require budget dominance`);
      }
      if (desc.effects.includes("Tool") && !desc.constraints?.requiresToolContract) {
        errors.push(`${id}: Tool effect should require tool contract`);
      }
    }

    return { valid: errors.length === 0, errors };
  }

  /**
   * Export registry as JSON for tooling.
   */
  toJSON(): Record<string, PrimitiveDescriptor> {
    return Object.fromEntries(this.descriptors);
  }

  /**
   * Load registry from JSON.
   */
  static fromJSON(data: Record<string, PrimitiveDescriptor>): PrimitiveRegistry {
    const registry = new PrimitiveRegistry();
    for (const desc of Object.values(data)) {
      registry.register(desc);
    }
    return registry;
  }
}

/**
 * Global default registry instance.
 */
export const defaultRegistry = new PrimitiveRegistry();

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/types.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * Effect kinds for capability calculus.
 * Closed set - all effects must be one of these.
 */
export type Effect =
  | "Pure"           // No effects, referentially transparent
  | "Oracle"         // LLM inference (requires OracleCap)
  | "Tool"           // External tool call (requires ToolCap + contract)
  | "Store"          // Persistent storage (requires StoreCap)
  | "Sink"           // Emit to stream/output (requires SinkCap)
  | "Source"         // Observe from input (requires SourceCap)
  | "Clock"          // Time access (requires ClockPort for determinism)
  | "Concurrency"    // Fiber spawning/scheduling
  | "Constraint"     // Constraint propagation
  | "Nondet"         // Nondeterministic choice
  | "Control";       // Control flow effects (bind, catch, loop)

/**
 * Type signature for primitives.
 * Initially string-based; can upgrade to full type system later.
 */
export interface TypeSig {
  params: Array<{
    name: string;
    type: string;
    optional?: boolean;
  }>;
  returns: string;
}

/**
 * Cost model for budget estimation.
 */
export interface CostModel {
  /**
   * Static cost estimate (or formula string).
   */
  estimate?: {
    llmCalls?: number | string;   // e.g., 1 or "promptTokens / 1000"
    tokens?: number | string;
    timeMs?: number | string;
    toolCalls?: number | string;
  };
  /**
   * Dynamic estimator function (for runtime estimation).
   */
  estimator?: (args: unknown[], ctx: unknown) => {
    llmCalls?: number;
    tokens?: number;
    timeMs?: number;
    toolCalls?: number;
  };
}

/**
 * Lowering rule: how surface form compiles to IR.
 */
export interface LoweringRule {
  kind: "Intrinsic" | "MacroExpand" | "LowerHook";
  irTag?: string;              // For Intrinsic: which FlowIR tag
  hook?: string;               // For LowerHook: hook function id
}

/**
 * Lint constraints for static analysis.
 */
export interface LintConstraints {
  mustBeDominatedByBudget?: boolean;
  mustBeDominatedByTimeout?: boolean;
  requiresToolContract?: boolean;
  requiresSchema?: boolean;
}

/**
 * Documentation for the primitive.
 */
export interface PrimitiveDoc {
  summary: string;
  detail?: string;
  laws?: string[];             // Equational laws (crucial for refactoring)
  examples?: Array<{
    input: string;
    output: string;
    description?: string;
  }>;
}

/**
 * Deprecation info.
 */
export interface DeprecationInfo {
  since: string;
  replacedBy?: string;
  note?: string;
}

/**
 * Complete primitive descriptor.
 */
export interface PrimitiveDescriptor {
  /** Canonical namespaced ID, e.g., "framelisp/infer" */
  id: string;

  /** Which layer this primitive belongs to */
  layer: "FrameLisp" | "LambdaLLM" | "OmegaLLM" | "LambdaRLM";

  /** Kind of primitive */
  kind: "SpecialForm" | "Function" | "Macro" | "ProtocolMethod";

  /** Type signature */
  signature: TypeSig;

  /** Effect requirements (closed set) */
  effects: Effect[];

  /** Cost model for budget planning */
  resources?: CostModel;

  /** Documentation */
  doc: PrimitiveDoc;

  /** How to compile to IR */
  lowering?: LoweringRule;

  /** Runtime implementation reference */
  runtime?: {
    implementer?: string;      // e.g., "omega-kernel/prim/add"
  };

  /** Lint constraints */
  constraints?: LintConstraints;

  /** Semantic version */
  version: string;

  /** Deprecation info if deprecated */
  deprecated?: DeprecationInfo;
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/registry/validate.ts
// ═══════════════════════════════════════════════════════════════════════════

import { PrimitiveRegistry } from "./registry";
import type { PrimitiveDescriptor } from "./types";

export interface ValidationResult {
  valid: boolean;
  errors: string[];
}

export function validateDescriptor(descriptor: PrimitiveDescriptor): ValidationResult {
  const errors: string[] = [];

  if (!descriptor.id) {
    errors.push("missing id");
  }
  if (!descriptor.signature) {
    errors.push(`${descriptor.id || "<unknown>"}: missing signature`);
  }
  if (!descriptor.doc?.summary) {
    errors.push(`${descriptor.id || "<unknown>"}: missing doc.summary`);
  }
  if (!descriptor.version) {
    errors.push(`${descriptor.id || "<unknown>"}: missing version`);
  }
  if (!descriptor.effects || descriptor.effects.length === 0) {
    errors.push(`${descriptor.id || "<unknown>"}: missing effects`);
  }
  if (descriptor.effects?.includes("Oracle") && !descriptor.constraints?.mustBeDominatedByBudget) {
    errors.push(`${descriptor.id || "<unknown>"}: Oracle effect should require budget dominance`);
  }
  if (descriptor.effects?.includes("Tool") && !descriptor.constraints?.requiresToolContract) {
    errors.push(`${descriptor.id || "<unknown>"}: Tool effect should require tool contract`);
  }

  return { valid: errors.length === 0, errors };
}

export function validateRegistry(registry: PrimitiveRegistry): ValidationResult {
  return registry.validate();
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/repl/commands/opr.ts
// ═══════════════════════════════════════════════════════════════════════════

/**
 * OPR REPL Commands
 *
 * Commands for interactive OPR usage: :opr-kernels, :opr-step, :opr-run, :opr-receipts, :opr-verify
 */

import type { KernelState, OprReceipt } from '../../core/opr/types';
import { verifyReceiptChain, InMemoryReceiptStore, type ReceiptStore } from '../../core/opr/receipts';
import { OprRuntime, type KernelPromptConfig, type SessionBudget } from '../../core/opr/runtime';
import type { OprLLMAdapter } from '../../core/opr/adapters/types';
import { readFile } from 'fs/promises';

/**
 * OPR Session State - tracks receipts and kernel states across commands
 */
export interface OprSessionState {
  receipts: ReceiptStore;
  activeKernels: Map<
    string,
    {
      kernelId: string;
      state: KernelState;
      receipts: OprReceipt[];
    }
  >;
  stats: {
    totalSteps: number;
    totalAttempts: number;
    successfulSteps: number;
    callbacksExecuted: number;
  };
}

/**
 * Kernel registry interface
 */
export interface KernelRegistry {
  list(): string[];
  get(id: string): KernelPromptConfig | undefined;
}

/**
 * Context required for OPR commands
 */
export interface OprCommandContext {
  /** Get or create OPR session state */
  getOprState(): OprSessionState;

  /** Create an LLM adapter for OPR calls */
  createAdapter(): OprLLMAdapter;

  /** Session budget (optional) */
  budget?: SessionBudget;

  /** Kernel registry */
  kernelRegistry: KernelRegistry;

  /** Evaluate a Lisp expression and return the result */
  evalLisp?(expr: string): Promise<unknown>;

  /** Log output */
  log(message: string): void;
}

/**
 * Create a new OPR session state
 */
export function createOprSessionState(): OprSessionState {
  return {
    receipts: new InMemoryReceiptStore(),
    activeKernels: new Map(),
    stats: {
      totalSteps: 0,
      totalAttempts: 0,
      successfulSteps: 0,
      callbacksExecuted: 0,
    },
  };
}

/**
 * Handle :opr-kernels command - list available kernels
 */
export async function handleOprKernels(ctx: OprCommandContext): Promise<void> {
  const kernels = ctx.kernelRegistry.list();

  ctx.log('');
  ctx.log('Available OPR Kernels');
  ctx.log('=====================');

  if (kernels.length === 0) {
    ctx.log('  (no kernels registered)');
  } else {
    for (const id of kernels) {
      ctx.log(`  - ${id}`);
    }
  }

  ctx.log('');
}

/**
 * Handle :opr-step command - execute single kernel step
 */
export async function handleOprStep(ctx: OprCommandContext, args: string): Promise<void> {
  const match = args.match(/^(\S+)\s+(.+)$/);
  if (!match) {
    ctx.log('Usage: :opr-step <kernel-id> <program-expr>');
    ctx.log('Example: :opr-step opr.logic.v1 (hash :rules "..." :facts \'(...))');
    return;
  }

  const [, kernelId, programExpr] = match;

  // Validate kernel exists
  const kernel = ctx.kernelRegistry.get(kernelId);
  if (!kernel) {
    ctx.log(`Unknown kernel: ${kernelId}`);
    ctx.log('Use :opr-kernels to list available kernels.');
    return;
  }

  // Evaluate the program expression
  let program: unknown;
  if (ctx.evalLisp) {
    try {
      program = await ctx.evalLisp(programExpr);
    } catch (e) {
      ctx.log(`Error evaluating program expression: ${(e as Error).message}`);
      return;
    }
  } else {
    // Fallback: try to parse as JSON
    try {
      program = JSON.parse(programExpr);
    } catch {
      ctx.log('Cannot evaluate expression: no Lisp evaluator available and not valid JSON');
      return;
    }
  }

  const oprState = ctx.getOprState();

  // Create runtime
  const runtime = new OprRuntime({
    kernel,
    adapter: ctx.createAdapter(),
    receipts: oprState.receipts,
    budget: { maxAttempts: 3 },
    sessionBudget: ctx.budget,
  });

  ctx.log(`\nExecuting ${kernelId} step...`);

  // Execute step
  const result = await runtime.step({
    program,
    state: oprState.activeKernels.get(kernelId)?.state ?? null,
  });

  // Update session state
  oprState.stats.totalSteps++;
  oprState.stats.totalAttempts += result.attempts;

  if (result.tag === 'ok') {
    oprState.stats.successfulSteps++;

    // Store active kernel state for continuation
    if (result.output.next_state !== null) {
      oprState.activeKernels.set(kernelId, {
        kernelId,
        state: result.output.next_state,
        receipts: result.receipts,
      });
    } else {
      oprState.activeKernels.delete(kernelId);
    }

    ctx.log('');
    ctx.log('Step Succeeded');
    ctx.log(`  Kernel: ${kernelId}`);
    ctx.log(`  Attempts: ${result.attempts}`);
    ctx.log(`  Result: ${JSON.stringify(result.output.result, null, 2)}`);
    if (result.output.next_state) {
      ctx.log(`  Next State: ${JSON.stringify(result.output.next_state, null, 2)}`);
    }
    if (result.output.effects.length > 0) {
      ctx.log(`  Effects: ${result.output.effects.length} callback(s) pending`);
    }
  } else {
    ctx.log('');
    ctx.log(`Step Failed: ${result.tag}`);
    ctx.log(`  Attempts: ${result.attempts}`);

    if (result.tag === 'validation-failed') {
      ctx.log('  Violations:');
      for (const v of result.violations) {
        ctx.log(`    ${v.path}: ${v.message}`);
      }
    }
  }

  ctx.log('');
}

/**
 * Handle :opr-run command - run kernel to fixpoint
 */
export async function handleOprRun(ctx: OprCommandContext, args: string): Promise<void> {
  const match = args.match(/^(\S+)\s+(.+)$/);
  if (!match) {
    ctx.log('Usage: :opr-run <kernel-id> <program-expr>');
    return;
  }

  const [, kernelId, programExpr] = match;

  const kernel = ctx.kernelRegistry.get(kernelId);
  if (!kernel) {
    ctx.log(`Unknown kernel: ${kernelId}. Use :opr-kernels to list.`);
    return;
  }

  let program: unknown;
  if (ctx.evalLisp) {
    try {
      program = await ctx.evalLisp(programExpr);
    } catch (e) {
      ctx.log(`Error evaluating program expression: ${(e as Error).message}`);
      return;
    }
  } else {
    try {
      program = JSON.parse(programExpr);
    } catch {
      ctx.log('Cannot evaluate expression');
      return;
    }
  }

  const oprState = ctx.getOprState();

  const runtime = new OprRuntime({
    kernel,
    adapter: ctx.createAdapter(),
    receipts: oprState.receipts,
    budget: { maxAttempts: 3 },
    sessionBudget: ctx.budget,
    invariants: {
      iterationMonotonic: true,
      derivedMonotonic: true,
      deltaTermination: false,
    },
  });

  ctx.log(`\nRunning ${kernelId} to fixpoint...`);

  const result = await runtime.runToFixpoint({
    program,
    state: null,
  });

  if (result.tag === 'ok') {
    ctx.log('');
    ctx.log('Fixpoint Reached');
    ctx.log(`  Iterations: ${result.iterations}`);
    ctx.log(`  Total receipts: ${result.receipts.length}`);
    ctx.log(`  Final State: ${JSON.stringify(result.finalState, null, 2)}`);
  } else if (result.tag === 'max-iterations') {
    ctx.log(`\nMax iterations (${result.iterations}) reached without fixpoint`);
  } else {
    ctx.log(`\nError after ${result.iterations} iterations: ${result.error.tag}`);
  }

  ctx.log('');
}

/**
 * Handle :opr-receipts command - show receipt chain
 */
export async function handleOprReceipts(ctx: OprCommandContext): Promise<void> {
  const oprState = ctx.getOprState();
  const receipts = oprState.receipts.getAll();

  if (receipts.length === 0) {
    ctx.log('\nNo OPR receipts in current session.\n');
    return;
  }

  ctx.log('');
  ctx.log('OPR Receipt Chain');
  ctx.log('==================');

  for (let i = 0; i < receipts.length; i++) {
    const r = receipts[i];
    const statusIcon = r.status === 'OK' ? '[OK]' : '[X]';
    ctx.log(`${i + 1}. ${statusIcon} ${r.status} - ${r.kernel_id}:${r.op}`);
    ctx.log(`     Attempt: ${r.attempt}  Created: ${r.created_at}`);
    if (r.errors.length > 0) {
      ctx.log(`     Errors: ${r.errors[0]}`);
    }
  }

  const validity = verifyReceiptChain(receipts);
  ctx.log('');
  ctx.log(`Chain Integrity: ${validity.valid ? 'VALID' : `BROKEN at ${validity.brokenAt}`}`);
  ctx.log('');
}

/**
 * Handle :opr-verify command - verify receipt chain integrity
 */
export async function handleOprVerify(ctx: OprCommandContext, args: string): Promise<void> {
  let receipts: OprReceipt[];

  if (args.trim()) {
    // Load from file
    try {
      const content = await readFile(args.trim(), 'utf-8');
      receipts = JSON.parse(content);
    } catch (e) {
      ctx.log(`Error loading receipt file: ${(e as Error).message}`);
      return;
    }
  } else {
    // Use session receipts
    const oprState = ctx.getOprState();
    receipts = oprState.receipts.getAll();
    if (receipts.length === 0) {
      ctx.log('No OPR receipts in session. Provide a file path to verify.');
      return;
    }
  }

  const result = verifyReceiptChain(receipts);

  if (result.valid) {
    ctx.log('');
    ctx.log('Receipt chain is VALID');
    ctx.log(`  ${receipts.length} receipts verified`);
    if (receipts.length > 0) {
      ctx.log(`  Chain hash: ${receipts[receipts.length - 1].receipt_hash}`);
    }
  } else {
    ctx.log('');
    ctx.log('Receipt chain is BROKEN');
    ctx.log(`  Broken at index: ${result.brokenAt}`);
    ctx.log(`  Error: ${result.error}`);
  }

  ctx.log('');
}

/**
 * Get all OPR command definitions for registration
 */
export function getOprCommands(): Record<
  string,
  {
    description: string;
    usage: string;
    handler: (ctx: OprCommandContext, args: string) => Promise<void>;
  }
> {
  return {
    ':opr-kernels': {
      description: 'List available OPR kernels',
      usage: ':opr-kernels',
      handler: async (ctx) => handleOprKernels(ctx),
    },
    ':opr-step': {
      description: 'Execute single OPR kernel step',
      usage: ':opr-step <kernel-id> <program-expr>',
      handler: handleOprStep,
    },
    ':opr-run': {
      description: 'Run OPR kernel to fixpoint',
      usage: ':opr-run <kernel-id> <program-expr>',
      handler: handleOprRun,
    },
    ':opr-receipts': {
      description: 'Show OPR receipt chain for current session',
      usage: ':opr-receipts',
      handler: async (ctx) => handleOprReceipts(ctx),
    },
    ':opr-verify': {
      description: 'Verify OPR receipt chain integrity',
      usage: ':opr-verify [receipt-file]',
      handler: handleOprVerify,
    },
  };
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: src/runtime.ts
// ═══════════════════════════════════════════════════════════════════════════

// src/runtime.ts
// OmegaRuntime - Clean API for external integrations
//
// Usage:
//   import { OmegaRuntime, createAnthropicAdapter } from "omega-llm";
//
//   const omega = new OmegaRuntime();
//   const result = await omega.eval("(+ 1 2)");
//   console.log(result.value); // 3

import type { Val } from "./core/eval/values";
import type { OracleAdapter } from "./core/oracle/adapter";
import type { MeaningVal } from "./core/oracle/meaning";
import type { Ctx } from "./core/ctx/ctx";
import type { CapSet } from "./core/governance/caps";
import type { BudgetLimits } from "./core/governance/budgets";
import type { Profile } from "./core/governance/profile";
import type { State } from "./core/eval/machine";
import type { Expr } from "./core/ast";
import type { DistVal } from "./core/eval/dist";

import { ctxRootFromProfile, ctxSeal, ctxApplyProfile } from "./core/ctx/ctx";
import { DEFAULT_PROFILE, PROFILE_SPECULATIVE, PROFILE_TEST_CERTIFIED, PROFILE_PROOF_CERTIFIED } from "./core/governance/profile";
import { COWStore } from "./core/eval/store";
import { installPrims } from "./core/prims";
import { runToCompletion } from "./core/eval/run";
import { RuntimeImpl } from "./core/effects/runtimeImpl";
import { compileTextToExpr } from "./core/pipeline/compileText";
import { DepthTrackingAdapter } from "./core/oracle/adapters/types";
import { SnapshotRepo } from "./core/oracle/snapshots";
import { InMemoryReceiptStore } from "./core/oracle/receipts";

/**
 * Configuration for OmegaRuntime
 */
export type OmegaConfig = {
  /** Oracle adapter for LLM calls (optional - without it, infer.op will fail) */
  adapter?: OracleAdapter;

  /** Maximum Oracle recursion depth (default: 4) */
  maxOracleDepth?: number;

  /** Default capability set for new contexts */
  defaultCaps?: CapSet;

  /** Default budget limits for new contexts */
  defaultBudgets?: BudgetLimits;

  /** Truth regime profile (default: PROFILE_SPECULATIVE) */
  profile?: Profile;

  /** Maximum evaluation steps (default: 500000) */
  maxSteps?: number;
};

/**
 * Result of an eval operation
 */
export type EvalResult = {
  /** Whether evaluation succeeded */
  ok: boolean;

  /** The result value (if ok) */
  value?: Val;

  /** Error message (if not ok) */
  error?: string;
};

/**
 * Result of an infer operation
 */
export type InferResult = {
  /** Whether inference succeeded */
  ok: boolean;

  /** The Meaning returned by Oracle */
  meaning?: MeaningVal;

  /** Just the denotation (convenience accessor) */
  value?: Val;

  /** Confidence score (0-1) */
  confidence?: number;

  /** Error message (if not ok) */
  error?: string;
};

// Mock commit adapter for standalone runtime
const mockCommitAdapter = {
  async commit(_payload: Val, _ctxDigest: string): Promise<Val> {
    return { tag: "Str", s: "commit:" + Math.random().toString(16).slice(2) } as Val;
  }
};

// installPrims is now imported from ./core/prims (117 production primitives)

/**
 * OmegaRuntime - Main entry point for external integrations
 *
 * Provides a clean, promise-based API for:
 * - Evaluating Lisp expressions
 * - Running Oracle-powered inference
 * - Managing contexts with governance
 * - Integrating with VS Code, CLI tools, etc.
 */
export class OmegaRuntime {
  private adapter?: OracleAdapter;
  private config: OmegaConfig;
  private rootCtx: Ctx;
  private maxSteps: number;

  constructor(config: OmegaConfig = {}) {
    this.config = config;
    this.maxSteps = config.maxSteps ?? 500_000;

    const profile = config.profile ?? DEFAULT_PROFILE;
    this.rootCtx = ctxRootFromProfile(profile);

    // Wrap adapter with depth tracking if provided
    if (config.adapter) {
      this.adapter = new DepthTrackingAdapter(
        config.adapter,
        config.maxOracleDepth ?? 4
      );
    }

    // Apply profile restrictions if non-default caps/budgets specified
    if (config.defaultCaps || config.defaultBudgets) {
      const restrictProfile: Profile = {
        name: "custom",
        caps: config.defaultCaps ?? profile.caps,
        budgets: config.defaultBudgets ?? profile.budgets,
        truth: profile.truth,
      };
      this.rootCtx = ctxApplyProfile(this.rootCtx, restrictProfile);
    }
  }

  /**
   * Create initial machine state from expression
   */
  private initialState(expr: Expr): State {
    const store0 = new COWStore();
    const prim = installPrims(store0);
    return {
      control: { tag: "Expr", e: expr },
      env: prim.env,
      store: prim.store,
      kont: [],
      handlers: [],
    };
  }

  /**
   * Evaluate a Lisp expression
   *
   * @param code - Lisp source code
   * @param options - Optional context overrides
   * @returns EvalResult with value or error
   *
   * @example
   * const result = await omega.eval("(+ 1 2 3)");
   * console.log(result.value); // 6
   */
  async eval(
    code: string,
    options?: { sealed?: boolean }
  ): Promise<EvalResult> {
    try {
      // Compile text to expression
      const expr = compileTextToExpr(code);

      // Set up context
      let ctx = this.rootCtx;
      if (options?.sealed) {
        ctx = ctxSeal(ctx);
      }

      // Create runtime with Oracle support
      const snapshots = new SnapshotRepo();
      const receipts = new InMemoryReceiptStore("off");
      const runtime = new RuntimeImpl(
        this.adapter as OracleAdapter,  // May be undefined - infer.op will fail gracefully
        snapshots,
        receipts,
        mockCommitAdapter,
        this.config.profile
      );

      // Run to completion
      const value = await runToCompletion(runtime, this.initialState(expr), this.maxSteps);

      return { ok: true, value };
    } catch (e) {
      return { ok: false, error: String(e) };
    }
  }

  /**
   * Run Oracle-powered inference
   *
   * @param query - Natural language or structured query
   * @param options - Optional context and confidence threshold
   * @returns InferResult with meaning or error
   *
   * @example
   * const result = await omega.infer("Simplify: 2x + 3x");
   * if (result.ok && result.confidence > 0.8) {
   *   console.log(result.value);
   * }
   */
  async infer(
    query: string | Record<string, unknown>,
    options?: { minConfidence?: number; sealed?: boolean }
  ): Promise<InferResult> {
    if (!this.adapter) {
      return { ok: false, error: "No Oracle adapter configured" };
    }

    // Build the infer expression
    const payload = typeof query === "string"
      ? `"${query.replace(/"/g, '\\"')}"`
      : JSON.stringify(query);
    const code = `(effect int.op ${payload})`;

    try {
      const result = await this.eval(code, { sealed: options?.sealed });

      if (!result.ok) {
        return { ok: false, error: result.error };
      }

      const val = result.value;
      if (val && typeof val === "object" && "tag" in val && val.tag === "Meaning") {
        const meaning = val as MeaningVal;
        const confidence = meaning.confidence ?? 0;

        if (options?.minConfidence !== undefined && confidence < options.minConfidence) {
          return {
            ok: false,
            error: `Confidence ${confidence} below threshold ${options.minConfidence}`,
            meaning,
            confidence,
          };
        }

        return {
          ok: true,
          meaning,
          value: meaning.denotation as Val | undefined,
          confidence,
        };
      }

      return { ok: false, error: "Inference did not return a Meaning" };
    } catch (e) {
      return { ok: false, error: String(e) };
    }
  }

  /**
   * Multi-shot search returning a distribution of solutions
   *
   * @param query - Query for the Oracle
   * @param options - Optional sample count and threshold
   * @returns Array of candidate solutions with probabilities
   */
  async search(
    query: string | Record<string, unknown>,
    options?: { maxCandidates?: number; minProb?: number }
  ): Promise<{ candidates: Array<{ value: Val | undefined; prob: number; confidence: number }> }> {
    if (!this.adapter) {
      return { candidates: [] };
    }

    const payload = typeof query === "string"
      ? `"${query.replace(/"/g, '\\"')}"`
      : JSON.stringify(query);
    const code = `(effect search.op ${payload})`;

    const result = await this.eval(code);
    if (!result.ok || !result.value) {
      return { candidates: [] };
    }

    const val = result.value;
    if (typeof val === "object" && "tag" in val && val.tag === "Dist") {
      const distVal = val as DistVal;
      const candidates = distVal.support
        .filter((item) => options?.minProb === undefined || item.w >= options.minProb)
        .slice(0, options?.maxCandidates ?? 10)
        .map((item) => {
          const meaning = item.v as MeaningVal;
          return {
            value: meaning.denotation as Val | undefined,
            prob: item.w,
            confidence: meaning.confidence ?? 0,
          };
        });
      return { candidates };
    }

    return { candidates: [] };
  }

  /**
   * Create a sealed sandbox for untrusted inference
   *
   * @param caps - Restricted capability set
   * @returns A new OmegaRuntime with sealed context
   */
  sandbox(caps: CapSet): OmegaRuntime {
    const sandboxed = new OmegaRuntime({
      ...this.config,
      defaultCaps: caps,
    });
    sandboxed.rootCtx = ctxSeal(sandboxed.rootCtx);
    return sandboxed;
  }

  /**
   * Get the underlying adapter (for advanced use)
   */
  getAdapter(): OracleAdapter | undefined {
    return this.adapter;
  }

  /**
   * Check if Oracle is available
   */
  hasOracle(): boolean {
    return !!this.adapter;
  }
}

/**
 * Quick eval helper - creates a runtime and evaluates code
 *
 * @example
 * const result = await evalOmegaCode("(+ 1 2)");
 * if (result.ok) console.log(result.value);
 */
export async function evalOmegaCode(code: string): Promise<EvalResult> {
  const runtime = new OmegaRuntime();
  return runtime.eval(code);
}

// ═══════════════════════════════════════════════════════════════════════════
// FILE: bin/omega-repl.ts
// ═══════════════════════════════════════════════════════════════════════════

#!/usr/bin/env npx tsx
// bin/omega-repl.ts
// Interactive Omega REPL with dual-REPL oracle support
// SOURCE: ARCHITECTURE/32-LANGUAGE-OFFICIAL-IMPLEMENTATION-20.md
//
// Run:  npx tsx bin/omega-repl.ts
//       npx tsx bin/omega-repl.ts --verbose   (show oracle transcript)

import * as readline from "readline";
import * as fs from "fs";
import * as path from "path";

// Load .env file if it exists
const envPath = path.join(process.cwd(), ".env");
if (fs.existsSync(envPath)) {
  const envContent = fs.readFileSync(envPath, "utf8");
  for (const line of envContent.split("\n")) {
    const match = line.match(/^([^=]+)=(.*)$/);
    if (match && !process.env[match[1]]) {
      process.env[match[1]] = match[2].trim();
    }
  }
}
import { COWStore, type Store } from "../src/core/eval/store";
import { RuntimeImpl } from "../src/core/effects/runtimeImpl";
import { SnapshotRepo } from "../src/core/oracle/snapshots";
import { InMemoryReceiptStore } from "../src/core/oracle/receipts";
import { installPrims } from "../test/helpers/prims";
import { createOpenAIAdapter, createAnthropicAdapter } from "../src/core/oracle/adapters";
import { DepthTrackingAdapter } from "../src/core/oracle/adapters/types";
import type { OracleAdapter } from "../src/core/oracle/adapter";
import type { State, Frame } from "../src/core/eval/machine";
import { runToCompletionWithState } from "../src/core/eval/run";
import { stepOnce } from "../src/core/eval/machineStep";
import type { StepOutcome } from "../src/core/eval/machine";
import { compileTextToExpr } from "../src/core/pipeline/compileText";
import type { Val } from "../src/core/eval/values";
import { VUnit } from "../src/core/eval/values";
import type { Env } from "../src/core/eval/env";
import { ScriptedOracleAdapter } from "../src/core/oracle/scriptedOracle";
import { SessionWriter, SessionReader, JumpController, renderTrace } from "../src/core/session";
import type { SessionIndex } from "../src/core/session";
import { buildNativeRegistry } from "../src/core/session/nativeRegistry";
import { buildSolverRegistry } from "../src/core/session/solverRegistry";

// OPR imports
import { OprRuntime } from "../src/core/opr/runtime";
import { InMemoryReceiptStore as OprReceiptStore } from "../src/core/opr/receipts";
import { OpenAIOprAdapter } from "../src/core/opr/adapters/openai";
import { AnthropicOprAdapter } from "../src/core/opr/adapters/anthropic";
import { listKernels, getKernel } from "../src/core/opr/kernels";

// ─────────────────────────────────────────────────────────────────
// LLM Integration
// ─────────────────────────────────────────────────────────────────
function loadApiKey(): string | undefined {
  if (process.env.OPENAI_API_KEY) return process.env.OPENAI_API_KEY;
  if (process.env.ANTHROPIC_API_KEY) return process.env.ANTHROPIC_API_KEY;
  try {
    const configPath = path.join(process.cwd(), "../LambdaRLM/config.yaml");
    const content = fs.readFileSync(configPath, "utf8");
    const match = content.match(/api_key:\s*(\S+)/);
    if (match?.[1]) return match[1];
  } catch { /* ignore */ }
  return undefined;
}

async function askLLM(prompt: string, apiKey: string): Promise<string> {
  // Simple OpenAI API call (legacy, non-agentic)
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 500,
    }),
  });
  const data = await response.json() as any;
  return data.choices?.[0]?.message?.content || "";
}

// ─────────────────────────────────────────────────────────────────
// LLM Adapter Interface (pluggable LLM support)
// ─────────────────────────────────────────────────────────────────

interface LLMToolCall {
  id: string;
  name: string;
  args: Record<string, any>;
}

interface LLMResponse {
  content?: string;
  toolCalls?: LLMToolCall[];
  finishReason?: string;
}

interface LLMAdapter {
  name: string;
  supportsToolCalls: boolean;
  chat(messages: any[], tools?: any[]): Promise<LLMResponse>;
}

// OpenAI Adapter (native tool support)
class OpenAIAdapter implements LLMAdapter {
  name = "openai";
  supportsToolCalls = true;

  constructor(private apiKey: string, private model = "gpt-4o-mini") {}

  async chat(messages: any[], tools?: any[]): Promise<LLMResponse> {
    const body: any = {
      model: this.model,
      messages,
      max_tokens: 1500,
    };
    if (tools && tools.length > 0) {
      body.tools = tools;
      body.tool_choice = "auto";
    }

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify(body),
    });

    const data = await response.json() as any;
    const choice = data.choices?.[0];
    const message = choice?.message;

    if (!message) {
      return { content: undefined, finishReason: "error" };
    }

    const toolCalls = message.tool_calls?.map((tc: any) => ({
      id: tc.id,
      name: tc.function.name,
      args: JSON.parse(tc.function.arguments || "{}"),
    }));

    return {
      content: message.content || undefined,
      toolCalls,
      finishReason: choice.finish_reason,
    };
  }
}

// Text-based adapter for LLMs without tool support
// Uses structured text format: [TOOL:name] {json args}
class TextBasedAdapter implements LLMAdapter {
  name = "text-based";
  supportsToolCalls = false;

  constructor(private apiKey: string, private endpoint: string, private model: string) {}

  async chat(messages: any[], _tools?: any[]): Promise<LLMResponse> {
    // Add instruction about text-based tool format
    const toolInstructions = `
When you need to use a tool, format your response EXACTLY like this:
[TOOL:tool_name] {"arg1": "value1", "arg2": "value2"}

Available tools:
- [TOOL:eval_lisp] {"code": "(+ 1 2)"}
- [TOOL:get_definitions] {}
- [TOOL:inspect_value] {"name": "factorial"}
- [TOOL:debug_load] {"code": "(+ 1 2)"}
- [TOOL:debug_step] {"count": 1}
- [TOOL:debug_run] {}
- [TOOL:debug_goto] {"step": 5}
- [TOOL:debug_state] {}
- [TOOL:debug_stack] {}
- [TOOL:debug_trace] {"start": 0, "count": 20}
- [TOOL:set_breakpoint] {"type": "step", "condition": "10"}
- [TOOL:list_breakpoints] {}
- [TOOL:delete_breakpoint] {"id": 1}

After each tool result, you can call another tool or provide your final answer.
Only provide your final answer (without [TOOL:...]) when you're done with tool calls.
`;

    // Prepend tool instructions to system message
    const enhancedMessages = messages.map((m, i) => {
      if (i === 0 && m.role === "system") {
        return { ...m, content: m.content + "\n\n" + toolInstructions };
      }
      return m;
    });

    const response = await fetch(this.endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model: this.model,
        messages: enhancedMessages,
        max_tokens: 1500,
      }),
    });

    const data = await response.json() as any;
    const content = data.choices?.[0]?.message?.content || "";

    // Parse text-based tool calls
    const toolCalls = this.parseTextToolCalls(content);

    // If we found tool calls, extract the non-tool content
    let textContent = content;
    if (toolCalls.length > 0) {
      textContent = content.replace(/\[TOOL:\w+\]\s*\{[^}]*\}/g, "").trim();
    }

    return {
      content: textContent || undefined,
      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,
      finishReason: data.choices?.[0]?.finish_reason,
    };
  }

  private parseTextToolCalls(text: string): LLMToolCall[] {
    const toolCalls: LLMToolCall[] = [];
    const regex = /\[TOOL:(\w+)\]\s*(\{[^}]*\})/g;
    let match;
    let id = 1;

    while ((match = regex.exec(text)) !== null) {
      try {
        const name = match[1];
        const args = JSON.parse(match[2]);
        toolCalls.push({ id: `text-${id++}`, name, args });
      } catch (e) {
        // Skip malformed tool calls
      }
    }

    return toolCalls;
  }
}

// Anthropic adapter (native tool support via messages API)
class AnthropicAdapter implements LLMAdapter {
  name = "anthropic";
  supportsToolCalls = true;

  constructor(private apiKey: string, private model = "claude-3-5-sonnet-20241022") {}

  private convertToolsToAnthropic(openaiTools: any[]): any[] {
    return openaiTools.map(t => ({
      name: t.function.name,
      description: t.function.description,
      input_schema: t.function.parameters,
    }));
  }

  async chat(messages: any[], tools?: any[]): Promise<LLMResponse> {
    // Convert messages format (OpenAI -> Anthropic)
    const systemMsg = messages.find(m => m.role === "system");
    const nonSystemMsgs = messages.filter(m => m.role !== "system").map(m => {
      if (m.role === "tool") {
        // Convert tool response format
        return {
          role: "user",
          content: [{ type: "tool_result", tool_use_id: m.tool_call_id, content: m.content }],
        };
      }
      if (m.tool_calls) {
        // Convert assistant message with tool calls
        const content: any[] = [];
        if (m.content) content.push({ type: "text", text: m.content });
        for (const tc of m.tool_calls) {
          content.push({
            type: "tool_use",
            id: tc.id,
            name: tc.function.name,
            input: JSON.parse(tc.function.arguments || "{}"),
          });
        }
        return { role: "assistant", content };
      }
      return { role: m.role, content: m.content };
    });

    const body: any = {
      model: this.model,
      max_tokens: 1500,
      messages: nonSystemMsgs,
    };
    if (systemMsg) body.system = systemMsg.content;
    if (tools && tools.length > 0) {
      body.tools = this.convertToolsToAnthropic(tools);
    }

    const response = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-api-key": this.apiKey,
        "anthropic-version": "2023-06-01",
      },
      body: JSON.stringify(body),
    });

    const data = await response.json() as any;

    // Parse Anthropic response
    let content: string | undefined;
    const toolCalls: LLMToolCall[] = [];

    for (const block of data.content || []) {
      if (block.type === "text") {
        content = (content || "") + block.text;
      } else if (block.type === "tool_use") {
        toolCalls.push({
          id: block.id,
          name: block.name,
          args: block.input || {},
        });
      }
    }

    return {
      content,
      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,
      finishReason: data.stop_reason,
    };
  }
}

// Factory to create the right adapter
function createLLMAdapter(): LLMAdapter | null {
  // Try OpenAI first
  const openaiKey = process.env.OPENAI_API_KEY;
  if (openaiKey) {
    return new OpenAIAdapter(openaiKey);
  }

  // Try Anthropic
  const anthropicKey = process.env.ANTHROPIC_API_KEY;
  if (anthropicKey) {
    return new AnthropicAdapter(anthropicKey);
  }

  // Try loading from config
  try {
    const configPath = path.join(process.cwd(), "../LambdaRLM/config.yaml");
    const content = fs.readFileSync(configPath, "utf8");
    const keyMatch = content.match(/api_key:\s*(\S+)/);
    const providerMatch = content.match(/provider:\s*(\S+)/);

    if (keyMatch?.[1]) {
      const provider = providerMatch?.[1]?.toLowerCase() || "openai";
      if (provider === "anthropic") {
        return new AnthropicAdapter(keyMatch[1]);
      }
      return new OpenAIAdapter(keyMatch[1]);
    }
  } catch { /* ignore */ }

  return null;
}

// ─────────────────────────────────────────────────────────────────
// Agentic LLM with Tool Calls
// ─────────────────────────────────────────────────────────────────

// Tool definitions for OpenAI function calling (also used by Anthropic)
const REPL_TOOLS = [
  // === EVALUATION ===
  {
    type: "function" as const,
    function: {
      name: "eval_lisp",
      description: "Evaluate a Lisp s-expression and return the result. Use this to run code, test functions, or compute values.",
      parameters: {
        type: "object",
        properties: {
          code: { type: "string", description: "The Lisp s-expression to evaluate, e.g. '(+ 1 2)' or '(define (fact n) (if (<= n 1) 1 (* n (fact (- n 1)))))'" }
        },
        required: ["code"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "get_definitions",
      description: "Get a list of all user-defined functions and variables in the current session.",
      parameters: { type: "object", properties: {} }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "inspect_value",
      description: "Look up the current value of a defined variable or function.",
      parameters: {
        type: "object",
        properties: {
          name: { type: "string", description: "The name of the variable or function to inspect" }
        },
        required: ["name"]
      }
    }
  },

  // === DEBUGGING ===
  {
    type: "function" as const,
    function: {
      name: "debug_load",
      description: "Load an expression into the debugger for step-by-step execution. This starts a debug session.",
      parameters: {
        type: "object",
        properties: {
          code: { type: "string", description: "The Lisp expression to debug" }
        },
        required: ["code"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_step",
      description: "Execute N steps in the debugger. Returns the current state after stepping.",
      parameters: {
        type: "object",
        properties: {
          count: { type: "number", description: "Number of steps to execute (default 1)" }
        }
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_run",
      description: "Run the debugger to completion or until a breakpoint is hit.",
      parameters: { type: "object", properties: {} }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_goto",
      description: "Jump to a specific step in the execution trace (time travel debugging).",
      parameters: {
        type: "object",
        properties: {
          step: { type: "number", description: "The step number to jump to" }
        },
        required: ["step"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_state",
      description: "Get the current debugger state including control, stack depth, and step number.",
      parameters: { type: "object", properties: {} }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_stack",
      description: "Get the current call stack showing all continuation frames.",
      parameters: { type: "object", properties: {} }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "debug_trace",
      description: "Get the execution trace showing all recorded steps.",
      parameters: {
        type: "object",
        properties: {
          start: { type: "number", description: "Start index (default 0)" },
          count: { type: "number", description: "Number of steps to show (default 20)" }
        }
      }
    }
  },

  // === BREAKPOINTS ===
  {
    type: "function" as const,
    function: {
      name: "set_breakpoint",
      description: "Set a breakpoint. Types: 'step' (break at step N), 'expr' (break on expression type), 'effect' (break on effect operation).",
      parameters: {
        type: "object",
        properties: {
          type: { type: "string", enum: ["step", "expr", "effect"], description: "Breakpoint type" },
          condition: { type: "string", description: "Condition: step number, expression tag (If, App, Define, etc.), or effect name" }
        },
        required: ["type", "condition"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "list_breakpoints",
      description: "List all set breakpoints.",
      parameters: { type: "object", properties: {} }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "delete_breakpoint",
      description: "Delete a breakpoint by ID.",
      parameters: {
        type: "object",
        properties: {
          id: { type: "number", description: "Breakpoint ID to delete" }
        },
        required: ["id"]
      }
    }
  }
];

// Trace types for recording agentic interactions
interface LLMTraceEntry {
  type: "request" | "response" | "tool_call" | "tool_result" | "env_snapshot";
  timestamp: number;
  data: any;
}

interface LLMTrace {
  id: string;
  question: string;
  answer?: string;
  startTime: number;
  endTime?: number;
  entries: LLMTraceEntry[];
  toolCallCount: number;
}

// In-memory trace store (could be persisted later)
const llmTraces: Map<string, LLMTrace> = new Map();

function generateTraceId(): string {
  return `t-${Date.now().toString(36)}-${Math.random().toString(36).slice(2, 8)}`;
}

// Execute a tool call against the REPL
async function executeToolCall(
  toolName: string,
  args: any,
  replState: ReplState,
  trace: LLMTrace
): Promise<{ result: string; replState: ReplState }> {
  const startTime = Date.now();
  let result: string;

  // Helper to get active state (debug or last)
  const getActiveState = () => replState.debugState || replState.lastState;

  switch (toolName) {
    // === EVALUATION TOOLS ===
    case "eval_lisp": {
      const code = args.code as string;
      try {
        const { value, replState: newState } = await evalInRepl(code, replState);
        replState = newState;
        result = valToSexp(value);
      } catch (err: any) {
        result = `error: ${err.message}`;
      }
      break;
    }

    case "get_definitions": {
      if (replState.defs.length === 0) {
        result = "(no definitions yet)";
      } else {
        result = replState.defs.join("\n");
      }
      break;
    }

    case "inspect_value": {
      const name = args.name as string;
      const activeState = getActiveState();
      if (!activeState) {
        result = "(no state available)";
      } else {
        let ctx: any = activeState.env;
        let addr: number | undefined;
        while (ctx) {
          if (ctx.frame?.has?.(name)) {
            addr = ctx.frame.get(name);
            break;
          }
          ctx = ctx.parent;
        }
        if (addr !== undefined) {
          const val = activeState.store.read(addr);
          result = valToSexp(val);
        } else {
          result = `(binding '${name}' not found)`;
        }
      }
      break;
    }

    // === DEBUG TOOLS ===
    case "debug_load": {
      const code = args.code as string;
      try {
        replState = debugLoadExpr(code, replState);
        result = `Debug session started for: ${code.slice(0, 50)}${code.length > 50 ? "..." : ""}\nStep 0: ${controlToString(replState.debugState!.control)}\nUse debug_step to begin stepping.`;
      } catch (err: any) {
        result = `error: ${err.message}`;
      }
      break;
    }

    case "debug_step": {
      const count = (args.count as number) || 1;
      if (!replState.debugState) {
        result = "(no debug session - use debug_load first)";
      } else {
        const lines: string[] = [];
        for (let i = 0; i < count; i++) {
          const { result: stepResult, replState: newState } = debugStep(replState);
          replState = newState;
          if (!stepResult) {
            lines.push("(step failed)");
            break;
          }
          if (stepResult.tag === "Done") {
            lines.push(`DONE at step ${replState.stepCount}: ${valToSexp(stepResult.value)}`);
            break;
          }
          if (stepResult.tag === "Op") {
            lines.push(`EFFECT at step ${replState.stepCount}: ${stepResult.opcall.op}`);
            break;
          }
        }
        if (replState.debugState) {
          lines.push(`Step ${replState.stepCount}: ${controlToString(replState.debugState.control)}`);
          lines.push(`Stack depth: ${replState.debugState.kont.length}`);
        }
        result = lines.join("\n");
      }
      break;
    }

    case "debug_run": {
      if (!replState.debugState) {
        result = "(no debug session - use debug_load first)";
      } else {
        const startStep = replState.stepCount;
        replState = debugRun(replState);
        const endStep = replState.stepCount;

        if (replState.debugState) {
          result = `Ran ${endStep - startStep} steps. Stopped at step ${endStep}.\n${controlToString(replState.debugState.control)}\nStack depth: ${replState.debugState.kont.length}`;
        } else {
          // Completed - get the last trace entry to find the result
          const lastTrace = replState.trace[replState.trace.length - 1];
          if (lastTrace?.state.control.tag === "Val") {
            result = `Completed after ${endStep} steps. Result: ${valToSexp(lastTrace.state.control.v)}`;
          } else {
            result = `Completed after ${endStep} steps.`;
          }
        }
      }
      break;
    }

    case "debug_goto": {
      const step = args.step as number;
      if (replState.trace.length === 0) {
        result = "(no trace recorded - run the program first)";
      } else {
        replState = debugGoto(replState, step);
        if (replState.debugState) {
          result = `Jumped to step ${replState.stepCount}.\n${controlToString(replState.debugState.control)}\nStack depth: ${replState.debugState.kont.length}`;
        } else {
          result = `Failed to jump to step ${step}. Available: 0-${replState.trace[replState.trace.length - 1].step}`;
        }
      }
      break;
    }

    case "debug_state": {
      if (!replState.debugState) {
        result = "(no debug session active)";
      } else {
        result = [
          `Step: ${replState.stepCount}`,
          `Control: ${controlToString(replState.debugState.control)}`,
          `Stack depth: ${replState.debugState.kont.length}`,
          `Handlers: ${replState.debugState.handlers.length}`,
          `Trace length: ${replState.trace.length}`,
        ].join("\n");
      }
      break;
    }

    case "debug_stack": {
      const activeState = getActiveState();
      if (!activeState) {
        result = "(no state available)";
      } else {
        const kont = activeState.kont;
        if (kont.length === 0) {
          result = "(empty stack)";
        } else {
          const lines = [`Stack depth: ${kont.length}`];
          for (let i = kont.length - 1; i >= 0; i--) {
            lines.push(frameToString(kont[i], i));
          }
          result = lines.join("\n");
        }
      }
      break;
    }

    case "debug_trace": {
      const start = (args.start as number) || 0;
      const count = (args.count as number) || 20;
      if (replState.trace.length === 0) {
        result = "(no trace recorded)";
      } else {
        const lines = [`Trace (${replState.trace.length} steps recorded):`];
        const end = Math.min(start + count, replState.trace.length);
        for (let i = start; i < end; i++) {
          const t = replState.trace[i];
          const marker = t.step === replState.stepCount ? " <-- current" : "";
          lines.push(`  [${t.step}] ${t.controlSummary} | stack=${t.stackDepth}${marker}`);
        }
        if (end < replState.trace.length) {
          lines.push(`  ... (${replState.trace.length - end} more)`);
        }
        result = lines.join("\n");
      }
      break;
    }

    // === BREAKPOINT TOOLS ===
    case "set_breakpoint": {
      const type = args.type as Breakpoint["type"];
      const condition = args.condition as string;
      if (!["step", "expr", "effect"].includes(type)) {
        result = "Invalid breakpoint type. Use: step, expr, or effect";
      } else {
        const bp: Breakpoint = {
          id: replState.nextBreakpointId++,
          type,
          condition: type === "step" ? parseInt(condition) : condition,
          enabled: true,
        };
        replState.breakpoints.push(bp);
        result = `Breakpoint ${bp.id} added: ${type} = ${bp.condition}`;
      }
      break;
    }

    case "list_breakpoints": {
      if (replState.breakpoints.length === 0) {
        result = "No breakpoints set.";
      } else {
        const lines = ["Breakpoints:"];
        for (const bp of replState.breakpoints) {
          lines.push(`  ${bp.id}: ${bp.type} = ${bp.condition} [${bp.enabled ? "enabled" : "disabled"}]`);
        }
        result = lines.join("\n");
      }
      break;
    }

    case "delete_breakpoint": {
      const id = args.id as number;
      const idx = replState.breakpoints.findIndex(bp => bp.id === id);
      if (idx < 0) {
        result = `Breakpoint ${id} not found.`;
      } else {
        replState.breakpoints.splice(idx, 1);
        result = `Breakpoint ${id} deleted.`;
      }
      break;
    }

    default:
      result = `unknown tool: ${toolName}`;
  }

  // Record tool result in trace
  trace.entries.push({
    type: "tool_result",
    timestamp: Date.now(),
    data: { toolName, args, result, durationMs: Date.now() - startTime }
  });

  return { result, replState };
}

// Main agentic loop
async function runAgenticQuery(
  question: string,
  replState: ReplState,
  adapter: LLMAdapter,
  maxIterations = 15
): Promise<{ answer: string; traceId: string; replState: ReplState }> {
  const traceId = generateTraceId();
  const trace: LLMTrace = {
    id: traceId,
    question,
    startTime: Date.now(),
    entries: [],
    toolCallCount: 0
  };

  // System prompt explaining the environment with debugging capabilities
  const systemPrompt = `You are an assistant with access to a Lisp REPL (Omega dialect) with FULL DEBUGGING capabilities.
You can evaluate Lisp code, inspect definitions, debug step-by-step, set breakpoints, and time-travel through execution.

Current definitions in the session:
${replState.defs.length > 0 ? replState.defs.join("\n") : "(none)"}

AVAILABLE PRIMITIVES:
- Arithmetic: +, -, *, /, modulo
- Comparison: =, <, >, <=, >=, eq?
- Logic: not, and, or
- List ops: cons, car, cdr, list, append, null?, pair?
- Forms: define, lambda, let, if, begin, quote

AVAILABLE TOOLS:
1. EVALUATION:
   - eval_lisp: Run Lisp code and get the result
   - get_definitions: See all defined functions
   - inspect_value: Look up a specific binding

2. DEBUGGING (step through execution):
   - debug_load: Load expression into debugger
   - debug_step: Execute N steps
   - debug_run: Run to completion/breakpoint
   - debug_goto: Jump to any step (time travel!)
   - debug_state: Current state info
   - debug_stack: View call stack
   - debug_trace: View execution trace

3. BREAKPOINTS:
   - set_breakpoint: Break on step/expr/effect
   - list_breakpoints: Show breakpoints
   - delete_breakpoint: Remove breakpoint

This is a metacircular Lisp - if you need a function that doesn't exist (like map, filter, reverse, length),
DEFINE IT YOURSELF using the primitives above. For example:
  (define (length lst) (if (null? lst) 0 (+ 1 (length (cdr lst)))))
  (define (map f lst) (if (null? lst) (list) (cons (f (car lst)) (map f (cdr lst)))))

When the user asks a question:
1. If it requires computation, use eval_lisp to run code
2. If you need helper functions that don't exist, define them first
3. If debugging is needed, use debug_load to step through execution
4. Test your code before giving the final answer
5. Provide a clear, concise final answer

Always verify your results with actual evaluation rather than guessing.`;

  const messages: any[] = [
    { role: "system", content: systemPrompt },
    { role: "user", content: question }
  ];

  // Record initial request
  trace.entries.push({
    type: "request",
    timestamp: Date.now(),
    data: { systemPrompt, question, adapter: adapter.name }
  });

  for (let iter = 0; iter < maxIterations; iter++) {
    // Call LLM through adapter
    const response = await adapter.chat(messages, REPL_TOOLS);

    if (!response.content && !response.toolCalls) {
      trace.entries.push({ type: "response", timestamp: Date.now(), data: { error: "No response from LLM", raw: response } });
      break;
    }

    // Record LLM response
    trace.entries.push({
      type: "response",
      timestamp: Date.now(),
      data: { content: response.content, toolCalls: response.toolCalls, finishReason: response.finishReason }
    });

    // Check if LLM wants to call tools
    if (response.toolCalls && response.toolCalls.length > 0) {
      // Add assistant message with tool calls (in OpenAI format for message history)
      const assistantMsg: any = { role: "assistant", content: response.content || null };
      assistantMsg.tool_calls = response.toolCalls.map(tc => ({
        id: tc.id,
        type: "function",
        function: { name: tc.name, arguments: JSON.stringify(tc.args) }
      }));
      messages.push(assistantMsg);

      for (const toolCall of response.toolCalls) {
        // Record tool call
        trace.entries.push({
          type: "tool_call",
          timestamp: Date.now(),
          data: { id: toolCall.id, name: toolCall.name, args: toolCall.args }
        });
        trace.toolCallCount++;

        // Execute the tool
        const { result, replState: newState } = await executeToolCall(toolCall.name, toolCall.args, replState, trace);
        replState = newState;

        // Add tool result to messages
        messages.push({
          role: "tool",
          tool_call_id: toolCall.id,
          content: result
        });
      }
      // Continue the loop to get next LLM response
      continue;
    }

    // No tool calls - this is the final answer
    if (response.content) {
      trace.answer = response.content;
      trace.endTime = Date.now();
      llmTraces.set(traceId, trace);
      return { answer: response.content, traceId, replState };
    }

    // Unexpected state
    break;
  }

  // Fallback if we hit max iterations or error
  trace.answer = "(no answer - max iterations or error)";
  trace.endTime = Date.now();
  llmTraces.set(traceId, trace);
  return { answer: trace.answer, traceId, replState };
}

// Format trace for display
function formatTrace(trace: LLMTrace, verbose = false): string {
  const lines: string[] = [];
  lines.push(`Trace ID: ${trace.id}`);
  lines.push(`Question: ${trace.question}`);
  lines.push(`Answer: ${trace.answer || "(none)"}`);
  lines.push(`Duration: ${trace.endTime ? trace.endTime - trace.startTime : "?"}ms`);
  lines.push(`Tool calls: ${trace.toolCallCount}`);

  if (verbose) {
    lines.push("");
    lines.push("─── Full Trace ───");
    for (const entry of trace.entries) {
      const ts = new Date(entry.timestamp).toISOString().slice(11, 23);
      switch (entry.type) {
        case "request":
          lines.push(`[${ts}] REQUEST`);
          lines.push(`  Question: ${entry.data.question}`);
          break;
        case "response":
          lines.push(`[${ts}] LLM RESPONSE`);
          if (entry.data.content) lines.push(`  Content: ${entry.data.content.slice(0, 200)}${entry.data.content.length > 200 ? "..." : ""}`);
          if (entry.data.tool_calls) lines.push(`  Tool calls: ${entry.data.tool_calls.length}`);
          break;
        case "tool_call":
          lines.push(`[${ts}] TOOL CALL: ${entry.data.name}`);
          lines.push(`  Args: ${JSON.stringify(entry.data.args)}`);
          break;
        case "tool_result":
          lines.push(`[${ts}] TOOL RESULT (${entry.data.durationMs}ms)`);
          lines.push(`  Result: ${entry.data.result.slice(0, 200)}${entry.data.result.length > 200 ? "..." : ""}`);
          break;
        case "env_snapshot":
          lines.push(`[${ts}] ENV SNAPSHOT`);
          lines.push(`  Defs: ${entry.data.defs?.length || 0}`);
          break;
      }
    }
  }

  return lines.join("\n");
}

// ─────────────────────────────────────────────────────────────────
// Configuration
// ─────────────────────────────────────────────────────────────────
const VERBOSE = process.argv.includes("--verbose") || process.argv.includes("-v");

// ─────────────────────────────────────────────────────────────────
// Session Persistence
// ─────────────────────────────────────────────────────────────────
const SESSION_DIR = path.join(process.env.HOME || process.env.USERPROFILE || ".", ".omega-sessions");
const SESSION_LOG_DIR = process.env.OMEGA_SESSION_DIR
  ? path.resolve(process.env.OMEGA_SESSION_DIR)
  : path.join(process.cwd(), ".omega-session");

function ensureSessionDir() {
  if (!fs.existsSync(SESSION_DIR)) {
    fs.mkdirSync(SESSION_DIR, { recursive: true });
  }
}

function getSessionPath(name: string): string {
  return path.join(SESSION_DIR, `repl-${name}.json`);
}

interface SessionData {
  defs: string[];
  debugMode: boolean;
  debugCode?: string;
  stepCount: number;
  traceLength: number;
  breakpoints: Breakpoint[];
  nextBreakpointId: number;
  recordingEnabled: boolean;
}

function saveSession(replState: ReplState, name: string): void {
  ensureSessionDir();
  const data: SessionData = {
    defs: replState.defs,
    debugMode: replState.debugMode,
    debugCode: replState.debugCode,
    stepCount: replState.stepCount,
    traceLength: replState.trace.length,
    breakpoints: replState.breakpoints,
    nextBreakpointId: replState.nextBreakpointId,
    recordingEnabled: replState.recordingEnabled,
  };
  fs.writeFileSync(getSessionPath(name), JSON.stringify(data, null, 2));
}

async function loadSession(name: string): Promise<ReplState | null> {
  const sessionPath = getSessionPath(name);
  if (!fs.existsSync(sessionPath)) {
    return null;
  }

  try {
    const data: SessionData = JSON.parse(fs.readFileSync(sessionPath, "utf8"));
    let replState = await initReplState();

    // Restore defines
    replState.defs = data.defs || [];
    replState.breakpoints = data.breakpoints || [];
    replState.nextBreakpointId = data.nextBreakpointId || 1;
    replState.recordingEnabled = data.recordingEnabled !== undefined ? data.recordingEnabled : true;

    // If there was a debug session, restore it
    if (data.debugMode && data.debugCode) {
      replState = debugLoadExpr(data.debugCode, replState);

      // Replay to the saved step
      let count = 0;
      while (replState.debugState && count < data.stepCount) {
        const { replState: newState } = debugStep(replState);
        replState = newState;
        count++;
        if (!replState.debugState) break;
      }
    }

    return replState;
  } catch (err) {
    console.error(`Error loading session: ${err}`);
    return null;
  }
}

// Parse command line args
function parseArgs(): { session?: string; cmd?: string; json?: boolean; file?: string } {
  const args = process.argv.slice(2);
  const result: { session?: string; cmd?: string; json?: boolean; file?: string } = {};

  for (let i = 0; i < args.length; i++) {
    if ((args[i] === "--session" || args[i] === "-s") && args[i + 1]) {
      result.session = args[++i];
    } else if ((args[i] === "--cmd" || args[i] === "-c") && args[i + 1]) {
      result.cmd = args[++i];
    } else if ((args[i] === "--json" || args[i] === "-j")) {
      result.json = true;
    } else if ((args[i] === "--file" || args[i] === "-f") && args[i + 1]) {
      result.file = args[++i];
    }
  }

  return result;
}

// ─────────────────────────────────────────────────────────────────
// S-expression extraction (handles multi-line)
// ─────────────────────────────────────────────────────────────────
function extractSexpressions(text: string): string[] {
  const results: string[] = [];
  let current = "";
  let depth = 0;
  let inString = false;
  let escape = false;

  for (const char of text) {
    if (escape) {
      current += char;
      escape = false;
      continue;
    }

    if (char === "\\") {
      current += char;
      escape = true;
      continue;
    }

    if (char === '"') {
      inString = !inString;
      current += char;
      continue;
    }

    if (inString) {
      current += char;
      continue;
    }

    if (char === "(") {
      if (depth === 0 && current.trim()) {
        // Push any non-paren content before this
        results.push(current.trim());
        current = "";
      }
      depth++;
      current += char;
    } else if (char === ")") {
      depth--;
      current += char;
      if (depth === 0) {
        results.push(current.trim());
        current = "";
      }
    } else {
      current += char;
    }
  }

  // Handle any remaining content (atoms, numbers, etc.)
  if (current.trim()) {
    results.push(current.trim());
  }

  return results.filter(s => s.length > 0);
}

// ─────────────────────────────────────────────────────────────────
// Pretty printing values as s-expressions
// ─────────────────────────────────────────────────────────────────
function valToSexp(v: Val): string {
  switch (v.tag) {
    case "Unit": return "null";
    case "Num": return String(v.n);
    case "Bool": return v.b ? "#t" : "#f";
    case "Str": {
      // Check if it's a serialized symbol from quote (workaround)
      if (v.s.startsWith('{"sym":"')) {
        try {
          const parsed = JSON.parse(v.s);
          if (parsed.sym) return parsed.sym;
        } catch { /* ignore */ }
      }
      return JSON.stringify(v.s);
    }
    case "Sym": return v.name;
    case "Vector": {
      // Check if it's a proper list (cons cells ending in null)
      const items: Val[] = [];
      let current: Val = v;
      while (current.tag === "Vector" && current.items.length === 2) {
        items.push(current.items[0]);
        current = current.items[1];
      }
      if (current.tag === "Unit") {
        // Proper list
        return `(${items.map(valToSexp).join(" ")})`;
      }
      // Improper list or vector
      if (items.length > 0) {
        return `(${items.map(valToSexp).join(" ")} . ${valToSexp(current)})`;
      }
      // Regular vector
      return `[${v.items.map(valToSexp).join(" ")}]`;
    }
    case "Closure": return `<closure (${(v as any).params?.join(" ") || "..."})>`;
    case "Native": return `<prim>`;
    case "Cont": return `<continuation>`;
    case "OracleProc": return `<oracle-proc>`;
    case "Meaning": {
      const m = v as any;
      const parts: string[] = ["meaning"];
      if (m.denotation) parts.push(`(denotation ${valToSexp(m.denotation)})`);
      if (m.confidence !== undefined) parts.push(`(confidence ${m.confidence})`);
      if (m.trace) parts.push(`(trace ${valToSexp(m.trace)})`);
      return `(${parts.join(" ")})`;
    }
    default:
      return JSON.stringify(v);
  }
}

// ─────────────────────────────────────────────────────────────────
// Debugging types
// ─────────────────────────────────────────────────────────────────
interface TraceRecord {
  step: number;
  state: State;
  controlSummary: string;
  stackDepth: number;
}

interface Breakpoint {
  id: number;
  type: "step" | "expr" | "effect";
  condition: string | number;
  enabled: boolean;
}

interface Snapshot {
  name: string;
  step: number;
  state: State;
  timestamp: Date;
}

// ─────────────────────────────────────────────────────────────────
// Persistent REPL state (accumulates defines)
// ─────────────────────────────────────────────────────────────────
interface ReplState {
  store: Store;
  env: State["env"];
  baseState: State;
  defs: string[];  // history of (define ...) forms
  lastState?: State;  // Last evaluated state for debugging
  lastError?: Error;  // Last error for debugging
  nativeRegistry: Map<string, Val>;
  solverRegistry: Map<string, Val>;
  sessionDir: string;
  sessionWriter?: SessionWriter;
  loadedSession?: SessionReader;
  jumpController?: JumpController;
  sessionState?: State;
  sessionSeq?: number;
  sessionName?: string;

  // Debug mode state
  debugMode: boolean;
  debugState?: State;  // Current debug state (stepping mode)
  stepCount: number;
  trace: TraceRecord[];
  breakpoints: Breakpoint[];
  nextBreakpointId: number;
  debugCode?: string;  // Code being debugged

  // Advanced debugger features
  snapshots: Map<string, Snapshot>;  // Named snapshots
  history: { step: number; state: State; control: string }[];  // Step history (limited)
  maxHistory: number;  // Max history entries (default 100)
  recordingEnabled: boolean;  // Toggle trace recording
  running: boolean;  // Execution control flag
}

async function initReplState(): Promise<ReplState> {
  const store0 = new COWStore();
  const prim = installPrims(store0);
  const baseState: State = {
    control: { tag: "Val", v: VUnit },
    env: prim.env,
    store: prim.store,
    kont: [],
    handlers: [],
  };
  const nativeRegistry = buildNativeRegistry(prim.store);
  const solverRegistry = buildSolverRegistry(prim.store);
  return {
    store: prim.store,
    env: prim.env,
    baseState,
    defs: [],
    debugMode: false,
    stepCount: 0,
    trace: [],
    breakpoints: [],
    nextBreakpointId: 1,
    snapshots: new Map(),
    history: [],
    maxHistory: 100,
    recordingEnabled: true,
    running: false,
    nativeRegistry,
    solverRegistry,
    sessionDir: SESSION_LOG_DIR,
    sessionWriter: undefined,
    loadedSession: undefined,
    jumpController: undefined,
    sessionState: baseState,
    sessionSeq: undefined,
    sessionName: "current",
  };
}

// ─────────────────────────────────────────────────────────────────
// Evaluate one expression in the REPL state
// ─────────────────────────────────────────────────────────────────
function createReplRuntime(): RuntimeImpl {
  const snapshots = new SnapshotRepo();
  const receipts = new InMemoryReceiptStore("off");
  const scripted = process.env.OMEGA_SCRIPTED_ORACLE === "1";

  // Select adapter: OMEGA_ADAPTER=anthropic|openai (default: openai)
  const adapterType = process.env.OMEGA_ADAPTER ?? "openai";
  const model = process.env.OMEGA_MODEL; // Optional model override

  let baseOracle;
  if (scripted) {
    baseOracle = undefined;
  } else if (adapterType === "anthropic") {
    baseOracle = createAnthropicAdapter(model ? { model } : undefined);
  } else {
    baseOracle = createOpenAIAdapter(model ? { model } : undefined);
  }

  const oracle = baseOracle
    ? new DepthTrackingAdapter(baseOracle, 8)
    : new ScriptedOracleAdapter();

  return new RuntimeImpl(oracle as unknown as OracleAdapter, snapshots, receipts, {
    async commit(_payload: Val) { return VUnit; }
  });
}

async function evalInRepl(
  src: string,
  replState: ReplState,
  opts?: { baseState?: State }
): Promise<{ value: Val; replState: ReplState; state: State }> {
  const runtime = createReplRuntime();

  // Check if this is a define - extract the name
  const defineMatch = src.trim().match(/^\(define\s+(?:\(([\w\-\?\!]+)|([\w\-\?\!]+))/);
  const isDefine = !!defineMatch;
  const defineName = defineMatch?.[1] || defineMatch?.[2]; // function name or variable name

  let defsToUse = replState.defs;
  if (isDefine && defineName) {
    defsToUse = replState.defs.filter(d => {
      const prevMatch = d.trim().match(/^\(define\s+(?:\(([\w\-\?\!]+)|([\w\-\?\!]+))/);
      const prevName = prevMatch?.[1] || prevMatch?.[2];
      return prevName !== defineName;
    });
  }

  const allForms = [...defsToUse, src];
  const baseState = opts?.baseState ?? replState.sessionState ?? replState.baseState;
  const programSrc = `(begin\n${allForms.join("\n")}\n)`;
  const expr = compileTextToExpr(programSrc);
  const activeExpr = expr.tag === "Begin" && expr.exprs.length > 0
    ? expr.exprs[expr.exprs.length - 1]
    : expr;

  const state0: State = {
    control: { tag: "Expr", e: activeExpr },
    env: baseState?.env ?? replState.env,
    store: baseState?.store ?? replState.store,
    kont: [],
    handlers: baseState?.handlers ?? [],
  };

  const { value, state: finalState } = await runToCompletionWithState(runtime, state0, 100_000);
  normalizeCtxBindings(finalState.env as any);

  if (isDefine && defineName) {
    // Remove previous definition with same name to allow redefinition
    replState.defs = replState.defs.filter(d => {
      const prevMatch = d.trim().match(/^\(define\s+(?:\(([\w\-\?\!]+)|([\w\-\?\!]+))/);
      const prevName = prevMatch?.[1] || prevMatch?.[2];
      return prevName !== defineName;
    });
    replState.defs.push(src);
  }

  // Store final state for debugging and future evaluations
  replState.lastState = finalState;
  replState.baseState = finalState;
  replState.sessionState = finalState;
  replState.env = finalState.env;
  replState.store = finalState.store;
  replState.lastError = undefined;

  // For defines, return the symbol name (Lisp convention) instead of void
  // BUT only if it's JUST a define (not define + call)
  const hasMultipleExprs = extractSexpressions(src.trim()).length > 1;
  if (isDefine && defineName && !hasMultipleExprs) {
    return { value: { tag: "Sym", name: defineName } as Val, replState, state: finalState };
  }

  return { value, replState, state: finalState };
}

function normalizeCtxBindings(env?: any): void {
  let ctx = env;
  while (ctx) {
    if (ctx.frame && ctx.frame instanceof Map) {
      for (const [name, addr] of Array.from(ctx.frame.entries())) {
        const plain = typeof name === "string" ? name.replace(/\$bid#\d+$/, "") : name;
        if (typeof plain === "string" && plain !== name && !ctx.frame.has(plain)) {
          ctx.frame.set(plain, addr);
        }
      }
    }
    ctx = ctx.parent;
  }
}

function handleEffectExpression(src: string, replState: ReplState): { value: Val; state: State } {
  const baseState = replState.sessionState ?? replState.baseState;
  const opMatch = src.match(/^\(effect\s+([^\s\)]+)(.*)$/s);
  const op = opMatch?.[1] ?? "effect";
  const argsPreview = (opMatch?.[2] ?? "").trim();

  if (baseState) {
    replState.sessionWriter?.checkpoint(baseState, "llm_boundary");
  }
  replState.sessionWriter?.pushDepth();
  replState.sessionWriter?.step(`effect:${op}`);
  replState.sessionWriter?.effect(op, [argsPreview]);

  const receiptKey = replState.sessionWriter?.llmRequest("mock-llm", argsPreview, { op, args: argsPreview }) ?? "";
  const response = `mock:${op}`;
  if (receiptKey) {
    replState.sessionWriter?.llmResponse(
      receiptKey,
      response,
      { request: { op, args: argsPreview }, response: { content: response } },
      0
    );
  }

  const finalState: State = {
    control: { tag: "Val", v: { tag: "Str", s: response } as Val },
    env: baseState?.env ?? replState.env,
    store: baseState?.store ?? replState.store,
    kont: [],
    handlers: [],
  };

  normalizeCtxBindings(finalState.env as any);
  replState.sessionWriter?.checkpoint(finalState, "llm_boundary");
  replState.sessionWriter?.resume(response);
  replState.sessionWriter?.popDepth();
  replState.baseState = finalState;
  replState.sessionState = finalState;
  replState.lastState = finalState;

  return { value: finalState.control.v, state: finalState };
}

// ─────────────────────────────────────────────────────────────────
// Debugger utilities
// ─────────────────────────────────────────────────────────────────
function frameToString(frame: Frame, index: number): string {
  switch (frame.tag) {
    case "KIf": return `  ${index}: KIf (if ... conseq alt)`;
    case "KBegin": return `  ${index}: KBegin (${frame.rest.length} more forms)`;
    case "KDefine": return `  ${index}: KDefine (define ${frame.name} ...)`;
    case "KSet": return `  ${index}: KSet (set! ${frame.name} ...)`;
    case "KAppFun": return `  ${index}: KAppFun (evaluating function, ${frame.args.length} args pending)`;
    case "KAppArg": return `  ${index}: KAppArg (evaluated fn, ${frame.acc.length}/${frame.pending.length + frame.acc.length} args)`;
    case "KCall": return `  ${index}: KCall (in function body)`;
    case "KEffect": return `  ${index}: KEffect (${frame.op}, ${frame.acc.length}/${frame.pending.length + frame.acc.length} args)`;
    case "KHandleBoundary": return `  ${index}: KHandleBoundary (handler ${frame.hid})`;
    case "KHandleReturn": return `  ${index}: KHandleReturn (${frame.mode} handler ${frame.hid})`;
    case "KMatch": return `  ${index}: KMatch (${frame.clauses.length} clauses)`;
    default: return `  ${index}: ${(frame as any).tag ?? "Unknown"}`;
  }
}

function envToBindings(env: Env): Array<{ name: string; addr: number }> {
  const bindings: Array<{ name: string; addr: number }> = [];
  // Traverse the context chain (Ctx has frame: Map<string, Addr> and parent: Ctx)
  let ctx: any = env;
  const seen = new Set<string>();
  while (ctx) {
    if (ctx.frame && ctx.frame instanceof Map) {
      for (const [name, addr] of ctx.frame.entries()) {
        if (!seen.has(name)) {
          seen.add(name);
          bindings.push({ name, addr: addr as number });
        }
      }
    }
    ctx = ctx.parent;
  }
  return bindings.sort((a, b) => a.name.localeCompare(b.name));
}

// ─────────────────────────────────────────────────────────────────
// Debug mode helpers
// ─────────────────────────────────────────────────────────────────
function controlToString(ctrl: State["control"]): string {
  if (ctrl.tag === "Val") {
    return `Value: ${valToSexp(ctrl.v)}`;
  }
  if (ctrl.tag === "Expr") {
    const e = ctrl.e;
    switch (e.tag) {
      case "Lit": return `Expr: Lit(${JSON.stringify(e.value)})`;
      case "Var": return `Expr: Var(${e.name})`;
      case "App": return `Expr: App(...)`;
      case "If": return `Expr: If(...)`;
      case "Lambda": return `Expr: Lambda(${(e as any).params?.length || 0} params)`;
      case "Begin": return `Expr: Begin(${(e as any).exprs?.length || 0} exprs)`;
      case "Define": return `Expr: Define(${(e as any).name || "?"})`;
      case "Effect": return `Expr: Effect(${(e as any).op || "?"})`;
      default: return `Expr: ${e.tag}`;
    }
  }
  // Fallback for any future control types
  return `Control: ${(ctrl as any).tag}`;
}

function cloneState(s: State): State {
  return { ...s, kont: [...s.kont], handlers: [...s.handlers] };
}

function checkBreakpoints(state: State, stepCount: number, breakpoints: Breakpoint[]): Breakpoint | null {
  for (const bp of breakpoints) {
    if (!bp.enabled) continue;

    if (bp.type === "step" && stepCount === bp.condition) {
      return bp;
    }
    if (bp.type === "expr" && state.control.tag === "Expr") {
      const e = state.control.e;
      if (e.tag === bp.condition) return bp;
      if (e.tag === "Define" && (e as any).name === bp.condition) return bp;
      if (e.tag === "Var" && (e as any).name === bp.condition) return bp;
    }
    if (bp.type === "effect" && state.control.tag === "Expr") {
      const e = state.control.e;
      if (e.tag === "Effect" && (e as any).op === bp.condition) return bp;
    }
  }
  return null;
}

function debugLoadExpr(src: string, replState: ReplState): ReplState {
  // Build full program with accumulated defines
  const allForms = [...replState.defs, src];
  const fullProgram = `(begin\n${allForms.join("\n")}\n)`;
  const expr = compileTextToExpr(fullProgram);

  // Fresh state with primitives
  const store0 = new COWStore();
  const prim = installPrims(store0);

  const state0: State = {
    control: { tag: "Expr", e: expr },
    env: prim.env,
    store: prim.store,
    kont: [],
    handlers: [],
  };

  // Record initial state
  const trace: TraceRecord[] = [{
    step: 0,
    state: cloneState(state0),
    controlSummary: controlToString(state0.control),
    stackDepth: 0,
  }];

  return {
    ...replState,
    debugMode: true,
    debugState: state0,
    stepCount: 0,
    trace,
    debugCode: src,
  };
}

function debugStep(replState: ReplState): { result: StepOutcome | null; replState: ReplState } {
  if (!replState.debugState) {
    console.log("(no debug session - use :debug (expr) to start)");
    return { result: null, replState };
  }

  // Save to history (limited)
  if (replState.history.length >= replState.maxHistory) {
    replState.history.shift();
  }
  replState.history.push({
    step: replState.stepCount,
    state: cloneState(replState.debugState),
    control: controlToString(replState.debugState.control),
  });

  const result = stepOnce(replState.debugState);
  replState.stepCount++;

  if (result.tag === "State") {
    replState.debugState = result.state;

    // Record to trace (if recording enabled)
    if (replState.recordingEnabled) {
      replState.trace.push({
        step: replState.stepCount,
        state: cloneState(result.state),
        controlSummary: controlToString(result.state.control),
        stackDepth: result.state.kont.length,
      });
    }
  } else if (result.tag === "Done") {
    console.log(`\n=== DONE at step ${replState.stepCount} ===`);
    console.log(`Result: ${valToSexp(result.value)}`);
    console.log(`Trace: ${replState.trace.length} steps recorded. Use :trace to view, :goto N to jump.`);

    // Check if it was a define - add to defs
    if (replState.debugCode?.trim().startsWith("(define")) {
      replState.defs.push(replState.debugCode);
    }

    // Exit debug mode but KEEP the trace for post-mortem inspection
    replState.debugMode = false;
    replState.debugState = undefined;
    // Note: trace is preserved so :trace and :goto still work
  } else if (result.tag === "Op") {
    console.log(`\n=== EFFECT at step ${replState.stepCount} ===`);
    console.log(`Operation: ${result.opcall.op}`);
    console.log(`Args: ${result.opcall.args.map(a => valToSexp(a)).join(", ")}`);
    replState.debugState = result.state;
  }

  return { result, replState };
}

function debugRun(replState: ReplState, maxSteps = 100000): ReplState {
  if (!replState.debugState) {
    console.log("(no debug session - use :debug (expr) to start)");
    return replState;
  }

  let steps = 0;
  while (replState.debugState && steps < maxSteps) {
    // Check breakpoints BEFORE stepping (skip first step)
    if (steps > 0) {
      const bp = checkBreakpoints(replState.debugState, replState.stepCount, replState.breakpoints);
      if (bp) {
        console.log(`\n*** Breakpoint ${bp.id} hit at step ${replState.stepCount} ***`);
        console.log(`  Type: ${bp.type}, Condition: ${bp.condition}`);
        break;
      }
    }

    const { result, replState: newState } = debugStep(replState);
    replState = newState;
    steps++;

    if (!result || result.tag === "Done" || result.tag === "Op") {
      break;
    }
  }

  if (steps >= maxSteps && replState.debugState) {
    console.log(`\nStopped after ${maxSteps} steps (use :run to continue)`);
  }

  return replState;
}

function debugGoto(replState: ReplState, targetStep: number): ReplState {
  if (replState.trace.length === 0) {
    console.log("(no trace recorded - run the program first)");
    return replState;
  }

  const record = replState.trace.find(r => r.step === targetStep);
  if (!record) {
    console.log(`Step ${targetStep} not found. Available: 0-${replState.trace[replState.trace.length - 1].step}`);
    return replState;
  }

  replState.debugState = cloneState(record.state);
  replState.stepCount = record.step;
  replState.debugMode = true;
  console.log(`Jumped to step ${replState.stepCount}`);
  return replState;
}

function printDebugState(replState: ReplState): void {
  if (!replState.debugState) {
    console.log("(no debug session active)");
    return;
  }

  console.log(`\n─── Step ${replState.stepCount} ───`);
  console.log(`Control: ${controlToString(replState.debugState.control)}`);
  console.log(`Stack depth: ${replState.debugState.kont.length}`);
  console.log(`Handlers: ${replState.debugState.handlers.length}`);
}

function printTrace(replState: ReplState, start = 0, count = 20): void {
  if (replState.trace.length === 0) {
    console.log("(no trace recorded)");
    return;
  }

  console.log(`\nTrace (${replState.trace.length} steps recorded):`);
  const end = Math.min(start + count, replState.trace.length);
  for (let i = start; i < end; i++) {
    const t = replState.trace[i];
    const marker = t.step === replState.stepCount ? " <-- current" : "";
    console.log(`  [${t.step}] ${t.controlSummary} | stack=${t.stackDepth}${marker}`);
  }
  if (end < replState.trace.length) {
    console.log(`  ... (${replState.trace.length - end} more, use ':trace ${end} ${count}' to see more)`);
  }
}

// ─────────────────────────────────────────────────────────────────
// Unified command processor (for both interactive and session mode)
// ─────────────────────────────────────────────────────────────────
async function processReplCommand(
  trimmed: string,
  replState: ReplState
): Promise<{ replState: ReplState; output: string; shouldExit: boolean }> {
  const output: string[] = [];
  const log = (...msgs: any[]) => output.push(msgs.join(" "));
  let shouldExit = false;

  // Helper to get the active state (debug or last)
  const getActiveState = () => replState.debugState || replState.sessionState || replState.lastState;

  // Session management commands
  const sessionsPath = path.join(replState.sessionDir, "sessions");

  if (trimmed === ":session list") {
    if (!fs.existsSync(sessionsPath)) {
      log("No saved sessions.");
      return { replState, output: output.join("\n"), shouldExit };
    }
    const files = fs.readdirSync(sessionsPath).filter(f => f.endsWith(".jsonl"));
    if (files.length === 0) {
      log("No saved sessions.");
    } else {
      log("Saved sessions:");
      for (const f of files) {
        const name = f.replace(".jsonl", "");
        const indexPath = path.join(sessionsPath, `${name}.index.json`);
        if (fs.existsSync(indexPath)) {
          const idx = JSON.parse(fs.readFileSync(indexPath, "utf8"));
          log(`  ${name} (${idx.eventCount ?? 0} events, ${(idx.checkpoints ?? []).length} checkpoints)`);
        } else {
          log(`  ${name}`);
        }
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed.startsWith(":session save ")) {
    const name = trimmed.slice(14).trim();
    if (!name) {
      log("Usage: :session save <name>");
      return { replState, output: output.join("\n"), shouldExit };
    }
    fs.mkdirSync(sessionsPath, { recursive: true });
    try {
      replState.sessionWriter?.close();
      const baseName = replState.sessionWriter?.getSessionId() || replState.sessionName || "current";
      const srcJsonl = path.join(sessionsPath, `${baseName}.jsonl`);
      const srcIndex = path.join(sessionsPath, `${baseName}.index.json`);
      const dstJsonl = path.join(sessionsPath, `${name}.jsonl`);
      const dstIndex = path.join(sessionsPath, `${name}.index.json`);
      if (fs.existsSync(srcJsonl)) fs.copyFileSync(srcJsonl, dstJsonl);
      if (fs.existsSync(srcIndex)) fs.copyFileSync(srcIndex, dstIndex);
      log(`Session saved as '${name}'`);
    } catch (err: any) {
      log(`Error saving session: ${err.message}`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed.startsWith(":session fork ")) {
    const name = trimmed.slice(14).trim();
    if (!name) {
      log("Usage: :session fork <name>");
      return { replState, output: output.join("\n"), shouldExit };
    }
    fs.mkdirSync(sessionsPath, { recursive: true });
    const sourceName = replState.loadedSession
      ? (replState.sessionName || "current")
      : (replState.sessionWriter?.getSessionId() || replState.sessionName || "current");
    const sourceJsonl = path.join(sessionsPath, `${sourceName}.jsonl`);
    const sourceIndex = path.join(sessionsPath, `${sourceName}.index.json`);

    if (!fs.existsSync(sourceJsonl) || !fs.existsSync(sourceIndex)) {
      log(`Session '${sourceName}' not found`);
      return { replState, output: output.join("\n"), shouldExit };
    }

    try {
      const rawLines = fs.readFileSync(sourceJsonl, "utf8").split(/\r?\n/).filter(Boolean);
      const events = rawLines.map(line => JSON.parse(line));
      const maxSeq = events.reduce((max, e) => (typeof (e as any).seq === "number" ? Math.max(max, (e as any).seq) : max), -1);
      const cutoffSeq = replState.sessionSeq !== undefined ? Math.min(replState.sessionSeq, maxSeq) : maxSeq;
      const trimmedEvents = events.filter(e => !("seq" in e) || (e as any).seq <= cutoffSeq);

      if (trimmedEvents.length > 0 && (trimmedEvents[0] as any).type === "session") {
        trimmedEvents[0] = { ...(trimmedEvents[0] as any), id: name, created: new Date().toISOString() };
      } else {
        trimmedEvents.unshift({ type: "session", version: 1, id: name, created: new Date().toISOString() });
      }

      const forkJsonl = path.join(sessionsPath, `${name}.jsonl`);
      const checkpointOffsets = new Map<number, number>();
      let offset = 0;
      const lines: string[] = [];
      for (const event of trimmedEvents) {
        const line = `${JSON.stringify(event)}\n`;
        if ((event as any).type === "checkpoint" && typeof (event as any).seq === "number") {
          checkpointOffsets.set((event as any).seq, offset);
        }
        lines.push(line);
        offset += Buffer.byteLength(line, "utf8");
      }
      fs.writeFileSync(forkJsonl, lines.join(""));

      const indexData = JSON.parse(fs.readFileSync(sourceIndex, "utf8"));
      const checkpoints = (indexData.checkpoints ?? [])
        .filter((cp: any) => cp.seq <= cutoffSeq)
        .map((cp: any) => ({
          ...cp,
          byteOffset: checkpointOffsets.get(cp.seq) ?? cp.byteOffset,
        }));
      const stateIds = new Set(checkpoints.map((cp: any) => cp.stateId));
      const states: Record<string, any> = {};
      for (const id of stateIds) {
        if (indexData.states?.[id] !== undefined) {
          states[id] = indexData.states[id];
        }
      }
      const receiptKeys = new Set(trimmedEvents.filter(e => (e as any).type === "llm_resp").map(e => (e as any).receiptKey));
      const receipts: Record<string, any> = {};
      for (const key of receiptKeys) {
        if (indexData.receipts?.[key] !== undefined) {
          receipts[key] = indexData.receipts[key];
        }
      }

      const forkIndex: SessionIndex = {
        sessionId: name,
        eventCount: cutoffSeq >= 0 ? cutoffSeq + 1 : 0,
        checkpoints,
        states,
        receipts,
      };

      const forkIndexPath = path.join(sessionsPath, `${name}.index.json`);
      fs.writeFileSync(forkIndexPath, JSON.stringify(forkIndex, null, 2));

      const forkReader = new SessionReader(forkJsonl, forkIndexPath, replState.nativeRegistry, replState.solverRegistry);
      await forkReader.loadAll();

      replState.loadedSession = forkReader;
      replState.jumpController = new JumpController(forkReader);

      replState.sessionWriter?.close();
      replState.sessionWriter = new SessionWriter(replState.sessionDir, name, { append: true, index: forkIndex });
      replState.sessionName = name;
      replState.sessionSeq = cutoffSeq >= 0 ? cutoffSeq : undefined;

      log(`Session forked as '${name}'`);
    } catch (err: any) {
      log(`Error forking session: ${err.message}`);
    }

    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed.startsWith(":session load ")) {
    const name = trimmed.slice(14).trim();
    if (!name) {
      log("Usage: :session load <name>");
      return { replState, output: output.join("\n"), shouldExit };
    }
    const eventFile = path.join(sessionsPath, `${name}.jsonl`);
    const indexFile = path.join(sessionsPath, `${name}.index.json`);
    if (!fs.existsSync(eventFile) || !fs.existsSync(indexFile)) {
      log(`Session '${name}' not found`);
      return { replState, output: output.join("\n"), shouldExit };
    }
    try {
      const reader = new SessionReader(eventFile, indexFile, replState.nativeRegistry, replState.solverRegistry);
      await reader.loadAll();
      replState.loadedSession = reader;
      replState.jumpController = new JumpController(reader);
      replState.sessionName = name;
      replState.defs = reader.getAllEvents()
        .filter(e => (e as any).type === "input" && (e as any).code?.trim?.().startsWith("(define"))
        .map(e => (e as any).code as string);
      log(`Loaded session '${name}' (${reader.getEventCount()} events)`);
      log("Use :session goto <seq> to jump, :session trace to view");
    } catch (err: any) {
      log(`Error loading session: ${err.message}`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed.startsWith(":session goto ")) {
    const seq = parseInt(trimmed.slice(14).trim(), 10);
    if (!replState.loadedSession || !replState.jumpController) {
      log("No session loaded. Use :session load <name> first.");
      return { replState, output: output.join("\n"), shouldExit };
    }
    if (isNaN(seq)) {
      log("Usage: :session goto <seq>");
      return { replState, output: output.join("\n"), shouldExit };
    }
    try {
      const result = await replState.jumpController.jumpTo(seq);
      replState.sessionState = result.state;
      replState.baseState = result.state;
      replState.lastState = result.state;
      replState.sessionSeq = result.seq;
      replState.debugMode = true;
      if (replState.loadedSession) {
        replState.defs = replState.loadedSession.getAllEvents()
          .filter(e => (e as any).type === "input" && typeof (e as any).seq === "number" && (e as any).seq <= seq && (e as any).code?.trim?.().startsWith("(define"))
          .map(e => (e as any).code as string);
      }
      log(`Jumped to seq ${result.seq}`);
      log(`  Replayed ${result.replayedSteps} steps`);
      log(`  Used ${result.usedReceipts.length} cached LLM receipts`);
      log(`  Control: ${controlToString(result.state.control)}`);
    } catch (err: any) {
      log(err.message);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":session checkpoints") {
    if (!replState.loadedSession) {
      log("No session loaded.");
    } else {
      const cps = replState.loadedSession.getCheckpoints();
      log(`Checkpoints (${cps.length}):`);
      for (const cp of cps) {
        log(`  [${String(cp.seq).padStart(3, "0")}] ${cp.reason} (state: ${cp.stateId})`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":session trace" || trimmed.startsWith(":session trace ")) {
    if (!replState.loadedSession) {
      log("No session loaded. Use :session load <name> first.");
    } else {
      const events = replState.loadedSession.getAllEvents();
      const verbose = trimmed.includes("--verbose") || trimmed.includes("-v");
      const traceOutput = renderTrace(events, verbose ? { showTime: true } : undefined);
      log(traceOutput);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":session resume") {
    if (!replState.loadedSession || replState.sessionState === undefined) {
      log("No state to resume from. Use :session goto <seq> first.");
      return { replState, output: output.join("\n"), shouldExit };
    }
    const currentSeq = replState.sessionSeq ?? 0;
    const cps = replState.loadedSession.getCheckpoints();
    const next = cps.find(cp => cp.seq > currentSeq);
    if (!next) {
      log("No later checkpoint to resume to.");
      return { replState, output: output.join("\n"), shouldExit };
    }
    const state = replState.loadedSession.getCheckpointState(next.stateId);
    replState.sessionState = state;
    replState.baseState = state;
    replState.lastState = state;
    replState.sessionSeq = next.seq;
    const events = replState.loadedSession.getEventsInRange(currentSeq + 1, next.seq);
    const usedReceipts = events.filter(e => (e as any).type === "llm_resp").map(e => (e as any).receiptKey);
    if (usedReceipts.length > 0) {
      log(`Used ${usedReceipts.length} cached receipts`);
    }
    log(`Resumed to seq ${next.seq}`);
    return { replState, output: output.join("\n"), shouldExit };
  }

  // Commands
  if (trimmed === ":quit" || trimmed === ":q") {
    log("Goodbye!");
    shouldExit = true;
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":help" || trimmed === ":h") {
    log("Commands:");
    log("  :help, :h      — show this help");
    log("");
    log("  EVALUATION:");
    log("  (expr)         — evaluate expression immediately");
    log("  :loadfile <path> — load and evaluate code from file");
    log("");
    log("  SESSION:");
    log("  :session list            - list saved sessions");
    log("  :session save <name>     - save current session");
    log("  :session fork <name>     - fork session from current point");
    log("  :session load <name>     - load a saved session");
    log("  :session goto <seq>      - jump to a checkpoint or event");
    log("  :session trace           - render session trace");
    log("  :session checkpoints     - list checkpoints");
    log("  :session resume          - resume to next checkpoint");
    log("");
    log("  DEBUGGING:");
    log("  :debug (expr)  — load expression into debugger (step mode)");
    log("  :step [N]      — execute N steps (default 1)");
    log("  :run           — run until breakpoint or completion");
    log("  :stop          — stop execution");
    log("  :goto <N>      — jump to step N in recorded trace");
    log("  :trace [s] [n] — show trace (start at s, show n steps)");
    log("  :state         — show current debug state");
    log("");
    log("  BREAKPOINTS:");
    log("  :break step <N>    — break at step N");
    log("  :break expr <tag>  — break on expression type");
    log("  :break effect <op> — break on effect operation");
    log("  :breaks            — list all breakpoints");
    log("  :delbreak <id>     — delete breakpoint");
    log("  :toggle <id>       — toggle breakpoint on/off");
    log("");
    log("  SNAPSHOTS:");
    log("  :save <name>       — save current state as snapshot");
    log("  :restore <name>    — restore snapshot");
    log("  :snapshots         — list all snapshots");
    log("  :export <name> <file> — export snapshot to file");
    log("");
    log("  HISTORY & TIME TRAVEL:");
    log("  :back [N]          — go back N steps in history");
    log("  :history [N]       — show last N history entries");
    log("  :record on|off     — toggle trace recording");
    log("  :dump <file>       — save trace to file");
    log("  :replay <file>     — load and replay dump");
    log("");
    log("  INSPECTION:");
    log("  :env           — show current environment bindings");
    log("  :env <name>    — lookup specific binding");
    log("  :defs          — show defined functions");
    log("  :stack         — show call stack");
    log("  :frame <n>     — inspect frame N");
    log("  :control       — show current control (expr or value)");
    log("");
    log("  LLM (Agentic):");
    log("  :ask <question>    — ask LLM (uses tool calls to eval code iteratively)");
    log("  :traces            — list recent LLM interaction traces");
    log("  :trace <id>        — show trace summary");
    log("  :trace <id> -v     — show full trace (prompts, responses, tool calls)");
    log("");
    log("  OPR (Omega Protocol Runtime):");
    log("  :opr-list          — list available OPR kernels");
    log("  :opr-run <kernel> <json> — run kernel with program JSON");
    log("  :opr-receipts      — show OPR receipt chain for current session");
    log("  :opr-verify [file] — verify OPR receipt chain integrity");
    log("");
    log("  :quit, :q      — exit REPL");
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :debug - load expression into debugger
  if (trimmed.startsWith(":debug ")) {
    const expr = trimmed.slice(7).trim();
    if (!expr) {
      log("Usage: :debug (expression)");
    } else {
      replState = debugLoadExpr(expr, replState);
      log(`Debug session started. Use :step to begin stepping.`);
      printDebugState(replState);
      output.push(...getConsoleOutput(() => printDebugState(replState)));
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :step - step in debugger
  if (trimmed === ":step" || trimmed.startsWith(":step ")) {
    const parts = trimmed.split(/\s+/);
    const count = parseInt(parts[1]) || 1;

    for (let i = 0; i < count; i++) {
      const { result, replState: newState } = debugStep(replState);
      replState = newState;
      if (!result || result.tag === "Done" || result.tag === "Op") break;
    }

    if (replState.debugState) {
      output.push(...getConsoleOutput(() => printDebugState(replState)));
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :run - run to completion or breakpoint
  if (trimmed === ":run" || trimmed === ":continue" || trimmed === ":c") {
    replState = debugRun(replState);
    if (replState.debugState) {
      output.push(...getConsoleOutput(() => printDebugState(replState)));
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :goto - jump to step in trace
  if (trimmed.startsWith(":goto ") || trimmed.startsWith(":g ")) {
    const parts = trimmed.split(/\s+/);
    const step = parseInt(parts[1]);
    if (isNaN(step)) {
      log("Usage: :goto <step-number>");
    } else {
      replState = debugGoto(replState, step);
      if (replState.debugState) {
        output.push(...getConsoleOutput(() => printDebugState(replState)));
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :trace - show debug trace (no args or numeric args only)
  // Note: :trace <id> and :trace --last are handled later for LLM traces
  if (trimmed === ":trace") {
    output.push(...getConsoleOutput(() => printTrace(replState, 0, 20)));
    return { replState, output: output.join("\n"), shouldExit };
  }
  if (trimmed.startsWith(":trace ")) {
    const parts = trimmed.split(/\s+/);
    // Only handle if first arg is a number (debug trace pagination)
    const firstArg = parts[1];
    if (firstArg && /^\d+$/.test(firstArg)) {
      const start = parseInt(parts[1]) || 0;
      const count = parseInt(parts[2]) || 20;
      output.push(...getConsoleOutput(() => printTrace(replState, start, count)));
      return { replState, output: output.join("\n"), shouldExit };
    }
    // Otherwise fall through to LLM trace handler below
  }

  // :state - show debug state
  if (trimmed === ":state" || trimmed === ":st") {
    output.push(...getConsoleOutput(() => printDebugState(replState)));
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :break - add breakpoint
  if (trimmed.startsWith(":break ") || trimmed.startsWith(":b ")) {
    const parts = trimmed.split(/\s+/);
    const type = parts[1] as Breakpoint["type"];
    const condition = parts[2];

    if (!type || !condition) {
      log("Usage: :break step <N> | :break expr <tag> | :break effect <op>");
    } else if (!["step", "expr", "effect"].includes(type)) {
      log("Invalid breakpoint type. Use: step, expr, or effect");
    } else {
      const bp: Breakpoint = {
        id: replState.nextBreakpointId++,
        type,
        condition: type === "step" ? parseInt(condition) : condition,
        enabled: true,
      };
      replState.breakpoints.push(bp);
      log(`Breakpoint ${bp.id} added: ${type} = ${bp.condition}`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :breaks - list breakpoints
  if (trimmed === ":breaks" || trimmed === ":breakpoints") {
    if (replState.breakpoints.length === 0) {
      log("No breakpoints set.");
    } else {
      log("Breakpoints:");
      for (const bp of replState.breakpoints) {
        log(`  ${bp.id}: ${bp.type} = ${bp.condition} [${bp.enabled ? "enabled" : "disabled"}]`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :delbreak - delete breakpoint
  if (trimmed.startsWith(":delbreak ") || trimmed.startsWith(":del ")) {
    const parts = trimmed.split(/\s+/);
    const id = parseInt(parts[1]);
    if (isNaN(id)) {
      log("Usage: :delbreak <id>");
    } else {
      const idx = replState.breakpoints.findIndex(bp => bp.id === id);
      if (idx < 0) {
        log(`Breakpoint ${id} not found.`);
      } else {
        replState.breakpoints.splice(idx, 1);
        log(`Breakpoint ${id} deleted.`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :toggle - toggle breakpoint
  if (trimmed.startsWith(":toggle ")) {
    const parts = trimmed.split(/\s+/);
    const id = parseInt(parts[1]);
    if (isNaN(id)) {
      log("Usage: :toggle <id>");
    } else {
      const bp = replState.breakpoints.find(b => b.id === id);
      if (!bp) {
        log(`Breakpoint ${id} not found.`);
      } else {
        bp.enabled = !bp.enabled;
        log(`Breakpoint ${id} ${bp.enabled ? "enabled" : "disabled"}.`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :save - save snapshot
  if (trimmed.startsWith(":save ")) {
    const name = trimmed.slice(6).trim();
    if (!name) {
      log("Usage: :save <name>");
    } else if (!replState.debugState) {
      log("(no debug session - use :debug (expr) first)");
    } else {
      const snapshot: Snapshot = {
        name,
        step: replState.stepCount,
        state: cloneState(replState.debugState),
        timestamp: new Date(),
      };
      replState.snapshots.set(name, snapshot);
      log(`Saved snapshot '${name}' at step ${replState.stepCount}`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :restore - restore snapshot
  if (trimmed.startsWith(":restore ")) {
    const name = trimmed.slice(9).trim();
    if (!name) {
      log("Usage: :restore <name>");
    } else {
      const snapshot = replState.snapshots.get(name);
      if (!snapshot) {
        log(`Snapshot '${name}' not found.`);
      } else {
        replState.debugState = cloneState(snapshot.state);
        replState.stepCount = snapshot.step;
        replState.debugMode = true;
        log(`Loaded snapshot '${name}' (step ${replState.stepCount})`);
        output.push(...getConsoleOutput(() => printDebugState(replState)));
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :snapshots - list snapshots
  if (trimmed === ":snapshots" || trimmed === ":snaps") {
    if (replState.snapshots.size === 0) {
      log("No snapshots saved.");
    } else {
      log("\nSnapshots:");
      for (const [name, snap] of replState.snapshots) {
        log(`  ${name}: step ${snap.step} (${snap.timestamp.toISOString()})`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :export - export snapshot to file
  if (trimmed.startsWith(":export ")) {
    const parts = trimmed.slice(8).trim().split(/\s+/);
    const name = parts[0];
    const filepath = parts.slice(1).join(" ");
    if (!name || !filepath) {
      log("Usage: :export <snapshot-name> <filepath>");
    } else {
      const snapshot = replState.snapshots.get(name);
      if (!snapshot) {
        log(`Snapshot '${name}' not found.`);
      } else {
        const data = JSON.stringify({
          name: snapshot.name,
          step: snapshot.step,
          timestamp: snapshot.timestamp.toISOString(),
          controlTag: snapshot.state.control.tag,
          stackDepth: snapshot.state.kont.length,
        }, null, 2);
        try {
          fs.writeFileSync(filepath, data);
          log(`Exported snapshot metadata to ${filepath}`);
        } catch (err: any) {
          log(`Error exporting: ${err.message}`);
        }
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :back - go back in history
  if (trimmed === ":back" || trimmed.startsWith(":back ")) {
    const parts = trimmed.split(/\s+/);
    const steps = parseInt(parts[1]) || 1;
    if (replState.history.length === 0) {
      log("No history available.");
    } else {
      const targetIdx = Math.max(0, replState.history.length - steps);
      const entry = replState.history[targetIdx];
      replState.debugState = cloneState(entry.state);
      replState.stepCount = entry.step;
      replState.debugMode = true;
      replState.history = replState.history.slice(0, targetIdx);
      log(`Rewound to step ${replState.stepCount}`);
      output.push(...getConsoleOutput(() => printDebugState(replState)));
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :history - show history
  if (trimmed === ":history" || trimmed === ":hist" || trimmed.startsWith(":history ") || trimmed.startsWith(":hist ")) {
    const parts = trimmed.split(/\s+/);
    const count = parseInt(parts[1]) || 10;
    if (replState.history.length === 0) {
      log("No history available.");
    } else {
      log(`\nHistory (last ${Math.min(count, replState.history.length)} steps):`);
      const start = Math.max(0, replState.history.length - count);
      for (let i = start; i < replState.history.length; i++) {
        const h = replState.history[i];
        log(`  [${h.step}] ${h.control}`);
      }
      log(`  [${replState.stepCount}] <current>`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :record - toggle recording
  if (trimmed.startsWith(":record ")) {
    const parts = trimmed.split(/\s+/);
    const mode = parts[1];
    if (mode === "on") {
      replState.recordingEnabled = true;
      log("Recording: ON");
    } else if (mode === "off") {
      replState.recordingEnabled = false;
      log("Recording: OFF");
      log("Warning: Without recording, 'goto' and 'dump' won't have new steps.");
    } else {
      log("Usage: :record on|off");
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :dump - save trace to file
  if (trimmed.startsWith(":dump ")) {
    const filepath = trimmed.slice(6).trim();
    if (!filepath) {
      log("Usage: :dump <filepath>");
    } else if (replState.trace.length === 0) {
      log("No trace to dump.");
    } else {
      const dumpData = {
        version: 1,
        code: replState.debugCode || "",
        timestamp: new Date().toISOString(),
        totalSteps: replState.trace.length,
        traceSummary: replState.trace.map(t => ({
          step: t.step,
          control: t.controlSummary,
          stackDepth: t.stackDepth,
        })),
      };
      try {
        fs.writeFileSync(filepath, JSON.stringify(dumpData, null, 2));
        log(`Dumped trace summary to ${filepath} (${replState.trace.length} steps)`);
        log("To replay: load the code and step through, or use ':replay <file>'");
      } catch (err: any) {
        log(`Error dumping: ${err.message}`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :replay - load and replay dump
  if (trimmed.startsWith(":replay ")) {
    const filepath = path.resolve(trimmed.slice(8).trim());
    if (!filepath) {
      log("Usage: :replay <filepath>");
    } else if (!fs.existsSync(filepath)) {
      log(`File not found: ${filepath}`);
    } else {
      try {
        const content = fs.readFileSync(filepath, "utf8");
        const data = JSON.parse(content);
        if (!data.code) {
          log("Dump file missing 'code' field - cannot replay.");
        } else {
          log(`Loading dump from: ${filepath}`);
          log(`Original timestamp: ${data.timestamp}`);
          log(`Total steps: ${data.totalSteps}`);
          log("\nReplaying execution...");

          // Load and run to completion
          replState = debugLoadExpr(data.code, replState);
          let count = 0;
          while (replState.debugState && count < (data.totalSteps || 100000)) {
            const { replState: newState } = debugStep(replState);
            replState = newState;
            count++;
            if (!replState.debugState) break;
          }

          log(`\nReplay complete. ${replState.trace.length} steps recorded.`);
          log("Use ':goto <step>' to jump to any step, or ':trace' to see the trace.");
        }
      } catch (err: any) {
        log(`Error loading dump: ${err.message}`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :loadfile - load code from file
  if (trimmed.startsWith(":loadfile ")) {
    const filepath = path.resolve(trimmed.slice(10).trim());
    if (!filepath) {
      log("Usage: :loadfile <path>");
    } else if (!fs.existsSync(filepath)) {
      log(`File not found: ${filepath}`);
    } else {
      try {
        const code = fs.readFileSync(filepath, "utf8");
        log(`Loaded from: ${filepath}`);

        // Evaluate the file content
        const { value, replState: newState } = await evalInRepl(code, replState);
        replState = newState;
        log("=>", valToSexp(value));
      } catch (err: any) {
        log("error:", err.message);
        replState.lastError = err;
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :stop - stop execution
  if (trimmed === ":stop") {
    replState.running = false;
    log("Stopped.");
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :env - show environment or lookup specific binding
  if (trimmed === ":env" || trimmed.startsWith(":env ")) {
    const bindingName = trimmed.slice(4).trim();
    const activeState = getActiveState();

    if (bindingName) {
      if (activeState) {
        // Search through the context chain
        let ctx: any = activeState.env;
        let addr: number | undefined;
        while (ctx) {
          if (ctx.frame && ctx.frame instanceof Map && ctx.frame.has(bindingName)) {
            addr = ctx.frame.get(bindingName);
            break;
          }
          ctx = ctx.parent;
        }
        if (addr !== undefined) {
          const val = activeState.store.read(addr);
          log(`${bindingName} = ${valToSexp(val)}`);
        } else {
          log(`(binding '${bindingName}' not found)`);
        }
      } else {
        log("(no state available - evaluate an expression first)");
      }
    } else {
      log("(Current environment has primitives: +, -, *, /, =, <, >, etc.)");
      if (replState.defs.length > 0) {
        log("User-defined:");
        for (const d of replState.defs) {
          log("  " + d.slice(0, 60) + (d.length > 60 ? "..." : ""));
        }
      }
      if (activeState) {
        const bindings = envToBindings(activeState.env);
        log(`(${bindings.length} total bindings)`);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :defs
  if (trimmed === ":defs") {
    if (replState.defs.length === 0) {
      log("(no user definitions yet)");
    } else {
      for (const d of replState.defs) log(d);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :stack
  if (trimmed === ":stack") {
    const activeState = getActiveState();
    if (!activeState) {
      log("(no state available - evaluate an expression first)");
    } else {
      const kont = activeState.kont;
      if (kont.length === 0) {
        log("(empty stack)");
      } else {
        log(`Stack depth: ${kont.length}`);
        for (let i = kont.length - 1; i >= 0; i--) {
          log(frameToString(kont[i], i));
        }
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :frame
  if (trimmed.startsWith(":frame ")) {
    const nStr = trimmed.slice(7).trim();
    const n = parseInt(nStr, 10);
    const activeState = getActiveState();

    if (isNaN(n)) {
      log("Usage: :frame <number>");
    } else if (!activeState) {
      log("(no state available)");
    } else {
      const kont = activeState.kont;
      if (n < 0 || n >= kont.length) {
        log(`(frame ${n} out of range, stack has ${kont.length} frames)`);
      } else {
        const frame = kont[n];
        log(frameToString(frame, n));
        log(`  tag: ${frame.tag}`);
        if ("env" in frame && frame.env) {
          const bindings = envToBindings(frame.env as Env);
          log(`  env: ${bindings.length} bindings`);
          if (bindings.length <= 10) {
            for (const b of bindings) {
              log(`    ${b.name} -> @${b.addr}`);
            }
          }
        }
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :control
  if (trimmed === ":control") {
    const activeState = getActiveState();
    if (!activeState) {
      log("(no state available)");
    } else {
      log(controlToString(activeState.control));
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :ask - Agentic LLM with tool calls
  if (trimmed.startsWith(":ask ")) {
    const request = trimmed.slice(5).trim();
    const adapter = createLLMAdapter();
    if (!adapter) {
      log("error: No API key. Set OPENAI_API_KEY, ANTHROPIC_API_KEY, or add to config.yaml");
    } else {
      log("; --- agentic session begins ---");
      log(`; using: ${adapter.name} (tools: ${adapter.supportsToolCalls ? "native" : "text-based"})`);
      log(`; question: "${request}"`);

      try {
        const { answer, traceId, replState: newState } = await runAgenticQuery(request, replState, adapter);
        replState = newState;

        log("");
        log(`Answer: ${answer}`);
        log("");
        log(`Trace ID: ${traceId}`);
        log(`(use ':trace ${traceId}' to see details, ':trace ${traceId} --verbose' for full trace)`);
        log("; --- agentic session ends ---");
      } catch (err: any) {
        log("LLM error:", err.message);
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :traces - List recent LLM traces
  if (trimmed === ":traces") {
    if (llmTraces.size === 0) {
      log("(no traces recorded yet)");
    } else {
      log("Recent LLM Traces:");
      llmTraces.forEach((trace, id) => {
        const duration = trace.endTime ? trace.endTime - trace.startTime : "?";
        log(`  ${id}: "${trace.question.slice(0, 40)}${trace.question.length > 40 ? "..." : ""}" (${duration}ms, ${trace.toolCallCount} tool calls)`);
      });
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // :trace <id> [--verbose] or :trace --last [-v] - Show specific trace
  if (trimmed.startsWith(":trace ")) {
    const parts = trimmed.slice(7).trim().split(/\s+/);
    const verbose = parts.includes("--verbose") || parts.includes("-v");
    const isLast = parts.includes("--last") || parts.includes("-l");

    let trace: LLMTrace | undefined;
    if (isLast) {
      // Get the most recent trace
      let lastTrace: LLMTrace | undefined;
      llmTraces.forEach(t => { lastTrace = t; });
      trace = lastTrace;
      if (!trace) {
        log("No traces recorded yet.");
        return { replState, output: output.join("\n"), shouldExit };
      }
    } else {
      // Find the trace ID (first part that's not a flag)
      const traceId = parts.find(p => !p.startsWith("-"));
      if (!traceId) {
        log("Usage: :trace <id> [--verbose] or :trace --last [--verbose]");
        return { replState, output: output.join("\n"), shouldExit };
      }
      trace = llmTraces.get(traceId);
      if (!trace) {
        log(`Trace '${traceId}' not found. Use :traces to list available traces.`);
        return { replState, output: output.join("\n"), shouldExit };
      }
    }

    log(formatTrace(trace, verbose));
    return { replState, output: output.join("\n"), shouldExit };
  }

  // OPR Commands
  if (trimmed === ":opr-list") {
    log("\nAvailable OPR Kernels:");
    log("======================");
    for (const id of listKernels()) {
      const kernel = getKernel(id);
      if (kernel) {
        log(`  ${id} (op: ${kernel.op})`);
      }
    }
    log("\nUse :opr-run <kernel-id> <program-json> to execute a kernel.");
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed.startsWith(":opr-run ")) {
    const args = trimmed.slice(9).trim();
    const spaceIdx = args.indexOf(" ");
    if (spaceIdx === -1) {
      log("Usage: :opr-run <kernel-id> <program-json>");
      log("Example: :opr-run opr.classify.v1 {\"item\":\"error at line 42\",\"categories\":[\"bug\",\"feature\"]}");
      return { replState, output: output.join("\n"), shouldExit };
    }

    const kernelId = args.slice(0, spaceIdx);
    const programJson = args.slice(spaceIdx + 1).trim();

    const kernel = getKernel(kernelId);
    if (!kernel) {
      log(`Unknown kernel: ${kernelId}`);
      log("Use :opr-list to see available kernels.");
      return { replState, output: output.join("\n"), shouldExit };
    }

    let program: unknown;
    try {
      program = JSON.parse(programJson);
    } catch (e: any) {
      log(`Invalid JSON: ${e.message}`);
      return { replState, output: output.join("\n"), shouldExit };
    }

    // Get API key
    const openaiKey = process.env.OPENAI_API_KEY;
    const anthropicKey = process.env.ANTHROPIC_API_KEY;

    if (!openaiKey && !anthropicKey) {
      log("No API key found. Set OPENAI_API_KEY or ANTHROPIC_API_KEY.");
      return { replState, output: output.join("\n"), shouldExit };
    }

    // Create adapter
    const adapter = openaiKey
      ? new OpenAIOprAdapter({ apiKey: openaiKey, model: "gpt-4o-mini" })
      : new AnthropicOprAdapter({ apiKey: anthropicKey!, model: "claude-sonnet-4-20250514" });

    const receipts = new OprReceiptStore();
    const runtime = new OprRuntime({
      kernel,
      adapter,
      receipts,
      budget: { maxAttempts: 3 },
    });

    log(`\nRunning kernel: ${kernelId}`);
    log(`Program: ${JSON.stringify(program, null, 2)}`);
    log("\nCalling LLM...\n");

    try {
      const result = await runtime.step({ program, state: null });

      if (result.tag === "ok") {
        log("SUCCESS!");
        log(`\nResult: ${JSON.stringify(result.output.result, null, 2)}`);
        if (result.output.next_state) {
          log(`\nNext State: ${JSON.stringify(result.output.next_state, null, 2)}`);
        }
        if (result.output.effects && result.output.effects.length > 0) {
          log(`\nEffects: ${JSON.stringify(result.output.effects, null, 2)}`);
        }
        log(`\nAttempts: ${result.attempts}`);
      } else {
        log(`FAILED: ${result.tag}`);
        if ("error" in result) {
          log(`Error: ${(result.error as Error).message}`);
        }
      }

      // Store receipts in session
      (replState as any).oprReceipts = [
        ...((replState as any).oprReceipts || []),
        ...result.receipts,
      ];
      log(`\nReceipts: ${result.receipts.length} generated (use :opr-receipts to view)`);
    } catch (e: any) {
      log(`Error running kernel: ${e.message}`);
    }

    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":opr-receipts") {
    const oprReceipts = (replState as any).oprReceipts;
    if (!oprReceipts || oprReceipts.length === 0) {
      log("No OPR receipts in current session.");
    } else {
      log("\nOPR Receipt Chain:");
      log("==================");
      for (let i = 0; i < oprReceipts.length; i++) {
        const r = oprReceipts[i];
        const statusIcon = r.status === 'OK' ? '[OK]' : '[X]';
        log(`${i + 1}. ${statusIcon} ${r.status} - ${r.kernel_id}:${r.op}`);
        log(`     Attempt: ${r.attempt}  Created: ${r.created_at}`);
        if (r.errors && r.errors.length > 0) {
          log(`     Errors: ${r.errors[0]}`);
        }
      }
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  if (trimmed === ":opr-verify" || trimmed.startsWith(":opr-verify ")) {
    const arg = trimmed.slice(12).trim();
    let receipts: any[];

    if (arg) {
      // Load from file
      try {
        const content = fs.readFileSync(arg, 'utf-8');
        receipts = JSON.parse(content);
      } catch (e: any) {
        log(`Error loading receipt file: ${e.message}`);
        return { replState, output: output.join("\n"), shouldExit };
      }
    } else {
      receipts = (replState as any).oprReceipts || [];
      if (receipts.length === 0) {
        log("No OPR receipts in session. Provide a file path to verify.");
        return { replState, output: output.join("\n"), shouldExit };
      }
    }

    // Simple chain verification
    let valid = true;
    let brokenAt = -1;
    let error = "";

    if (receipts.length > 0 && receipts[0].prev_receipt_hash !== null) {
      valid = false;
      brokenAt = 0;
      error = "First receipt should have null prev_receipt_hash";
    } else {
      for (let i = 1; i < receipts.length; i++) {
        if (receipts[i].prev_receipt_hash !== receipts[i - 1].receipt_hash) {
          valid = false;
          brokenAt = i;
          error = "Chain link broken";
          break;
        }
      }
    }

    if (valid) {
      log(`\nReceipt chain is VALID`);
      log(`  ${receipts.length} receipts verified`);
      if (receipts.length > 0) {
        log(`  Chain hash: ${receipts[receipts.length - 1].receipt_hash}`);
      }
    } else {
      log(`\nReceipt chain is BROKEN`);
      log(`  Broken at index: ${brokenAt}`);
      log(`  Error: ${error}`);
    }
    return { replState, output: output.join("\n"), shouldExit };
  }

  // Skip other commands starting with :
  if (trimmed.startsWith(":")) {
    log(`Unknown command: ${trimmed}. Type :help for commands.`);
    return { replState, output: output.join("\n"), shouldExit };
  }

  // Empty line
  if (trimmed === "") {
    return { replState, output: "", shouldExit };
  }

  // Otherwise, evaluate as Lisp expression
  replState.sessionWriter?.input(trimmed);
  const isEffectCall = /^\(effect\b/.test(trimmed);
  const useMockEffects = process.env.OMEGA_MOCK_EFFECTS === "1";

  try {
    // Use mock effects only if explicitly enabled (for testing)
    if (isEffectCall && useMockEffects) {
      const { value, state } = handleEffectExpression(trimmed, replState);
      log("=>", valToSexp(value));
      replState.sessionWriter?.result(valToSexp(value));
      replState.sessionWriter?.checkpoint(state, "manual");
    } else {
      replState.sessionWriter?.step(trimmed);
      const { value, replState: newState, state } = await evalInRepl(trimmed, replState);
      replState = newState;
      replState.sessionState = state;
      replState.baseState = state;
      log("=>", valToSexp(value));
      replState.sessionWriter?.result(valToSexp(value));
      replState.sessionWriter?.checkpoint(state, "manual");
    }
  } catch (err: any) {
    log("error:", err.message);
    replState.lastError = err;
    replState.sessionWriter?.error(err.message, err.stack);
  }

  return { replState, output: output.join("\n"), shouldExit };
}

// Helper to capture console output from functions that use console.log
function getConsoleOutput(fn: () => void): string[] {
  const output: string[] = [];
  const originalLog = console.log;
  console.log = (...msgs: any[]) => output.push(msgs.join(" "));
  try {
    fn();
  } finally {
    console.log = originalLog;
  }
  return output;
}

type ReplArgs = ReturnType<typeof parseArgs>;

type BatchMetadata = {
  command?: string;
  file?: string;
};

async function runBatch(
  args: Pick<ReplArgs, "cmd" | "file">,
  replState: ReplState
): Promise<{ replState: ReplState; output: string; metadata: BatchMetadata }> {
  if (args.cmd) {
    const { replState: newState, output } = await processReplCommand(args.cmd.trim(), replState);
    return { replState: newState, output, metadata: { command: args.cmd } };
  }

  if (args.file) {
    const filePath = path.resolve(args.file);
    if (!fs.existsSync(filePath)) {
      console.error(`File not found: ${filePath}`);
      process.exit(1);
    }

    // Read file and extract complete S-expressions (handles multi-line)
    const fileContent = fs.readFileSync(filePath, "utf8");

    // Strip comment lines before parsing
    const cleanedContent = fileContent
      .split("\n")
      .filter(line => !line.trim().startsWith(";"))
      .join("\n");

    // Extract balanced S-expressions
    const sexprs = extractSexpressions(cleanedContent);
    const outputs: string[] = [];

    for (const sexpr of sexprs) {
      const trimmed = sexpr.trim();
      if (!trimmed) continue;

      const { replState: newState, output, shouldExit } = await processReplCommand(trimmed, replState);
      replState = newState;
      if (output) outputs.push(output);
      if (shouldExit) break;
    }

    return { replState, output: outputs.join("\n"), metadata: { file: args.file } };
  }

  return { replState, output: "", metadata: {} };
}

function emitBatchOutput(
  args: Pick<ReplArgs, "session" | "json">,
  replState: ReplState,
  output: string,
  metadata: BatchMetadata
): void {
  if (args.json) {
    const result = {
      session: args.session,
      command: metadata.command,
      file: metadata.file,
      debugMode: replState.debugMode,
      stepCount: replState.stepCount,
      defsCount: replState.defs.length,
      output,
    };
    console.log(JSON.stringify(result, null, 2));
    return;
  }

  if (output) {
    console.log(output);
  }
}

// ─────────────────────────────────────────────────────────────────
// Main REPL loop
// ─────────────────────────────────────────────────────────────────
async function main() {
  const args = parseArgs();

  if (args.cmd || args.file) {
    const replState = args.session
      ? await loadSession(args.session) || await initReplState()
      : await initReplState();
    const { replState: newState, output, metadata } = await runBatch(args, replState);

    if (args.session) {
      saveSession(newState, args.session);
    }

    emitBatchOutput(args, newState, output, metadata);
    return;
  }

  // ─────────────────────────────────────────────────────────────────
  // Session mode: run command(s) against a named session
  // ─────────────────────────────────────────────────────────────────
  if (args.session) {
    // Load existing session or create new one
    let replState = await loadSession(args.session) || await initReplState();

    // No command or file, just show session info
    console.log(`Session '${args.session}' loaded.`);
    console.log(`  Definitions: ${replState.defs.length}`);
    console.log(`  Debug mode: ${replState.debugMode}`);
    if (replState.debugMode) {
      console.log(`  Step count: ${replState.stepCount}`);
      console.log(`  Trace length: ${replState.trace.length}`);
    }
    console.log(`  Breakpoints: ${replState.breakpoints.length}`);
    return;
  }

  // ─────────────────────────────────────────────────────────────────
  // Interactive mode
  // ─────────────────────────────────────────────────────────────────
  const isTTY = process.stdin.isTTY;

  if (isTTY) {
    console.log("═".repeat(60));
    console.log("Ω REPL — Omega Lisp with Oracle Protocol & Debugger");
    console.log("═".repeat(60));
    console.log("Type Lisp expressions to evaluate.");
    console.log("Commands: :help :debug :step :run :goto :trace :break :quit");
    console.log("Session mode: npx tsx bin/omega-repl.ts -s <name> -c '<cmd>'");
    console.log("");
  if (VERBOSE) console.log("[verbose mode: oracle traces enabled]");
  console.log("");
}

let replState = await initReplState();
replState.sessionWriter = new SessionWriter(replState.sessionDir, replState.sessionName || "current");
process.on("exit", () => {
  try { replState.sessionWriter?.close(); } catch { /* ignore */ }
});

// For non-TTY (piped) input, process line by line
  if (!isTTY) {
    const rl = readline.createInterface({ input: process.stdin });
    let buffer = "";
    let depth = 0;

    try {
      for await (const line of rl) {
        const trimmed = line.trim();
        if (trimmed === ":quit" || trimmed === ":q") break;
        if (trimmed === "" || trimmed.startsWith(";")) continue; // skip empty and comments

        // Commands start with :
        if (trimmed.startsWith(":")) {
          const { replState: newState, output, shouldExit } = await processReplCommand(trimmed, replState);
          replState = newState;
          if (output) console.log(output);
          if (shouldExit) break;
          continue;
        }

        // Accumulate multi-line expressions
        buffer += (buffer ? "\n" : "") + line;
        for (const ch of line) {
          if (ch === "(") depth++;
          if (ch === ")") depth--;
        }

        // Balanced parens - evaluate
        if (depth <= 0) {
          const { replState: newState, output } = await processReplCommand(buffer, replState);
          replState = newState;
          if (output) console.log(output);
          buffer = "";
          depth = 0;
        }
      }
    } finally {
      rl.close();
      process.stdin.pause();
    }
    return;
  }

  // TTY interactive mode
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
    prompt: replState.debugMode ? "Ωdbg> " : "Ω> ",
  });

  rl.prompt();

  let multilineBuffer = "";
  let parenDepth = 0;

  rl.on("line", async (line) => {
    const trimmed = line.trim();

    // Commands start with :
    if (trimmed.startsWith(":")) {
      const { replState: newState, output, shouldExit } = await processReplCommand(trimmed, replState);
      replState = newState;
      if (output) console.log(output);
      if (shouldExit) {
        rl.close();
        process.exit(0);
      }
      // Update prompt based on debug mode
      rl.setPrompt(replState.debugMode ? "Ωdbg> " : "Ω> ");
      rl.prompt();
      return;
    }

    // Empty line
    if (trimmed === "") {
      rl.prompt();
      return;
    }

    // Accumulate multi-line input (track parenthesis depth)
    multilineBuffer += (multilineBuffer ? "\n" : "") + line;
    for (const ch of line) {
      if (ch === "(") parenDepth++;
      if (ch === ")") parenDepth--;
    }

    // If parens aren't balanced, wait for more input
    if (parenDepth > 0) {
      rl.setPrompt(".. ");
      rl.prompt();
      return;
    }

    // Parens balanced, evaluate
    const src = multilineBuffer;
    multilineBuffer = "";
    parenDepth = 0;

    const { replState: newState, output } = await processReplCommand(src, replState);
    replState = newState;
    if (output) console.log(output);

    rl.setPrompt(replState.debugMode ? "Ωdbg> " : "Ω> ");
    rl.prompt();
  });

  rl.on("close", () => {
    console.log("\nGoodbye!");
    process.exit(0);
  });
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});
